\documentclass[a4paper, 11pt]{article}

% --- íŒ¨í‚¤ì§€ ì„¤ì • ---
\usepackage{kotex} % í•œê¸€ ì§€ì›
\usepackage{geometry} % ì—¬ë°± ì„¤ì •
\geometry{left=25mm, right=25mm, top=25mm, bottom=25mm}
\usepackage{amsmath, amssymb, amsfonts} % ìˆ˜ì‹ íŒ¨í‚¤ì§€
\usepackage{graphicx}
\usepackage{adjustbox}  % í‘œ/ë°•ìŠ¤ í¬ê¸° ì¡°ì ˆ % ì´ë¯¸ì§€ ì‚½ì…
\usepackage{hyperref} % í•˜ì´í¼ë§í¬
\usepackage{xcolor} % ìƒ‰ìƒ ì§€ì›
\usepackage{listings} % ì½”ë“œ ë¸”ë¡
\usepackage[most]{tcolorbox}
\tcbuselibrary{breakable} % ë°•ìŠ¤ ë””ìì¸
\usepackage{enumitem} % ë¦¬ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼
\usepackage{booktabs} % í‘œ ë””ìì¸
\usepackage{array} % í‘œ ì •ë ¬

% --- ìƒ‰ìƒ ì •ì˜ ---
\definecolor{conceptblue}{RGB}{60, 100, 160}
\definecolor{analogygreen}{RGB}{80, 160, 100}
\definecolor{alertred}{RGB}{200, 60, 60}
\definecolor{exampleorange}{RGB}{230, 120, 30}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{backcolour}{rgb}{0.96,0.96,0.96}

% --- ì½”ë“œ ìŠ¤íƒ€ì¼ ì„¤ì • ---
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{analogygreen},
    keywordstyle=\color{conceptblue},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{exampleorange},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=4,
    frame=single
}
\lstset{style=mystyle}

% --- ë°•ìŠ¤ ìŠ¤íƒ€ì¼ ì •ì˜ ---
\newtcolorbox{summarybox}[1]{
    colback=conceptblue!5!white,
    colframe=conceptblue!80!black,
    fonttitle=\bfseries,
    title=ğŸ“Œ #1
}

\newtcolorbox{analogybox}[1]{
    colback=analogygreen!5!white,
    colframe=analogygreen!80!black,
    fonttitle=\bfseries,
    title=ğŸ’¡ #1 (ì§ê´€ì  ë¹„ìœ )
}

\newtcolorbox{warningbox}[1]{
    colback=alertred!5!white,
    colframe=alertred!80!black,
    fonttitle=\bfseries,
    title=âš ï¸ #1 (ì˜¤í•´ ë°©ì§€ ê°€ì´ë“œ)
}

\newtcolorbox{examplebox}[1]{
    colback=exampleorange!5!white,
    colframe=exampleorange!80!black,
    fonttitle=\bfseries,
    title=ğŸ§® #1 (ì‹¤ì „ ì‹œë‚˜ë¦¬ì˜¤ \& ê³„ì‚°)
}

% --- ë¬¸ì„œ ì •ë³´ ---
\title{\textbf{[CS230] Deep Neural Networks: \\ Dimensions \& Initialization}}
\author{Lecturer: Gemini (Integrated Editor)}
\date{}

\begin{document}

\maketitle

% --- 1. ì „ì²´ ëª©ì°¨ (TOC) ---
\section*{ğŸ“š Course Table of Contents}
\begin{itemize}
    \item[Chapter 1-3.] Foundations \& Shallow Networks \textit{- Completed}
    \item[Chapter 4.] Deep Neural Networks
    \begin{itemize}
        \item 4.1 Deep L-Layer Neural Network Architecture \textit{- Completed}
        \item \textbf{4.2 Dimensions \& Initialization (Current Unit)}
        \begin{itemize}
            \item The Law of Matrix Dimensions
            \item Symmetry Breaking (Why not Zero?)
            \item He Initialization (The Standard for ReLU)
            \item Implementation \& Verification
        \end{itemize}
        \item 4.3 Building a Deep Neural Network Application \textit{- Upcoming}
    \end{itemize}
\end{itemize}

\vspace{0.5cm}
\hrule
\vspace{0.5cm}

% --- 3. ì´ì „ ë‹¨ì› ì—°ê²° ---
\section*{ğŸ”— ì§€ë‚œ ì‹œê°„ ë³µìŠµ ë° ì—°ê²°}
ìš°ë¦¬ëŠ” ì´ì œ ê±°ëŒ€í•œ ì‹¬ì¸µ ì‹ ê²½ë§ì„ ì„¤ê³„í•  ìˆ˜ ìˆëŠ” ê±´ì¶•ê°€ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì„¤ê³„ë„ë§Œ ê·¸ë ¸ì„ ë¿, ì•„ì§ ì°©ê³µë„ í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.
ê±´ë¬¼ì„ ì˜¬ë¦¬ê¸° ì „ì— ê°€ì¥ ë¨¼ì € í•´ì•¼ í•  ì¼ì€ ë¬´ì—‡ì¼ê¹Œìš”? \textbf{ì„¤ê³„ë„ ê²€ì¦(ì°¨ì› í™•ì¸)}ê³¼ \textbf{ê¸°ì´ˆ ê³µì‚¬(ì´ˆê¸°í™”)}ì…ë‹ˆë‹¤. ì´ ë‘ ê°€ì§€ë¥¼ ì†Œí™€íˆ í•˜ë©´ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ìë§ˆì ì—ëŸ¬ê°€ í„°ì§€ê±°ë‚˜(Dimension Mismatch), ì—ëŸ¬ ë©”ì‹œì§€ í•˜ë‚˜ ì—†ì´ í•™ìŠµì´ ì „í˜€ ì•ˆ ë˜ëŠ”(Bad Initialization) ì¹¨ë¬µì˜ ë²„ê·¸ë¥¼ ë§Œë‚˜ê²Œ ë©ë‹ˆë‹¤.

% --- 4. ê°œìš” ---
\section{Unit Overview}
\begin{summarybox}{í•µì‹¬ ëª©í‘œ}
ì´ ë‹¨ì›ì€ ë””ë²„ê¹… ì‹œê°„ì„ íšê¸°ì ìœ¼ë¡œ ì¤„ì—¬ì£¼ëŠ” \textbf{'ì°¨ì› ë¶„ì„'}ê³¼ í•™ìŠµ ì„±ê³µì˜ ì—´ì‡ ì¸ \textbf{'íŒŒë¼ë¯¸í„° ì´ˆê¸°í™”'}ë¥¼ ë‹¤ë£¹ë‹ˆë‹¤.
\begin{itemize}
    \item \textbf{ë¶„ì„:} $L$ì¸µ ì‹ ê²½ë§ì˜ íŒŒë¼ë¯¸í„°($W, b$)ì™€ ë°ì´í„°($Z, A$)ì˜ í˜•ìƒ(Shape)ì„ ì •í™•íˆ ë„ì¶œí•©ë‹ˆë‹¤.
    \item \textbf{ì´ìœ :} ê°€ì¤‘ì¹˜ë¥¼ 0ìœ¼ë¡œ ì´ˆê¸°í™”í–ˆì„ ë•Œ ë°œìƒí•˜ëŠ” \textbf{'ëŒ€ì¹­ì„± ë¬¸ì œ(Symmetry Problem)'}ë¥¼ ì¦ëª…í•©ë‹ˆë‹¤.
    \item \textbf{í•´ê²°:} ReLUë¥¼ ìœ„í•œ í‘œì¤€ ì´ˆê¸°í™” ë°©ë²•ì¸ \textbf{He Initialization}ì˜ ì›ë¦¬ì™€ ì½”ë“œë¥¼ ìµí™ë‹ˆë‹¤.
\end{itemize}
\end{summarybox}

% --- 5. ìš©ì–´ ì •ë¦¬ ---
\section{Essential Terminology}
\begin{center}
\begin{tabular}{|c|l|l|}
\hline
\textbf{ìš©ì–´} & \textbf{ì„¤ëª…} & \textbf{í•µì‹¬ í¬ì¸íŠ¸} \\ \hline
\textbf{Shape} & í–‰ë ¬ì˜ ì°¨ì› (í–‰, ì—´) & ë””ë²„ê¹…ì˜ 90\%ëŠ” Shape ë§ì¶”ê¸°ì…ë‹ˆë‹¤. \\ \hline
\textbf{Symmetry Breaking} & ëŒ€ì¹­ì„± íŒŒê´´ & ë‰´ëŸ°ë“¤ì´ ì„œë¡œ ë‹¤ë¥´ê²Œ í•™ìŠµë˜ë„ë¡ ì´ˆê¸°ê°’ì„ ë‹¤ë¥´ê²Œ ì£¼ëŠ” ê²ƒ. \\ \hline
\textbf{Zero Init} & 0ìœ¼ë¡œ ì´ˆê¸°í™” & ëª¨ë“  ë‰´ëŸ°ì´ ë˜‘ê°™ì´ ë™ì‘í•˜ê²Œ ë§Œë“œëŠ” \textbf{ìµœì•…ì˜ ë°©ë²•}. \\ \hline
\textbf{He Init} & He ì´ˆê¸°í™” & ReLU ì‚¬ìš© ì‹œ ë¶„ì‚°ì„ ìœ ì§€í•´ì£¼ëŠ” \textbf{ìµœê³ ì˜ ë°©ë²•}. \\ \hline
\textbf{Xavier Init} & Xavier ì´ˆê¸°í™” & Sigmoid/Tanh ì‚¬ìš© ì‹œ ì í•©í•œ ì´ˆê¸°í™” ë°©ë²•. \\ \hline
\end{tabular}
\end{center}

% --- 6. í•µì‹¬ ê°œë… ìƒì„¸ ì„¤ëª… ---
\section{Core Concepts: ë””ë²„ê¹…ì„ ìœ„í•œ í—Œë²•}

\subsection{1. Matrix Dimensions Rules (ì°¨ì›ì˜ ë²•ì¹™)}
ì½”ë”©í•˜ë‹¤ í—·ê°ˆë¦´ ë•Œë§ˆë‹¤ ì´ í‘œë¥¼ ë³´ì‹­ì‹œì˜¤. $n^{[l]}$ì€ í˜„ì¬ ì¸µì˜ ë‰´ëŸ° ìˆ˜, $m$ì€ ë°ì´í„° ê°œìˆ˜ì…ë‹ˆë‹¤.

\begin{tcolorbox}[colback=white, colframe=black, title=Shape Cheat Sheet]
\begin{itemize}
    \item \textbf{íŒŒë¼ë¯¸í„° (í•™ìŠµ ëŒ€ìƒ):}
    \begin{itemize}
        \item $W^{[l]}$: $(n^{[l]}, n^{[l-1]})$ $\rightarrow$ (í˜„ì¬ ì¸µ, ì´ì „ ì¸µ)
        \item $b^{[l]}$: $(n^{[l]}, 1)$ $\rightarrow$ ì—´ ë²¡í„° (Column Vector)
    \end{itemize}
    \item \textbf{ë°ì´í„° íë¦„ (Activations):}
    \begin{itemize}
        \item $Z^{[l]}, A^{[l]}$: $(n^{[l]}, m)$
        \item $dZ^{[l]}, dA^{[l]}$: $(n^{[l]}, m)$ $\rightarrow$ ì›ë˜ ë°ì´í„°ì™€ Shape ë™ì¼
    \end{itemize}
\end{itemize}
\end{tcolorbox}

\vspace{0.5cm}\hrule\vspace{0.5cm}

\subsection{2. Why Not Zero Initialization? (0 ì´ˆê¸°í™”ì˜ ì €ì£¼)}
"êµìˆ˜ë‹˜, ë¡œì§€ìŠ¤í‹± íšŒê·€ì—ì„  0ìœ¼ë¡œ í•´ë„ ì˜ ëì–ì•„ìš”?"
ë„¤, í•˜ì§€ë§Œ \textbf{ì‹ ê²½ë§(ì€ë‹‰ì¸µì´ ìˆëŠ” ê²½ìš°)ì—ì„œëŠ” ì ˆëŒ€ ì•ˆ ë©ë‹ˆë‹¤.}

\begin{analogybox}{ë³µì œ ì¸ê°„ êµ°ëŒ€ ë¹„ìœ }
\begin{itemize}
    \item \textbf{ìƒí™©:} ëª¨ë“  ê°€ì¤‘ì¹˜ $W$ë¥¼ 0ìœ¼ë¡œ ì´ˆê¸°í™”í–ˆìŠµë‹ˆë‹¤.
    \item \textbf{Forward:} ëª¨ë“  ì€ë‹‰ ë‰´ëŸ°ì´ ì…ë ¥ê°’ì— ìƒê´€ì—†ì´ ë˜‘ê°™ì€ ê°’(0)ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    \item \textbf{Backward:} ëª¨ë“  ë‰´ëŸ°ì´ ë˜‘ê°™ì€ ì˜¤ì°¨(Gradient)ë¥¼ ë³´ê³ ë°›ìŠµë‹ˆë‹¤.
    \item \textbf{Update:} ëª¨ë“  ë‰´ëŸ°ì´ ë˜‘ê°™ì€ ê°’ìœ¼ë¡œ ìˆ˜ì •ë©ë‹ˆë‹¤.
    \item \textbf{ê²°ê³¼:} ë‰´ëŸ°ì´ 100ë§Œ ê°œì—¬ë„, ê²°êµ­ \textbf{ë‰´ëŸ° 1ê°œì§œë¦¬ ì„ í˜• ëª¨ë¸}ê³¼ ë˜‘ê°™ì´ í–‰ë™í•©ë‹ˆë‹¤. ì´ë¥¼ \textbf{ëŒ€ì¹­ì„±(Symmetry)} ë¬¸ì œë¼ê³  í•˜ë©°, í•™ìŠµì´ ì‹¤íŒ¨í•©ë‹ˆë‹¤.
\end{itemize}
\end{analogybox}

\vspace{0.5cm}\hrule\vspace{0.5cm}

\subsection{3. Best Practice: He Initialization}
ê·¸ë ‡ë‹¤ë©´ ëœë¤í•˜ê²Œ(Random) ì´ˆê¸°í™”í•˜ë©´ ë ê¹Œìš”? 
ë„ˆë¬´ í¬ë©´(x10) ê¸°ìš¸ê¸° ì†Œì‹¤ì´ ì˜¤ê³ , ë„ˆë¬´ ì‘ìœ¼ë©´(x0.0001) ì‹ í˜¸ê°€ ì£½ì–´ë²„ë¦½ë‹ˆë‹¤.



Kaiming He ë°•ì‚¬ê°€ ì œì•ˆí•œ \textbf{He Initialization}ì€ ReLUë¥¼ ì‚¬ìš©í•  ë•Œ ë¶„ì‚°ì„ ì¼ì •í•˜ê²Œ ìœ ì§€í•´ì£¼ëŠ” ë§ˆë²•ì˜ ê³µì‹ì…ë‹ˆë‹¤.

$$ W^{[l]} \sim \text{Random} \times \sqrt{\frac{2}{n^{[l-1]}}} $$
\begin{itemize}
    \item ì´ì „ ì¸µì˜ ë‰´ëŸ° ê°œìˆ˜($n^{[l-1]}$)ê°€ ë§ì„ìˆ˜ë¡, ê°€ì¤‘ì¹˜ë¥¼ ë” ì‘ê²Œ ë§Œë“¤ì–´ ì¤ë‹ˆë‹¤.
    \item $\sqrt{2}$ëŠ” ReLUê°€ ìŒìˆ˜ ì˜ì—­ì„ 0ìœ¼ë¡œ ë§Œë“¤ì–´ ë¶„ì‚°ì„ ì ˆë°˜ìœ¼ë¡œ ê¹ì•„ë¨¹ëŠ” ê²ƒì„ ë³´ìƒí•´ì¤ë‹ˆë‹¤.
\end{itemize}

% --- 7. êµ¬í˜„ ì½”ë“œ ---
\section{Implementation: Initialization Strategies}

ë‚˜ìœ ì˜ˆ(Zero, Large Random)ì™€ ì¢‹ì€ ì˜ˆ(He)ë¥¼ ì½”ë“œë¡œ ë¹„êµí•´ë´…ì‹œë‹¤.

\begin{lstlisting}[language=Python, caption=Parameter Initialization Methods, breaklines=true]
import numpy as np

class Initializer:
    def __init__(self, layer_dims):
        self.layer_dims = layer_dims # ì˜ˆ: [1000, 100, 10]
        self.L = len(layer_dims) - 1

    def init_zeros(self):
        """
        BAD: ëª¨ë“  ê°€ì¤‘ì¹˜ë¥¼ 0ìœ¼ë¡œ ì´ˆê¸°í™” -> í•™ìŠµ ë¶ˆê°€
        """
        params = {}
        for l in range(1, self.L + 1):
            params['W' + str(l)] = np.zeros((self.layer_dims[l], self.layer_dims[l-1]))
            params['b' + str(l)] = np.zeros((self.layer_dims[l], 1))
        return params

    def init_he(self):
        """
        BEST: He Initialization (Standard for ReLU)
        """
        params = {}
        for l in range(1, self.L + 1):
            # 1. ì°¨ì› ì •ì˜
            n_curr = self.layer_dims[l]
            n_prev = self.layer_dims[l-1]
            
            # 2. He Initialization ê³µì‹ ì ìš©
            # np.random.randn: í‰ê·  0, ë¶„ì‚° 1ì¸ ì •ê·œë¶„í¬
            # scaling: ë¶„ì‚°ì„ 2/n_prev ë¡œ ë§ì¶°ì¤Œ
            scaling = np.sqrt(2 / n_prev)
            
            params['W' + str(l)] = np.random.randn(n_curr, n_prev) * scaling
            params['b' + str(l)] = np.zeros((n_curr, 1)) # í¸í–¥ì€ 0ì´ì–´ë„ ë¨!
            
        return params

# --- ê²€ì¦ ---
if __name__ == "__main__":
    dims = [1000, 100, 10]
    init = Initializer(dims)
    
    # He Init ê²°ê³¼ í™•ì¸
    params = init.init_he()
    W1 = params['W1']
    
    print("Shape Check:", W1.shape) # (100, 1000)
    print("Variance Check:", np.var(W1)) 
    print("Expected Variance:", 2/1000) # 0.002 ê·¼ì²˜ì—¬ì•¼ í•¨
\end{lstlisting}

% --- 8. FAQ ---
\section{FAQ \& Pitfalls}

\begin{warningbox}{í¸í–¥(Bias) $b$ëŠ” 0ìœ¼ë¡œ í•´ë„ ë˜ë‚˜ìš”?}
\textbf{ë„¤, ë©ë‹ˆë‹¤!}
ëŒ€ì¹­ì„± ë¬¸ì œëŠ” ê°€ì¤‘ì¹˜ $W$ì—ì„œ ë°œìƒí•©ë‹ˆë‹¤. $W$ê°€ ì´ë¯¸ ëœë¤í•˜ê²Œ ì„ì—¬ ìˆë‹¤ë©´(Symmetry Broken), í¸í–¥ $b$ê°€ ëª¨ë‘ 0ì´ì–´ë„ ë‰´ëŸ°ë“¤ì€ ì„œë¡œ ë‹¤ë¥¸ ê°’ì„ ì¶œë ¥í•˜ê²Œ ë©ë‹ˆë‹¤. ë”°ë¼ì„œ $b$ëŠ” í¸ì˜ìƒ `np.zeros`ë¡œ ì´ˆê¸°í™”í•˜ëŠ” ê²ƒì´ ì¼ë°˜ì ì…ë‹ˆë‹¤.
\end{warningbox}

\textbf{Q. Xavier ì´ˆê¸°í™”ëŠ” ë­”ê°€ìš”?} \\
\textbf{A.} Sigmoidë‚˜ Tanh í•¨ìˆ˜ë¥¼ ì“¸ ë•Œ ì‚¬ìš©í•˜ëŠ” ì´ˆê¸°í™” ë°©ë²•ì…ë‹ˆë‹¤. ê³„ìˆ˜ê°€ $\sqrt{1/n}$ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ìš”ì¦˜ ë”¥ëŸ¬ë‹ì€ ëŒ€ë¶€ë¶„ ReLUë¥¼ ì“°ê¸° ë•Œë¬¸ì— He ì´ˆê¸°í™”($\sqrt{2/n}$)ê°€ ë” ë§ì´ ì“°ì…ë‹ˆë‹¤.

% --- 9. ë‹¤ìŒ ë‹¨ì› ì—°ê²° ---
\section*{ğŸ”— ë‹¤ìŒ ë‹¨ê³„ (Next Step)}
ì´ì œ ìš°ë¦¬ëŠ” \textbf{ì„¤ê³„(Architecture)}, \textbf{ê¸°ì´ˆ ê³µì‚¬(Initialization)}, \textbf{ìì¬ ê²€ìˆ˜(Dimension Check)}ê¹Œì§€ ì™„ë²½í•˜ê²Œ ë§ˆì³¤ìŠµë‹ˆë‹¤.

ì´ì œ ë‚¨ì€ ê²ƒì€ ê±´ë¬¼ì„ ì§“ëŠ” ê²ƒë¿ì…ë‹ˆë‹¤. ë‹¤ìŒ ì‹œê°„ì—ëŠ” \textbf{[Project] Building a Deep Neural Network Application}ì„ í†µí•´, ìš°ë¦¬ê°€ ë§Œë“  ì½”ë“œë¡œ \textbf{'ê³ ì–‘ì´ vs ê°œ'} ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜í•˜ëŠ” ì¸ê³µì§€ëŠ¥ì„ ì™„ì„±í•˜ê² ìŠµë‹ˆë‹¤. ì—¬ëŸ¬ë¶„ì˜ ì²« ë²ˆì§¸ Deep Learning í”„ë¡œì íŠ¸ê°€ ì‹œì‘ë©ë‹ˆë‹¤!

\vspace{0.5cm}

\begin{summarybox}{ë‹¨ì› ìš”ì•½ (Cheat Sheet)}
\begin{enumerate}
    \item \textbf{Dimensions:} $W$ëŠ” $(n^{[l]}, n^{[l-1]})$ì´ë‹¤. ì°¨ì› í™•ì¸ì´ ë””ë²„ê¹…ì˜ ì‹œì‘ì´ë‹¤.
    \item \textbf{Zero Init:} $W$ë¥¼ 0ìœ¼ë¡œ í•˜ë©´ í•™ìŠµì´ ì•ˆ ëœë‹¤. (ëŒ€ì¹­ì„± ë¬¸ì œ)
    \item \textbf{He Init:} ReLUë¥¼ ì“¸ ë•ŒëŠ” `randn * sqrt(2/n)` ê³µì‹ì„ ì‚¬ìš©í•˜ë¼.
    \item \textbf{Bias:} í¸í–¥ $b$ëŠ” 0ìœ¼ë¡œ ì´ˆê¸°í™”í•´ë„ ì•ˆì „í•˜ë‹¤.
\end{enumerate}
\end{summarybox}

\end{document}