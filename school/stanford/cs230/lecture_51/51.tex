\documentclass[a4paper, 11pt]{article}

% --- íŒ¨í‚¤ì§€ ì„¤ì • ---
\usepackage{kotex} % í•œê¸€ ì§€ì›
\usepackage{geometry} % ì—¬ë°± ì„¤ì •
\geometry{left=25mm, right=25mm, top=25mm, bottom=25mm}
\usepackage{amsmath, amssymb, amsfonts} % ìˆ˜ì‹ íŒ¨í‚¤ì§€
\usepackage{graphicx}
\usepackage{adjustbox}  % í‘œ/ë°•ìŠ¤ í¬ê¸° ì¡°ì ˆ % ì´ë¯¸ì§€ ì‚½ì…
\usepackage{hyperref} % í•˜ì´í¼ë§í¬
\usepackage{xcolor} % ìƒ‰ìƒ ì§€ì›
\usepackage{listings} % ì½”ë“œ ë¸”ë¡
\usepackage[most]{tcolorbox}
\tcbuselibrary{breakable} % ë°•ìŠ¤ ë””ìì¸
\usepackage{enumitem} % ë¦¬ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼
\usepackage{booktabs} % í‘œ ë””ìì¸
\usepackage{array} % í‘œ ì •ë ¬

% --- ìƒ‰ìƒ ì •ì˜ ---
\definecolor{conceptblue}{RGB}{60, 100, 160}
\definecolor{analogygreen}{RGB}{80, 160, 100}
\definecolor{alertred}{RGB}{200, 60, 60}
\definecolor{exampleorange}{RGB}{230, 120, 30}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{backcolour}{rgb}{0.96,0.96,0.96}

% --- ì½”ë“œ ìŠ¤íƒ€ì¼ ì„¤ì • ---
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{analogygreen},
    keywordstyle=\color{conceptblue},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{exampleorange},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=4,
    frame=single
}
\lstset{style=mystyle}

% --- ë°•ìŠ¤ ìŠ¤íƒ€ì¼ ì •ì˜ ---
\newtcolorbox{summarybox}[1]{
    colback=conceptblue!5!white,
    colframe=conceptblue!80!black,
    fonttitle=\bfseries,
    title=ğŸ“Œ #1
}

\newtcolorbox{analogybox}[1]{
    colback=analogygreen!5!white,
    colframe=analogygreen!80!black,
    fonttitle=\bfseries,
    title=ğŸ’¡ #1 (ì§ê´€ì  ë¹„ìœ )
}

\newtcolorbox{warningbox}[1]{
    colback=alertred!5!white,
    colframe=alertred!80!black,
    fonttitle=\bfseries,
    title=âš ï¸ #1 (ì˜¤í•´ ë°©ì§€ ê°€ì´ë“œ)
}

\newtcolorbox{mathbox}[1]{
    colback=exampleorange!5!white,
    colframe=exampleorange!80!black,
    fonttitle=\bfseries,
    title=ğŸ§® #1 (í•µì‹¬ ì›ë¦¬)
}

% --- ë¬¸ì„œ ì •ë³´ ---
\title{\textbf{[CS230] Sequence Models: \\ The Transformer Architecture}}
\author{Lecturer: Gemini (Integrated Editor)}
\date{}

\begin{document}

\maketitle

% --- 1. ì „ì²´ ëª©ì°¨ (TOC) ---
\section*{ğŸ“š Course Table of Contents}
\begin{itemize}
    \item[Chapter 1-9.] Deep Learning Fundamentals \& CNNs \textit{- Completed}
    \item[\textbf{Chapter 10.}] \textbf{Sequence Models (Current Part)}
    \begin{itemize}
        \item 10.1-10.11 RNN, LSTM, Self-Attention \textit{- Completed}
        \item \textbf{10.12 The Transformer Architecture}
        \begin{itemize}
            \item Positional Encoding: Giving Order to Sets
            \item Encoder Block: Deep Understanding
            \item Decoder Block: Sequential Generation
            \item BERT vs GPT: Architectural Philosophy
        \end{itemize}
    \end{itemize}
\end{itemize}

\vspace{0.5cm}
\hrule
\vspace{0.5cm}

% --- 3. ì´ì „ ë‹¨ì› ì—°ê²° ---
\section*{ğŸ”— ì§€ë‚œ ì‹œê°„ ë³µìŠµ ë° ì—°ê²°}
ìš°ë¦¬ëŠ” ì§€ë‚œ ì‹œê°„ì— Self-Attentionì´ë¼ëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ì˜ í•µì‹¬ ì—”ì§„ì„ ë°°ì› ìŠµë‹ˆë‹¤. ì˜¤ëŠ˜ì€ ì´ ì—”ì§„ë“¤ì„ ì¡°ë¦½í•´ì„œ ì–´ë–»ê²Œ BERTë‚˜ GPT ê°™ì€ ê±°ëŒ€ ëª¨ë¸ì˜ ë¼ˆëŒ€ê°€ ë˜ëŠ” \textbf{íŠ¸ëœìŠ¤í¬ë¨¸ ì•„í‚¤í…ì²˜(Transformer Architecture)}ê°€ ì™„ì„±ë˜ëŠ”ì§€ í•´ë¶€í•´ ë³´ê² ìŠµë‹ˆë‹¤. íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” í¬ê²Œ ì •ë³´ë¥¼ ì½ì–´ ë“¤ì´ëŠ” \textbf{ì¸ì½”ë”(Encoder)}ì™€ ì •ë³´ë¥¼ ìƒì„±í•˜ëŠ” \textbf{ë””ì½”ë”(Decoder)} ë‘ ë¶€ë¶„ìœ¼ë¡œ ë‚˜ë‰©ë‹ˆë‹¤.



% --- 4. ê°œìš” ---
\section{Unit Overview}
\begin{summarybox}{í•µì‹¬ ëª©í‘œ}
ì´ ë‹¨ì›ì€ í˜„ëŒ€ AI ì‹œìŠ¤í…œì˜ ì„¤ê³„ë„ì¸ íŠ¸ëœìŠ¤í¬ë¨¸ì˜ êµ¬ì¡°ë¥¼ ì™„ë²½íˆ ì´í•´í•©ë‹ˆë‹¤.
\begin{itemize}
    \item \textbf{ì „ì²´ êµ¬ì¡°:} ì¸ì½”ë”ì™€ ë””ì½”ë”ì˜ ì—°ê²° ë©”ì»¤ë‹ˆì¦˜ì„ íŒŒì•…í•©ë‹ˆë‹¤.
    \item \textbf{ìˆœì„œ ì¸ì‹:} RNN ì—†ì´ ìˆœì„œë¥¼ íŒŒì•…í•˜ëŠ” \textbf{Positional Encoding}ì„ ë°°ì›ë‹ˆë‹¤.
    \item \textbf{ì•ˆì •ì„±:} ê¹Šì€ ì¸µì„ ìŒ“ê¸° ìœ„í•œ \textbf{Add \& Norm} (ì”ì°¨ ì—°ê²° ë° ì •ê·œí™”) ì¥ì¹˜ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
    \item \textbf{ì² í•™ì˜ ì°¨ì´:} ì¸ì½”ë” ê¸°ë°˜ì˜ \textbf{BERT}ì™€ ë””ì½”ë” ê¸°ë°˜ì˜ \textbf{GPT} ì°¨ì´ë¥¼ ì´í•´í•©ë‹ˆë‹¤.
\end{itemize}
\end{summarybox}

% --- 5. í•µì‹¬ êµ¬ì„± ìš”ì†Œ ---
\section{Core Components: ì„¤ê³„ë„ í•´ë¶€}

\subsection{1. Positional Encoding (ìœ„ì¹˜ ì •ë³´ ì£¼ì…)}
íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” ë‹¨ì–´ë¥¼ í•œêº¼ë²ˆì— ë³‘ë ¬ë¡œ ì…ë ¥ë°›ê¸° ë•Œë¬¸ì—, "I love you"ì™€ "You love me"ë¥¼ êµ¬ë¶„í•˜ì§€ ëª»í•©ë‹ˆë‹¤. 

\begin{mathbox}{ìœ„ì¹˜ ì‹ í˜¸ ì£¼ì…}
ê° ë‹¨ì–´ ë²¡í„°ì— ê³ ìœ í•œ ìœ„ì¹˜ ê°’ì„ ë”í•´ì¤ë‹ˆë‹¤. ì£¼ê¸° í•¨ìˆ˜ì¸ Sineê³¼ Cosineì„ í™œìš©í•˜ì—¬ ê³ ì°¨ì› ê³µê°„ì—ì„œ ë‹¨ì–´ì˜ ìƒëŒ€ì /ì ˆëŒ€ì  ìœ„ì¹˜ë¥¼ ì…í™ë‹ˆë‹¤.
$$ PE_{(pos, 2i)} = \sin(pos/10000^{2i/d_{model}}) $$
$$ PE_{(pos, 2i+1)} = \cos(pos/10000^{2i/d_{model}}) $$
\end{mathbox}



\subsection{2. Encoder Block (ì¸ì½”ë”: ì´í•´ì˜ ì˜ì—­)}
ì¸ì½”ë”ëŠ” ì…ë ¥ ë¬¸ì¥ì„ í†µì§¸ë¡œ ë³´ê³  ë¬¸ë§¥ì„ íŒŒì•…í•©ë‹ˆë‹¤.
\begin{itemize}
    \item \textbf{Multi-Head Self-Attention:} ë‹¨ì–´ ì‚¬ì´ì˜ ìœ ê¸°ì  ê´€ê³„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    \item \textbf{Add \& Norm:} ì”ì°¨ ì—°ê²°ë¡œ ê¸°ìš¸ê¸° ì†Œì‹¤ì„ ë§‰ê³  Layer Normìœ¼ë¡œ í•™ìŠµì„ ë•ìŠµë‹ˆë‹¤.
    \item \textbf{BERT:} ì´ ì¸ì½”ë”ë¥¼ ìŒ“ì•„ ë§Œë“  ëª¨ë¸ë¡œ, ë¬¸ë§¥ì„ ì–‘ë°©í–¥(Bi-directional)ìœ¼ë¡œ ì´í•´í•©ë‹ˆë‹¤.
\end{itemize}

\subsection{3. Decoder Block (ë””ì½”ë”: ìƒì„±ì˜ ì˜ì—­)}
ë””ì½”ë”ëŠ” ë¶„ì„ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¨ì–´ë¥¼ í•˜ë‚˜ì”© ìƒì„±í•©ë‹ˆë‹¤.
\begin{itemize}
    \item \textbf{Masked Self-Attention:} ë‹¨ì–´ ìƒì„± ì‹œ ë¯¸ë˜ ë‹¨ì–´ë¥¼ ë¯¸ë¦¬ ë³´ê³  ì •ë‹µì„ ìœ ì¶”í•˜ì§€ ëª»í•˜ë„ë¡ ë§ˆìŠ¤í‚¹ì„ ì ìš©í•©ë‹ˆë‹¤.
    \item \textbf{Encoder-Decoder Attention:} ë‹¨ì–´ë¥¼ ë±‰ì„ ë•Œë§ˆë‹¤ ì¸ì½”ë”ê°€ ë¶„ì„í•œ ì›ë¬¸ ì •ë³´ë¥¼ ë‹¤ì‹œ ì°¸ê³ í•©ë‹ˆë‹¤.
    \item \textbf{GPT:} ì´ ë””ì½”ë”ë¥¼ ìŒ“ì•„ ë§Œë“  ëª¨ë¸ë¡œ, ë‹¤ìŒ ë‹¨ì–´ ì˜ˆì¸¡(Auto-regressive)ì— íŠ¹í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
\end{itemize}



\vspace{0.5cm}\hrule\vspace{0.5cm}

\section{Deep Dive: BERT vs GPT}

ê°™ì€ íŠ¸ëœìŠ¤í¬ë¨¸ ë¿Œë¦¬ë¥¼ ë‘ì§€ë§Œ, ë¶€í’ˆ ì„ íƒì— ë”°ë¼ ì„±ê²©ì´ ì™„ì „íˆ ë‹¬ë¼ì§‘ë‹ˆë‹¤.

\begin{center}
\begin{tabular}{>{\raggedright\arraybackslash}p{2.5cm} p{5cm} p{5cm}}
\toprule
\textbf{íŠ¹ì§•} & \textbf{BERT} & \textbf{GPT} \\ \midrule
\textbf{ê¸°ë°˜ êµ¬ì¡°} & íŠ¸ëœìŠ¤í¬ë¨¸ ì¸ì½”ë” & íŠ¸ëœìŠ¤í¬ë¨¸ ë””ì½”ë” \\
\textbf{í•™ìŠµ ë°©í–¥} & ì–‘ë°©í–¥ (Bi-directional) & ë‹¨ë°©í–¥ (Left-to-Right) \\
\textbf{ì£¼ìš” ëª©ì } & ë¬¸ì¥ ë¶„ë¥˜, ì§ˆì˜ì‘ë‹µ & ë¬¸ì¥ ìƒì„±, ëŒ€í™”, ì°½ì‘ \\
\textbf{ë¹„ìœ } & ë¹ˆì¹¸ ì±„ìš°ê¸° ì˜í•˜ëŠ” ëª¨ë²”ìƒ & ì´ì•¼ê¸°ë¥¼ ì§€ì–´ë‚´ëŠ” ì†Œì„¤ê°€ \\ \bottomrule
\end{tabular}
\end{center}

% --- 7. êµ¬í˜„ ê´€ì  ---
\section{Implementation: Hugging Face Transformers}

í˜„ëŒ€ ê°œë°œìë“¤ì€ ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ë¥¼ ë¶ˆëŸ¬ì™€ì„œ ë¯¸ì„¸ ì¡°ì •(Fine-tuning)í•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤.

\begin{lstlisting}[language=Python, caption=Loading Pre-trained Transformers, breaklines=true]
from transformers import BertModel, GPT2Model

# BERT: ì˜ë¯¸ ì¶”ì¶œ ë° ë¬¸ì¥ ë¶„ë¥˜ ì‹œ
bert = BertModel.from_pretrained('bert-base-uncased')

# GPT: í…ìŠ¤íŠ¸ ìƒì„± ë° ì±—ë´‡ êµ¬í˜„ ì‹œ
gpt = GPT2Model.from_pretrained('gpt2')
\end{lstlisting}

% --- 8. ìš”ì•½ ë° ë§ˆë¬´ë¦¬ ---
\section*{ğŸ Summary \& Next Step}
\begin{enumerate}
    \item \textbf{Transformer:} RNNì„ ëŒ€ì²´í•œ ì™„ë²½í•œ ë³‘ë ¬ ì²˜ë¦¬ ì•„í‚¤í…ì²˜.
    \item \textbf{Positional Encoding:} ì–´í…ì…˜ì— 'ìˆœì„œ'ë¼ëŠ” ìƒëª…ë ¥ì„ ë¶ˆì–´ë„£ëŠ” ì¥ì¹˜.
    \item \textbf{Functional Split:} ì´í•´ë¥¼ ì›í•˜ë©´ ì¸ì½”ë”(BERT), ìƒì„±ì„ ì›í•˜ë©´ ë””ì½”ë”(GPT).
\end{enumerate}

ì´ì œ ì—¬ëŸ¬ë¶„ì€ í˜„ëŒ€ ì¸ê³µì§€ëŠ¥ì´ ì¸ê°„ì˜ ì–¸ì–´ë¥¼ ì–´ë–»ê²Œ ì²˜ë¦¬í•˜ëŠ”ì§€ ê·¸ ë°‘ë°”ë‹¥ ì„¤ê³„ë„ë¥¼ ë³´ì…¨ìŠµë‹ˆë‹¤. ì´ êµ¬ì¡°ëŠ” ì´ì œ ì–¸ì–´ë¥¼ ë„˜ì–´ ì´ë¯¸ì§€(ViT), ìŒì„±(Whisper) ë“±ìœ¼ë¡œ ë¬´í•œíˆ í™•ì¥ë˜ê³  ìˆìŠµë‹ˆë‹¤.

\vspace{0.5cm}
\begin{summarybox}{ìƒê°í•´ë³¼ ê±°ë¦¬}
ë§ˆìŠ¤í‚¹(Masking)ì´ ì—†ë‹¤ë©´ ë””ì½”ë”ëŠ” ì™œ í•™ìŠµì´ ë¶ˆê°€ëŠ¥í• ê¹Œìš”? ì”ì°¨ ì—°ê²°(Residual Connection)ì´ ê¹Šì€ íŠ¸ëœìŠ¤í¬ë¨¸ ì¸µì—ì„œ ì™œ í•„ìˆ˜ì ì¼ê¹Œìš”? ê¶ê¸ˆí•œ ì ì´ ìˆë‹¤ë©´ ì–¸ì œë“  ì§ˆë¬¸í•´ ì£¼ì„¸ìš”!
\end{summarybox}

\end{document}