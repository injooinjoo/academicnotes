\documentclass[a4paper, 11pt]{article}

% --- íŒ¨í‚¤ì§€ ì„¤ì • ---
\usepackage{kotex} % í•œê¸€ ì§€ì›
\usepackage{geometry} % ì—¬ë°± ì„¤ì •
\geometry{left=25mm, right=25mm, top=25mm, bottom=25mm}
\usepackage{amsmath, amssymb, amsfonts} % ìˆ˜ì‹ íŒ¨í‚¤ì§€
\usepackage{graphicx}
\usepackage{adjustbox}  % í‘œ/ë°•ìŠ¤ í¬ê¸° ì¡°ì ˆ % ì´ë¯¸ì§€ ì‚½ì…
\usepackage{hyperref} % í•˜ì´í¼ë§í¬
\usepackage{xcolor} % ìƒ‰ìƒ ì§€ì›
\usepackage{listings} % ì½”ë“œ ë¸”ë¡
\usepackage[most]{tcolorbox}
\tcbuselibrary{breakable} % ë°•ìŠ¤ ë””ìì¸
\usepackage{enumitem} % ë¦¬ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼
\usepackage{booktabs} % í‘œ ë””ìì¸
\usepackage{array} % í‘œ ì •ë ¬

% --- ìƒ‰ìƒ ì •ì˜ ---
\definecolor{conceptblue}{RGB}{60, 100, 160}
\definecolor{analogygreen}{RGB}{80, 160, 100}
\definecolor{alertred}{RGB}{200, 60, 60}
\definecolor{exampleorange}{RGB}{230, 120, 30}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{backcolour}{rgb}{0.96,0.96,0.96}

% --- ì½”ë“œ ìŠ¤íƒ€ì¼ ì„¤ì • ---
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{analogygreen},
    keywordstyle=\color{conceptblue},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{exampleorange},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=4,
    frame=single
}
\lstset{style=mystyle}

% --- ë°•ìŠ¤ ìŠ¤íƒ€ì¼ ì •ì˜ ---
\newtcolorbox{summarybox}[1]{
    colback=conceptblue!5!white,
    colframe=conceptblue!80!black,
    fonttitle=\bfseries,
    title=ğŸ“Œ #1
}

\newtcolorbox{analogybox}[1]{
    colback=analogygreen!5!white,
    colframe=analogygreen!80!black,
    fonttitle=\bfseries,
    title=ğŸ’¡ #1 (ì§ê´€ì  ë¹„ìœ )
}

\newtcolorbox{warningbox}[1]{
    colback=alertred!5!white,
    colframe=alertred!80!black,
    fonttitle=\bfseries,
    title=âš ï¸ #1 (ì˜¤í•´ ë°©ì§€ ê°€ì´ë“œ)
}

\newtcolorbox{tipbox}[1]{
    colback=exampleorange!5!white,
    colframe=exampleorange!80!black,
    fonttitle=\bfseries,
    title=ğŸ’¡ #1 (ì‹¤ì „ íŒ)
}

% --- ë¬¸ì„œ ì •ë³´ ---
\title{\textbf{[CS230] Optimization Algorithms: \\ Hyperparameter Tuning Strategy}}
\author{Lecturer: Gemini (Integrated Editor)}
\date{}

\begin{document}

\maketitle

% --- 1. ì „ì²´ ëª©ì°¨ (TOC) ---
\section*{ğŸ“š Course Table of Contents}
\begin{itemize}
    \item[Chapter 1-4.] Neural Networks Basics \textit{- Completed}
    \item[\textbf{Chapter 5.}] \textbf{Practical Aspects of Deep Learning (Current Unit)}
    \begin{itemize}
        \item 5.1-5.5 Regularization \& Data Setup \textit{- Completed}
        \item 5.6-5.9 Optimization (Mini-batch, Adam, Decay) \textit{- Completed}
        \item \textbf{5.10 Hyperparameter Tuning Strategy}
        \begin{itemize}
            \item Tuning Priority (Alpha is King)
            \item Grid Search vs Random Search
            \item Picking Appropriate Scale (Log Scale)
            \item Coarse to Fine Strategy
        \end{itemize}
        \item 5.11 Batch Normalization \textit{- Upcoming}
    \end{itemize}
\end{itemize}

\vspace{0.5cm}
\hrule
\vspace{0.5cm}

% --- 3. ì´ì „ ë‹¨ì› ì—°ê²° ---
\section*{ğŸ”— ì§€ë‚œ ì‹œê°„ ë³µìŠµ ë° ì—°ê²°}
ìš°ë¦¬ëŠ” ì§€ê¸ˆê¹Œì§€ ì‹ ê²½ë§ì„ ë§Œë“¤ê³ (Architecture), í•™ìŠµì‹œí‚¤ê³ (Adam), ê·œì œ(Regularization)í•˜ëŠ” ëª¨ë“  ë°©ë²•ì„ ë°°ì› ìŠµë‹ˆë‹¤.
í•˜ì§€ë§Œ ë§‰ìƒ ì—¬ëŸ¬ë¶„ì´ ëª¨ë¸ì„ ëŒë¦¬ë ¤ê³  í•˜ë©´ ê±°ëŒ€í•œ ë²½ì— ë¶€ë”ªí™ë‹ˆë‹¤.
"í•™ìŠµë¥ ì€ 0.01? 0.0001?", "ë°°ì¹˜ í¬ê¸°ëŠ” 32? 64?"
ìˆ˜ì‹­ ê°œì˜ ë‹¤ì´ì–¼ì„ ë¬´ì‘ìœ„ë¡œ ëŒë¦¬ëŠ” ê²ƒì€ ë„ë°•ì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” \textbf{ì²´ê³„ì ì´ê³  ê³¼í•™ì ì¸ íƒìƒ‰ ì „ëµ}ì´ í•„ìš”í•©ë‹ˆë‹¤.

% --- 4. ê°œìš” ---
\section{Unit Overview}
\begin{summarybox}{í•µì‹¬ ëª©í‘œ}
ì´ ë‹¨ì›ì€ SOTA(State-of-the-art) ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ê¸° ìœ„í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì˜ \textbf{ìš°ì„ ìˆœìœ„}ì™€ \textbf{íƒìƒ‰ ê¸°ë²•}ì„ ë‹¤ë£¹ë‹ˆë‹¤.
\begin{itemize}
    \item \textbf{ìš°ì„ ìˆœìœ„:} í•™ìŠµë¥ ($\alpha$)ì´ ê°€ì¥ ì¤‘ìš”í•˜ë‹¤ëŠ” ê³„ì¸µ êµ¬ì¡°ë¥¼ ì´í•´í•©ë‹ˆë‹¤.
    \item \textbf{ì „ëµ:} ê³ ì°¨ì› ê³µê°„ì—ì„œëŠ” \textbf{Random Search}ê°€ Grid Searchë³´ë‹¤ ì••ë„ì ìœ¼ë¡œ ìœ ë¦¬í•œ ì´ìœ ë¥¼ ê¸°í•˜í•™ì ìœ¼ë¡œ ì¦ëª…í•©ë‹ˆë‹¤.
    \item \textbf{ìŠ¤ì¼€ì¼:} í•™ìŠµë¥  ë“±ì„ íƒìƒ‰í•  ë•Œ ì„ í˜•(Linear)ì´ ì•„ë‹Œ \textbf{ë¡œê·¸ ìŠ¤ì¼€ì¼(Log Scale)}ì„ ì¨ì•¼ í•˜ëŠ” ìˆ˜í•™ì  ì´ìœ ë¥¼ ë°°ì›ë‹ˆë‹¤.
\end{itemize}
\end{summarybox}

% --- 5. ìš©ì–´ ì •ë¦¬ ---
\section{Essential Terminology}
\begin{center}
\begin{tabular}{|c|l|l|}
\hline
\textbf{ê¸°ë²•} & \textbf{ì„¤ëª…} & \textbf{ë¹„ìœ } \\ \hline
\textbf{Grid Search} & ëª¨ë“  ì¡°í•©ì„ ê²©ìë¬´ëŠ¬ë¡œ ë‹¤ í•´ë³´ëŠ” ê²ƒ. & ìë¬¼ì‡  ë²ˆí˜¸ë¥¼ 0000ë¶€í„° 9999ê¹Œì§€ ë‹¤ ëŒë ¤ë´„. \\ \hline
\textbf{Random Search} & ë¬´ì‘ìœ„ë¡œ ê°’ì„ ì°ì–´ë³´ëŠ” ê²ƒ. & ê°ìœ¼ë¡œ ì°ì–´ì„œ ë§ì¶¤ (ê³ ì°¨ì›ì—ì„œ ìœ ë¦¬). \\ \hline
\textbf{Log Scale} & ìë¦¿ìˆ˜ ë‹¨ìœ„ë¡œ íƒìƒ‰ ($10^{-4}, 10^{-3} \dots$). & í˜„ë¯¸ê²½ ë°°ìœ¨ì„ 10ë°°, 100ë°°ë¡œ ì¡°ì ˆí•˜ë©° ê´€ì°°. \\ \hline
\textbf{Coarse to Fine} & ë„“ê²Œ í›‘ê³ (Coarse), ì¢‹ì€ ê³³ì„ ì§‘ì¤‘ ê³µëµ(Fine). & ìˆ² ì „ì²´ë¥¼ ìŠ¤ìº”í•˜ê³ , ì˜ì‹¬ ê°€ëŠ” êµ¬ì—­ë§Œ ìˆ˜ìƒ‰. \\ \hline
\end{tabular}
\end{center}

% --- 6. í•µì‹¬ ê°œë… ìƒì„¸ ì„¤ëª… ---
\section{Core Concepts: ë¬´ì—‡ì´ ì¤‘ìš”í•œê°€?}

\subsection{1. Tuning Priority (ìš°ì„ ìˆœìœ„ ê³„ê¸‰ë„)}
ëª¨ë“  íŒŒë¼ë¯¸í„°ê°€ í‰ë“±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì•¤ë“œë¥˜ ì‘ êµìˆ˜ì˜ ê²½í—˜ì  ê°€ì´ë“œë¼ì¸ì…ë‹ˆë‹¤.

\begin{itemize}
    \item \textbf{Tier 1 (King - ê°€ì¥ ì¤‘ìš”):}
    \begin{itemize}
        \item \textbf{Learning Rate ($\alpha$)}: ì´ê²ƒì´ í‹€ë¦¬ë©´ ë‹¤ë¥¸ ê±¸ ì•„ë¬´ë¦¬ ì˜ ë§ì¶°ë„ ì†Œìš©ì—†ìŠµë‹ˆë‹¤.
    \end{itemize}
    \item \textbf{Tier 2 (Queen - ì¤‘ìš”):}
    \begin{itemize}
        \item Momentum ($\beta$), Mini-batch Size, Hidden Units ê°œìˆ˜.
    \end{itemize}
    \item \textbf{Tier 3 (Pawn - ëœ ì¤‘ìš”):}
    \begin{itemize}
        \item Layer ê°œìˆ˜, Learning Rate Decay.
    \end{itemize}
    \item \textbf{Do Not Touch (ê±´ë“œë¦¬ì§€ ë§ˆì„¸ìš”):}
    \begin{itemize}
        \item Adamì˜ $\beta_1(0.9), \beta_2(0.999), \epsilon(10^{-8})$.
    \end{itemize}
\end{itemize}

\vspace{0.5cm}\hrule\vspace{0.5cm}

\subsection{2. Grid Search vs Random Search}


\begin{analogybox}{ë³´ë¬¼ ì°¾ê¸°}
ì§€ë„ìƒì— ë³´ë¬¼ì´ ì–´ë”” ìˆëŠ”ì§€ ëª¨ë¦…ë‹ˆë‹¤.
\begin{itemize}
    \item \textbf{Grid Search:} ì§€ë„ë¥¼ ë°”ë‘‘íŒì²˜ëŸ¼ ë‚˜ëˆ„ê³  êµì°¨ì ë§Œ íŒë‹ˆë‹¤. ë§Œì•½ ë³´ë¬¼ì´ êµì°¨ì  ì‚¬ì´ì— ìˆë‹¤ë©´? ì˜ì›íˆ ëª» ì°¾ìŠµë‹ˆë‹¤.
    \item \textbf{Random Search:} ì§€ë„ë¥¼ ë¬´ì‘ìœ„ë¡œ ì½•ì½• ì°Œë¦…ë‹ˆë‹¤. ê°™ì€ íšŸìˆ˜ë¥¼ ì‹œë„í•˜ë”ë¼ë„, ì¤‘ìš”í•œ íŒŒë¼ë¯¸í„°ì— ëŒ€í•´ \textbf{í›¨ì”¬ ë” ë‹¤ì–‘í•œ ê°’}ì„ í…ŒìŠ¤íŠ¸í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
\end{itemize}
\end{analogybox}

\vspace{0.5cm}\hrule\vspace{0.5cm}

\subsection{3. Scale Matters: Log Scale Sampling}
í•™ìŠµë¥  $\alpha$ë¥¼ $0.0001$ì—ì„œ $1$ ì‚¬ì´ì—ì„œ ì°¾ëŠ”ë‹¤ê³  í•©ì‹œë‹¤.

\textbf{ë‚˜ìœ ë°©ë²• (Linear):} `np.random.rand()`
\begin{itemize}
    \item 90\%ì˜ ê°’ì´ $0.1 \sim 1$ êµ¬ê°„ì— ëª°ë¦½ë‹ˆë‹¤.
    \item ì •ì‘ ì¤‘ìš”í•œ $0.0001 \sim 0.1$ êµ¬ê°„ì€ ì „ì²´ì˜ 10\%ë°–ì— íƒìƒ‰í•˜ì§€ ëª»í•©ë‹ˆë‹¤.
\end{itemize}

\textbf{ì¢‹ì€ ë°©ë²• (Log Scale):}
\begin{itemize}
    \item $10^{-4}, 10^{-3}, 10^{-2}, 10^{-1}$ ê° êµ¬ê°„ì„ ê³µí‰í•˜ê²Œ íƒìƒ‰í•´ì•¼ í•©ë‹ˆë‹¤.
    \item ì§€ìˆ˜($r$)ë¥¼ $-4 \sim 0$ ì‚¬ì´ì—ì„œ ë½‘ê³ , $10^r$ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
\end{itemize}

% --- 7. êµ¬í˜„ ì½”ë“œ ---
\section{Implementation: Scientific Search}

ì˜¬ë°”ë¥¸ ìŠ¤ì¼€ì¼ë¡œ íŒŒë¼ë¯¸í„°ë¥¼ ë½‘ëŠ” í•¨ìˆ˜ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.

\begin{lstlisting}[language=Python, caption=Hyperparameter Sampling Strategies, breaklines=true]
import numpy as np

class HyperparameterSearch:
    def sample_linear(self, low, high, num_samples):
        """
        ì€ë‹‰ ìœ ë‹› ìˆ˜, ì¸µ ìˆ˜ ë“± (ë“±ê°„ê²©ì´ ì˜ë¯¸ ìˆëŠ” ê²½ìš°)
        """
        return np.random.uniform(low, high, num_samples)

    def sample_log_scale(self, low_exp, high_exp, num_samples):
        """
        í•™ìŠµë¥ (alpha), ì •ê·œí™”ìƒìˆ˜(lambda) ë“± (ìë¦¿ìˆ˜ê°€ ì¤‘ìš”í•œ ê²½ìš°)
        ë²”ìœ„: 10^low_exp ~ 10^high_exp
        """
        # 1. ì§€ìˆ˜(r)ë¥¼ ê· ë“±í•˜ê²Œ ë½‘ìŒ (-4 ~ 0)
        r = np.random.uniform(low_exp, high_exp, num_samples)
        # 2. 10ì˜ ê±°ë“­ì œê³±ìœ¼ë¡œ ë³€í™˜
        return 10 \textbf{ r

    def sample_beta(self, num_samples):
        """
        Momentum Beta (0.9 ~ 0.999)
        1-beta ê°’ì„ ë¡œê·¸ ìŠ¤ì¼€ì¼ë¡œ ë½‘ëŠ” ê²ƒì´ í•µì‹¬!
        """
        # 1-beta ë²”ìœ„: 0.1 ~ 0.001 (10^-1 ~ 10^-3)
        r = np.random.uniform(-3, -1, num_samples)
        return 1 - (10 } r)

# --- ì‹¤í–‰ ---
if __name__ == "__main__":
    searcher = HyperparameterSearch()
    
    # í•™ìŠµë¥  íƒìƒ‰: 0.0001 ~ 1.0
    alphas = searcher.sample_log_scale(-4, 0, 5)
    print("Alphas:", np.round(alphas, 6))
    
    # ëª¨ë©˜í…€ íƒìƒ‰: 0.9 ~ 0.999
    betas = searcher.sample_beta(5)
    print("Betas:", np.round(betas, 6))
\end{lstlisting}

% --- 8. FAQ ---
\section{FAQ \& Pitfalls}

\begin{tipbox}{Coarse to Fine ì „ëµ}
ì²˜ìŒë¶€í„° 100 Epochì”© ëŒë¦¬ë©° ì™„ë²½í•œ ê°’ì„ ì°¾ìœ¼ë ¤ í•˜ì§€ ë§ˆì„¸ìš”.
1. \textbf{Coarse:} ë„“ì€ ë²”ìœ„ì—ì„œ 5~10 Epochë§Œ ì§§ê²Œ ëŒë ¤ ëŒ€ëµì ì¸ ì„±ëŠ¥ì„ ë´…ë‹ˆë‹¤.
2. \textbf{Zoom In:} ì„±ëŠ¥ì´ ì¢‹ì€ ì˜ì—­ì„ ë°œê²¬í•˜ë©´ ê·¸ êµ¬ê°„ì„ ì§‘ì¤‘ í™•ëŒ€í•©ë‹ˆë‹¤.
3. \textbf{Fine:} ì¢ì€ ì˜ì—­ì—ì„œ ì •ë°€í•˜ê²Œ ë‹¤ì‹œ Random Searchë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
\end{tipbox}

\textbf{Q. $\beta$(Momentum)ëŠ” ì™œ $1-\beta$ë¡œ ë¡œê·¸ ìƒ˜í”Œë§í•˜ë‚˜ìš”?} \\
\textbf{A.} $\beta$ëŠ” 1ì— ê°€ê¹Œì›Œì§ˆìˆ˜ë¡ ë¯¼ê°í•´ì§€ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.
$0.9 \to 0.9005$ëŠ” ë³„ ì°¨ì´ ì—†ì§€ë§Œ, $0.999 \to 0.9995$ëŠ” í‰ê·  ê¸°ê°„ì´ 1000ì¼ì—ì„œ 2000ì¼ë¡œ 2ë°°ê°€ ë©ë‹ˆë‹¤. 1ì— ê°€ê¹Œìš´ ê°’ì„ ë” ì„¸ë°€í•˜ê²Œ íƒìƒ‰í•´ì•¼ í•©ë‹ˆë‹¤.

% --- 9. ë‹¤ìŒ ë‹¨ì› ì—°ê²° ---
\section*{ğŸ”— ë‹¤ìŒ ë‹¨ê³„ (Next Step)}
ì´ì œ ìµœì ì˜ íŒŒë¼ë¯¸í„°ê¹Œì§€ ì°¾ì•˜ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ëª¨ë¸ì´ ê¹Šì–´ì§ˆìˆ˜ë¡ \textbf{"í•™ìŠµ ì†ë„ê°€ ëŠë ¤ì§€ê³  ì´ˆê¸°ê°’ì— ë„ˆë¬´ ë¯¼ê°í•´ì§€ëŠ” ë¬¸ì œ"}ê°€ ë°œìƒí•©ë‹ˆë‹¤. ë°ì´í„° ë¶„í¬ê°€ ì¸µì„ ì§€ë‚  ë•Œë§ˆë‹¤ í‹€ì–´ì§€ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë”¥ëŸ¬ë‹ ì—­ì‚¬ìƒ ê°€ì¥ ìœ„ëŒ€í•œ ë°œëª… ì¤‘ í•˜ë‚˜ì¸ \textbf{[Batch Normalization]}ì´ ë“±ì¥í–ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ì‹œê°„ì— ì´ ë§ˆë²• ê°™ì€ ê¸°ë²•ì„ íŒŒí—¤ì³ ë³´ê² ìŠµë‹ˆë‹¤.

\vspace{0.5cm}

\begin{summarybox}{ë‹¨ì› ìš”ì•½ (Cheat Sheet)}
\begin{enumerate}
    \item \textbf{Priority:} í•™ìŠµë¥ ($\alpha$)ì´ 1ìˆœìœ„ë‹¤.
    \item \textbf{Strategy:} Grid Searchë³´ë‹¤ëŠ” \textbf{Random Search}ê°€ íš¨ìœ¨ì ì´ë‹¤.
    \item \textbf{Log Scale:} $\alpha$ë‚˜ $\lambda$ëŠ” ìë¦¿ìˆ˜ ë‹¨ìœ„ë¡œ íƒìƒ‰í•´ì•¼ í•œë‹¤. ($10^{-4}, 10^{-3}\dots$)
    \item \textbf{Process:} ë„“ê²Œ í›‘ê³ (Coarse), ì¢ê²Œ íŒŒê³ ë“¤ì–´ë¼(Fine).
\end{enumerate}
\end{summarybox}

\end{document}