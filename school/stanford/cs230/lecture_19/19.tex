\documentclass[a4paper, 11pt]{article}

% --- íŒ¨í‚¤ì§€ ì„¤ì • ---
\usepackage{kotex} % í•œê¸€ ì§€ì›
\usepackage{geometry} % ì—¬ë°± ì„¤ì •
\geometry{left=25mm, right=25mm, top=25mm, bottom=25mm}
\usepackage{amsmath, amssymb, amsfonts} % ìˆ˜ì‹ íŒ¨í‚¤ì§€
\usepackage{graphicx}
\usepackage{adjustbox}  % í‘œ/ë°•ìŠ¤ í¬ê¸° ì¡°ì ˆ % ì´ë¯¸ì§€ ì‚½ì…
\usepackage{hyperref} % í•˜ì´í¼ë§í¬
\usepackage{xcolor} % ìƒ‰ìƒ ì§€ì›
\usepackage{listings} % ì½”ë“œ ë¸”ë¡
\usepackage[most]{tcolorbox}
\tcbuselibrary{breakable} % ë°•ìŠ¤ ë””ìì¸
\usepackage{enumitem} % ë¦¬ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼
\usepackage{booktabs} % í‘œ ë””ìì¸
\usepackage{array} % í‘œ ì •ë ¬

% --- ìƒ‰ìƒ ì •ì˜ ---
\definecolor{conceptblue}{RGB}{60, 100, 160}
\definecolor{analogygreen}{RGB}{80, 160, 100}
\definecolor{alertred}{RGB}{200, 60, 60}
\definecolor{exampleorange}{RGB}{230, 120, 30}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{backcolour}{rgb}{0.96,0.96,0.96}

% --- ì½”ë“œ ìŠ¤íƒ€ì¼ ì„¤ì • ---
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{analogygreen},
    keywordstyle=\color{conceptblue},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{exampleorange},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=4,
    frame=single
}
\lstset{style=mystyle}

% --- ë°•ìŠ¤ ìŠ¤íƒ€ì¼ ì •ì˜ ---
\newtcolorbox{summarybox}[1]{
    colback=conceptblue!5!white,
    colframe=conceptblue!80!black,
    fonttitle=\bfseries,
    title=ğŸ“Œ #1
}

\newtcolorbox{analogybox}[1]{
    colback=analogygreen!5!white,
    colframe=analogygreen!80!black,
    fonttitle=\bfseries,
    title=ğŸ’¡ #1 (ì§ê´€ì  ë¹„ìœ )
}

\newtcolorbox{warningbox}[1]{
    colback=alertred!5!white,
    colframe=alertred!80!black,
    fonttitle=\bfseries,
    title=âš ï¸ #1 (ì˜¤í•´ ë°©ì§€ ê°€ì´ë“œ)
}

\newtcolorbox{mathbox}[1]{
    colback=exampleorange!5!white,
    colframe=exampleorange!80!black,
    fonttitle=\bfseries,
    title=ğŸ§® #1 (ìˆ˜í•™ì  ì›ë¦¬)
}

% --- ë¬¸ì„œ ì •ë³´ ---
\title{\textbf{[CS230] Optimization Algorithms: \\ Learning Rate Decay}}
\author{Lecturer: Gemini (Integrated Editor)}
\date{}

\begin{document}

\maketitle

% --- 1. ì „ì²´ ëª©ì°¨ (TOC) ---
\section*{ğŸ“š Course Table of Contents}
\begin{itemize}
    \item[Chapter 1-4.] Neural Networks Basics \textit{- Completed}
    \item[\textbf{Chapter 5.}] \textbf{Practical Aspects of Deep Learning (Current Unit)}
    \begin{itemize}
        \item 5.1-5.5 Regularization \& Data Setup \textit{- Completed}
        \item 5.6 Mini-batch Gradient Descent \textit{- Completed}
        \item 5.7-5.8 Momentum, RMSprop, Adam \textit{- Completed}
        \item \textbf{5.9 Learning Rate Decay}
        \begin{itemize}
            \item The Parking Problem (Oscillation)
            \item Decay Schedules (Inverse Time, Exponential, Step)
            \item Implementation \& Visualization
        \end{itemize}
        \item 5.10 Hyperparameter Tuning Strategy \textit{- Upcoming}
    \end{itemize}
\end{itemize}

\vspace{0.5cm}
\hrule
\vspace{0.5cm}

% --- 3. ì´ì „ ë‹¨ì› ì—°ê²° ---
\section*{ğŸ”— ì§€ë‚œ ì‹œê°„ ë³µìŠµ ë° ì—°ê²°}
ì§€ë‚œ ì‹œê°„ì— ìš°ë¦¬ëŠ” Adam Optimizerë¥¼ í†µí•´ ìµœì í™”ì˜ ì •ì ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì•„ì£¼ ë¯¸ì„¸í•œ ë¬¸ì œê°€ í•˜ë‚˜ ë‚¨ì•˜ìŠµë‹ˆë‹¤. í•™ìŠµ í›„ë°˜ë¶€ê°€ ë˜ë©´ ì†ì‹¤ í•¨ìˆ˜(Cost)ì˜ ìµœì €ì  ê·¼ì²˜ì—ì„œ ëª¨ë¸ì´ ì•ˆì°©í•˜ì§€ ëª»í•˜ê³  ê³„ì† ë§´ë„ëŠ” \textbf{ì§„ë™(Oscillation)} í˜„ìƒì´ ë°œìƒí•©ë‹ˆë‹¤.
ì£¼ì°¨ì¥ì—ì„œ ì‹œì† 100kmë¡œ ë‹¬ë¦¬ë©´ ì ˆëŒ€ ì£¼ì°¨ ì¹¸ì— ì°¨ë¥¼ ë„£ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëª©ì ì§€ ê·¼ì²˜ì—ì„œëŠ” ì†ë„ë¥¼ ì¤„ì—¬ì•¼ í•©ë‹ˆë‹¤. ì´ê²ƒì´ ë°”ë¡œ \textbf{í•™ìŠµë¥  ê°ì‡ (Learning Rate Decay)}ê°€ í•„ìš”í•œ ì´ìœ ì…ë‹ˆë‹¤.

% --- 4. ê°œìš” ---
\section{Unit Overview}
\begin{summarybox}{í•µì‹¬ ëª©í‘œ}
ì´ ë‹¨ì›ì€ í•™ìŠµ ë‹¨ê³„ë³„ë¡œ í•™ìŠµë¥ ($\alpha$)ì„ ì¡°ì ˆí•˜ì—¬ ëª¨ë¸ ì„±ëŠ¥ì„ ê·¹ëŒ€í™”í•˜ëŠ” ê¸°ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤.
\begin{itemize}
    \item \textbf{ì´ìœ :} ê³ ì •ëœ í•™ìŠµë¥ ì´ ìµœì €ì  ê·¼ì²˜ì—ì„œ ìˆ˜ë ´í•˜ì§€ ëª»í•˜ëŠ” ì´ìœ ë¥¼ ê¸°í•˜í•™ì ìœ¼ë¡œ ì´í•´í•©ë‹ˆë‹¤.
    \item \textbf{ì „ëµ:} ì‹œê°„ ê¸°ë°˜(Inverse Time), ì§€ìˆ˜(Exponential), ê³„ë‹¨ì‹(Step) ê°ì‡ ì˜ ìˆ˜ì‹ì  ì°¨ì´ë¥¼ íŒŒì•…í•©ë‹ˆë‹¤.
    \item \textbf{êµ¬í˜„:} Pythonìœ¼ë¡œ ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ êµ¬í˜„í•˜ê³  ì—í­(Epoch)ì— ë”°ë¥¸ ë³€í™”ë¥¼ ê·¸ë˜í”„ë¡œ í™•ì¸í•©ë‹ˆë‹¤.
\end{itemize}
\end{summarybox}

% --- 5. ìš©ì–´ ì •ë¦¬ ---
\section{Essential Terminology}
\begin{center}
\begin{tabular}{|c|c|l|}
\hline
\textbf{ìš©ì–´} & \textbf{ê¸°í˜¸} & \textbf{ì„¤ëª…} \\ \hline
\textbf{Learning Rate} & $\alpha$ & í•œ ë²ˆ ì—…ë°ì´íŠ¸í•  ë•Œ ì´ë™í•˜ëŠ” ë³´í­ì˜ í¬ê¸°. \\ \hline
\textbf{Decay Rate} & $k$ & í•™ìŠµë¥ ì„ ì–¼ë§ˆë‚˜ ë¹¨ë¦¬ ì¤„ì¼ì§€ ê²°ì •í•˜ëŠ” ê³„ìˆ˜. \\ \hline
\textbf{Epoch} & $t$ & ì „ì²´ ë°ì´í„°ë¥¼ í•œ ë²ˆ í•™ìŠµí•œ íšŸìˆ˜. (ì‹œê°„ ë‹¨ìœ„) \\ \hline
\textbf{Initial LR} & $\alpha_0$ & í•™ìŠµ ì‹œì‘ ì‹œì ì˜ ì´ˆê¸° í•™ìŠµë¥ . \\ \hline
\end{tabular}
\end{center}

% --- 6. í•µì‹¬ ê°œë… ìƒì„¸ ì„¤ëª… ---
\section{Core Concepts: ì†ë„ ì¡°ì ˆì˜ ë¯¸í•™}

\subsection{1. The Parking Problem (ì™œ ì¤„ì—¬ì•¼ í•˜ëŠ”ê°€?)}


\begin{analogybox}{ê³ ì†ë„ë¡œì™€ ì£¼ì°¨ì¥ ë¹„ìœ }
\begin{itemize}
    \item \textbf{Early Stage (ê³ ì†ë„ë¡œ):} ìµœì €ì ì´ ë©€ë¦¬ ìˆìŠµë‹ˆë‹¤. ì´ë•ŒëŠ” ë³´í­ì´ ì»¤ì•¼(High $\alpha$) ë¹¨ë¦¬ ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    \item \textbf{Late Stage (ì£¼ì°¨ì¥):} ìµœì €ì  ê·¼ì²˜ì…ë‹ˆë‹¤. ì´ë•Œë„ ë³´í­ì´ í¬ë‹¤ë©´ êµ¬ë©ì„ ì§€ë‚˜ì³ ë²„ë¦¬ê³ (Overshooting), ë‹¤ì‹œ ëŒì•„ì˜¤ë ¤ë‹¤ ë˜ ì§€ë‚˜ì¹©ë‹ˆë‹¤.
    \item \textbf{Solution:} ëª©ì ì§€ì— ê°€ê¹Œì›Œì§ˆìˆ˜ë¡ ì†ë„ë¥¼ ì„œì„œíˆ ì¤„ì—¬ì„œ ì •ë°€í•˜ê²Œ ì£¼ì°¨(ìˆ˜ë ´)í•´ì•¼ í•©ë‹ˆë‹¤.
\end{itemize}
\end{analogybox}

\vspace{0.5cm}\hrule\vspace{0.5cm}

\subsection{2. Decay Schedules (ê°ì‡  ì „ëµ)}
ì‹œê°„($t$, Epoch)ì´ ì§€ë‚ ìˆ˜ë¡ $\alpha$ë¥¼ ì¤„ì´ëŠ” ëŒ€í‘œì ì¸ ê³µì‹ë“¤ì…ë‹ˆë‹¤.

\begin{itemize}
    \item \textbf{1. Inverse Time Decay (ì‹œê°„ ê¸°ë°˜):}
    $$ \alpha = \frac{1}{1 + k \cdot t} \alpha_0 $$
    ê°€ì¥ ì™„ë§Œí•˜ê²Œ ì¤„ì–´ë“­ë‹ˆë‹¤.
    
    \item \textbf{2. Exponential Decay (ì§€ìˆ˜ ê°ì‡ ):}
    $$ \alpha = k^t \cdot \alpha_0 \quad (k < 1, \text{ì˜ˆ: } 0.95) $$
    ë¹ ë¥´ê²Œ 0ìœ¼ë¡œ ìˆ˜ë ´í•©ë‹ˆë‹¤.
    
    \item \textbf{3. Step Decay (ê³„ë‹¨ì‹ ê°ì‡ ):}
    10 ì—í­ë§ˆë‹¤ ì ˆë°˜ìœ¼ë¡œ ëš ë–¨ì–´ëœ¨ë¦½ë‹ˆë‹¤. (ResNet ë“± ì‹¬ì¸µ ëª¨ë¸ì—ì„œ ì„ í˜¸)
    
\end{itemize}

\vspace{0.5cm}\hrule\vspace{0.5cm}

\section{Deep Dive: Adaptive Methodsì™€ì˜ ê´€ê³„}

"êµìˆ˜ë‹˜, Adamì´ ì•Œì•„ì„œ í•™ìŠµë¥  ì¡°ì ˆí•´ì£¼ì§€ ì•Šë‚˜ìš”?"
\begin{itemize}
    \item \textbf{Adam/RMSprop:} íŒŒë¼ë¯¸í„°ë§ˆë‹¤ *ê°œë³„ì ìœ¼ë¡œ* í•™ìŠµë¥ ì„ ì¡°ì ˆ(Adaptive)í•˜ì§€ë§Œ, ì „ì²´ì ì¸ *ê¸€ë¡œë²Œ í•™ìŠµë¥ *($\alpha$) ìì²´ëŠ” ê³ ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
    \item \textbf{ê²°ë¡ :} Adamì„ ì“°ë”ë¼ë„ Learning Rate Decayë¥¼ í•¨ê»˜ ì ìš©í•˜ë©´, ìµœì €ì ì—ì„œì˜ ì§„ë™ì„ ì¤„ì—¬ ì„±ëŠ¥ì„ ë” ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. (SOTA ëª¨ë¸ë“¤ì˜ í•„ìˆ˜ í…Œí¬ë‹‰)
\end{itemize}

% --- 7. êµ¬í˜„ ì½”ë“œ ---
\section{Implementation: Decay Scheduler}

ì§ì ‘ ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ë§Œë“¤ê³  ê·¸ë˜í”„ë¥¼ ê·¸ë ¤ë´…ì‹œë‹¤.

\begin{lstlisting}[language=Python, caption=Learning Rate Schedulers, breaklines=true]
import numpy as np
import matplotlib.pyplot as plt

class LRScheduler:
    def __init__(self, init_lr=1.0):
        self.init_lr = init_lr
        
    def inverse_time_decay(self, epoch, k=0.1):
        """lr = lr0 / (1 + kt)"""
        return self.init_lr / (1 + k * epoch)
        
    def exponential_decay(self, epoch, k=0.95):
        """lr = lr0 * k^t"""
        return self.init_lr * np.power(k, epoch)
        
    def step_decay(self, epoch, drop=0.5, interval=10):
        """íŠ¹ì • ê°„ê²©(interval)ë§ˆë‹¤ drop ë¹„ìœ¨ë§Œí¼ ê°ì†Œ"""
        exponent = np.floor((1 + epoch) / interval)
        return self.init_lr * np.power(drop, exponent)

# --- ì‹œê°í™” ---
if __name__ == "__main__":
    epochs = np.arange(0, 100)
    scheduler = LRScheduler(init_lr=1.0)
    
    lr1 = [scheduler.inverse_time_decay(e) for e in epochs]
    lr2 = [scheduler.exponential_decay(e) for e in epochs]
    lr3 = [scheduler.step_decay(e) for e in epochs]
    
    plt.figure(figsize=(10, 6))
    plt.plot(epochs, lr1, label='Inverse Time')
    plt.plot(epochs, lr2, label='Exponential')
    plt.plot(epochs, lr3, label='Step Decay')
    plt.title('Learning Rate Decay Schedules')
    plt.xlabel('Epochs')
    plt.ylabel('Learning Rate')
    plt.legend()
    plt.grid(True)
    plt.show()
\end{lstlisting}

% --- 8. FAQ ---
\section{FAQ \& Pitfalls}

\begin{tipbox}{ReduceLROnPlateau (ì‹¤ì „ ê¿€íŒ)}
ê°€ì¥ ì‹¤ìš©ì ì¸ ë°©ë²•ì€ ìˆ˜ì‹ë³´ë‹¤ëŠ” \textbf{ì„±ëŠ¥}ì„ ë³´ê³  ì¤„ì´ëŠ” ê²ƒì…ë‹ˆë‹¤.
\textbf{"ì§€ë‚œ 10 ì—í­ ë™ì•ˆ Dev Errorê°€ ì¤„ì–´ë“¤ì§€ ì•Šì•˜ë„¤? (Plateau)"} $\rightarrow$ \textbf{"ì´ì œ ì •ë°€ íƒ€ê²©í•  ë•Œë‹¤. í•™ìŠµë¥ ì„ 1/10ë¡œ ì¤„ì—¬ë¼."}
Kerasë‚˜ PyTorchì—ì„œ `ReduceLROnPlateau` ì½œë°±ì„ ì‚¬ìš©í•˜ë©´ ë©ë‹ˆë‹¤.
\end{tipbox}

\textbf{Q. $k$(ê°ì‡ ìœ¨)ê°€ ë„ˆë¬´ í¬ë©´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?} \\
\textbf{A.} í•™ìŠµë¥ ì´ ë„ˆë¬´ ë¹¨ë¦¬ 0ì´ ë˜ì–´ë²„ë¦½ë‹ˆë‹¤. ìµœì €ì ì— ë„ë‹¬í•˜ê¸°ë„ ì „ì— ëª¨ë¸ì´ ë©ˆì¶°ë²„ë¦¬ëŠ” \textbf{ì¡°ê¸° ìˆ˜ë ´(Premature Convergence)} ë¬¸ì œê°€ ë°œìƒí•©ë‹ˆë‹¤.

% --- 9. ë‹¤ìŒ ë‹¨ì› ì—°ê²° ---
\section*{ğŸ”— ë‹¤ìŒ ë‹¨ê³„ (Next Step)}
ì´ì œ ìµœì í™” ë„êµ¬ë“¤ì€ ëª¨ë‘ ê°–ì·„ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ê°€ ë„ˆë¬´ ë§ì•„ì¡ŒìŠµë‹ˆë‹¤.
($\alpha, \beta_1, \beta_2, \epsilon, k, \lambda, \text{batch\_size} \dots$)

ì´ ë§ì€ ë‹¤ì´ì–¼ì„ ì–´ë–¤ ìˆœì„œë¡œ, ì–´ë–»ê²Œ ë§ì¶°ì•¼ í• ê¹Œìš”? ì‚¬ëŒì´ ì¼ì¼ì´ ëŒë ¤ë³´ê¸°ì—” ì‹œê°„ì´ ë„ˆë¬´ ë¶€ì¡±í•©ë‹ˆë‹¤.
ë‹¤ìŒ ì‹œê°„ì—ëŠ” \textbf{[Hyperparameter Tuning]} ì „ëµì„ í†µí•´, ì´ ë³µì¡í•œ í¼ì¦ì„ ì²´ê³„ì ìœ¼ë¡œ í‘¸ëŠ” ë²•ì„ ë°°ì›ë‹ˆë‹¤. \textbf{Grid Search}ì™€ \textbf{Random Search}ì˜ ìŠ¹ë¶€ê°€ í¼ì³ì§‘ë‹ˆë‹¤.

\vspace{0.5cm}

\begin{summarybox}{ë‹¨ì› ìš”ì•½ (Cheat Sheet)}
\begin{enumerate}
    \item \textbf{Need for Decay:} ê³ ì • í•™ìŠµë¥ ì€ ìµœì €ì  ê·¼ì²˜ì—ì„œ ì§„ë™í•œë‹¤. ì •ë°€í•œ ìˆ˜ë ´ì„ ìœ„í•´ ì¤„ì—¬ì•¼ í•œë‹¤.
    \item \textbf{Schedules:} Inverse Time(ì™„ë§Œ), Exponential(ê¸‰ê²©), Step(ê³„ë‹¨ì‹) ë“±ì´ ìˆë‹¤.
    \item \textbf{Best Practice:} Dev Errorê°€ ì •ì²´ë  ë•Œ ì¤„ì´ëŠ” \texttt{ReduceLROnPlateau} ë°©ì‹ì´ ê°€ì¥ íš¨ê³¼ì ì´ë‹¤.
    \item \textbf{With Adam:} Adamì„ ì“°ë”ë¼ë„ Decayë¥¼ í•¨ê»˜ ì“°ë©´ ì„±ëŠ¥ì´ ë” ì¢‹ì•„ì§„ë‹¤.
\end{enumerate}
\end{summarybox}

\end{document}