\documentclass[a4paper, 11pt]{article}

% --- íŒ¨í‚¤ì§€ ì„¤ì • ---
\usepackage{kotex} % í•œê¸€ ì§€ì›
\usepackage{geometry} % ì—¬ë°± ì„¤ì •
\geometry{left=25mm, right=25mm, top=25mm, bottom=25mm}
\usepackage{amsmath, amssymb, amsfonts} % ìˆ˜ì‹ íŒ¨í‚¤ì§€
\usepackage{graphicx}
\usepackage{adjustbox}  % í‘œ/ë°•ìŠ¤ í¬ê¸° ì¡°ì ˆ % ì´ë¯¸ì§€ ì‚½ì…
\usepackage{hyperref} % í•˜ì´í¼ë§í¬
\usepackage{xcolor} % ìƒ‰ìƒ ì§€ì›
\usepackage{listings} % ì½”ë“œ ë¸”ë¡
\usepackage[most]{tcolorbox}
\tcbuselibrary{breakable} % ë°•ìŠ¤ ë””ìì¸
\usepackage{enumitem} % ë¦¬ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼
\usepackage{booktabs} % í‘œ ë””ìì¸

% --- ìƒ‰ìƒ ì •ì˜ ---
\definecolor{conceptblue}{RGB}{60, 100, 160}
\definecolor{analogygreen}{RGB}{80, 160, 100}
\definecolor{alertred}{RGB}{200, 60, 60}
\definecolor{exampleorange}{RGB}{230, 120, 30}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{backcolour}{rgb}{0.96,0.96,0.96}

% --- ì½”ë“œ ìŠ¤íƒ€ì¼ ì„¤ì • ---
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{analogygreen},
    keywordstyle=\color{conceptblue},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{exampleorange},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=4,
    frame=single
}
\lstset{style=mystyle}

% --- ë°•ìŠ¤ ìŠ¤íƒ€ì¼ ì •ì˜ ---
\newtcolorbox{summarybox}[1]{
    colback=conceptblue!5!white,
    colframe=conceptblue!80!black,
    fonttitle=\bfseries,
    title=ğŸ“Œ #1
}

\newtcolorbox{analogybox}[1]{
    colback=analogygreen!5!white,
    colframe=analogygreen!80!black,
    fonttitle=\bfseries,
    title=ğŸ’¡ #1 (ì§ê´€ì  ë¹„ìœ )
}

\newtcolorbox{warningbox}[1]{
    colback=alertred!5!white,
    colframe=alertred!80!black,
    fonttitle=\bfseries,
    title=âš ï¸ #1 (ì˜¤í•´ ë°©ì§€ ê°€ì´ë“œ)
}

\newtcolorbox{examplebox}[1]{
    colback=exampleorange!5!white,
    colframe=exampleorange!80!black,
    fonttitle=\bfseries,
    title=ğŸ§® #1 (ì‹¤ì „ ì‹œë‚˜ë¦¬ì˜¤ \& ë²¤ì¹˜ë§ˆí¬)
}

% --- ë¬¸ì„œ ì •ë³´ ---
\title{\textbf{[CS230] Foundations of Neural Networks: \\ Python \& Vectorization}}
\author{Lecturer: Gemini (Integrated Editor)}
\date{}

\begin{document}

\maketitle

% --- 1. ì „ì²´ ëª©ì°¨ (TOC) ---
\section*{ğŸ“š Course Table of Contents}
\begin{itemize}
    \item[Chapter 1.] Deep Learning Big Picture \textit{- Completed}
    \item[Chapter 2.] Logistic Regression as a Neural Network
    \begin{itemize}
        \item 2.1 Architecture \& Forward Propagation \textit{- Completed}
        \item 2.2 Cost Function \& Gradient Descent \textit{- Completed}
        \item \textbf{2.3 Python \& Vectorization (Current Unit)}
        \begin{itemize}
            \item Overview: Why Vectorization?
            \item SIMD: The Hardware Magic
            \item Broadcasting Rules
            \item Implementation \& Benchmark
        \end{itemize}
    \end{itemize}
    \item[Chapter 3.] Shallow Neural Networks \textit{- Upcoming}
\end{itemize}

\vspace{0.5cm}
\hrule
\vspace{0.5cm}

% --- 3. ì´ì „ ë‹¨ì› ì—°ê²° ---
\section*{ğŸ”— ì§€ë‚œ ì‹œê°„ ë³µìŠµ ë° ì—°ê²°}
ìš°ë¦¬ëŠ” ì§€ë‚œ ì‹œê°„ê¹Œì§€ ë”¥ëŸ¬ë‹ì˜ \textbf{'ì´ë¡ ì  í† ëŒ€(ë¹„ìš© í•¨ìˆ˜, ê²½ì‚¬ í•˜ê°•ë²•)'}ë¥¼ ì™„ì„±í–ˆìŠµë‹ˆë‹¤. ì´ë¡ ì ìœ¼ë¡œëŠ” ì™„ë²½í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ ì´ ìˆ˜ì‹ì„ ì»´í“¨í„°ì—ê²Œ ê·¸ëŒ€ë¡œ ì£¼ë©´ í•™ìŠµí•˜ëŠ” ë° ìˆ˜ì‹­ ë…„ì´ ê±¸ë¦´ì§€ë„ ëª¨ë¦…ë‹ˆë‹¤. ì´ì œ ì´ ì´ë¡ ì— \textbf{'ì œíŠ¸ ì—”ì§„'}ì„ ë‹¬ì•„ì¤„ ì‹œê°„ì…ë‹ˆë‹¤. ì´ˆì‹¬ìì™€ ì „ë¬¸ê°€ë¥¼ ê°€ë¥´ëŠ” ê°€ì¥ ê²°ì •ì ì¸ ê¸°ìˆ , \textbf{ë²¡í„°í™”(Vectorization)}ë¥¼ ë°°ì›Œë´…ì‹œë‹¤.

% --- 4. ê°œìš” ---
\section{Unit Overview}
\begin{summarybox}{í•µì‹¬ ëª©í‘œ}
ì´ ë‹¨ì›ì€ ë”¥ëŸ¬ë‹ ì½”ë“œë¥¼ ìˆ˜ë°± ë°° ë¹ ë¥´ê²Œ ë§Œë“œëŠ” \textbf{'ìµœì í™” ê¸°ìˆ '}ì„ ë‹¤ë£¹ë‹ˆë‹¤.
\begin{itemize}
    \item \textbf{ê°œë…:} `for-loop`ë¥¼ ì£„ì•…ì‹œí•˜ê³ , í–‰ë ¬ ë‹¨ìœ„ ì—°ì‚°(Vectorization)ì„ í•´ì•¼ í•˜ëŠ” ì´ìœ ë¥¼ ë°°ì›ë‹ˆë‹¤.
    \item \textbf{ì›ë¦¬:} CPU/GPUì˜ SIMD(ë³‘ë ¬ ì²˜ë¦¬) ì•„í‚¤í…ì²˜ê°€ ì–´ë–»ê²Œ ì—°ì‚°ì„ ê°€ì†í•˜ëŠ”ì§€ ì´í•´í•©ë‹ˆë‹¤.
    \item \textbf{ê¸°ìˆ :} NumPyì˜ í•µì‹¬ ê¸°ëŠ¥ì¸ \textbf{ë¸Œë¡œë“œìºìŠ¤íŒ…(Broadcasting)}ì˜ ê·œì¹™ê³¼ ìœ„í—˜ì„±ì„ íŒŒì•…í•©ë‹ˆë‹¤.
    \item \textbf{ê²€ì¦:} ì‹¤ì œ ì½”ë“œë¡œ 100ë§Œ ê°œì˜ ë°ì´í„°ë¥¼ ì—°ì‚°í•´ë³´ë©° ì†ë„ ì°¨ì´ë¥¼ ëˆˆìœ¼ë¡œ í™•ì¸í•©ë‹ˆë‹¤.
\end{itemize}
\end{summarybox}

% --- 5. ìš©ì–´ ì •ë¦¬ ---
\section{Essential Terminology}
\begin{center}
\begin{tabular}{|c|l|l|}
\hline
\textbf{ìš©ì–´} & \textbf{ì„¤ëª…} & \textbf{í•œ ì¤„ í•µì‹¬ ìš”ì•½} \\ \hline
\textbf{Vectorization} & ë²¡í„°í™” & ë°˜ë³µë¬¸ ì—†ì´ ë°ì´í„°ë¥¼ í†µì§¸ë¡œ(í–‰ë ¬ë¡œ) ì—°ì‚°í•˜ëŠ” ê¸°ë²• \\ \hline
\textbf{SIMD} & Single Instruction, Multiple Data & ëª…ë ¹ì–´ í•˜ë‚˜ë¡œ ì—¬ëŸ¬ ë°ì´í„°ë¥¼ ë™ì‹œì— ì²˜ë¦¬í•˜ëŠ” CPU ê¸°ìˆ  \\ \hline
\textbf{Broadcasting} & ë¸Œë¡œë“œìºìŠ¤íŒ… & ëª¨ì–‘ì´ ë‹¤ë¥¸ ë°°ì—´ë¼ë¦¬ ì—°ì‚°í•  ë•Œ ìë™ìœ¼ë¡œ í¬ê¸°ë¥¼ ë§ì¶°ì£¼ëŠ” ê¸°ëŠ¥ \\ \hline
\textbf{NumPy} & ë„˜íŒŒì´ & íŒŒì´ì¬ì˜ ëŠë¦° ì†ë„ë¥¼ Cì–¸ì–´ ë ˆë²¨ ìµœì í™”ë¡œ ê·¹ë³µí•œ ìˆ˜ì¹˜ ì—°ì‚° ë¼ì´ë¸ŒëŸ¬ë¦¬ \\ \hline
\textbf{Rank-1 Array} & ë­í¬-1 ë°°ì—´ & `(5,)` ì²˜ëŸ¼ í–‰ë„ ì—´ë„ ì•„ë‹Œ ì• ë§¤í•œ ë°°ì—´ (ë²„ê·¸ì˜ ì£¼ë²”) \\ \hline
\end{tabular}
\end{center}

% --- 6. í•µì‹¬ ê°œë… ìƒì„¸ ì„¤ëª… ---
\section{Core Concepts: ì†ë„ì˜ ë¹„ë°€}

\subsection{1. Vectorization (ë²¡í„°í™”ë€ ë¬´ì—‡ì¸ê°€?)}
\textbf{í•œ ì¤„ ìš”ì•½:} í•˜ë‚˜ì”© ì²˜ë¦¬í•˜ì§€ ë§ê³ , íŠ¸ëŸ­ì— ì‹¤ì–´ì„œ í•œ ë²ˆì— ì˜®ê¸°ì‹­ì‹œì˜¤.

\begin{analogybox}{ì´ì‚¬ì§ ì˜®ê¸°ê¸° ë¹„ìœ }
100ë§Œ ê°œì˜ ë²½ëŒ(ë°ì´í„°)ì„ ì˜®ê²¨ì•¼ í•©ë‹ˆë‹¤.
\begin{itemize}
    \item \textbf{For-loop (Non-vectorized):} ì¸ë¶€ê°€ ë²½ëŒì„ \textbf{ì†ì— í•˜ë‚˜ì”© ë“¤ê³ } 100ë§Œ ë²ˆ ì™•ë³µí•©ë‹ˆë‹¤. (íŒŒì´ì¬ì´ ë°ì´í„°ë¥¼ í•˜ë‚˜ì”© êº¼ë‚´ì„œ ì²˜ë¦¬í•¨)
    \item \textbf{Vectorization:} 100ë§Œ ê°œì˜ ë²½ëŒì„ \textbf{ê±°ëŒ€í•œ ë¤í”„íŠ¸ëŸ­(í–‰ë ¬)}ì— ì‹£ê³  ë‹¨ í•œ ë²ˆì— ì´ë™í•©ë‹ˆë‹¤. (NumPyê°€ ë°ì´í„°ë¥¼ í†µì§¸ë¡œ ë©”ëª¨ë¦¬ì— ì˜¬ë ¤ ì²˜ë¦¬í•¨)
\end{itemize}
\end{analogybox}

\textbf{ê¸°ìˆ ì  ì •ì˜:}
$z = w^T x + b$ë¥¼ ê³„ì‚°í•  ë•Œ, $w_1x_1, w_2x_2 \dots$ë¥¼ ìˆœíšŒí•˜ì§€ ì•Šê³ , $w$ì™€ $x$ ì „ì²´ ë²¡í„°ë¥¼ í•œ ë²ˆì— ë‚´ì (Dot Product)í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

\vspace{0.5cm}\hrule\vspace{0.5cm}

\subsection{2. Under the Hood: SIMD (í•˜ë“œì›¨ì–´ì˜ ë§ˆë²•)}
ì™œ NumPy(`np.dot`)ê°€ `for`ë¬¸ë³´ë‹¤ ë¹ ë¥¼ê¹Œìš”? ë‹¨ìˆœíˆ Cì–¸ì–´ë¡œ ì§œì—¬ì„œê°€ ì•„ë‹™ë‹ˆë‹¤. ì»´í“¨í„° êµ¬ì¡°ì ì¸ ì´ìœ ê°€ ìˆìŠµë‹ˆë‹¤.



\begin{itemize}
    \item \textbf{SISD (Single Instruction, Single Data):} ì¼ë°˜ì ì¸ `for`ë¬¸ì…ë‹ˆë‹¤. CPUê°€ "ê°€ì ¸ì™€", "ê³±í•´", "ì €ì¥í•´"ë¥¼ ë°ì´í„° í•˜ë‚˜ë§ˆë‹¤ ë°˜ë³µí•©ë‹ˆë‹¤.
    \item \textbf{SIMD (Single Instruction, Multiple Data):} ìµœì‹  CPUëŠ” "ì´ 8ê°œì˜ ë°ì´í„°ë¥¼ ë™ì‹œì— ê³±í•´!"ë¼ëŠ” ëª…ë ¹ì„ ë‚´ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë²¡í„°í™”ëŠ” ì´ ë³‘ë ¬ ì²˜ë¦¬ ê¸°ëŠ¥ì„ í™œìš©í•©ë‹ˆë‹¤.
\end{itemize}

\vspace{0.5cm}\hrule\vspace{0.5cm}

\subsection{3. Broadcasting (ë¸Œë¡œë“œìºìŠ¤íŒ…)}
\textbf{í•œ ì¤„ ìš”ì•½:} ì‘ì€ í–‰ë ¬ì„ í° í–‰ë ¬ í¬ê¸°ì— ë§ê²Œ ìë™ìœ¼ë¡œ 'ëŠ˜ë ¤ì„œ(Stretch)' ì—°ì‚°í•©ë‹ˆë‹¤.



\begin{itemize}
    \item \textbf{ìƒí™©:} $(4 \times 1)$ í–‰ë ¬ì— ìˆ«ì $100$(ìŠ¤ì¹¼ë¼)ì„ ë”í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤.
    \item \textbf{ì›ì¹™:} ìˆ˜í•™ì ìœ¼ë¡œëŠ” ë¶ˆê°€ëŠ¥í•˜ì§€ë§Œ, Pythonì€ $100$ì„ ìë™ìœ¼ë¡œ $(4 \times 1)$ í¬ê¸°ë¡œ ë³µì‚¬í•˜ì—¬ ë”í•´ì¤ë‹ˆë‹¤.
    \item \textbf{ì˜ˆì‹œ:} 
    $$ \begin{bmatrix} 1 \\ 2 \\ 3 \\ 4 \end{bmatrix} + 100 \rightarrow \begin{bmatrix} 1 \\ 2 \\ 3 \\ 4 \end{bmatrix} + \begin{bmatrix} 100 \\ 100 \\ 100 \\ 100 \end{bmatrix} = \begin{bmatrix} 101 \\ 102 \\ 103 \\ 104 \end{bmatrix} $$
\end{itemize}

% --- 7. ì‹¤ì „ ë²¤ì¹˜ë§ˆí¬ ---
\section{Implementation \& Benchmark (ì„±ëŠ¥ ê²€ì¦)}

"ë°±ë¬¸ì´ ë¶ˆì—¬ì¼ê²¬"ì…ë‹ˆë‹¤. 100ë§Œ ê°œì˜ ë°ì´í„°ë¥¼ ê³±í•˜ëŠ” ì‹œê°„ì„ ì§ì ‘ ì¸¡ì •í•´ ë´…ì‹œë‹¤.

\begin{examplebox}{For-loop vs Vectorization ì†ë„ ëŒ€ê²°}
\begin{lstlisting}[language=Python, breaklines=true]
import numpy as np
import time

# ë°ì´í„° ì¤€ë¹„: 100ë§Œ ê°œì˜ ë‚œìˆ˜ ìƒì„±
a = np.random.rand(1000000)
b = np.random.rand(1000000)

# --- 1. For-loop (ëŠë¦° ë°©ë²•) ---
c = 0
tic = time.time()
for i in range(1000000):
    c += a[i] * b[i]
toc = time.time()

print(f"For-loop: {c:.4f}")
print(f"Time: {1000 * (toc - tic):.2f} ms") # ì•½ 400~500ms ì†Œìš”

# --- 2. Vectorization (ë¹ ë¥¸ ë°©ë²•) ---
tic = time.time()
c_vec = np.dot(a, b) # SIMD ë³‘ë ¬ ì²˜ë¦¬
toc = time.time()

print(f"Vectorized: {c_vec:.4f}")
print(f"Time: {1000 * (toc - tic):.2f} ms") # ì•½ 1~2ms ì†Œìš”
\end{lstlisting}
\textbf{ê²°ê³¼ ë¶„ì„:} ë²¡í„°í™” ì½”ë“œê°€ ì•½ \textbf{300~500ë°°} ë” ë¹ ë¦…ë‹ˆë‹¤. ë”¥ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ ì‹œê°„ì´ 1ë‹¬ ê±¸ë¦´ ê²ƒì„ 2ì‹œê°„ìœ¼ë¡œ ì¤„ì—¬ì£¼ëŠ” ë§ˆë²•ì…ë‹ˆë‹¤.
\end{examplebox}

% --- 8. ì£¼ì˜ì‚¬í•­ ë° FAQ ---
\section{Pitfalls \& FAQ}

\begin{warningbox}{Rank-1 Arrayì˜ í•¨ì •}
NumPyì—ì„œ `a = np.random.randn(5)`ë¥¼ í•˜ë©´ ëª¨ì–‘(Shape)ì´ `(5,)`ê°€ ë©ë‹ˆë‹¤.
ì´ê²ƒì€ í–‰ ë²¡í„°ë„, ì—´ ë²¡í„°ë„ ì•„ë‹Œ ì• ë§¤í•œ ìƒíƒœë¼ ì „ì¹˜(Transpose)ê°€ ì•ˆ ë©ë‹ˆë‹¤.
\begin{itemize}
    \item \textbf{ë‚˜ìœ ì˜ˆ:} `a = np.random.randn(5)` $\rightarrow$ ë²„ê·¸ ë°œìƒ ìœ„í—˜ ë†’ìŒ.
    \item \textbf{ì¢‹ì€ ì˜ˆ:} `a = np.random.randn(5, 1)` (ì—´ ë²¡í„°) ë˜ëŠ” `(1, 5)` (í–‰ ë²¡í„°)ë¡œ ëª…ì‹œí•˜ì‹­ì‹œì˜¤.
    \item \textbf{ìŠµê´€:} ì½”ë“œ ì¤‘ê°„ì— `assert(a.shape == (5, 1))`ì„ ë„£ì–´ ì°¨ì›ì„ í™•ì¸í•˜ì‹­ì‹œì˜¤.
\end{itemize}
\end{warningbox}

\subsection*{FAQ: ìì£¼ ë¬»ëŠ” ì§ˆë¬¸}
\textbf{Q1. GPUëŠ” ì–¸ì œ ì“°ë‚˜ìš”?} \\
A. NumPyëŠ” ê¸°ë³¸ì ìœ¼ë¡œ CPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ë‚˜ì¤‘ì— ë°°ìš¸ TensorFlowë‚˜ PyTorchëŠ” ì´ ë²¡í„°í™” ì—°ì‚°ì„ GPU(ê·¸ë˜í”½ ì¹´ë“œ)ì—ì„œ ìˆ˜í–‰í•˜ì—¬, CPUë³´ë‹¤ í›¨ì”¬ ë” ë§ì€ ë³‘ë ¬ ì²˜ë¦¬(ìˆ˜ì²œ ê°œì˜ ì½”ì–´)ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. ì›ë¦¬ëŠ” ë˜‘ê°™ìŠµë‹ˆë‹¤.

\textbf{Q2. ëª¨ë“  ì½”ë“œë¥¼ ë²¡í„°í™”í•  ìˆ˜ ìˆë‚˜ìš”?} \\
A. ëŒ€ë¶€ë¶„ì˜ ìˆ˜í•™ ì—°ì‚°ì€ ê°€ëŠ¥í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ ë³µì¡í•œ ì¡°ê±´ë¬¸(`if-else`)ì´ ë°ì´í„°ë§ˆë‹¤ ë‹¤ë¥´ê²Œ ì ìš©ë˜ì–´ì•¼ í•œë‹¤ë©´ ë²¡í„°í™”ê°€ ì–´ë ¤ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¼ì—ë„ 99\%ì˜ ë”¥ëŸ¬ë‹ ì—°ì‚°ì€ ë²¡í„°í™”ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.

% --- 9. ë‹¤ìŒ ë‹¨ì› ì—°ê²° ---
\section*{ğŸ”— ë‹¤ìŒ ë‹¨ê³„ (Next Step)}
ì¶•í•˜í•©ë‹ˆë‹¤! ì—¬ëŸ¬ë¶„ì€ ì´ì œ \textbf{'ê³ ì† ì—°ì‚° ì—”ì§„(Vectorization)'}ì„ ì¥ì°©í–ˆìŠµë‹ˆë‹¤. 

ì§€ê¸ˆê¹Œì§€ëŠ” ë‰´ëŸ°ì´ ë”± í•˜ë‚˜(ë¡œì§€ìŠ¤í‹± íšŒê·€)ë¿ì´ì—ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ì¥ \textbf{[Chapter 3. Shallow Neural Networks]}ì—ì„œëŠ” ì´ ê°•ë ¥í•œ ì—”ì§„ì„ í™œìš©í•´ ë‰´ëŸ°ì„ ìˆ˜ë°± ê°œë¡œ ëŠ˜ë ¤ë³´ê² ìŠµë‹ˆë‹¤. ì´ì œ ì§„ì§œ 'ì‹ ê²½ë§'ë‹¤ìš´ ì‹ ê²½ë§ì„ ë§Œë“¤ ì°¨ë¡€ì…ë‹ˆë‹¤.

\vspace{0.5cm}

\begin{summarybox}{ë‹¨ì› ìš”ì•½ (Cheat Sheet)}
\begin{enumerate}
    \item \textbf{Vectorization:} `for`ë¬¸ì€ ì£„ì•…ì´ë‹¤. `np.dot` ë“±ì„ ì¨ì„œ í–‰ë ¬ ë‹¨ìœ„ë¡œ ê³„ì‚°í•˜ë¼.
    \item \textbf{SIMD:} ë²¡í„°í™”ëŠ” CPUì˜ ë³‘ë ¬ ì²˜ë¦¬ ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì†ë„ë¥¼ ìˆ˜ë°± ë°° ë†’ì¸ë‹¤.
    \item \textbf{Broadcasting:} ì°¨ì›ì´ ë‹¬ë¼ë„ NumPyê°€ ì•Œì•„ì„œ ë§ì¶°ì£¼ì§€ë§Œ, ë²„ê·¸ë¥¼ ì¡°ì‹¬í•´ì•¼ í•œë‹¤.
    \item \textbf{Shape Check:} `(n,)` ëŒ€ì‹  `(n, 1)`ì„ ì‚¬ìš©í•˜ì—¬ ì°¨ì›ì„ ëª…ì‹œí•˜ëŠ” ìŠµê´€ì„ ë“¤ì—¬ë¼.
\end{enumerate}
\end{summarybox}

\end{document}