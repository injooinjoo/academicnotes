\documentclass[a4paper, 11pt]{article}

% --- íŒ¨í‚¤ì§€ ì„¤ì • ---
\usepackage{kotex} % í•œê¸€ ì§€ì›
\usepackage{geometry} % ì—¬ë°± ì„¤ì •
\geometry{left=25mm, right=25mm, top=25mm, bottom=25mm}
\usepackage{amsmath, amssymb, amsfonts} % ìˆ˜ì‹ íŒ¨í‚¤ì§€
\usepackage{graphicx}
\usepackage{adjustbox}  % í‘œ/ë°•ìŠ¤ í¬ê¸° ì¡°ì ˆ % ì´ë¯¸ì§€ ì‚½ì…
\usepackage{hyperref} % í•˜ì´í¼ë§í¬
\usepackage{xcolor} % ìƒ‰ìƒ ì§€ì›
\usepackage{listings} % ì½”ë“œ ë¸”ë¡
\usepackage[most]{tcolorbox}
\tcbuselibrary{breakable} % ë°•ìŠ¤ ë””ìì¸
\usepackage{enumitem} % ë¦¬ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼
\usepackage{booktabs} % í‘œ ë””ìì¸
\usepackage{array} % í‘œ ì •ë ¬

% --- ìƒ‰ìƒ ì •ì˜ ---
\definecolor{conceptblue}{RGB}{60, 100, 160}
\definecolor{analogygreen}{RGB}{80, 160, 100}
\definecolor{alertred}{RGB}{200, 60, 60}
\definecolor{exampleorange}{RGB}{230, 120, 30}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{backcolour}{rgb}{0.96,0.96,0.96}

% --- ì½”ë“œ ìŠ¤íƒ€ì¼ ì„¤ì • ---
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{analogygreen},
    keywordstyle=\color{conceptblue},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{exampleorange},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=4,
    frame=single
}
\lstset{style=mystyle}

% --- ë°•ìŠ¤ ìŠ¤íƒ€ì¼ ì •ì˜ ---
\newtcolorbox{summarybox}[1]{
    colback=conceptblue!5!white,
    colframe=conceptblue!80!black,
    fonttitle=\bfseries,
    title=ğŸ“Œ #1
}

\newtcolorbox{analogybox}[1]{
    colback=analogygreen!5!white,
    colframe=analogygreen!80!black,
    fonttitle=\bfseries,
    title=ğŸ’¡ #1 (ì§ê´€ì  ë¹„ìœ )
}

\newtcolorbox{warningbox}[1]{
    colback=alertred!5!white,
    colframe=alertred!80!black,
    fonttitle=\bfseries,
    title=âš ï¸ #1 (ì˜¤í•´ ë°©ì§€ ê°€ì´ë“œ)
}

\newtcolorbox{mathbox}[1]{
    colback=exampleorange!5!white,
    colframe=exampleorange!80!black,
    fonttitle=\bfseries,
    title=ğŸ§® #1 (ìˆ˜í•™ì  ì›ë¦¬)
}

% --- ë¬¸ì„œ ì •ë³´ ---
\title{\textbf{[CS230] Improving Deep Neural Networks: \\ Dropout Regularization}}
\author{Lecturer: Gemini (Integrated Editor)}
\date{}

\begin{document}

\maketitle

% --- 1. ì „ì²´ ëª©ì°¨ (TOC) ---
\section*{ğŸ“š Course Table of Contents}
\begin{itemize}
    \item[Chapter 1-4.] Neural Networks Basics \textit{- Completed}
    \item[\textbf{Chapter 5.}] \textbf{Practical Aspects of Deep Learning (Current Unit)}
    \begin{itemize}
        \item 5.1 Train / Dev / Test Sets Strategy \textit{- Completed}
        \item 5.2 Bias vs Variance Analysis \textit{- Completed}
        \item 5.3 Regularization (L1/L2) \textit{- Completed}
        \item \textbf{5.4 Dropout Regularization}
        \begin{itemize}
            \item The Concept: Killing Neurons
            \item Why does it work? (Ensemble Effect)
            \item Inverted Dropout (Scaling)
            \item Implementation Details
        \end{itemize}
        \item 5.5 Input Normalization \textit{- Upcoming}
    \end{itemize}
\end{itemize}

\vspace{0.5cm}
\hrule
\vspace{0.5cm}

% --- 3. ì´ì „ ë‹¨ì› ì—°ê²° ---
\section*{ğŸ”— ì§€ë‚œ ì‹œê°„ ë³µìŠµ ë° ì—°ê²°}
ì§€ë‚œ ì‹œê°„ì— ìš°ë¦¬ëŠ” ê°€ì¤‘ì¹˜($W$)ì˜ í¬ê¸°ë¥¼ ê°•ì œë¡œ ì¤„ì—¬ë²„ë¦¬ëŠ” \textbf{L2 ì •ê·œí™”(Weight Decay)}ë¥¼ ë°°ì› ìŠµë‹ˆë‹¤.
ì˜¤ëŠ˜ ë°°ìš¸ ê¸°ë²•ì€ ì¡°ê¸ˆ ë” 'ê³¼ê²©'í•©ë‹ˆë‹¤. ëª¨ë¸ì˜ ê³¼ëŒ€ì í•©(Overfitting)ì„ ë§‰ê¸° ìœ„í•´, í•™ìŠµ ê³¼ì •ì—ì„œ ë©€ì©¡í•œ ë‰´ëŸ°ë“¤ì„ ë¬´ì‘ìœ„ë¡œ \textbf{'ì œê±°(Kill)'}í•´ë²„ë¦½ë‹ˆë‹¤. ë°”ë¡œ \textbf{ë“œë¡­ì•„ì›ƒ(Dropout)}ì…ë‹ˆë‹¤.
"ë‡Œì„¸í¬ë¥¼ ì£½ì´ëŠ”ë° ë‡Œê°€ ë” ë˜‘ë˜‘í•´ì§„ë‹¤ë‹ˆ?"ë¼ëŠ” ì˜ë¬¸ì´ ë“¤ê² ì§€ë§Œ, ì´ê²ƒì´ í˜„ëŒ€ ë”¥ëŸ¬ë‹ì—ì„œ ê°€ì¥ ê°•ë ¥í•œ ì •ê·œí™” ê¸°ë²•ì…ë‹ˆë‹¤. ê·¸ ì—­ì„¤ì ì¸ ì›ë¦¬ë¥¼ íŒŒí—¤ì³ ë³´ê² ìŠµë‹ˆë‹¤.

% --- 4. ê°œìš” ---
\section{Unit Overview}
\begin{summarybox}{í•µì‹¬ ëª©í‘œ}
ì´ ë‹¨ì›ì€ ì‹ ê²½ë§ì˜ ê°•ê±´í•¨(Robustness)ì„ ë†’ì´ëŠ” \textbf{ë“œë¡­ì•„ì›ƒ}ì˜ ì›ë¦¬ì™€ êµ¬í˜„ì„ ë‹¤ë£¹ë‹ˆë‹¤.
\begin{itemize}
    \item \textbf{ì›ë¦¬:} ë“œë¡­ì•„ì›ƒì´ ì–´ë–»ê²Œ íŠ¹ì • ë‰´ëŸ°ì— ëŒ€í•œ ì˜ì¡´ë„(Co-adaptation)ë¥¼ ë‚®ì¶”ëŠ”ì§€ ì´í•´í•©ë‹ˆë‹¤.
    \item \textbf{ìˆ˜í•™:} í•™ìŠµê³¼ í…ŒìŠ¤íŠ¸ ì‹œì˜ ì¶œë ¥ê°’ ì°¨ì´ë¥¼ ë³´ì •í•˜ëŠ” \textbf{Inverted Dropout} ê¸°ìˆ ì„ ìµí™ë‹ˆë‹¤.
    \item \textbf{ê·œì¹™:} ë“œë¡­ì•„ì›ƒì€ ì˜¤ì§ \textbf{í•™ìŠµ(Training)} ë•Œë§Œ ì¼œê³ , í…ŒìŠ¤íŠ¸(Test) ë•ŒëŠ” ëˆë‹¤ëŠ” ì›ì¹™ì„ ëª…ì‹¬í•©ë‹ˆë‹¤.
    \item \textbf{êµ¬í˜„:} NumPyë¥¼ ì‚¬ìš©í•˜ì—¬ ë§ˆìŠ¤í¬ í–‰ë ¬(Mask Matrix)ì„ ë§Œë“¤ê³  ì ìš©í•´ë´…ë‹ˆë‹¤.
\end{itemize}
\end{summarybox}

% --- 5. ìš©ì–´ ì •ë¦¬ ---
\section{Essential Terminology}
\begin{center}
\begin{tabular}{|c|l|l|}
\hline
\textbf{ìš©ì–´} & \textbf{ë³€ìˆ˜} & \textbf{ì„¤ëª…} \\ \hline
\textbf{Dropout} & - & í•™ìŠµ ì‹œ ë‰´ëŸ°ì„ ë¬´ì‘ìœ„ë¡œ ì‚­ì œ(0ìœ¼ë¡œ ì„¤ì •)í•˜ëŠ” ê¸°ë²•. \\ \hline
\textbf{Keep Probability} & \texttt{keep\_prob} & ë‰´ëŸ°ì„ \textbf{'ì‚´ë ¤ë‘˜'} í™•ë¥ . (ì˜ˆ: 0.8 = 20\% ì‚­ì œ). \\ \hline
\textbf{Inverted Dropout} & - & í•™ìŠµ ì‹œ ê°’ì„ \texttt{keep\_prob}ë¡œ ë‚˜ëˆ„ì–´ ìŠ¤ì¼€ì¼ì„ ë³´ì •í•˜ëŠ” í‘œì¤€ ë°©ì‹. \\ \hline
\textbf{Ensemble} & - & ì—¬ëŸ¬ ëª¨ë¸ì˜ ì˜ˆì¸¡ì„ í‰ê·  ë‚´ëŠ” ê²ƒ. ë“œë¡­ì•„ì›ƒì€ ì´ íš¨ê³¼ë¥¼ ëƒ„. \\ \hline
\end{tabular}
\end{center}

% --- 6. í•µì‹¬ ê°œë… ìƒì„¸ ì„¤ëª… ---
\section{Core Concepts: ë¬´ì‘ìœ„ ì‚­ì œì˜ ë¯¸í•™}

\subsection{1. ì§ê´€ì  í•´ì„ (Why does it work?)}


\begin{analogybox}{ì²œì¬ì—ê²Œ ì˜ì¡´í•˜ëŠ” íŒ€ í”„ë¡œì íŠ¸}
\begin{itemize}
    \item \textbf{ìƒí™© (No Dropout):} íŒ€ì— ì²œì¬ í•œ ëª…(íŠ¹ì • ë‰´ëŸ°)ì´ ìˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ íŒ€ì›ë“¤ì€ ê·¸ ì²œì¬ë§Œ ë¯¿ê³  ì¼ì„ ì•ˆ í•©ë‹ˆë‹¤. ë§Œì•½ ì²œì¬ê°€ ê²°ê·¼í•˜ë©´(ìƒˆë¡œìš´ ë°ì´í„°), í”„ë¡œì íŠ¸ëŠ” ë§í•©ë‹ˆë‹¤. (ê³¼ëŒ€ì í•©)
    \item \textbf{ìƒí™© (Dropout):} ë§¤ì¼ ë¬´ì‘ìœ„ë¡œ íŒ€ì›ì„ ì¶œê·¼ì‹œí‚¤ì§€ ì•ŠìŠµë‹ˆë‹¤. ì²œì¬ê°€ ê²°ê·¼í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
    \item \textbf{ê²°ê³¼:} íŒ€ì›ë“¤ì€ ëˆ„êµ¬ì—ê²Œë„ ì˜ì¡´í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ, \textbf{ëª¨ë‘ê°€ ì—…ë¬´ ì „ë°˜ì„ ìµíˆê²Œ ë©ë‹ˆë‹¤.} ê²°êµ­ íŒ€ ì „ì²´ê°€ ê°•ë ¥í•˜ê³  ìœ ì—°í•´ì§‘ë‹ˆë‹¤.
\end{itemize}
\end{analogybox}
ë“œë¡­ì•„ì›ƒì„ ì ìš©í•˜ë©´ ë‰´ëŸ°ë“¤ì´ íŠ¹ì • ì…ë ¥(ì¹œêµ¬)ì—ë§Œ ì˜ì¡´í•˜ì§€ ì•Šê³ , \textbf{ê°€ì¤‘ì¹˜ë¥¼ ê³¨ê³ ë£¨ ë¶„ì‚°(Spread out)}ì‹œí‚¤ê²Œ ë©ë‹ˆë‹¤. ì´ëŠ” L2 ì •ê·œí™”ì™€ ë¹„ìŠ·í•œ íš¨ê³¼ë¥¼ ëƒ…ë‹ˆë‹¤.

\vspace{0.5cm}\hrule\vspace{0.5cm}

\section{Deep Dive: Inverted Dropout (ì—­ ë“œë¡­ì•„ì›ƒ)}

ì´ ì„¹ì…˜ì€ ë©´ì ‘ ë‹¨ê³¨ ì§ˆë¬¸ì¸ "ì™œ í•™ìŠµ ë•Œ ê°’ì„ ë‚˜ëˆ„ë‚˜ìš”?"ì— ëŒ€í•œ ë‹µì…ë‹ˆë‹¤.

\begin{mathbox}{The Scale Problem}
\texttt{keep\_prob = 0.5} (50\% ì‚­ì œ)ë¼ê³  ê°€ì •í•©ì‹œë‹¤.

\textbf{1. í•™ìŠµ ë‹¨ê³„ (Train):}
ë‰´ëŸ°ì˜ ì ˆë°˜ì´ 0ì´ ë˜ë¯€ë¡œ, ë‹¤ìŒ ì¸µìœ¼ë¡œ ì „ë‹¬ë˜ëŠ” í•©ê³„($Z = \sum w_i a_i$)ë„ ëŒ€ëµ \textbf{ì ˆë°˜}ìœ¼ë¡œ ì¤„ì–´ë“­ë‹ˆë‹¤.

\textbf{2. í…ŒìŠ¤íŠ¸ ë‹¨ê³„ (Test):}
í…ŒìŠ¤íŠ¸ ë•ŒëŠ” ë“œë¡­ì•„ì›ƒì„ ë•ë‹ˆë‹¤(ëª¨ë“  ë‰´ëŸ° ì‚¬ìš©). $Z$ ê°’ì´ í•™ìŠµ ë•Œë³´ë‹¤ \textbf{2ë°° ë»¥íŠ€ê¸°} ë©ë‹ˆë‹¤. ì˜ˆì¸¡ê°’ì´ ì™„ì „íˆ ë‹¬ë¼ì§‘ë‹ˆë‹¤.

\textbf{3. í•´ê²°ì±… (Inverted Dropout):}
í•™ìŠµ ë‹¨ê³„ì—ì„œ ì‚´ì•„ë‚¨ì€ ë‰´ëŸ°ì˜ ê°’ì„ ë¯¸ë¦¬ \textbf{2ë°°ë¡œ í‚¤ì›Œì¤ë‹ˆë‹¤ ($A /= 0.5$)}.
ì´ë ‡ê²Œ í•˜ë©´ í•™ìŠµ ë•Œì˜ ê¸°ëŒ“ê°’($E[A]$)ì´ í…ŒìŠ¤íŠ¸ ë•Œì™€ ë¹„ìŠ·í•˜ê²Œ ìœ ì§€ë©ë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ ë•ŒëŠ” ì•„ë¬´ëŸ° ì—°ì‚°ë„ í•  í•„ìš”ê°€ ì—†ì–´ì§‘ë‹ˆë‹¤.
\end{mathbox}

% --- 7. êµ¬í˜„ ì½”ë“œ ---
\section{Implementation: Dropout Layer}

ê°€ì¥ ì¤‘ìš”í•œ ê²ƒì€ `is_training` í”Œë˜ê·¸ì…ë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ ë•ŒëŠ” ë“œë¡­ì•„ì›ƒì„ ì ìš©í•˜ë©´ ì•ˆ ë©ë‹ˆë‹¤.

\begin{lstlisting}[language=Python, caption=Inverted Dropout Implementation, breaklines=true]
import numpy as np

class Dropout:
    def __init__(self, keep_prob=0.8):
        self.keep_prob = keep_prob
        self.mask = None # ì—­ì „íŒŒìš© ë§ˆìŠ¤í¬ ì €ì¥

    def forward(self, A, is_training=True):
        """
        A: Activation values
        """
        if is_training:
            # 1. ë§ˆìŠ¤í¬ ìƒì„± (0 ~ 1 ë‚œìˆ˜ < keep_prob)
            # keep_probë³´ë‹¤ ì‘ìœ¼ë©´ True(1), í¬ë©´ False(0)
            D = np.random.rand(A.shape[0], A.shape[1])
            D = (D < self.keep_prob).astype(int)
            self.mask = D
            
            # 2. ë‰´ëŸ° ë„ê¸° (Shut down)
            A = A * D
            
            # 3. ìŠ¤ì¼€ì¼ ë³´ì • (Inverted Dropout í•µì‹¬!)
            A = A / self.keep_prob
            
        return A

    def backward(self, dA):
        """
        ì—­ì „íŒŒ: ì£½ì€ ë‰´ëŸ°ì€ ë¯¸ë¶„ê°’ë„ 0ì´ì–´ì•¼ í•¨
        """
        # 1. ë§ˆìŠ¤í¬ ì ìš©
        dA = dA * self.mask
        
        # 2. ìŠ¤ì¼€ì¼ ë³´ì • (ìˆœì „íŒŒ ë•Œ ë‚˜ëˆ´ìœ¼ë‹ˆ ì—¬ê¸°ì„œë„ ë‚˜ëˆ ì•¼ í•¨)
        dA = dA / self.keep_prob
        
        return dA

# --- ì‹¤í–‰ ì˜ˆì œ ---
if __name__ == "__main__":
    np.random.seed(1)
    A = np.ones((5, 3)) * 10 # ëª¨ë“  ê°’ì´ 10ì¸ í–‰ë ¬
    
    dropout = Dropout(keep_prob=0.8)
    
    # Train Mode
    A_train = dropout.forward(A, is_training=True)
    print("Train Output:\n", A_train)
    # ì¼ë¶€ëŠ” 0, ë‚˜ë¨¸ì§€ëŠ” 12.5 (10 / 0.8)ê°€ ë¨
    
    # Test Mode
    A_test = dropout.forward(A, is_training=False)
    print("\nTest Output:\n", A_test)
    # ì›ë³¸ ê·¸ëŒ€ë¡œ 10 ìœ ì§€
\end{lstlisting}

% --- 8. FAQ ---
\section{FAQ \& Pitfalls}

\begin{warningbox}{ë¹„ìš© í•¨ìˆ˜(Cost Function) ì§„ë™ ë¬¸ì œ}
ë“œë¡­ì•„ì›ƒì„ ì“°ë©´ ë§¤ë²ˆ ë„¤íŠ¸ì›Œí¬ êµ¬ì¡°ê°€ ë¬´ì‘ìœ„ë¡œ ë°”ë€ë‹ˆë‹¤. ë”°ë¼ì„œ ë¹„ìš© í•¨ìˆ˜ $J$ê°€ ë§¤ë„ëŸ½ê²Œ ë‚´ë ¤ê°€ì§€ ì•Šê³  \textbf{í†±ë‹ˆë°”í€´ì²˜ëŸ¼ ì§„ë™}í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ë””ë²„ê¹…í•  ë•ŒëŠ” ì ì‹œ `keep_prob = 1.0`(ë“œë¡­ì•„ì›ƒ ë„ê¸°)ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ $J$ê°€ ì˜ ë‚´ë ¤ê°€ëŠ”ì§€ í™•ì¸í•œ í›„, ë‹¤ì‹œ ì¼œëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
\end{warningbox}

\textbf{Q. ì…ë ¥ì¸µ(Input Layer)ì—ë„ ë“œë¡­ì•„ì›ƒì„ ì“°ë‚˜ìš”?} \\
\textbf{A.} ë³´í†µì€ ì•ˆ ì”ë‹ˆë‹¤. ì›ë³¸ ë°ì´í„°($X$)ë¥¼ ì§€ì›Œë²„ë¦¬ë©´ ì •ë³´ ì†ì‹¤ì´ ë„ˆë¬´ í¬ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ì£¼ë¡œ íŒŒë¼ë¯¸í„°ê°€ ë§ì€ ì€ë‹‰ì¸µ(FC Layer)ì— ì‚¬ìš©í•©ë‹ˆë‹¤.

\textbf{Q. \texttt{keep\_prob}ëŠ” ì–´ë–»ê²Œ ì •í•˜ë‚˜ìš”?} \\
\textbf{A.} ê³¼ëŒ€ì í•©ì´ ì‹¬í•  ê²ƒ ê°™ì€ ì¸µ(ë‰´ëŸ°ì´ ë§ì€ ì¸µ)ì€ ë‚®ê²Œ(0.5), ê·¸ë ‡ì§€ ì•Šì€ ì¸µì€ ë†’ê²Œ(0.8~1.0) ì„¤ì •í•©ë‹ˆë‹¤.

% --- 9. ë‹¤ìŒ ë‹¨ì› ì—°ê²° ---
\section*{ğŸ”— ë‹¤ìŒ ë‹¨ê³„ (Next Step)}
ì´ì œ ìš°ë¦¬ëŠ” ê³¼ëŒ€ì í•©ì„ ë§‰ëŠ” ë‘ ê°€ì§€ ê°•ë ¥í•œ ë°©íŒ¨(L2, Dropout)ë¥¼ ì–»ì—ˆìŠµë‹ˆë‹¤. 
í•˜ì§€ë§Œ ëª¨ë¸ í•™ìŠµì´ ë„ˆë¬´ ëŠë¦¬ë‹¤ë©´ ì–´ë–¨ê¹Œìš”? ì•„ë¬´ë¦¬ ì¢‹ì€ ëª¨ë¸ë„ í•™ìŠµì— 1ë…„ì´ ê±¸ë¦°ë‹¤ë©´ ë¬´ìš©ì§€ë¬¼ì…ë‹ˆë‹¤.

ë‹¤ìŒ ì‹œê°„ì—ëŠ” í•™ìŠµ ì†ë„ë¥¼ ë¹„ì•½ì ìœ¼ë¡œ ë†’ì—¬ì£¼ëŠ” \textbf{[Optimization]} ê¸°ìˆ ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤. ê·¸ ì²« ë²ˆì§¸ ì—´ì‡ ì¸ \textbf{'ì…ë ¥ ì •ê·œí™”(Input Normalization)'}ê°€ ì™œ ê²½ì‚¬ í•˜ê°•ë²•ì˜ ì†ë„ë¥¼ ë†’ì´ëŠ”ì§€ ê¸°í•˜í•™ì ìœ¼ë¡œ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.

\vspace{0.5cm}

\begin{summarybox}{ë‹¨ì› ìš”ì•½ (Cheat Sheet)}
\begin{enumerate}
    \item \textbf{Dropout:} í•™ìŠµ ì‹œ ë¬´ì‘ìœ„ë¡œ ë‰´ëŸ°ì„ ëˆë‹¤. (Ensemble íš¨ê³¼, ê³¼ëŒ€ì í•© ë°©ì§€)
    \item \textbf{Inverted Dropout:} í•™ìŠµ ì‹œ ì¶œë ¥ê°’ì„ \texttt{keep\_prob}ë¡œ ë‚˜ëˆ ì£¼ì–´ ê¸°ëŒ“ê°’ì„ ìœ ì§€í•œë‹¤.
    \item \textbf{Test Time:} í…ŒìŠ¤íŠ¸ ì‹œì—ëŠ” ì ˆëŒ€ ë“œë¡­ì•„ì›ƒì„ ì“°ì§€ ì•ŠëŠ”ë‹¤.
    \item \textbf{Caution:} Cost ê·¸ë˜í”„ê°€ ì§„ë™í•  ìˆ˜ ìˆìœ¼ë‹ˆ ë””ë²„ê¹… ì‹œì—” ë„ê³  í™•ì¸í•œë‹¤.
\end{enumerate}
\end{summarybox}

\end{document}