\documentclass[a4paper, 11pt]{article}

% --- íŒ¨í‚¤ì§€ ì„¤ì • ---
\usepackage{kotex} % í•œê¸€ ì§€ì›
\usepackage{geometry} % ì—¬ë°± ì„¤ì •
\geometry{left=25mm, right=25mm, top=25mm, bottom=25mm}
\usepackage{amsmath, amssymb, amsfonts} % ìˆ˜ì‹ íŒ¨í‚¤ì§€
\usepackage{graphicx}
\usepackage{adjustbox}  % í‘œ/ë°•ìŠ¤ í¬ê¸° ì¡°ì ˆ % ì´ë¯¸ì§€ ì‚½ì…
\usepackage{hyperref} % í•˜ì´í¼ë§í¬
\usepackage{xcolor} % ìƒ‰ìƒ ì§€ì›
\usepackage{listings} % ì½”ë“œ ë¸”ë¡
\usepackage[most]{tcolorbox}
\tcbuselibrary{breakable} % ë°•ìŠ¤ ë””ìì¸
\usepackage{enumitem} % ë¦¬ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼
\usepackage{booktabs} % í‘œ ë””ìì¸
\usepackage{array} % í‘œ ì •ë ¬

% --- ìƒ‰ìƒ ì •ì˜ ---
\definecolor{conceptblue}{RGB}{60, 100, 160}
\definecolor{analogygreen}{RGB}{80, 160, 100}
\definecolor{alertred}{RGB}{200, 60, 60}
\definecolor{exampleorange}{RGB}{230, 120, 30}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{backcolour}{rgb}{0.96,0.96,0.96}

% --- ì½”ë“œ ìŠ¤íƒ€ì¼ ì„¤ì • ---
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{analogygreen},
    keywordstyle=\color{conceptblue},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{exampleorange},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=4,
    frame=single
}
\lstset{style=mystyle}

% --- ë°•ìŠ¤ ìŠ¤íƒ€ì¼ ì •ì˜ ---
\newtcolorbox{summarybox}[1]{
    colback=conceptblue!5!white,
    colframe=conceptblue!80!black,
    fonttitle=\bfseries,
    title=ğŸ“Œ #1
}

\newtcolorbox{analogybox}[1]{
    colback=analogygreen!5!white,
    colframe=analogygreen!80!black,
    fonttitle=\bfseries,
    title=ğŸ’¡ #1 (ì§ê´€ì  ë¹„ìœ )
}

\newtcolorbox{warningbox}[1]{
    colback=alertred!5!white,
    colframe=alertred!80!black,
    fonttitle=\bfseries,
    title=âš ï¸ #1 (ì˜¤í•´ ë°©ì§€ ê°€ì´ë“œ)
}

\newtcolorbox{mathbox}[1]{
    colback=exampleorange!5!white,
    colframe=exampleorange!80!black,
    fonttitle=\bfseries,
    title=ğŸ§® #1 (ìˆ˜í•™ì  ì›ë¦¬)
}

% --- ë¬¸ì„œ ì •ë³´ ---
\title{\textbf{[CS230] Optimization Algorithms: \\ Adam Optimizer}}
\author{Lecturer: Gemini (Integrated Editor)}
\date{}

\begin{document}

\maketitle

% --- 1. ì „ì²´ ëª©ì°¨ (TOC) ---
\section*{ğŸ“š Course Table of Contents}
\begin{itemize}
    \item[Chapter 1-4.] Neural Networks Basics \textit{- Completed}
    \item[\textbf{Chapter 5.}] \textbf{Practical Aspects of Deep Learning (Current Unit)}
    \begin{itemize}
        \item 5.1-5.5 Regularization \& Data Setup \textit{- Completed}
        \item 5.6 Mini-batch Gradient Descent \textit{- Completed}
        \item 5.7 Momentum \& RMSprop \textit{- Completed}
        \item \textbf{5.8 Adam Optimizer}
        \begin{itemize}
            \item The Ultimate Fusion: Momentum + RMSprop
            \item Bias Correction Mechanism
            \item Hyperparameter Standards ($\alpha, \beta_1, \beta_2, \epsilon$)
            \item Implementation from Scratch
        \end{itemize}
        \item 5.9 Hyperparameter Tuning Strategy \textit{- Upcoming}
    \end{itemize}
\end{itemize}

\vspace{0.5cm}
\hrule
\vspace{0.5cm}

% --- 3. ì´ì „ ë‹¨ì› ì—°ê²° ---
\section*{ğŸ”— ì§€ë‚œ ì‹œê°„ ë³µìŠµ ë° ì—°ê²°}
ìš°ë¦¬ëŠ” ì§€ë‚œ ë‘ ê°•ì˜ë¥¼ í†µí•´ 'ê´€ì„±'ì„ ì´ìš©í•´ ì†ë„ë¥¼ ë†’ì´ëŠ” \textbf{Momentum}ê³¼, 'ë³´í­'ì„ ì¡°ì ˆí•´ ì§„ë™ì„ ì¤„ì´ëŠ” \textbf{RMSprop}ì„ ë°°ì› ìŠµë‹ˆë‹¤.
ê·¸ë ‡ë‹¤ë©´ ìì—°ìŠ¤ëŸ¬ìš´ ì§ˆë¬¸ì´ ìƒê¹ë‹ˆë‹¤. \textbf{"ì´ ë‘ ê°€ì§€ ì¥ì ì„ ëª¨ë‘ í•©ì¹  ìˆ˜ëŠ” ì—†ì„ê¹Œ?"}
ê·¸ í•´ë‹µì´ ë°”ë¡œ \textbf{Adam (Adaptive Moment Estimation)}ì…ë‹ˆë‹¤. Adamì€ í˜„ì¬ ë”¥ëŸ¬ë‹ í•™ê³„ì™€ í˜„ì—…ì—ì„œ \textbf{'Default Optimizer(ê¸°ë³¸ ì„¤ì •)'}ë¡œ í†µí•©ë‹ˆë‹¤. ì–´ë–¤ ì˜µí‹°ë§ˆì´ì €ë¥¼ ì“¸ì§€ ê³ ë¯¼ë  ë•Œ, ì¼ë‹¨ Adamì„ ì“°ë©´ 80ì  ì´ìƒì€ ê°‘ë‹ˆë‹¤.

% --- 4. ê°œìš” ---
\section{Unit Overview}
\begin{summarybox}{í•µì‹¬ ëª©í‘œ}
ì´ ë‹¨ì›ì€ í˜„ëŒ€ ë”¥ëŸ¬ë‹ì˜ í‘œì¤€ì¸ \textbf{Adam Optimizer}ì˜ ë‚´ë¶€ êµ¬ì¡°ë¥¼ í•´ë¶€í•©ë‹ˆë‹¤.
\begin{itemize}
    \item \textbf{í†µí•©:} Adamì´ Momentumì˜ í‰ê· (1ì°¨)ê³¼ RMSpropì˜ ë¶„ì‚°(2ì°¨)ì„ ì–´ë–»ê²Œ ê²°í•©í•˜ëŠ”ì§€ ìˆ˜ì‹ìœ¼ë¡œ ì´í•´í•©ë‹ˆë‹¤.
    \item \textbf{ë³´ì •:} í•™ìŠµ ì´ˆê¸°ì— 0ìœ¼ë¡œ ì ë¦¬ëŠ” í˜„ìƒì„ ë§‰ê¸° ìœ„í•œ \textbf{í¸í–¥ ë³´ì •(Bias Correction)}ì„ ìµí™ë‹ˆë‹¤.
    \item \textbf{í‘œì¤€:} $\beta_1, \beta_2, \epsilon$ ë“± í•˜ì´í¼íŒŒë¼ë¯¸í„°ì˜ êµ­ë£°(Standard Value)ì„ ë°°ì›ë‹ˆë‹¤.
    \item \textbf{êµ¬í˜„:} Pythonìœ¼ë¡œ í¸í–¥ ë³´ì •ì´ í¬í•¨ëœ ì „ì²´ ì•Œê³ ë¦¬ì¦˜ì„ ë°‘ë°”ë‹¥ë¶€í„° êµ¬í˜„í•©ë‹ˆë‹¤.
\end{itemize}
\end{summarybox}

% --- 5. ìš©ì–´ ì •ë¦¬ ---
\section{Essential Terminology}
\begin{center}
\begin{tabular}{|c|c|l|}
\hline
\textbf{ê¸°í˜¸} & \textbf{í‘œì¤€ê°’} & \textbf{ì—­í• } \\ \hline
$\alpha$ & íŠœë‹ í•„ìš” & \textbf{í•™ìŠµë¥  (Learning Rate)}. ê°€ì¥ ì¤‘ìš”í•¨. \\ \hline
$\beta_1$ & 0.9 & \textbf{Momentum ê³„ìˆ˜}. (ê¸°ìš¸ê¸°ì˜ ì§€ìˆ˜ í‰ê· ) \\ \hline
$\beta_2$ & 0.999 & \textbf{RMSprop ê³„ìˆ˜}. (ê¸°ìš¸ê¸° ì œê³±ì˜ ì§€ìˆ˜ í‰ê· ) \\ \hline
$\epsilon$ & $10^{-8}$ & \textbf{ì•ˆì •ì„± ìƒìˆ˜}. 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€. \\ \hline
\end{tabular}
\end{center}

% --- 6. í•µì‹¬ ê°œë… ìƒì„¸ ì„¤ëª… ---
\section{Core Concepts: ìµœê°•ì˜ ìœµí•©}

\subsection{1. The Fusion Algorithm}
Adamì€ ë§¤ ìŠ¤í…($t$)ë§ˆë‹¤ ë‹¤ìŒ 4ë‹¨ê³„ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.

\begin{enumerate}
    \item \textbf{Momentum ($v$):} ì†ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. (1ì°¨ ëª¨ë©˜íŠ¸)
    $$ v_t = \beta_1 v_{t-1} + (1 - \beta_1) dW $$
    
    \item \textbf{RMSprop ($s$):} ê°€ì†ë„ ì œì–´(ë§ˆì°°ë ¥)ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. (2ì°¨ ëª¨ë©˜íŠ¸)
    $$ s_t = \beta_2 s_{t-1} + (1 - \beta_2) dW^2 $$
    
    \item \textbf{Bias Correction (í•µì‹¬):} ì´ˆê¸° 0ìœ¼ë¡œ ì ë¦° ê°’ì„ ë³´ì •í•©ë‹ˆë‹¤.
    $$ v^{corr}_t = \frac{v_t}{1 - \beta_1^t}, \quad s^{corr}_t = \frac{s_t}{1 - \beta_2^t} $$
    
    \item \textbf{Update:} íŒŒë¼ë¯¸í„°ë¥¼ ê°±ì‹ í•©ë‹ˆë‹¤.
    $$ W = W - \alpha \frac{v^{corr}_t}{\sqrt{s^{corr}_t} + \epsilon} $$
\end{enumerate}

\vspace{0.5cm}\hrule\vspace{0.5cm}

\section{Deep Dive: Bias Correction (í¸í–¥ ë³´ì •)}

"êµìˆ˜ë‹˜, ì™œ êµ³ì´ $(1 - \beta^t)$ë¡œ ë‚˜ëˆ ì£¼ë‚˜ìš”?"
ì´ê²ƒì€ Adamì˜ ì •êµí•¨ì„ ë³´ì—¬ì£¼ëŠ” ëŒ€ëª©ì…ë‹ˆë‹¤.

\begin{mathbox}{ì´ˆê¸°ê°’ 0ì˜ ì €ì£¼}
ìš°ë¦¬ëŠ” $v_0 = 0$ìœ¼ë¡œ ì‹œì‘í•©ë‹ˆë‹¤. ì²« ë²ˆì§¸ ìŠ¤í…($t=1$)ì„ ë´…ì‹œë‹¤.
($\beta_1 = 0.9$ ê°€ì •)

$$ v_1 = 0.9 \times 0 + 0.1 \times dW = 0.1 dW $$

\textbf{ë¬¸ì œì :} ì‹¤ì œ ê¸°ìš¸ê¸°($dW$)ì˜ \textbf{10ë¶„ì˜ 1(0.1)}ë°–ì— ë°˜ì˜ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í•™ìŠµ ì´ˆë°˜ì— ê±°ë¶ì´ì²˜ëŸ¼ ëŠë ¤ì§‘ë‹ˆë‹¤.

\textbf{í•´ê²°ì±… (ë³´ì •):}
$$ 1 - \beta_1^1 = 1 - 0.9 = 0.1 $$
$$ v^{corr}_1 = \frac{v_1}{0.1} = \frac{0.1 dW}{0.1} = dW $$

\textbf{ê²°ê³¼:} ë³´ì • ë•ë¶„ì— ì´ˆê¸°ì—ë„ ê¸°ìš¸ê¸°ë¥¼ 100\% ë°˜ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
$t$ê°€ ì»¤ì§€ë©´ $\beta^t \to 0$ì´ ë˜ì–´, ë¶„ëª¨ê°€ 1ì´ ë˜ë¯€ë¡œ ë³´ì • íš¨ê³¼ëŠ” ìì—°ìŠ¤ëŸ½ê²Œ ì‚¬ë¼ì§‘ë‹ˆë‹¤.
\end{mathbox}

% --- 7. êµ¬í˜„ ì½”ë“œ ---
\section{Implementation: Adam from Scratch}

Adam êµ¬í˜„ ì‹œ ê°€ì¥ ì¤‘ìš”í•œ ê²ƒì€ í˜„ì¬ ë°˜ë³µ íšŸìˆ˜ \textbf{$t$}ë¥¼ ì¶”ì í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

\begin{lstlisting}[language=Python, caption=Adam Optimizer Implementation, breaklines=true]
import numpy as np

def update_parameters_with_adam(parameters, grads, v, s, t, learning_rate=0.01,
                                beta1=0.9, beta2=0.999, epsilon=1e-8):
    """
    t: í˜„ì¬ iteration count (1ë¶€í„° ì‹œì‘í•´ì•¼ í•¨!)
    v, s: ì´ì „ ìŠ¤í…ê¹Œì§€ ëˆ„ì ëœ Momentum, RMSprop ë³€ìˆ˜
    """
    L = len(parameters) // 2
    v_corrected = {} 
    s_corrected = {} 
    
    for l in range(1, L + 1):
        # --- 1. Momentum (v) ---
        v["dW" + str(l)] = beta1 * v["dW" + str(l)] + (1 - beta1) * grads["dW" + str(l)]
        v["db" + str(l)] = beta1 * v["db" + str(l)] + (1 - beta1) * grads["db" + str(l)]
        
        # --- 2. Bias Correction (v) ---
        # 1 - beta^t ë¡œ ë‚˜ëˆ”
        v_corrected["dW" + str(l)] = v["dW" + str(l)] / (1 - np.power(beta1, t))
        v_corrected["db" + str(l)] = v["db" + str(l)] / (1 - np.power(beta1, t))
        
        # --- 3. RMSprop (s) ---
        # ê¸°ìš¸ê¸° ì œê³±(square) ì£¼ì˜!
        s["dW" + str(l)] = beta2 * s["dW" + str(l)] + (1 - beta2) * np.square(grads["dW" + str(l)])
        s["db" + str(l)] = beta2 * s["db" + str(l)] + (1 - beta2) * np.square(grads["db" + str(l)])
        
        # --- 4. Bias Correction (s) ---
        s_corrected["dW" + str(l)] = s["dW" + str(l)] / (1 - np.power(beta2, t))
        s_corrected["db" + str(l)] = s["db" + str(l)] / (1 - np.power(beta2, t))
        
        # --- 5. Update Parameters ---
        # ë¶„ëª¨: sqrt(s_corr) + epsilon
        parameters["W" + str(l)] -= learning_rate * (v_corrected["dW" + str(l)] / (np.sqrt(s_corrected["dW" + str(l)]) + epsilon))
        parameters["b" + str(l)] -= learning_rate * (v_corrected["db" + str(l)] / (np.sqrt(s_corrected["db" + str(l)]) + epsilon))
        
    return parameters, v, s
\end{lstlisting}

% --- 8. FAQ ---
\section{FAQ \& Pitfalls}

\begin{warningbox}{Iteration Count $t$ ì£¼ì˜}
í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•  ë•Œ $t$ëŠ” ë°˜ë“œì‹œ 1ë¶€í„° ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤. ë§Œì•½ $t=0$ì´ë©´ $1 - \beta^0 = 1 - 1 = 0$ì´ ë˜ì–´ \textbf{ZeroDivisionError}ê°€ ë°œìƒí•©ë‹ˆë‹¤.
\end{warningbox}

\textbf{Q. Adamì´ í•­ìƒ ìµœê³ ì¸ê°€ìš”?} \\
\textbf{A.} ëŒ€ë¶€ë¶„ì˜ ê²½ìš°(CV, NLP, GAN) ê·¸ë ‡ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì•„ì£¼ ì •êµí•œ ìˆ˜ë ´ì´ í•„ìš”í•  ë•Œ(SOTA ë…¼ë¬¸ ë“±)ëŠ” ì¼ë°˜ SGD+Momentumì´ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë‚¼ ë•Œë„ ìˆìŠµë‹ˆë‹¤. ê·¸ë˜ë„ ì‹œì‘ì€ ë¬´ì¡°ê±´ Adamì„ ì¶”ì²œí•©ë‹ˆë‹¤.

% --- 9. ë‹¤ìŒ ë‹¨ì› ì—°ê²° ---
\section*{ğŸ”— ë‹¤ìŒ ë‹¨ê³„ (Next Step)}
ì´ë¡œì¨ ìš°ë¦¬ëŠ” ìµœì í™” ì•Œê³ ë¦¬ì¦˜ì˜ ì •ì ì¸ Adamì„ ì •ë³µí–ˆìŠµë‹ˆë‹¤. ì´ì œ ì—¬ëŸ¬ë¶„ì€ ì–´ë–¤ ëª¨ë¸ì´ë“  ë¹ ë¥´ê³  ì•ˆì •ì ìœ¼ë¡œ í•™ìŠµì‹œí‚¬ ìˆ˜ ìˆëŠ” ì—”ì§„ì„ ê°–ì·„ìŠµë‹ˆë‹¤.

í•˜ì§€ë§Œ ì—”ì§„ ì„±ëŠ¥ì´ ì¢‹ì•„ë„, ê¸°ì–´ ë³€ì†(í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •)ì„ ì˜ëª»í•˜ë©´ ì°¨ê°€ ë‚˜ê°€ì§€ ì•ŠìŠµë‹ˆë‹¤. $\alpha$, $\beta$, ë°°ì¹˜ í¬ê¸°, ì€ë‹‰ì¸µ ê°œìˆ˜... ë„ëŒ€ì²´ ë¬´ì—‡ë¶€í„° ì¡°ì ˆí•´ì•¼ í• ê¹Œìš”?
ë‹¤ìŒ ì‹œê°„ì—ëŠ” ì´ ìˆ˜ë§ì€ ë‹¤ì´ì–¼ì„ ì–´ë–¤ ìˆœì„œë¡œ ëŒë ¤ì•¼ í•˜ëŠ”ì§€, \textbf{[Hyperparameter Tuning]}ì˜ ì²´ê³„ì ì¸ ì „ëµ(Random Search vs Grid Search)ì„ ì•Œë ¤ë“œë¦¬ê² ìŠµë‹ˆë‹¤.

\vspace{0.5cm}

\begin{summarybox}{ë‹¨ì› ìš”ì•½ (Cheat Sheet)}
\begin{enumerate}
    \item \textbf{Adam:} Momentum(ì†ë„) + RMSprop(ê°€ì†ë„ ì œì–´) + Bias Correction(ì´ˆê¸° ë³´ì •).
    \item \textbf{Standard Params:} $\alpha$(íŠœë‹), $\beta_1(0.9)$, $\beta_2(0.999)$, $\epsilon(10^{-8})$.
    \item \textbf{Bias Correction:} í•™ìŠµ ì´ˆë°˜ì— íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸ê°€ ë„ˆë¬´ ì‘ì•„ì§€ëŠ” ê²ƒì„ ë§‰ì•„ì¤€ë‹¤.
    \item \textbf{Memory:} $v$ì™€ $s$ë¥¼ ë”°ë¡œ ì €ì¥í•´ì•¼ í•˜ë¯€ë¡œ ì¼ë°˜ SGDë³´ë‹¤ ë©”ëª¨ë¦¬ë¥¼ ë” ì“´ë‹¤.
\end{enumerate}
\end{summarybox}

\end{document}