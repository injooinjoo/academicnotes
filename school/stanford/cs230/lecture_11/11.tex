\documentclass[a4paper, 11pt]{article}

% --- íŒ¨í‚¤ì§€ ì„¤ì • ---
\usepackage{kotex} % í•œê¸€ ì§€ì›
\usepackage{geometry} % ì—¬ë°± ì„¤ì •
\geometry{left=25mm, right=25mm, top=25mm, bottom=25mm}
\usepackage{amsmath, amssymb, amsfonts} % ìˆ˜ì‹ íŒ¨í‚¤ì§€
\usepackage{graphicx}
\usepackage{adjustbox}  % í‘œ/ë°•ìŠ¤ í¬ê¸° ì¡°ì ˆ % ì´ë¯¸ì§€ ì‚½ì…
\usepackage{hyperref} % í•˜ì´í¼ë§í¬
\usepackage{xcolor} % ìƒ‰ìƒ ì§€ì›
\usepackage{listings} % ì½”ë“œ ë¸”ë¡
\usepackage[most]{tcolorbox}
\tcbuselibrary{breakable} % ë°•ìŠ¤ ë””ìì¸
\usepackage{enumitem} % ë¦¬ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼
\usepackage{booktabs} % í‘œ ë””ìì¸
\usepackage{array} % í‘œ ì •ë ¬
\usepackage{colortbl} % í‘œ ìƒ‰ìƒ

% --- ìƒ‰ìƒ ì •ì˜ ---
\definecolor{conceptblue}{RGB}{60, 100, 160}
\definecolor{analogygreen}{RGB}{80, 160, 100}
\definecolor{alertred}{RGB}{200, 60, 60}
\definecolor{exampleorange}{RGB}{230, 120, 30}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{backcolour}{rgb}{0.96,0.96,0.96}

% --- ì½”ë“œ ìŠ¤íƒ€ì¼ ì„¤ì • ---
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{analogygreen},
    keywordstyle=\color{conceptblue},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{exampleorange},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=4,
    frame=single
}
\lstset{style=mystyle}

% --- ë°•ìŠ¤ ìŠ¤íƒ€ì¼ ì •ì˜ ---
\newtcolorbox{summarybox}[1]{
    colback=conceptblue!5!white,
    colframe=conceptblue!80!black,
    fonttitle=\bfseries,
    title=ğŸ“Œ #1
}

\newtcolorbox{analogybox}[1]{
    colback=analogygreen!5!white,
    colframe=analogygreen!80!black,
    fonttitle=\bfseries,
    title=ğŸ’¡ #1 (ì§ê´€ì  ë¹„ìœ )
}

\newtcolorbox{warningbox}[1]{
    colback=alertred!5!white,
    colframe=alertred!80!black,
    fonttitle=\bfseries,
    title=âš ï¸ #1 (ì˜¤í•´ ë°©ì§€ ê°€ì´ë“œ)
}

\newtcolorbox{diagnosisbox}[1]{
    colback=purple!5!white,
    colframe=purple!80!black,
    fonttitle=\bfseries,
    title=ğŸ©º #1 (ëª¨ë¸ ì§„ë‹¨)
}

% --- ë¬¸ì„œ ì •ë³´ ---
\title{\textbf{[CS230] Improving Deep Neural Networks: \\ Data Setup Strategy}}
\author{Lecturer: Gemini (Integrated Editor)}
\date{}

\begin{document}

\maketitle

% --- 1. ì „ì²´ ëª©ì°¨ (TOC) ---
\section*{ğŸ“š Course Table of Contents}
\begin{itemize}
    \item[Chapter 1-4.] Neural Networks Basics \textit{- Completed}
    \item[\textbf{Chapter 5.}] \textbf{Practical Aspects of Deep Learning (Current Unit)}
    \begin{itemize}
        \item \textbf{5.1 Train / Dev / Test Sets Strategy}
        \begin{itemize}
            \item The Purpose of Splitting
            \item Big Data Era Ratio (98/1/1)
            \item Distribution Mismatch \& Data Leakage
            \item Bias-Variance Diagnosis
        \end{itemize}
        \item 5.2 Regularization (L2, Dropout)
        \item 5.3 Optimization Algorithms (Adam, RMSProp)
    \end{itemize}
\end{itemize}

\vspace{0.5cm}
\hrule
\vspace{0.5cm}

% --- 3. ì´ì „ ë‹¨ì› ì—°ê²° ---
\section*{ğŸ”— ì§€ë‚œ ì‹œê°„ ë³µìŠµ ë° ì—°ê²°}
ì§€ê¸ˆê¹Œì§€ ìš°ë¦¬ëŠ” ì‹ ê²½ë§ì´ë¼ëŠ” \textbf{'ìµœê³ ê¸‰ ì—”ì§„'}ì„ ì¡°ë¦½í–ˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ í˜ë¼ë¦¬ ì—”ì§„ì„ íŠ¸ë™í„°ì— ë‹¬ê±°ë‚˜, ë¶ˆìˆœë¬¼ì´ ì„ì¸ ì—°ë£Œë¥¼ ë„£ìœ¼ë©´ ì•„ë¬´ ì†Œìš©ì´ ì—†ìŠµë‹ˆë‹¤.
ì´ì œë¶€í„°ëŠ” ì—”ì§„ì„ \textbf{'ì–´ë–»ê²Œ ìš´ìš©í•´ì•¼(Strategy)'} ìµœê³ ì˜ ì„±ëŠ¥ì„ ë‚¼ ìˆ˜ ìˆëŠ”ì§€ ë°°ì›ë‹ˆë‹¤. ê·¸ ì²«ê±¸ìŒì€ ë°ì´í„°ë¥¼ ì˜¬ë°”ë¥´ê²Œ ë‚˜ëˆ„ëŠ” ê²ƒì…ë‹ˆë‹¤. ë§ì€ ì´ˆì‹¬ìê°€ ë°ì´í„°ë¥¼ ëª½ë•… í„¸ì–´ ë„£ê³  í•™ìŠµë¶€í„° ì‹œí‚¤ì§€ë§Œ, ì´ëŠ” "ì±„ì  ê¸°ì¤€ë„ ëª¨ë¥¸ ì±„ ì‹œí—˜ ê³µë¶€ë¥¼ í•˜ëŠ” ê²ƒ"ê³¼ ê°™ìŠµë‹ˆë‹¤.

% --- 4. ê°œìš” ---
\section{Unit Overview}
\begin{summarybox}{í•µì‹¬ ëª©í‘œ}
ì´ ë‹¨ì›ì€ ì„±ê³µì ì¸ ë¨¸ì‹ ëŸ¬ë‹ í”„ë¡œì íŠ¸ì˜ ë‚˜ì¹¨ë°˜ì¸ \textbf{'ë°ì´í„° ë¶„í•  ì „ëµ'}ì„ ë‹¤ë£¹ë‹ˆë‹¤.
\begin{itemize}
    \item \textbf{ì •ì˜:} Train(í•™ìŠµ), Dev(íŠœë‹), Test(í‰ê°€) ì„¸íŠ¸ì˜ ëª…í™•í•œ ì—­í•  ì°¨ì´ë¥¼ ì´í•´í•©ë‹ˆë‹¤.
    \item \textbf{ë¹„ìœ¨:} ë¹…ë°ì´í„° ì‹œëŒ€(100ë§Œ ê°œ ì´ìƒ)ì— ì™œ \textbf{98:1:1} ë¹„ìœ¨ì„ ì‚¬ìš©í•˜ëŠ”ì§€ í†µê³„ì ìœ¼ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤.
    \item \textbf{ì›ì¹™:} Devì™€ Test ì„¸íŠ¸ê°€ ë°˜ë“œì‹œ \textbf{ë™ì¼í•œ ë¶„í¬(Same Distribution)}ì—¬ì•¼ í•˜ëŠ” ì´ìœ ë¥¼ ë°°ì›ë‹ˆë‹¤.
    \item \textbf{ì§„ë‹¨:} ë°ì´í„° ë¶„í•  ê²°ê³¼ë¥¼ í†µí•´ ëª¨ë¸ì˜ ê³¼ì†Œì í•©/ê³¼ëŒ€ì í•©ì„ ì§„ë‹¨í•˜ëŠ” í‘œë¥¼ í•´ì„í•©ë‹ˆë‹¤.
\end{itemize}
\end{summarybox}

% --- 5. ìš©ì–´ ì •ë¦¬ ---
\section{Essential Terminology}
\begin{center}
\begin{tabular}{|c|l|l|}
\hline
\textbf{ë°ì´í„°ì…‹} & \textbf{ì—­í• } & \textbf{ë¹„ìœ  (ìˆ˜í—˜ìƒ)} \\ \hline
\textbf{Train Set} & ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„°($W, b$) í•™ìŠµ & \textbf{êµê³¼ì„œ} (í‰ì†Œ ê³µë¶€) \\ \hline
\textbf{Dev Set} & í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ \& ëª¨ë¸ ì„ íƒ & \textbf{ëª¨ì˜ê³ ì‚¬} (ì‹¤ë ¥ ì ê²€ ë° ê³µë¶€ë²• ìˆ˜ì •) \\ \hline
\textbf{Test Set} & ìµœì¢… ì„±ëŠ¥ í‰ê°€ (í•™ìŠµ/íŠœë‹ ê´€ì—¬ X) & \textbf{ìˆ˜ëŠ¥/ë³¸ê³ ì‚¬} (ê²°ê³¼ ë²ˆë³µ ë¶ˆê°€) \\ \hline
\end{tabular}
\end{center}
\textit{* Note: ê³¼ê±°ì—ëŠ” 'Validation Set'ì´ë¼ê³  ë¶ˆë €ìœ¼ë‚˜, Andrew Ng êµìˆ˜ëŠ” 'Dev Set'ì´ë¼ëŠ” ìš©ì–´ë¥¼ ì„ í˜¸í•©ë‹ˆë‹¤.}

% --- 6. í•µì‹¬ ê°œë… ìƒì„¸ ì„¤ëª… ---
\section{Core Concepts: ì „ëµì  ë¶„í• }

\subsection{1. The Era Shift: 60/20/20 vs 98/1/1}
ë°ì´í„°ì˜ ì–‘(Size)ì— ë”°ë¼ í™©ê¸ˆ ë¹„ìœ¨ì€ ë‹¬ë¼ì§‘ë‹ˆë‹¤.

\begin{itemize}
    \item \textbf{Traditional ML (Small Data):} ë°ì´í„°ê°€ 1ë§Œ ê°œ ë¯¸ë§Œì¼ ë•Œ.
    \begin{itemize}
        \item ë¹„ìœ¨: \textbf{60\% : 20\% : 20\%}
        \item ì´ìœ : í‰ê°€ìš© ë°ì´í„°ê°€ ë„ˆë¬´ ì ìœ¼ë©´ í†µê³„ì ìœ¼ë¡œ ì‹ ë¢°í•  ìˆ˜ ì—†ì–´ì„œ 20\%ë‚˜ ë–¼ì–´ë†”ì•¼ í–ˆìŠµë‹ˆë‹¤.
    \end{itemize}
    
    \item \textbf{Deep Learning Era (Big Data):} ë°ì´í„°ê°€ 100ë§Œ ê°œ ì´ìƒì¼ ë•Œ.
    \begin{itemize}
        \item ë¹„ìœ¨: \textbf{98\% : 1\% : 1\%}
        \item ì´ìœ : 100ë§Œ ê°œì˜ 1\%ë©´ 1ë§Œ ê°œì…ë‹ˆë‹¤. ì´ ì •ë„ë©´ í‰ê°€í•˜ê¸°ì— ì¶©ë¶„í•©ë‹ˆë‹¤. ë‚˜ë¨¸ì§€ 98\%ë¥¼ í•™ìŠµ(Train)ì— ëª°ì•„ì£¼ì–´ ì„±ëŠ¥ì„ ê·¹ëŒ€í™”í•˜ëŠ” ê²ƒì´ ìœ ë¦¬í•©ë‹ˆë‹¤.
    \end{itemize}
\end{itemize}



\subsection{2. The Golden Rule: Same Distribution}
\textbf{"Dev Setê³¼ Test Setì€ ë°˜ë“œì‹œ ê°™ì€ ê³¼ë…ì„ ê²¨ëƒ¥í•´ì•¼ í•œë‹¤."}

\begin{warningbox}{ë‚˜ìœ ì˜ˆì‹œ (Bad Example)}
\begin{itemize}
    \item \textbf{Train:} ì›¹ì—ì„œ í¬ë¡¤ë§í•œ ê³ í™”ì§ˆ ê³ ì–‘ì´ ì‚¬ì§„ (20ë§Œ ì¥)
    \item \textbf{Dev/Test:} ì‚¬ìš©ìê°€ í°ìœ¼ë¡œ ì°ì€ íë¦¿í•œ ê³ ì–‘ì´ ì‚¬ì§„ (1ë§Œ ì¥)
\end{itemize}
\textbf{ê²°ê³¼:} í›ˆë ¨ ë•ŒëŠ” 99ì (ê³ í™”ì§ˆ ë§ˆìŠ¤í„°)ì´ì§€ë§Œ, ì‹¤ì „ì—ì„œëŠ” 0ì ì…ë‹ˆë‹¤.
\textbf{í•´ê²°:} ëª¨ë“  ë°ì´í„°ë¥¼ ì„ì–´ì„œ(Shuffle) ë‚˜ëˆ„ê±°ë‚˜, Dev/Testë¥¼ ì‹¤ì œ ëª©í‘œ(ëª¨ë°”ì¼ ì‚¬ì§„)ë¡œë§Œ êµ¬ì„±í•´ì•¼ í•©ë‹ˆë‹¤.
\end{warningbox}

\vspace{0.5cm}\hrule\vspace{0.5cm}

\section{Deep Dive: ëª¨ë¸ ì§„ë‹¨ (Bias vs Variance)}

ë°ì´í„°ë¥¼ ë‚˜ëˆ„ëŠ” ì§„ì§œ ì´ìœ ëŠ” ëª¨ë¸ì˜ ìƒíƒœë¥¼ ì§„ë‹¨í•˜ê¸° ìœ„í•´ì„œì…ë‹ˆë‹¤.

\begin{diagnosisbox}{ì„±ëŠ¥ ì§„ë‹¨í‘œ (Human Error $\approx$ 0\% ê°€ì •)}
\begin{center}
\begin{tabular}{c|c|l|l}
\hline
\textbf{Train Error} & \textbf{Dev Error} & \textbf{ì§„ë‹¨ (Diagnosis)} & \textbf{ì²˜ë°© (Action)} \\ \hline
1\% & 11\% & \textbf{High Variance} (ê³¼ëŒ€ì í•©) & ë°ì´í„° ì¶”ê°€, ì •ê·œí™”(Dropout), ëª¨ë¸ ì¶•ì†Œ \\ \hline
15\% & 16\% & \textbf{High Bias} (ê³¼ì†Œì í•©) & ë” í° ëª¨ë¸(ì¸µ ì¶”ê°€), í•™ìŠµ ì‹œê°„ ì—°ì¥ \\ \hline
15\% & 30\% & \textbf{High Bias \& Variance} & ëª¨ë¸ êµ¬ì¡° ë³€ê²½, ë°ì´í„° ì •ì œ \\ \hline
0.5\% & 1\% & \textbf{Low Bias \& Low Variance} & \textbf{Ideal (ì„±ê³µ!)} \\ \hline
\end{tabular}
\end{center}
\end{diagnosisbox}

\begin{itemize}
    \item \textbf{Bias(í¸í–¥) ë¬¸ì œ:} Train Setì¡°ì°¨ ì œëŒ€ë¡œ ëª» ë§ì¶¤. (ê³µë¶€ë¥¼ ì•ˆ í•¨)
    \item \textbf{Variance(ë¶„ì‚°) ë¬¸ì œ:} Trainì€ ì˜ ë§ì¶”ëŠ”ë° DevëŠ” ëª» ë§ì¶¤. (êµê³¼ì„œë§Œ ë‹¬ë‹¬ ì™¸ì›€, ì‘ìš© ë¶ˆê°€)
\end{itemize}



% --- 7. êµ¬í˜„ ì½”ë“œ ---
\section{Implementation: Data Leakage ë°©ì§€}

ê°€ì¥ ì¤‘ìš”í•œ ê²ƒì€ \textbf{Data Leakage(ë°ì´í„° ëˆ„ìˆ˜)}ë¥¼ ë§‰ëŠ” ê²ƒì…ë‹ˆë‹¤. ì •ê·œí™”(Normalization)ë¥¼ í•  ë•Œ, ì „ì²´ ë°ì´í„°ì˜ í‰ê· ì„ ì“°ë©´ ì•ˆ ë©ë‹ˆë‹¤. \textbf{ì˜¤ì§ Train Setì˜ í†µê³„ëŸ‰}ë§Œ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.

\begin{lstlisting}[language=Python, caption=Stratified Split \& Safe Normalization, breaklines=true]
import numpy as np
from sklearn.model_selection import train_test_split

def prepare_data(X, y):
    """
    X: (m, n_x) features
    y: (m,) labels
    """
    # 1. Stratified Split (í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€í•˜ë©° ë¶„í• )
    # Train(98%) vs Temp(2%)
    X_train, X_temp, y_train, y_temp = train_test_split(
        X, y, test_size=0.02, random_state=42, stratify=y
    )
    
    # Tempë¥¼ ë‹¤ì‹œ ë°˜ë°˜ ë‚˜ëˆ„ì–´ Dev(1%) vs Test(1%)
    X_dev, X_test, y_dev, y_test = train_test_split(
        X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp
    )
    
    # 2. Data Leakage ë°©ì§€ ì „ì²˜ë¦¬ (í•µì‹¬!)
    # ì „ì²´ Xê°€ ì•„ë‹ˆë¼, ì˜¤ì§ X_train ë§Œìœ¼ë¡œ í‰ê· /í‘œì¤€í¸ì°¨ ê³„ì‚°
    mean = np.mean(X_train, axis=0)
    std = np.std(X_train, axis=0)
    
    # ê³„ì‚°ëœ í†µê³„ëŸ‰ìœ¼ë¡œ Train, Dev, Test ëª¨ë‘ ë³€í™˜
    X_train_norm = (X_train - mean) / (std + 1e-8)
    X_dev_norm = (X_dev - mean) / (std + 1e-8)
    X_test_norm = (X_test - mean) / (std + 1e-8)
    
    return X_train_norm, X_dev_norm, X_test_norm, y_train, y_dev, y_test
\end{lstlisting}

% --- 8. FAQ ---
\section{FAQ \& Pitfalls}

\textbf{Q1. Test Set ì—†ì´ Train/Devë§Œ ì“°ë©´ ì•ˆ ë˜ë‚˜ìš”?} \\
\textbf{A.} ê°€ëŠ¥ì€ í•©ë‹ˆë‹¤ë§Œ, ìœ„í—˜í•©ë‹ˆë‹¤. Dev Setì„ ë³´ê³  ëª¨ë¸ì„ ê³„ì† ìˆ˜ì •í•˜ë‹¤ ë³´ë©´, ëª¨ë¸ì´ Dev Setì— ê³¼ì í•©(Overfitting)ë©ë‹ˆë‹¤. ë§ˆì¹˜ ëª¨ì˜ê³ ì‚¬ ë‹µì„ ì™¸ì›Œë²„ë¦° ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤. ê°ê´€ì ì¸ ìµœì¢… í‰ê°€ë¥¼ ìœ„í•´ Test Setì€ í•œ ë²ˆë„ ë³´ì§€ ì•Šì€ ìƒíƒœë¡œ ë‚¨ê²¨ë‘¬ì•¼ í•©ë‹ˆë‹¤.

\textbf{Q2. ì‹œê³„ì—´ ë°ì´í„°(ì£¼ì‹)ë„ ëœë¤ ì…”í”Œ(Shuffle)í•´ë„ ë˜ë‚˜ìš”?} \\
\textbf{A.} \textbf{ì ˆëŒ€ ì•ˆ ë©ë‹ˆë‹¤.} ë¯¸ë˜ ì •ë³´ê°€ ê³¼ê±° í•™ìŠµ ë°ì´í„°ì— ì„ì—¬ ë“¤ì–´ê°€ê²Œ ë©ë‹ˆë‹¤(Look-ahead Bias). ì‹œê³„ì—´ ë°ì´í„°ëŠ” ì‹œê°„ ìˆœì„œëŒ€ë¡œ ì˜ë¼ì•¼ í•©ë‹ˆë‹¤. (ì˜ˆ: 1~9ì›” Train, 10ì›” Dev, 11ì›” Test)

% --- 9. ë‹¤ìŒ ë‹¨ì› ì—°ê²° ---
\section*{ğŸ”— ë‹¤ìŒ ë‹¨ê³„ (Next Step)}
ë°ì´í„° ì„¸íŒ…ì´ ëë‚¬ìŠµë‹ˆë‹¤. ì´ì œ ì—¬ëŸ¬ë¶„ì€ ëª¨ë¸ì´ \textbf{High Variance(ê³¼ëŒ€ì í•©)} ìƒíƒœì¸ì§€, \textbf{High Bias(ê³¼ì†Œì í•©)} ìƒíƒœì¸ì§€ ì§„ë‹¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ë§Œì•½ ì§„ë‹¨ ê²°ê³¼ ëª¨ë¸ì´ \textbf{High Variance(ê³¼ëŒ€ì í•©)}ë¼ë©´ ì–´ë–»ê²Œ í•´ì•¼ í• ê¹Œìš”? ë°ì´í„°ë¥¼ ë” ëª¨ìœ¼ëŠ” ê²ƒì´ ì¢‹ê² ì§€ë§Œ, ëˆê³¼ ì‹œê°„ì´ ë“­ë‹ˆë‹¤.
ë‹¤ìŒ ì‹œê°„ì—ëŠ” ë°ì´í„°ë¥¼ ëŠ˜ë¦¬ì§€ ì•Šê³ ë„ ê³¼ëŒ€ì í•©ì„ í•´ê²°í•˜ëŠ” ë§ˆë²• ê°™ì€ ê¸°ë²•, \textbf{[Regularization] (L2 Regularization \& Dropout)}ì„ ë°°ìš°ê² ìŠµë‹ˆë‹¤.

\vspace{0.5cm}

\begin{summarybox}{ë‹¨ì› ìš”ì•½ (Cheat Sheet)}
\begin{enumerate}
    \item \textbf{Split:} ë¹…ë°ì´í„° ì‹œëŒ€ì—ëŠ” \textbf{98/1/1} ë¹„ìœ¨ì´ ëŒ€ì„¸ë‹¤. Trainì— ì§‘ì¤‘í•˜ë¼.
    \item \textbf{Distribution:} Devì™€ TestëŠ” ë°˜ë“œì‹œ \textbf{ê°™ì€ ë¶„í¬}ì—¬ì•¼ í•œë‹¤.
    \item \textbf{Leakage:} ì •ê·œí™” ì‹œ í‰ê· ($\mu$)ê³¼ ë¶„ì‚°($\sigma$)ì€ \textbf{ì˜¤ì§ Train Set}ì—ì„œë§Œ êµ¬í•œë‹¤.
    \item \textbf{Diagnosis:} Train Errorì™€ Dev Errorì˜ ì°¨ì´ê°€ í¬ë©´ \textbf{Variance(ê³¼ëŒ€ì í•©)} ë¬¸ì œë‹¤.
  \end{enumerate}
\end{summarybox}

\end{document}