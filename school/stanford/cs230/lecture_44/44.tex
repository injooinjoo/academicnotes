\documentclass[a4paper, 11pt]{article}

% --- íŒ¨í‚¤ì§€ ì„¤ì • ---
\usepackage{kotex} % í•œê¸€ ì§€ì›
\usepackage{geometry} % ì—¬ë°± ì„¤ì •
\geometry{left=25mm, right=25mm, top=25mm, bottom=25mm}
\usepackage{amsmath, amssymb, amsfonts} % ìˆ˜ì‹ íŒ¨í‚¤ì§€
\usepackage{graphicx}
\usepackage{adjustbox}  % í‘œ/ë°•ìŠ¤ í¬ê¸° ì¡°ì ˆ % ì´ë¯¸ì§€ ì‚½ì…
\usepackage{hyperref} % í•˜ì´í¼ë§í¬
\usepackage{xcolor} % ìƒ‰ìƒ ì§€ì›
\usepackage{listings} % ì½”ë“œ ë¸”ë¡
\usepackage[most]{tcolorbox}
\tcbuselibrary{breakable} % ë°•ìŠ¤ ë””ìì¸
\usepackage{enumitem} % ë¦¬ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼
\usepackage{booktabs} % í‘œ ë””ìì¸
\usepackage{array} % í‘œ ì •ë ¬

% --- ìƒ‰ìƒ ì •ì˜ ---
\definecolor{conceptblue}{RGB}{60, 100, 160}
\definecolor{analogygreen}{RGB}{80, 160, 100}
\definecolor{alertred}{RGB}{200, 60, 60}
\definecolor{exampleorange}{RGB}{230, 120, 30}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{backcolour}{rgb}{0.96,0.96,0.96}

% --- ì½”ë“œ ìŠ¤íƒ€ì¼ ì„¤ì • ---
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{analogygreen},
    keywordstyle=\color{conceptblue},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{exampleorange},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=4,
    frame=single
}
\lstset{style=mystyle}

% --- ë°•ìŠ¤ ìŠ¤íƒ€ì¼ ì •ì˜ ---
\newtcolorbox{summarybox}[1]{
    colback=conceptblue!5!white,
    colframe=conceptblue!80!black,
    fonttitle=\bfseries,
    title=ğŸ“Œ #1
}

\newtcolorbox{analogybox}[1]{
    colback=analogygreen!5!white,
    colframe=analogygreen!80!black,
    fonttitle=\bfseries,
    title=ğŸ’¡ #1 (ì§ê´€ì  ë¹„ìœ )
}

\newtcolorbox{warningbox}[1]{
    colback=alertred!5!white,
    colframe=alertred!80!black,
    fonttitle=\bfseries,
    title=âš ï¸ #1 (ì˜¤í•´ ë°©ì§€ ê°€ì´ë“œ)
}

\newtcolorbox{formulabox}[1]{
    colback=exampleorange!5!white,
    colframe=exampleorange!80!black,
    fonttitle=\bfseries,
    title=ğŸ§® #1 (ìˆ˜í•™ì  ì›ë¦¬)
}

% --- ë¬¸ì„œ ì •ë³´ ---
\title{\textbf{[CS230] Sequence Models: \\ Word2Vec \& GloVe}}
\author{Lecturer: Gemini (Integrated Editor)}
\date{}

\begin{document}

\maketitle

% --- 1. ì „ì²´ ëª©ì°¨ (TOC) ---
\section*{ğŸ“š Course Table of Contents}
\begin{itemize}
    \item[Chapter 1-9.] Deep Learning Fundamentals \& CNNs \textit{- Completed}
    \item[\textbf{Chapter 10.}] \textbf{Sequence Models (Current Part)}
    \begin{itemize}
        \item 10.1-10.5 RNNs, LSTM, Word Representation \textit{- Completed}
        \item \textbf{10.6 Word Embedding Algorithms}
        \begin{itemize}
            \item The Philosophy: Distributional Hypothesis
            \item Word2Vec: Skip-gram \& Negative Sampling
            \item Word2Vec: CBOW (Continuous Bag of Words)
            \item GloVe (Global Vectors)
        \end{itemize}
        \item 10.7 Sentiment Classification \textit{- Upcoming}
    \end{itemize}
    \item[Chapter 11.] Attention Mechanism \textit{- Next Part}
\end{itemize}

\vspace{0.5cm}
\hrule
\vspace{0.5cm}

% --- 3. ì´ì „ ë‹¨ì› ì—°ê²° ---
\section*{ğŸ”— ì§€ë‚œ ì‹œê°„ ë³µìŠµ ë° ì—°ê²°}
ì§€ë‚œ ì‹œê°„ì— ìš°ë¦¬ëŠ” ë‹¨ì–´ë¥¼ ë²¡í„°ë¡œ ë°”ê¾¸ëŠ” \textbf{ì„ë² ë”©}ì˜ ê°œë…ì„ ë°°ì› ìŠµë‹ˆë‹¤. 'ì™•'ê³¼ 'ë‚¨ì'ê°€ ê°€ê¹ë‹¤ëŠ” ê²ƒì„ ì•Œì•˜ì£ .
ê·¸ë ‡ë‹¤ë©´ ì´ ë§ˆë²• ê°™ì€ ë²¡í„° ê°’ë“¤ì€ ì–´ë–»ê²Œ êµ¬í• ê¹Œìš”? ì–¸ì–´í•™ì ì¡´ í¼ìŠ¤ëŠ” ë§í–ˆìŠµë‹ˆë‹¤.
\textbf{"ë‹¨ì–´ì˜ ì˜ë¯¸ëŠ” ê·¸ ë‹¨ì–´ì˜ ì¹œêµ¬ë“¤(ì£¼ë³€ ë‹¨ì–´)ì„ ë³´ë©´ ì•Œ ìˆ˜ ìˆë‹¤."}
ì˜¤ëŠ˜ ë°°ìš¸ ì•Œê³ ë¦¬ì¦˜ë“¤ì€ ì´ ì² í•™ì„ êµ¬í˜„í•œ ê²ƒì…ë‹ˆë‹¤. ë°©ëŒ€í•œ í…ìŠ¤íŠ¸ë¥¼ ì½ìœ¼ë©° ë‹¨ì–´ì˜ ê´€ê³„ë¥¼ íŒŒì•…í•˜ê³  ì˜ë¯¸ë¥¼ í•™ìŠµí•˜ëŠ” \textbf{Word2Vec}ê³¼ \textbf{GloVe}ì— ëŒ€í•´ ì•Œì•„ë´…ë‹ˆë‹¤.

% --- 4. ê°œìš” ---
\section{Unit Overview}
\begin{summarybox}{í•µì‹¬ ëª©í‘œ}
ì´ ë‹¨ì›ì€ ë‹¨ì–´ ì„ë² ë”©ì„ í•™ìŠµí•˜ëŠ” ëŒ€í‘œì ì¸ ë‘ ê°€ì§€ ì•Œê³ ë¦¬ì¦˜ì„ ë‹¤ë£¹ë‹ˆë‹¤.
\begin{itemize}
    \item \textbf{Skip-gram:} ì¤‘ì‹¬ ë‹¨ì–´ë¡œ ì£¼ë³€ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ë©° í•™ìŠµí•˜ëŠ” ë°©ì‹ì„ ì´í•´í•©ë‹ˆë‹¤.
    \item \textbf{Negative Sampling:} ê±°ëŒ€í•œ Softmax ì—°ì‚°ì„ í”¼í•˜ê³  ì†ë„ë¥¼ ë†’ì´ëŠ” ìµœì í™” ê¸°ë²•ì„ ë°°ì›ë‹ˆë‹¤.
    \item \textbf{CBOW:} ì£¼ë³€ ë‹¨ì–´ë¡œ ì¤‘ì‹¬ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë°©ì‹ê³¼ Skip-gramì˜ ì°¨ì´ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.
    \item \textbf{GloVe:} ì „ì²´ ë§ë­‰ì¹˜ì˜ ë™ì‹œ ë“±ì¥ í–‰ë ¬ì„ í™œìš©í•˜ëŠ” í†µê³„ì  ë°©ë²•ì„ íŒŒì•…í•©ë‹ˆë‹¤.
\end{itemize}
\end{summarybox}

% --- 5. ìš©ì–´ ì •ë¦¬ ---
\section{Essential Terminology}
\begin{center}
\begin{tabular}{|c|l|l|}
\hline
\textbf{ì•Œê³ ë¦¬ì¦˜} & \textbf{ë°©ì‹} & \textbf{íŠ¹ì§•} \\ \hline
\textbf{Skip-gram} & ì¤‘ì‹¬ $\rightarrow$ ì£¼ë³€ ì˜ˆì¸¡ & í¬ê·€ ë‹¨ì–´ í•™ìŠµì— ìœ ë¦¬í•¨ (ë„ë¦¬ ì“°ì„). \\ \hline
\textbf{CBOW} & ì£¼ë³€ $\rightarrow$ ì¤‘ì‹¬ ì˜ˆì¸¡ & í•™ìŠµ ì†ë„ê°€ ë¹ ë¦„. \\ \hline
\textbf{Negative Sampling} & ì´ì§„ ë¶„ë¥˜ ë¬¸ì œë¡œ ë³€í™˜ & 10ë§Œ ê°œ í´ë˜ìŠ¤ ë¶„ë¥˜ë¥¼ O/X ë¬¸ì œë¡œ ë°”ê¿ˆ. \\ \hline
\textbf{GloVe} & í–‰ë ¬ ë¶„í•´ (Matrix Factorization) & ì „ì²´ í†µê³„ ì •ë³´ë¥¼ ì§ì ‘ í™œìš©í•¨. \\ \hline
\end{tabular}
\end{center}

% --- 6. í•µì‹¬ ê°œë… ìƒì„¸ ì„¤ëª… ---
\section{Core Concepts: ì¹œêµ¬ë¥¼ ë³´ë©´ ë„ˆë¥¼ ì•ˆë‹¤}

\subsection{1. Word2Vec: Skip-gram Model}


ìš°ë¦¬ëŠ” ë¼ë²¨ì´ ì—†ëŠ” í…ìŠ¤íŠ¸ë¥¼ ì§€ë„ í•™ìŠµ(Supervised Learning) ë¬¸ì œë¡œ ë°”ê¿‰ë‹ˆë‹¤.
\textbf{ë¬¸ì¥:} "I want a glass of \textbf{orange} \underline{juice} to drink."
\begin{itemize}
    \item \textbf{Input (Context):} orange (ì¤‘ì‹¬ ë‹¨ì–´)
    \item \textbf{Target:} juice (ì£¼ë³€ ë‹¨ì–´)
    \item \textbf{Task:} "orangeê°€ ë‚˜ì™”ì„ ë•Œ, ì£¼ë³€ì— juiceê°€ ë‚˜ì˜¬ í™•ë¥ ì€?"
\end{itemize}

\subsection{2. The Problem with Softmax}
$$ P(t | c) = \frac{e^{\theta_t^T e_c}}{\sum_{j=1}^{V} e^{\theta_j^T e_c}} $$
ë¶„ëª¨ì˜ í•©($\sum$)ì„ êµ¬í•˜ë ¤ë©´ ì‚¬ì „(Vocabulary)ì— ìˆëŠ” 10ë§Œ ê°œ ë‹¨ì–´ë¥¼ ë‹¤ ê³„ì‚°í•´ì•¼ í•©ë‹ˆë‹¤. í•™ìŠµ í•œ ë²ˆ í•  ë•Œë§ˆë‹¤ 10ë§Œ ë²ˆ ì—°ì‚°? \textbf{ë„ˆë¬´ ëŠë¦½ë‹ˆë‹¤.}

\subsection{3. The Solution: Negative Sampling}
êµ¬ê¸€ ì—°êµ¬íŒ€ì€ ë¬¸ì œë¥¼ ë°”ê¿¨ìŠµë‹ˆë‹¤. "10ë§Œ ê°œ ì¤‘ í•˜ë‚˜ ë§ì¶”ê¸°" $\rightarrow$ \textbf{"ì´ê²Œ ì§„ì§œ ìŒ(Pair)ì´ëƒ ê°€ì§œëƒ(Binary)?"}

\begin{itemize}
    \item \textbf{Positive Pair (ì§„ì§œ):} (orange, juice) $\rightarrow$ Label 1
    \item \textbf{Negative Pair (ê°€ì§œ):} (orange, king), (orange, book) ... $\rightarrow$ Label 0
\end{itemize}
ì´ì œ \textbf{1ê°œì˜ ì§„ì§œì™€ $k$ê°œì˜ ê°€ì§œ(ë³´í†µ 5~20ê°œ)}ë§Œ ê³„ì‚°í•˜ë©´ ë©ë‹ˆë‹¤. ì—°ì‚°ëŸ‰ì´ 1/10000ë¡œ ì¤„ì–´ë“­ë‹ˆë‹¤. ì´ê²ƒì´ Word2Vecì˜ í•µì‹¬ì…ë‹ˆë‹¤.

\vspace{0.5cm}\hrule\vspace{0.5cm}

\section{GloVe (Global Vectors)}

Word2Vecì€ ìœˆë„ìš°ë¥¼ ìŠ¬ë¼ì´ë”©í•˜ë©° êµ­ì†Œì (Local) ì •ë³´ë§Œ ë´…ë‹ˆë‹¤. GloVeëŠ” \textbf{ì „ì²´ í†µê³„(Global Statistics)}ë¥¼ ë´…ë‹ˆë‹¤.

\begin{formulabox}{Co-occurrence Matrix (ë™ì‹œ ë“±ì¥ í–‰ë ¬)}
$$ X_{ij} = \text{ë‹¨ì–´ } i \text{ ì£¼ë³€ì— ë‹¨ì–´ } j \text{ê°€ ë“±ì¥í•œ íšŸìˆ˜} $$
GloVeì˜ ëª©í‘œëŠ” ì„ë² ë”© ë²¡í„°ì˜ ë‚´ì ì´ ì´ íšŸìˆ˜ì˜ ë¡œê·¸ê°’ê³¼ ë¹„ìŠ·í•´ì§€ëŠ” ê²ƒì…ë‹ˆë‹¤.
$$ w_i^T w_j + b_i + b_j \approx \log(X_{ij}) $$
\end{formulabox}

% --- 7. êµ¬í˜„ ì½”ë“œ ---
\section{Implementation: Gensim Word2Vec}

ì‹¤ë¬´ì—ì„œëŠ” ì§ì ‘ êµ¬í˜„í•˜ê¸°ë³´ë‹¤ ìµœì í™”ëœ ë¼ì´ë¸ŒëŸ¬ë¦¬ `Gensim`ì„ ì”ë‹ˆë‹¤.

\begin{lstlisting}[language=Python, caption=Word2Vec Training with Gensim, breaklines=true]
from gensim.models import Word2Vec

# 1. í•™ìŠµ ë°ì´í„° (í† í°í™”ëœ ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸)
sentences = [
    ['I', 'love', 'machine', 'learning'],
    ['deep', 'learning', 'is', 'fun'],
    ['machine', 'learning', 'is', 'hard'],
    ['orange', 'juice', 'is', 'delicious']
]

# 2. ëª¨ë¸ í•™ìŠµ
# vector_size: ì„ë² ë”© ì°¨ì› (100~300)
# window: ì£¼ë³€ ë‹¨ì–´ ë²”ìœ„ (5)
# sg: 1=Skip-gram, 0=CBOW
model = Word2Vec(sentences, vector_size=10, window=2, min_count=1, sg=1)

# 3. ê²°ê³¼ í™•ì¸
vector = model.wv['machine']
print(f"Vector:\n{vector}")

# 4. ìœ ì‚¬ë„ í™•ì¸ (í•µì‹¬)
similar = model.wv.most_similar('deep')
print(f"Similar to 'deep': {similar}")
\end{lstlisting}

% --- 8. FAQ ---
\section{FAQ \& Pitfalls}

\begin{warningbox}{ë°ì´í„° ì–‘ì´ ì¤‘ìš”í•©ë‹ˆë‹¤}
ìœ„ì˜ ì˜ˆì œì²˜ëŸ¼ ë¬¸ì¥ 4ê°œë¡œëŠ” ì•„ë¬´ê²ƒë„ ëª» ë°°ì›ë‹ˆë‹¤. Word2Vecì´ ì œëŒ€ë¡œ ì‘ë™í•˜ë ¤ë©´ ìœ„í‚¤í”¼ë””ì•„ ì „ì²´ ê°™ì€ \textbf{ëŒ€ìš©ëŸ‰ í…ìŠ¤íŠ¸}ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì‹¤ë¬´ì—ì„œëŠ” ë³´í†µ êµ¬ê¸€ì´ë‚˜ í˜ì´ìŠ¤ë¶ì´ ë¯¸ë¦¬ í•™ìŠµí•´ë‘” ëª¨ë¸(Pre-trained)ì„ ë‹¤ìš´ë°›ì•„ ì”ë‹ˆë‹¤.
\end{warningbox}

\textbf{Q. Word2Vecê³¼ GloVe ì¤‘ ë­ê°€ ë” ì¢‹ë‚˜ìš”?} \\
\textbf{A.} \textbf{ë¹„ìŠ·í•©ë‹ˆë‹¤.} ì–´ë–¤ ë°ì´í„°ì…‹ì—ì„œëŠ” Word2Vecì´, ì–´ë–¤ ê³³ì—ì„œëŠ” GloVeê°€ ë‚«ìŠµë‹ˆë‹¤. ë³´í†µì€ ë‘˜ ë‹¤ ì¨ë³´ê³  ì„±ëŠ¥ ì¢‹ì€ ê±¸ íƒí•˜ê±°ë‚˜, ìµœê·¼ì—ëŠ” BERT ê°™ì€ ë¬¸ë§¥ ê¸°ë°˜ ì„ë² ë”©ì„ ì”ë‹ˆë‹¤.

% --- 9. ë‹¤ìŒ ë‹¨ì› ì—°ê²° ---
\section*{ğŸ”— ë‹¤ìŒ ë‹¨ê³„ (Next Step)}
ì´ì œ ìš°ë¦¬ëŠ” ë‹¨ì–´ í•˜ë‚˜í•˜ë‚˜ë¥¼ ì˜ë¯¸ ìˆëŠ” ë²¡í„°ë¡œ ë°”ê¾¸ëŠ” ë²•ì„ ì•Œì•˜ìŠµë‹ˆë‹¤.
í•˜ì§€ë§Œ "I ate an apple"ê³¼ "An apple was eaten by me"ëŠ” ë‹¨ì–´ ìˆœì„œê°€ ë‹¤ë¥´ì§€ë§Œ ì˜ë¯¸ëŠ” ê°™ìŠµë‹ˆë‹¤. ë°˜ë©´ RNNì€ ê¸¸ì´ê°€ ê¸¸ì–´ì§€ë©´ ì•ì„ ìŠì–´ë²„ë¦¬ëŠ” ë¬¸ì œê°€ ì—¬ì „í•©ë‹ˆë‹¤.

ë‹¤ìŒ ì‹œê°„ì—ëŠ” ì…ë ¥ ì‹œí€€ìŠ¤ ì „ì²´ë¥¼ ë³´ê³  ë²ˆì—­í•˜ê±°ë‚˜ ìš”ì•½í•˜ëŠ” \textbf{[Seq2Seq]} ëª¨ë¸ê³¼, ê¸´ ë¬¸ì¥ì—ì„œë„ ì¤‘ìš”í•œ ë‹¨ì–´ì— ì§‘ì¤‘í•˜ê²Œ ë§Œë“œëŠ” \textbf{[Attention Mechanism]}ì„ ë°°ìš°ê² ìŠµë‹ˆë‹¤. ì´ê²ƒì´ í˜„ëŒ€ AIì˜ ì •ì ì¸ \textbf{Transformer}ë¡œ ê°€ëŠ” ë§ˆì§€ë§‰ ê´€ë¬¸ì…ë‹ˆë‹¤.

\vspace{0.5cm}

\begin{summarybox}{ë‹¨ì› ìš”ì•½ (Cheat Sheet)}
\begin{enumerate}
    \item \textbf{Skip-gram:} ì¤‘ì‹¬ ë‹¨ì–´ë¡œ ì£¼ë³€ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•œë‹¤. (í¬ê·€ ë‹¨ì–´ì— ê°•í•¨)
    \item \textbf{Negative Sampling:} ì „ì²´ Softmax ëŒ€ì‹  O/X ë¬¸ì œë¡œ ë°”ê¿” ì†ë„ë¥¼ ë†’ì¸ë‹¤.
    \item \textbf{GloVe:} ì „ì²´ ë§ë­‰ì¹˜ì˜ í†µê³„(ë™ì‹œ ë“±ì¥ íšŸìˆ˜)ë¥¼ ì§ì ‘ í™œìš©í•œë‹¤.
    \item \textbf{Tip:} ë°ì´í„°ê°€ ì ì„ ë• Pre-trained ëª¨ë¸ì„ ì¨ë¼.
\end{enumerate}
\end{summarybox}

\end{document}