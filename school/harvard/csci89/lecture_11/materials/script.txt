89 day 11 - YouTube
https://www.youtube.com/watch?v=nbB6iaok12k

Transcript:
(00:01) Hello everyone. Hello Dr. K. Hello. How are you? I'm fine, thanks. How are you, sir? Yeah, good. So, today we have quiz number 10. First question, what is primary purpose of name and recognition in the field of natural language processing? Do you consider correct answer as B? Detecting and categorizing name named entities within the text. That's what we mean by named entity recognition.
(00:43) Second question. Which statement best describes a role based approach to named entity recognition? C. It uses predefined linguistic rules and patterns to systematically identify entities in text. Right? So this is rule-based approach is indeed what what we mean by C. Next one. What role does uh spacey library play in recognition tasks? And C tells us it offers built-in train recognition models for various languages.
(01:26) So this is inde what what it is for it has building models. Next one question four. How do scalability issues affect role by standard recognition systems? And uh we understand that in this case as rule sets grow right then problem becomes more and more complex. I mean the the system becomes more and more complex and difficult to manage effectively. So C is correct answer.
(01:51) And the last one is what are some key disadvantages of using statistical methods for named energy recognitions? They require a large well well annotated data sets for training which can be resource intense to accure and maintain right. So this is what what issues are with those models which are based on statistical methods.
(02:18) Any questions about this quiz? So now let me I had a question but just let me find it. Yeah. So today we have uh lecture 11 and we going to I found it if you want to. Sorry I took so long. Um just for question three I just wanted to make sure reason B is not true it's because it's not a it's not a gooey right it's just a static image that uh which question I'm sorry I'm sorry question three the reason be it visualizes pipelines it doesn't do it actually right yeah because it's a visualizer not a right it's not interactive no yeah it is also u
(03:15) Um, it it doesn't visualize pipelines, right? Perfect. Just wanted to make sure. Yeah, I thought it had display. Uh, I'm sorry. Say it again. I thought spacey has display. Yeah, but I think I think you can't interact with the images it makes. So, I don't think it's considered a GUI.
(03:38) I think it's just considered a visualizer or a static image. Well, we never went over what that means. like your uh like your computer interface, you can click on icons and and it it does something with them. With the uh with the display images, they just makes an image and we can't do anything with it. We can't click it to expand it to to alter it.
(03:57) Okay. So, the first part was okay, but the second part is where it's wrong. Yeah. And and I think that um Dr. Crush was also saying something about the the pipeline, but the second part is definitely wrong. So we okay right? So now uh today we are going to talk about so-called conditional random fields.
(04:27) Uh at first we are going to introduce um hidden mark of models. They are based on so-called markoff chains. So first we're going to talk about markoff chains. Then we introduce h mark of models and then as a sort of next step we are going to introduce conditional random fields. Next part is about sort of combination of LSTM.
(04:46) To be specifically people use birectional LSTM and they combine it together with conditional random fields to get bstalm with conditional random fields and then we are going to talk about original encoders and also briefly mention maybe if you have time generative adversarial networks so how they are sort of designed maybe we will not go into like specifics but at least in general terms I will tell you how generative networks are kind of designed.
(05:22) So now first is hidden mark of model but before that I want to briefly talk about mark of chain. Let me introduce mark of chain. I'm not sure if all of you know what mark of chain is. No it is like usually covered in probability courses maybe not in like introductory ones at least in advanced in advanced courses it usually it is usually covered. Let me talk about mark of chain.
(05:46) I will maybe introduce example first and then maybe I will give definition or maybe I will just use an example kind of tell how it should be defined. So first mark of mark of chain mark of chain before we introduce mark of hidden models let's talk about simple mark of chains. So this is mark of mark of chains right mark of chains you don't see it on the slides but it is something which we have to discuss first in order to understand the next step which is already hidden mark of model let me just take example and say let's assume that we have a number of states let's say three three
(06:29) states for example first states second state next state now if If you want like application to natural language processing, you can think that you have vocabulary which consist of only three words and nothing else. So only three words and you start generating speech and you say first time I start in state one it means my current word which I just generated is number one from my vocabulary and then I say let me generate next word and there is like probability of transitioning to state two which is let's say P12 moving from first to second it is some kind of
(07:10) probability basically or maybe I can go to state three probability it will be from 1 to three. It means if currently I generated first word from my vocabulary next word will be one of those or maybe even I can come back. So there is a possibility with probability P11 I can come back.
(07:37) So there is the strip possibility generally speaking it means next word which I'm going to generate will be the very same word for my vocabulary maybe next one maybe next one right those probabilities. So clearly we have constraints. Let's say conraints which we have is going to be P11 + P12 + P13 must be equal to one clearly right not to mention every PIG it is probability must be non negative clearly.
(08:10) So first of all we are talking about probabilities then on negatives and if I start in first state I have to end up somewhere it means P11 plus P12 plus P13 must be one because probability to end up somewhere is 100% like one it mean this way now if I start in second state I can talk about basically the same thing I can go to left I can go to right or I can come back everything is kind of possible now Maybe some probabilities will be small but we kind of assume everything is possible from second to third and similarly from second to first plus from second to second plus from second to third. So
(08:53) third state is equal to one that's how we kind of define it. Finally last state we understand that we have three types of transitions. Maybe I'll come to the first state P31 or maybe I come to second state P32 or maybe I'll come back which happens with probability 33 and I have last constraint P31 plus P32 plus P33 must be equal to one it is my set of constraints my probabilities which typically I have to estimate from data at let's say early stage ages.
(09:33) People try to model language this way. They would say we have words and we kind of know that next one must be generated based on what current is. So current word is going to influence what is going to be generated next and they use mark of chains to model it. Basically sometimes you can uh maybe model letters as well right letter then next letter next letter could be mark of chain could be kind of used in this case very simple model but nevertheless at some point we could use it now there is a one issue I would say one property it is called mark
(10:08) of property in this case when I say I'm in state one let's say it means currently I generated first word from my vocabulary then second one should be either first or second or third with those probabilities. Now the question is is it really correct to say that only last word matters maybe whatever comes before also is important right so it means mark of property explicitly tells me there is this type of assumption which tells me that basically past doesn't matter only present will define future dynamics now it means uh let's say mark of property
(10:49) which we in this case use is going to look this way. Mark of property let's say probability that next state now let me call like x at time t + one for example is going to be one of those first second or third no let me call it lower case xt + one it it means it means this is like x lowerase x means fixed one it is one two or three in my example basically and capital x is like random variable because next one is random variable and I say conditionally on whatever Previously it was it is xt xt minus one was xt minus one and so on
(11:34) there is like tail uh we go back to the start of sentence for example and by mark of property we we mean that this must be equal to probability of transition to state xt + 1 = to xt + 1 of those I just plug number this is correct for one correct for two correct for lower case x is like fixed one given previous was xt = to xt and nothing else.
(12:05) So basically history in this case is not important. This this is like this history is not important only present state is what I have to keep. This is called mark of property my transition or my future dynamic will be predetermined by current state. Now you can say it is very strong assumption. It means we cannot cover many models.
(12:30) We can cover only such specific dynamic where this is correct. Now I can tell you for example in reinforcement learning everything is basically mark of change. Not to be precise mark of decision process. In that case we also can make decisions but dynamic is actually exactly this way. Only current state matters.
(12:49) In that case current state and current action matters. history is not important and you can say uh well how is it possible that this field like reinforcement learning for example solves so many problems as you know maybe they already play better than than people right alpha go for example and so on they can play better than people cuz it's possible if it has such strong assumption and we know it is not always correct right I drive a car if I want to use portion learning to kind of uh develop self-driving algorithm. The question becomes I know that it is not only
(13:26) current state it is also maybe speed maybe something else something else I take my snapshots from cameras but snapshot is not not sufficient I want to know where something is moving like objects or people around how fast they are moving and so on it becomes kind of strange assumption that only current state matters in this case I can tell you current state generally speaking doesn't have to be like snapshot By current state we may we we may may actually mean by X some kind of history.
(13:58) For example in case of uh self-driving cars you can take easily a bunch of snapshots over time right it's like short video basically it will be like short video you basically current state is not just current location of car but location and also speed direction of of of like speed of all objects around and so on.
(14:22) basically typically means we take like movie four snapshots for example consequence snapshots. It allows you to recover speed and direction and everything of all objects. It means uh if you're really concerned like in terms of language for example you know that maybe next word is predominant not by current word only but maybe by a bunch of previous words. No. Okay.
(14:48) Your state could be not not not worth your state could be like two g for example or three gram. So three g three g three g you're moving around here then okay you can say my state is not just word but it is like three g for example then it becomes already more realistic why we say mark of property holds.
(15:07) So this idea so we can always say one to three means not just word from my vocabulary but already some kind of two gram or three gram from my vocabulary of three grams then it becomes more realistic that's why it can be applied in practice again I can tell you that the whole reinforcement learning is based on idea that this assumption holds and is being applied to many many different problems simply because we always can redefine what I mean by current state current state can be a bunch of different things even like a little history right for example 2 g or 3 g if you're talking about sentence
(15:39) which you're trying to generate using mark of chain so this idea behind mark of chains now in practice we observe let's say uh we're going to observe some kind of transitions if we run this mark of chain I'm going to say x you see xt right okay x first for example one is like t I'm going to observe something x second x third and so on. If my axis are words, I'm going to talk about words.
(16:15) First word, then I transit somewhere. I generate third one. Then from here I can move somewhere else. Maybe I generate second one. Then second one again and so on. This is what I kind of observe in practice. But when we try to sort of describe it, we say there are kind of capital X's.
(16:34) Capital X ais will be those which will be observed. But once they observed, it will be just the numbers. To be precise, they are not numbers. They are some kind of elements of some abstract space. Could be like tokens, could be two grams here or whatever. No, we typically use numbers which are actually not even numbers. I can tell you that they are actually to be specific.
(16:53) They are labels. It is like categorical variables. You can play them in quotes if you want. So they are sort of in quotes. Third state, second state, second state again. So that's what I mean by mark of chain in such cases. Any questions about mark of chain. So now there is one obvious disadvantage.
(17:20) No one disadvantage is that we say that um well disadvantage to to kind of history being not important is not not really disadvantage because we can always say that current state is a little bit more than just word. It could be more than one word. It could be like 2 g or 3 g for example then it is kind of resolved.
(17:43) Now second problem is we're going to say let's stick to example where my access will be like words single words. So I'm going to say that basically my next word is going to be predetermined by previous outcome previous observation of my previous word. I generate sentence and next word is sort of predetermined. No kind of improistic sense but it is still predetermined by previous observation.
(18:10) Now there is a kind of issue because what if I let's kind of be realistic right when we when we when we talk we can actually choose uh we can we may have some kind of intent to say something but we can potentially choose something different. I mean we can choose different words to explain the same notion.
(18:31) we can choose different synonyms right so it means uh maybe it's not only what we said is important before when I I'm talking about x3 maybe not what we said is important maybe it is important what we wanted to say there is some kind of hidden notion of what we want to say for example right what we want to say and then there is realization and then we actually move to next state and maybe what I wanted to say is even more important than what than what I just said because what I intended to say is like kind of hidden information about my intent right so this kind of idea behind
(19:06) hidden mark of models you can say that there are some sort of already hidden sort of states and I move from hidden state to hidden state but I observe only already realizations of particular kind of words for example let me move to next slide and say this is hidden mark of Mark of model it is defined this way. Let me let me maybe um erase something.
(19:32) So this is mark of chain. We understand what happens. We are talking about sequence of sequence of uh my uh let's say sequence of my awards. No, in my example in if I want to apply to natural language processing maybe I want to talk about sequence of words. Okay, I observe X first then I move to X second.
(20:00) Let me sketch it this way. I move to X second then I move to X3 then I move to X 4th and so on. So basically whatever I observe for example sx3 is predetermined by my previous word which I generated just before that. Okay this is a model right but it has some kind of disadvantages obviously because why next word only predetermined by previous words and then there is like next step which is called hidden mark of model.
(20:36) Let me say this is mark of chain and second one is already hidden hidden mark of model hidden mark of model this way. um and uh now you can see definition on the screen. Let me maybe first uh sketch also my observations. Let's say I'm going to actually assume that there is some kind of hidden state. Let me say there is like a uh hidden state right hidden state which allows me to transit from a one state to second state to next state but it is not really observable let's say y first then y second y third and so on again and if you want
(21:37) to apply it to language you may think about for example part of speech maybe my hidden state is exactly part of speech noun then after noun it makes sense to generate maybe a verb and so on right after noun maybe I maybe maybe I will generate noun again or maybe I will generate verb or whatever so those hidden states could be basically specific specific let's say part of speech which I want to generate and that's how I transit but I sort of assume that I don't even kind of observe them in case of part of speech you can
(22:12) always say observe them as well because you can can measure what it is. But it's more even more interesting when you don't really observe those hidden state. That's why it is called hidden because you may not even know what those are. But what you observe as a result of this is some kind of some kind of let's say output based on current hidden state.
(22:38) So there is like X first which is being generated based on your Y first this way. So why first is your hidden state some kind of intent maybe you want to generate something right but then there are some kind of options okay I already decided I want to generate noun but what kind of noun and then there is like observation which is already actual word which is x first and I will generate it this way you can sketch it basically this way then x second is what I generate if I observe second hidden state Then y3 is next hidden state and I get basically this type of dynamics where x's are
(23:22) generated right are generated I mean observed they kind of observable but y's are not even potentially observable now of course we have to still have some assumptions about like mark of property and so on in this case I basically say let me similarly say assumptions so assumptions.
(23:47) The assumptions they're also going to define parameters. My assumptions in case of hidden mark of mark of the model is going to be the following. Probability that I transit no let me say let me say even not assumptions but parameters they basically define my parameters. Let me say parameters parameters not parameters to estimate essentially in this case I at time t want to be in state j first second or whatever some kind of hidden state j in this case by the way is not like inter is like kind of label first second third state and uh then I was at time t minus one in different state like I so this
(24:33) way so this is basically my uh parameter which defines transition from hidden state to hidden state. Again hidden state is something which I not even never observe. Uh you can think that is like part of speech noun noun verb and and so on. But then I generate actual noun actual noun actual verb and so on.
(24:56) Then and it is called transition probabilities right. So this is it's called uh transitions essentially. Second notion is emissions. those gener generations of XS will be called emissions and I say probability of generating XT uh which is whatever it is like let me just keep it this way being I'm currently at time T by the way same time in state J is my probabilities of emissing those specific realizations I decided I want to generate noun it is hidden state and I generate specific noun and I observe is a vic noun. So this will be called emissions. So this
(25:39) is emissions right? Emissions those are also parameters but also initial state is important. This is also kind of parameter right. So initial state which tells me where I initially I'm initially supposed to be is kind of start of my sentence. So this is start of my sentence right at time t= to one this sub index one means time is equal to one. So this is called here mark of model.
(26:10) Now you can imagine if you generate specific like sentence it means if you observe specific sentence let's say someone generate specific sentence the question becomes how to fit hidden mark of model basically you say there are observables I have those let me compute likelihood and maximize likelihood in order to estimate all these parameters transition probabilities emission probabilities and also initial state it has to be chosen as well.
(26:40) also initial state initial state which was there also needs to be chosen based on your data based on your observations. So now I can using data by maximizing likelihood generate my maximize my likelihood and estimate my parameters. There are two main algorithms which are available b algorithm in this case we use expectation maximization typically it is used when we don't really observe wise we have no idea what they are if I say they are sort of parts of parts of speech in that case you kind of observe those you may not even need expectation maximizational grade because you already
(27:12) observe those your training data set at least will have all this annotations you know that this is noun noun verb and what what kind of noun what kind of noun and so on it means you have everything available if you have everything available you just compute likelihood and maximize it with respect to parameters and you have all these parameters if you don't have those sometimes you have no idea what they are you just like in case of let's say LSTM or recurren networks you assume that there is some kind of hidden you know
(27:43) hidden kind of variable uh but I don't observe it directly it means you have to somehow estimate parameters based on only observables. Generally speaking, X's are observables. Y's might not be observable. They sort of hidden from us. In that case, you have to use so-called expectation maximation algorithm, which means you take specific parameters, you construct your likelihood based on likelihood.
(28:13) you kind of approximately estimate I mean you kind of let's say generate possible wise according to your likelihood and you will know what kind of wise potentially could be there and then you using those generated twice maximize updated likelihood and so on that is called expectation maximation algorithm when you deal with variables which are not observable directly it is especially useful with expectation maximization algorithm If you have those obser observed ones I mean hidden one will be observed as well in your training data set typically people can say let us assume that hidden
(28:47) state represents parts of speech observables will be like actual words in that case you actually can run different algorithm which doesn't even require you to use expectation maximization like first one is example so any questions about hidden mark of models Um they already a little bit more flexible as you can see right than just mark of chains you have this kind of hidden hidden variables some kind of hidden information about your let's say generated word or whatever it doesn't have to be applied to natural language
(29:21) processing it could be applied to different problems as well you just assume that there is something hidden right but once you know yeah professor question here uh so where is this algorithm used like what is problem it is trying to solve. So we are trying to solve a problem such as for example we are trying to understand how to um uh how to uh identify which word is uh noun verb adjective and so on this type of problem if if I if I'm thinking about natural language processing I'm trying to solve a problem how to correctly label my words is it like noun is it verb is it
(30:05) adjective and so on Part of speech recognition POS problem part of speech right we're trying to understand part of speech what kind of part of speech it is of course it is applicable to many many actually problems it is just model which could be used to describe some kind of dynamics right some kind of dynamics of a system and we assume that whatever we observe is not actually how transitions are generated no why why cat set on the math why set should be generated ing next to it maybe something there is like hidden some kind of hidden state I generate cat set but there was something
(30:45) kind of underlying there which generates transition to next state and already state will generate my x that's how hidden kind of model works it is applicable to many kind of systems which sort of um let's say have this dynamic right it is assumption as a model we assume that my system doesn't have this simple dynamic like from SC to set to on the M and so on. But there is something hidden from us. We may potentially not even observe it.
(31:17) But we observe realization. It allows us to kind of already in more flexible way. It is still stcastic model. Clearly does not neural network. So we we can model whatever is happening under hood sort of. It is more flexible. allows you to estimate all these parameters and we can later try to for example let's say uh I'm not I'm not saying we can try to generate text no it's not for that it is actually for simp simpler problem such as we are trying to identify what kind of part of speech every every word is going to be what kind of part of speech so what happens in this case we are
(31:56) going to say let's assume we have training data set we have a sentence And we know what kind what part of speech it is noun noun verb adjective and so on. So basically y's could be available. If they available it's even easier because we can always compute those probabilities. I mean we have y available and it means we can compute likelihood as a result.
(32:22) We maximize likelihood simply maximize without any expectation step. We maximize likelihood and we already know how transitions look. Now if you take test data set the question becomes how to actually identify what part of speech it is and we sort of know let's say let's say this way by kind of you know guessing by trial and error which is not really correct but let's let's think this way now I take original all probabilities I know what happens if I'm in state noun I will generate word with such and such probability for example um right but now I take sentence from test data set which doesn't have any kind of
(33:02) labels I mean I don't know what kind of part of speech it is and my question be is going to be how to in the best way identify what part of speech it is so how it does it basically it tries to block here various kind of part of speech uh cases and sees in what case likelihood of whatever we observe from test data is going to maximal.
(33:31) Remember during training data set we already estimate all probabilities. It means we can kind of recover what part of speech we have to plug in here in order to get most likely whatever we observed. We observe specific sentence. It is test sentence. We try different parts of speech here and whatever result and maximum likelihood of whatever we observe will be basically those labels noun noun and so on.
(33:57) That's how we can use it in practice. So again y will be basically part of speech and x will be words if you train it on the data set and we able to estimate all the probabilities transition probabilities. The next step would be to try to recover from observables what is hidden there? What is hidden there? What is hidden there in in how to do it? We just need to basically uh supply or kind of uh plug in here those part of speeches which will result in maximum likelihood of whatever we observe on test set and that's how it works. Any further questions about this?
(34:37) Yeah. So um uh so so when we train this model we need to provide the observations as well as the part of the speech. Yes. you need to label that this is the observation because of this part of the speech. Yeah. If you want to if you if you want to um estimate um what kind of part of speech it is yes you have to supply your your wise you you indeed have to supply your wise which means what it is now you have to supply labeled labelled text every every word is labeled is it like noun verb adjective and so on. Yes, during training you have to supply those
(35:17) Y and X and during testing you supply only X's and you can recover what would most likely result in what you observe. That's how we basically train this model and how we use it in practice to recover part of speech on the test data set. But yes, for training data set we have to supply correct part of speech.
(35:43) So, so now um any ideas what kind of disadvantage we have in this case? We already discussed maybe right in this case disadvantage is obvious. This word is the only what determines next word. Not nice. You see x2 is the vortex x2 is only what determines my vortex three in this case. Let's say that y is part of speech noun noun and so on.
(36:19) What will determine my future dynamic? If I say this is noun for example x2 is like noun right. So let's say this is noun for example. What besides information that this is noun will determine future dynamics? What do you think? What else will impact future dynamics? Okay, I know y2 is noun. What else will impact future dynamics based on this model? Nothing.
(36:52) Nothing. Exactly. Only noun. Yeah. Yeah. Yes. So exactly based on this model only noun will impact future dynamics. You see how kind of you know um let's say um not advanc this model is is is still right. Of course we maximize likelihood and so on.
(37:14) Remember like in case of um in case of structural topic modeling we also would assume some kind of structure of this uh uh ways we generate words. If you try to generate it, it will not have any sense of course. But when you maximize likelihood and when you estimate parameters, those things actually start making sense.
(37:34) It's not like it is completely useful, but it is definitely disadvantage that only noun in location second will impact everything else not even word itself ext. So this is not nice. And this is main disadvantage. So how to to think about context and so on right. So an application uh speech recognition like example right what is speech let's let's say part of speech taking part of speech taking we already discussed wise will be part of speech access will be words that is one application second application is speech recognition actually in this case we say that um my uh let's say y is going to be actual
(38:23) text let's say actual word is why it is hidden state actual word but whatever we hear like speech like those like files with you know sound which characterize sound is going to be observable what we observe is already sound and hidden will be already actually text itself already y will be cat and x1 will be speech cat right so in this case we can also apply it for speech recognition So uh simplify dependencies as we already discussed only noun will impact future dynamics. is not nice.
(39:02) We can kind of don't like it, right? This mark of property basically restricts model's ability to capture complex long range dependencies. That's a problem. And by the way also it is computationally expensive because we have to in kind of when we see this let's say even when we do predictions when you see this type of access this type of words you have to understand what you have to plug in order to maximize your your your kind of likelihood of observing that uh and um there is like modification essentially of this approach. It is called
(39:40) conditional random fields. So keep this in mind. Now we are going to modify it. It is going to be called called conditional random fields. Let me erase this. Let me erase a mark of hidden mark of model and I'm going to say now I'm talking about actually conditional random field.
(40:03) This is like already next step. So there is a formula right? I will try to explain it now. But it actually it is quite related to hidden mark of model. That's why I want to modify this uh this representation to show what's going to happen next. So conditional random field conditional random fields conditional random fields fields right this way conditional random fields.
(40:52) So in this case we discussed that maybe it is not nice that only noun is what define my future dynamics. Let's make it more interesting. Now first of all in this case we kind of um um say that there is no like this causality of this time flow. Remember there was like birectional neural network combined with conditional random fields. We want to remove direction. It doesn't have to be like y2 is generated by y first.
(41:18) It means actually from mathematical point of view that we know that they jointly distributed but it's not like one cause second one. It it talks about specific um relations between those y2 may be imputed by y3 for example may go opposite way as well. That's why I raised those errors. they are jointly distributed if they connected right but it's not like one cause another one secondary um we actually want to if I'm talking about x3 we want to uh make sure that x3 is going to be also influenced by something else let's say uh x3 is going to be influenced by uh no
(42:07) let's say other axis right other axis I can try to connect it this way so let me think how to connect it uh I can can connect access with uh uh otherwise and also with other axis let's me let me focus on x3 so basically in fields I'm going to connect it with y2 for example maybe also with x2 to maybe I can even connect it with future.
(42:44) So maybe this way maybe with this way maybe it is also connected to something before that and so on. So it is like some kind of you know structure which I impose here and I say X3 could be generally speaking dependent on other things as well. So those are sort of connections which I u manually incorporate into my model.
(43:06) Formally speaking, it means I'm introducing the probability of Y given X is given by this function. Z is just normalization to make it probability like in case of just just like in case of soft max. We do it remember normalization. But what is this? This is some kind of a weighted sum by lambdas and there is some kind of function f which depends on yt yt minus one.
(43:30) You see those are connected y2 and y3 are connected and also x which is actually vector x it means all of x's is also part of my function. This is called a feature feature feature function right. So let me say we introduced uh feature functions this way. Let me let me focus on on time three for example like I sketched it means I'm going to introduce my function more than that I have I may introduce multiple of those I don't know which one is like best going to describe my dependencies is what I sketched only one of those so f subk f subk let's say
(44:13) first one for example I can take a f second one f third one as many as I want and I what I sketched here is like f first for example then I say y uh second tus one y firstly y3 then also all x's it means I'm talking about vector x first x second and so on all of them potentially right will be input to this function also time if I'm talking about time three will be time three in this case it is time current time I can use different function as well. I don't have to what I sketched is only like first one. So this is my first function which
(45:00) I sketched right but I can choose different kind of connections here and I say y second. No basically I'm going to say same but function is different yxc and so on third time step and I can continue and have as many functions as I want.
(45:26) Now it is like a little bit abstract and I'm telling you that this feature functions need to be constructed manually. You may ask a question how to do it right. So this is basically main disadvantage of this conditional fields. In theory it looks like very nice. We have so flexible model. We can now connect X3 with whatever we want. We can introduce context and so on. Now let me give you specific example.
(45:44) Let's say I want to understand if this is like name of a person and you can start thinking about those remember those rules those hardcoded rules. So basically you can say one of the possibilities if x2 happens to be let's say um uh let's say if x2 happens to be doctor for example or mister let's say mister mister if it happens to be mister most likely next one is name or last name right it means I can say if x2 in this case happens to be mister and x3 happens to be noun and x2 happens to be uh uh like um something else. Oh, b b b b b
(46:33) b b b b b b b b b b b b b b b basically mister is what kind of m is noun as well. So noun noun x2 is is like a mister and you kind of hardcode this this rules and you say f is equal to one if previous was previous was doctor or mister. This was noun. This is known as well. And this is for example capitalized.
(46:56) If it is capitalized, if x3 happens to start with capital letter, then I say that f is equal to one because I'm kind of confident most likely it is name or last name basically name like person basically. Then f f1 is is already defined. I can say f_sub_1 is going to be one. Typically f f is going to be like indicator function.
(47:16) The model itself doesn't impose this restriction but typically f and pract is going to be 01 is going to be one if it is like mister noun noun and capital capital letter for example but this is not the only option to understand that this is a person what else could be ms okay for this ms what else maybe previous was actually previous maybe was first name okay then mister then part of speeches noun for example example, right? And this X2 is capitalized and it is also capitalized. Then I'm kind of confident that it could be also name maybe first name then last
(47:56) name Mister first name last name and I have to manually say F2 is going to be one if this happens to be X first happens to be Mr. X2 happens to be uh some kind of let's say capitalized uh word start start with capital X3 also starts with capital X2 is noun x1 is noun then yes I can say this one and I kind of predetermine this like hardcoded rule in some sense using this f function but I don't define it I don't at least I don't define what lambda is supposed to be because lambda is going to be estimated using maximization of
(48:35) likelihood again. So when I maximize likelihood my lambda will be estimated and I will know how weight all these things that's why it's called conditional random fields you see we have this kind of access right and they related to everything like looks like field right uh and also this is only single one I can sketch different connections f_sub_2 will be different type of connections and so on for one kind of uh rule which I try to incorporate right into this model.
(49:10) I can connect X3 with X2 X1 for different row. I can connect X3 with X 55 as well. If I if I have to if I see any reason to do that to that to do that that's how this conditional random fields fields are designed. Now let me ask you what is this advantage of this conditional random fields? Seems like very very flexible model. We can actually incorporate those hardcoded rules essentially into this model and let model decide how to weight those rules. But there is obvious disadvantage which is that um if I may guess counting all these
(49:42) human probabilities will be difficult. Well, and probabilities I mean like lambdas. I mean I mean so just just counting. So in in so just counting the occurrences Y2 happened with Y3 happened with Y4 and so basically you're saying trying to manually craft those um feature functions is is is hard work right hard work. Yeah. So exactly that's main disadvantage. It is it is like nice and theory.
(50:14) It is it is more flexible than hardcoded rules as we last time kind of you know saw examples but it is still like huge work because you have to maintain all these functions manually right. It actually I mean this is a powerful tool as you understand very powerful tool actually but it requires a lots of lots of manual work and a lots of kind of um human involvement I would say.
(50:38) Yes, lambdas will be estimated from data. You don't have to decide which rule is more important, which rule is less important. If you kind of supply rule which is not really nice rule like kind of dumb rule, most likely corresponding lambda will be estimated to be very very small and your rule effectively will not be used effectively. But in order for this to work, you have to supply rules which are correct ones and it is very difficult difficult task. So those functions are not probability functions.
(51:09) So it looks like I'm not thinking about it the right way. So even f f is not probability. F is basically generally speaking whatever you want since we are going to wait it by lambda. It doesn't matter what it is. But typically in practice f is binary zero and one. We say if this pattern looks like what we want mister name let's say mister word starts with capital word starts with capital then this function becomes one like we literally say this what we want we want this to contribute to the sum even though formally speaking there is no any restriction on f you can choose whatever
(51:47) you want and it's it's clear why because there is like lamb lamb will be estimated and will kind of you know balance everything anyway you want and also So it will assume that we still having hidden variables and observed variables. In this case we assume yes we assume that those wise are hidden ones. Exactly. But during training we actually um supply correct wise as well.
(52:15) So during training we supply those and and one one more couple more questions. So we we give it all X. So very much so if I have a long sequence of events long long sequence of observed events then also my function will have to go through every single event that the past and the future. Yes.
(52:37) So we formally speaking allow this function to to to take as input entire x. It is done on purpose because we want to see some kind of or we want to use some kind of correlations of X3 not only with past words but also with future words. Well, I'm sorry to interrupt you but what if like if I follow the structure that you draw on the board here and uh X3 um is is is connected or jointly distributed with X2, X1, X4 and nothing else. and and nothing else.
(53:10) You see, because my F is manually crafted. Formally speaking, those axis, all X's are connected formally speaking or at least allow it to be connected. But once I choose specific example to sort of uh code my rule, whatever I have in in head, right? Whatever I have in mind, I can connect any way I want and say this is first rule.
(53:37) For second rule, I connect X3 with X55 or with whatever whatever you want. Connecting X3 with with anything like like everything is is not practical. My my F function should kind of reflect specific rule. For example, if x1 happens to be mister, if x2 happens to be capital word, x3 happens to be capital word, I remove all connections, then I say my function is going to be one. This kind of coded rule.
(54:09) Does make sense? Yes, it does. Yes. Otherwise, f is zero. So if I see the pattern which I want which I like mister a word which starts with capital word which starts with capital noun noun noun then I say okay looks like in this case I indeed have most likely name just as we typically understand it right when we look at the sentence we say okay Mr. uh John Smith.
(54:37) Okay, Smith probably is last name. You understand that? That's what we have to supply to this model. We have to say if X1 happens to be Mr. If X2 happens to be if you want you can even like say X2 is like equal to John. Okay, you can do even this rule you have as many rules as you want. Basic basically number of rules is not not limited. You can have as many rules as you want. Every single rule you have in M you can actually supplement here.
(55:01) Yeah. But but I I feel I feel we lost the elegance behind marov chains and hidden marov models using this manual this manual rules. Is there any anything in between CRFs and and hmms? Uh something that will not we still use probability? Uh there is not something in between. There is actually elegant way to create feature functions.
(55:27) Those f and what do you think we can do to create feature functions? Let me first show a slide where we have maybe applications name recognition part of speech tagging s segmentation task image processing. So basically all the problems can be solved using using this more advanced approach but you have to manually create this functions.
(55:54) Clearly we have um it is flexible and nice on one hand but um uh uh no independence assumptions. So they could be dependent everything is nice. We have this kind of flexibility to make three dependent on whatever you have to to make it but um disadvantage would be high computational demand clearly but most important last one is intensive feature engineering.
(56:20) We have to take every rule which we have in mind and try to try to create function f. Now if I ask you but how can we actually create function f without using manual approach. I I would personally use some probability rules, maybe join probabilities, conditional probabilities, close, close, close. But um so remember whenever we maybe started talking about like estimating dependencies is we would say there is this nice model which allows you to estimate any kind of dependence you want.
(56:58) What is that? LSTM. Yeah, LSTM. Exactly. Neural network. So basically when we have some kind of dependence and we don't know what it is supposed to be we try to use neural network to estimate dependence right and that's exactly what people realize they realized okay this f could be modeled via LSTM but to be precise because we go both directions x3 depends on past and also depends on future so it means f itself could be actually implemented via birectional LSTM that's how it is done f is going to be implemented by birectional LSTM. It allows you to have all this connections forward and
(57:39) backward and then there is no there's no need anymore to to manually craft those even though this was huge kind of deal right people would use it actually. Uh here question. Yes. So I'm so it's very very interesting. So if you don't mind me asking questions. Uh so the the the the LSTM function or the the network this one will be a classifier.
(58:02) So it will output zero or one or whatever we want it. Say it again. What was going to be 0 and one? So that so we can we will replace F1, F_sub_2 each with LTM or GR layer uh or a GR network network very much or almost. So what we are going to do let let's talk about this maybe after the break. Okay.
(58:28) So uh we're going to talk about this after the break. Um but basically those kind of hidden things will be replaced somewhat replaced with hidden state from your LSTM in some sense. Let's talk about this after the breakup. So now uh next step would be to try to use a neural network to kind of uh avoid
(1:13:19) this need to manually craft feature feature functions. Right? So in this case we're going to combine u uh conditional random field basically together with LSTM. It's not like going to be exactly random field. There is going to be some modification but this model essentially was inspired by conditional random field. That's why it is called this way.
(1:13:49) It is not like truly conditional random field because conditional random field doesn't have any input anywhere. As you can see, conditional random field doesn't have any input, right? It is kind of self-sufficient. We have some observables. Those wires are sort of hidden things which we can also assume will be observed in train data set if you want. If not, it is also possible to actually train it to kind of estimate best possible um uh transitions.
(1:14:14) But it will not will not be able to uh uh produce tax. If you want a tax you have to also supply wise essentially. Now in case of birectional LSTM what what do we have? So in this case um we are going to take um LSTM. Let me let me try to sketch something. So this is birectional LSTM with conditional random fields.
(1:15:02) So architecture is going to look this way. We have a sentence. Let me say I have a sentence X first X second and so on. It is going to be my my sentence X first X second. I'm going to supply it to my LSTM this way. X first, X uh second and so on. I continue this way.
(1:15:34) You know that LSTM they're connected this way, right? And so on. So this is my LSTM. Now next I'm going to on the top of this sort of build my um conditional random field layer. Again condition field layer is not supposed to take any inputs of any kind of you know um of any kind of sequence which is in this case output from my birectional LSM. But in this case u we have birectional which means uh we take one kind of direction also second direction we concatenate and we have this vectors.
(1:16:12) So let me let me see how how to sketch it. Um so we have uh those hidden states h first h second and so on but those h is actually based on not only single direction I sketch only single direction they are based on both directions and I concatenate them and they become slightly longer vectors and now those vectors are sort of used to uh kind of replace let's say this way replace my um my um feature functions uh to be specific I'm going to introduce something like like let's say E at time t it is called emission and I'm going to
(1:16:56) introduce it uh as my h at time t multiplied by w so let's say there is parameter w set of parameters w's then I have ht plus some kind of bias this way And uh this emissions ET is going to be vector of lens which corresponds to number of uh unique text which I have. For example, if this part of speech recognition that means number of unique like things like noun like I count noun verb and so on adjective I count how many I have. It means that effectively becomes like like a vector.
(1:17:40) I need first, I need second, I need a let's say M because I have M total unique parts of speech. Then W in this in this case is supposed to be W first W second first and so on and then W M first and this way is going to be length of my H. So it is like W then one and if my H has no let's say a K components I have to use K then W 2 K and so on W MK is my matrix and this is my HT first HT second HT K so as you can see number of hidden states at every point in time for every time is going to be K and typically I have like Birectional it means actually H first for example is
(1:18:38) going to be continuation of forward and backward right uh so this what what I have and also B first B second and so on BM so this is how I compute those emissions and they are going to be used as input to my conditional random field layer which basically play role those is in some sense play role of my of my of my functions functions f in some sense so it will be not exactly as as it was before because there is some modification but those are going to be used as inputs let's say now I'm going to have conditional random fields it means I'm going to let me sketch it somehow I'm going to translate it to it
(1:19:23) is like conditional random field right I'm going to translate it I'm going to use those um outputs those uh uh emissions right those emissions which are vectors themselves it is like to be precise it is like t first t second and and so on tm and then from here I will impose specific um kind of transformation which is going to map the whole result to my uh output which is going to be exactly my part of speech each which is like noun and so on and those like wise let's say y first y second and so on I supply them and I try to map it to those y's
(1:20:15) by minimizing specific loss function which allows me to kind of um assign my ys in a way that specific loss is going to be minimal. So this is kind of kind of on high level architecture of my birectional LSTM. So it it looks somewhat different from from conditional run field.
(1:20:39) This is like LSTM part LSTM part and this is already conditional in the field basically over there. But um you can you can see some analogy. You can say that E is kind of in some sense like feature feature uh feature uh functions they look like linear and my hes right my hes will be output from lm layer from birectional stem layer to be precise and they actually those uh hes will have as input my axis and they don't have any inputs like before there was input which is y is going to be already output actually to which I'm going to app how I'm going to classify it essentially right how I'm going to decide which one is which and
(1:21:24) then I'm going to map it to part of speech so this is in my example this is going to be part of speech like my labels correct ones and this is going to be my essentially words this way if I do it that way then it kind of resembles resembles uh idea behind random field But in this case there is no need anymore to create my features f because they are kind of created based on my hidden vector ht which comes out as as output from mystm of course on the way you also have to incorporate embeddings right this type of things and
(1:22:03) that's how it is it is it is designed birectional gan random field different architecture because now we have input to random field which we didn't have before. It is not like truly like the same conditional random field anymore because we actually simply going to use this output h with after some transformations as input to this condition field.
(1:22:34) And uh let me say why use birectional because we understand that the current x may be dependent on past observations on future observations. Since it is the case you want to use birectional, right? That's why and uh uh same applications essentially name recognition part of speech and so on. It kind of captures some kind of context already right in order to make decisions what part of speech it is and also in this case there's no need to construct our features anymore. They become effective they been replaced effectively
(1:23:10) with those emissions which are based on those hidden states. hes and it means uh we already don't have to do it as before but those part of speech is not going to be used as input to my feature it's going to be on the contrary being out is going to be output to which I'm going to map my ultimate u ultimate um output as classification so now um now let me uh say that uh of course we have advantage in this case we don't have to do do it manually anymore.
(1:23:46) It is already at our automatic feature learning clearly, right? So it is much much better and u it is still um accommodational cost is still high right model tuning and burning time is is still a problem. Here is a very simple example how to do it. Actually let me say just as I told you input is going to be my um my uh let's say sentence in this case my sentence is already sort of um uh uh labeled via indexes which refer to vocabulary I have first sentence second sentence 1 2 3 and zero because of padding it is my first sentence second sentence 4 5 6 7 that's
(1:24:33) just kind of d you know d to example which represents my sentence We understand that my text we understand that every sentence is a sequence of indexes which refer to vocabulary. That's why in this case it is simply sequence of indexes which refer to vocabulary. If sentence stops but I need more I need to add zeros as you know it is zero padding. This is second sentence and second one is like tags.
(1:25:00) Let's say it it represents like noun and so on in specific kind of order. Let's say 0 1 2 0 1 2 3 and four will be my my text just to example of course in practice you have to understand what they are you have to take your sentence you have to do tokenization and stuff like that and you have to create those those indexes same about text you have to actually if you know exact text you have to translate those into indexes of course um size of your uh vocabulary of text is potentially different that's why I have m here it is
(1:25:36) potentially different. So now uh let me just kind of briefly walk through in this case we're going to create u this u u class which is birectional lst with conditional random field. I'm going to oh use I'm going to inherit those methods and and um those um uh things from my from my uh neural network. Then I incorporate embedding layer.
(1:26:12) Then I use LSTM layer. In this case number of uh dimensions of my embed embedded uh embedded representation is 100. number of hidden dimensions that means number of those basically enters to my age is 256 is chosen to be 256. I have embed embedding layer then I have LSTM in this case since it is birectional right birectional is true dimensions typically refers to only one direction it means I take my 256 and divide it by two to get it like consistent with convention then I incorporate this linear transformation you can see here it is exactly what I sketched over there this linear
(1:26:59) transformation to get those hidden hidden X this is kind of emissions then I create my conditional random field and then I supply those emissions and tax over there and this likelihood is what I'm going to maximize ultimately and that's how it is it is done there are different actually uh realizations of this approach uh you can uh try to uh do it differently but the idea is going to stay the same exactly. So ID is going to stay the same.
(1:27:36) We're trying to take LSTM output from this birectional STM is going to be linearly transfer to those emissions and then conditional random field we'll be using those emissions to try to create likelihood which we're going to maximize and here we have some some result right maximize likelihood in this case loss is like negative or negative loss which is going to be minimized on the contrary.
(1:28:00) So any uh questions about uh birectional STM with conditional random field? Yes sir. So so I'm I'm just thinking about how this is is going to be implemented. So do we train the LS the the recurrent network first and then we we look at the intermediate outputs and we use them as an input to the CRF. Yeah. So we first take our sequence of tokens. Right. Let me miss our sentence.
(1:28:28) We apply all these techniques in order to create sequence of indexes. First we're going to have sequence of indexes. Basically this is what we have to get. Then we are going to insert here typically embedding layer. They will be represented by 100 dimensional vectors essentially right will be embedding layer.
(1:28:50) Then we have LSTM to be specific like birectional LSTM. From here we have output which is sequence of those hidden states of LSTM. And then we are going to use those hidden states and apply transformations of linear linear linear fashion linear type and those will be will be so-called emissions which we're going to use as input to our uh conditional random field.
(1:29:21) Remember there was like sum of those fs now not fs but but e sum of e essentially so those e will play role of f kind of those functions f which feature feature functions will be replaced with those e and that's how we do it and is is this available in caris or just this is no I think it is not available in caras um I don't think it is available in caris Okay. Yeah.
(1:29:51) So now uh let me see how much time we got. Um you will try to experiment with this yourself. Maybe on Friday we also will talk a little bit more about this and we'll try to apply birectional STM with conditional fields to something something else. Uh now let's talk about variational autoenccoders. Variational autoenccoders. Um so just just want to be clear that um this type of um architecture is not like literally field as it was before.
(1:30:33) It is slightly modified, right? We don't have this functions f anymore. they been replaced with those is and also we construct this uh likelihood based on also part of speech labels which we supply and which we try to map to what we are what we are trying to um est predict. So we introduce so-called score right and those scores will be used to kind of find best possible match encourage you to read about this a little bit more in detail if you want to kind of like reconstruct like mass exactly but you already understood like most of this so you can reconstruct
(1:31:18) all this final steps such as score and stuff like in no time. Now let's talk about auto encoders. So, where is the autoenccoders. So um in this case u let me uh say that we already covered out encoders and um all the encoders um assume that you supplies some kind of input then you have bottleneck and then you try to reproduce your input.
(1:32:21) This is how outcoders are designed right and it means if you try to move away from current representation of your inputs from current encodings away then what do you get now let me say regular out encoder regular out encoder let me say I'm going to have specific example where I have my encodings let's say C1 C2 two this way and uh my network takes input compress everything into two code encodings C1 C2 let's say have some kind of input so remember you remember like out encoders like regular ones it is input it is
(1:33:12) being compressed into some kind of X I'm sorry C1 C2 vector of encodings and then I can take it as input to my already decoder and recover X again right so I can create output which is presumably X again no it will be slightly different so I will say X prime or X X head whatever you like so this is like output this this C of C1 and C2 will be representation of my input and by the way potent that will be quite accurate representation right I mean if I don't really uh take it too harsh if I don't really reduce
(1:33:53) dimensionality like uh tremendously it means I can recover with high accuracy and I will see that it is almost same so this C1 C2 is quite quite accurate right potentially representation of my input now let me say what if I take this scalpel C1 C2 and I try to essentially move my couple of C1 C2 away from current location.
(1:34:30) So let's say I move it far away and I get some kind of coding C1 C2. I manually shift it. I created my out encoder. I have like couple C2. If I input to my decoder, I get some something reasonable, some kind of image, for example, text or whatever. Now if I start moving my encodings kind of manually by hand and I away move it away away from current location far away from current location and use it as input to my decoder and reproduce my output.
(1:35:04) What's going to happen if I use this as input to my decoder and reproduce output? What do you think? What your intuition tells you? Is this going is it going to produce something reasonable? some kind of result which looks realistic. Let's say this way. So now the thing is if I start messing with my encodings and pass it further through my various autoenccoder regular encoder nothing nice is going to happen. It means actually my my output will be destroyed. Let's say I has had some kind of image.
(1:35:41) Output was image. This sculp also corresponds to some kind of image. Now I shift it away. No, it means my output will be completely destroyed because my network is not designed to handle this type of perturbations. If I take my disturbance of my my encodings, if I apply a disturbance, then my output is going to be already not realistic.
(1:36:06) Now you can say but what if I don't move far away? Okay, I have this, you know, model. All the points corresponds to some kind of realistic image or realistic text. For example, you can say, let me try to maybe move my specific coles. You want it to a couple of um of my uh encodings not far away. You can say, let me move it not far away. Somewhere here.
(1:36:39) Turns out that even if I move it not far away then whatever I obtain as a result will not really or I will say will have not have to represent anything realistic anymore. It was like let's say 1.2 and this is 3.5. I make it 1.3 and 5.9. I move slightly and I pass it further from my network. Result may look completely different.
(1:37:06) There was no any reason or any kind of you know attempt for me to to to create model in a way that my encodings could be moved in this space of encodings and the result will still makes make sense. No turns out that if I move away from current locations which do do correspond to kind of realistic images or text or whatever those locations in the neighborhood they do not make any sense.
(1:37:32) I mean if I supply them as input to my decoder whatever I output from there doesn't have to look realistic doesn't have to be realistic text for example doesn't have to be realistic uh image if it was about images so those holes basically don't correspond to any realistic realistically looking images this particular point yes it does correspond because when I train it it was specific couple which correspond to my image But neighboring couple is already nothing.
(1:38:03) It doesn't correspond to any image. Even if I don't move far away, this couple doesn't have to be realistic anymore. This kind of idea I would say this is kind of disadvantage of regular autoenccoders. In this case, people say that our space of codings is unstructured. So let me say this way it is like unstructured structured encodings the unstructured kind of holes.
(1:38:38) If you move away slightly then whatever your output is not realistic anymore. And now you know that maybe you know about this that you can use neural networks and you can try to kind of you know continuously change your output. You can you know switch on smile for example person will be smiling more right for example in this case you can think that this for example encoding corresponds to smile let's say this corresponds to smile right and this corresponds to let's say size of eyes let's say this way eyes then turns out that if you slightly change encodings in coding which kind of
(1:39:21) supposed to correspond to smile and second to like size of eyes for example then you kind of move a little bit away and you completely destroy your image you don't even get anything reasonable anymore or in case of text the same you can destroy your text right away and then there was this idea which is called variational out encoders so the idea is the following saying okay since my data set of let's say space of encodings is not structured.
(1:39:52) Let's try to make it structured. What does it mean? So it means that during the training like in this case I focus only on particular point and I try to reconstruct my image or whatever for this particular point. Now I say training I'm going to introduce some kind of disturbance on the way which is random disturbance which look this way.
(1:40:16) Let me say it is input which is X vector. I supply it as input and I have this couple. She wants it to next. I'm not going to pass the same couple further. I'm going to say no no I don't want to have that one. I want to sort of test neighborhood in some sense and I'm going to sample it from neighborhood. That is to be specific.
(1:40:44) It is like normal distribution around my current point. Right. Distribution is characterized with this center and also variances as and I take randomly sampled vector C1 C2 random vector random variable basically and I sample from here and I try to reconstruct my output this way. So you can say this kind of strange procedure. Why do we do it that way? Why would we introduce this disturbance? It doesn't make any sense to disturb if I want to kind of nicely reconstruct it will spoil everything. Turns out that it is not I mean it may spoil something but turns
(1:41:23) out that it gives you opportunity to make your space as they say structured. It means now that your neighborhood of current point was also kind of tested on the way next time during next update during next mini batch you again randomly sample you take different point and you try to match it to your output and so It means everything around your current meal is going to be kind of tested.
(1:41:50) It means all the points in the neighborhood will start making sense as well. What does it mean in practice? That means you can take any couples you want you to. Again it make response to something like smell and eyes and you can try manually shift it either direction and you can see that your image for example becomes already already be starts smiling more and more and more because your space becomes structured.
(1:42:14) So it allows you to solve this problem. let's say structured uh encodings right structured space of encodings this way you can kind of walk in this space of encodings any questions about this I hope the kind of motivation is clear why we do it this way we incorporate this randomness on the way of forward propagation on purpose this is like forward propagation we get output x prime which is presumably same as x is very close to x in this case We do the same but on the way we incorporate disturbance random one. As you can see here we take point from our
(1:42:54) sample compute our recordings and then from here we sample from neighborhood and pass it further kind of a little bit strange procedure but it allows you to kind of test neighborhood of current couple of C12 of current encodings and it means neighborhood will already make sense. We don't have this holes anymore. Neighboring points will also make sense.
(1:43:19) Any questions about this? I hope motivation is understandable why we do this way. All we need to do is essentially we need to add this disturbance on the way. Now let me ask you a question. Uh you know kind of simple question actually. If we incorporate such disturbance will output will look better, worse or same? What do you think? A random disturbance.
(1:43:53) Would it look worse? Look worse. Yes, it must look worse. We are trying to kind of test neighborhood. We're trying to make neighborhood um um also trying trying to make it correspond to some kind of uh realistic output. It's it's nice idea but the problem is no not problem but the the issue kind of feature is output will be already uh worse remember if it is worse but neural network will have to minimize cost function and if I don't impose any restrictions on my mu and sigma let's on my sigma first of all on my variance what will network want to do with
(1:44:36) variance no any restrictions My network can make it large or can make it small whatever it wants. The only goal right now is to try to match it to the output to the input. If I say do whatever you can but try to match it and you say disturbance actually makes it worse.
(1:44:56) What will happen with my variance if I don't impose any restrictions on sigma? It will be zero. It will be zero. Yes, it will shrink to zero. Exactly. So if I don't have any restrictions on my sigma, it will shrink to zero. Exactly. So it turns out that actually in this case it is important to also impose some restrictions on my sigma and they um incorporate so-called calic divergence.
(1:45:24) Basically what that means they added to the loss function because we want to impose some restrictions on sigma. Sigma should not be too small and they say everything is nice but let's try to actually u make let's say in one dimensional case let's try to set up a goal typically it is like standard normal distribution this type of bell-shaped curve around zero and we are saying let's try to make mu close to zero for everyone it's important for everyone I'm trying to make mu close to zero And I'm trying to make my sigma close to one. No, it means uh one time for one input it may be
(1:46:07) slightly off. Understandable. So it is for one for one input. For second input it will be over there. Right? There is still will be some variability different m uh used. Let me keep only two. So it is transparent. But if I impose this type of loss function which tries to make not even loss no yeah it is loss function which tries to make every distribution in this case as close as possible to standard normal then actually my sigma will not shrink anymore because it has a restriction sigma should be close to one already that's how we do it let's say
(1:46:47) there is like mu1 which corresponds to one input mu2 from the distribution correspond to second input And remember the whole point of doing this was to try to test neighborhood. Now neighborhood everywhere is going to make some sense what it means. I can move from mu1 to mu2. This point correspond to one image. Second m correspond to second image.
(1:47:14) I can walk in this space along this line connecting m and my image of first type will continually transform to image of second type. Why so? Because neighborhood was tested every point here was somewhat tested during training. They kind of compactly centered around zero. Variance is actually one because I impose this restriction. Basically this diverence means let's make every distribution close to standard normal.
(1:47:38) Formally if you drive it will look this way but it's not important just tech technicality. What's important in this case is that we are trying to make every distribution kind of everyone should be should be moving towards zero first of all and variance should be moving towards one otherwise the network is smart enough to kind of shrink z sigma to zero that's why we impose this uh latent loss it is quite important but what what would be the benefit of uh centering the the mean around zero yeah so we want actually if they all over the place if one is far away and
(1:48:15) second is far away. Okay, let let's think this way. Uh shrinking sigma to zero is is what what is going to happen, right? Shrinking sigma to zero. What what is going to happen? Now you say let me not let your network shrink sigma to sigma to zero. But let me allow mute to be any anywhere it wants.
(1:48:39) So it will kind of you know spread everything around the space and effectively it become the same. If you zoom out you will see that effectively sigma becomes small if you zoom out right if they all over the place one m is over there second mu is far away on the left effectively it means everything is relative your sigma becomes quite small that's why I want to sort of keep them close to each other while sigma is is around one does make sense now um um okay okay let me put it differently if they overlap. If they overlap, I can walk from mu1 to mu2. Imagine
(1:49:17) image of one person and image of second person and I move here manually shift my my encodings and see what output is going to be. I can I can manually shift one image into second image. It will be continuously transforming. So because every point here is from the distribution and also from that distribution.
(1:49:40) It means all response will correspond to realistic output. Now if you say what if it is not the case what if I make my sigma to be around one right still but I have this is around approximately one approximately one this is around mu one this is around me two so you see what happens first of all if you can zoom out it effectively means my sigma is small already effectively there's no difference between making sigma small or making distance large first of all secondary if I move along this line there will be places right here for example where my image is already not realistically looking image it's not from the distribution it is not from
(1:50:25) that distribution this point was never tested if they don't develop this point if I move continuously was never tested that means I cannot continuously change one image to second image this is not realistic image anymore it is like whole essentially But so so the way I understand it is by by forcing all the means to be around zero we assume we we ensure that the the space is compact and continuous right no let's say this way yeah I'm not sure if it is correct terminology but your intuition is right exactly that we
(1:50:57) ensure let's say we ensure that the distributions overlap okay yes and it means if we continuously move from one center to second center we are never out we don't go through this hole. Yes. Yeah. So the point is to make them overlap to make this distribution overlapping so the the the space is continuous. Yeah. Let's say this way.
(1:51:21) I'm not sure if it is continum. Let's not kind of go into that road. But your intuition is right. I can tell you your intuition is right. Maybe wording is not right because continuous is very specific term. It must but intuition is definitely right. Okay. Thank you. Yeah.
(1:51:46) So we can we can kind of move from one m to second and we'll observe this transformations and on the way we will never if they if they far away effectively between there will be holes like this hole essentially which correspond to that hole. So if you don't make mu close below to each other it means they will be tempted to be far away network will compensate with w's it will say okay I cannot make sigma to be zero and I will make distance to be large right and compensate with w's later on it effectively means that we if you zoom out right it means effectively every distribution is tiny around its own location and we are back to this kind of scale
(1:52:27) That's why they they have to overlap. First of all, it means they should be close to zero and secondary variance should not shrink to zero. It means we say we want a one for the variance zero for one for variance.
(1:52:45) There is still will be some variability of course because we want to we still want to also reproduce output. They will not be same. They will be different from each other but they will be overlapping and this space becomes structured. We can now walk here nicely easily and we still get result which is realistically looking result.
(1:53:03) So this is called vational encoder quite quite cool stuff actually but this is not um most um kind of advanced algorithm uh which was introduced over the past like 20 years. Right? The next one which is called generative adversarial network is was considered to be one of the most important probably advancements right in your networks. Maybe it was before transformers but it was quite interesting people would be actually paying attention to this network. Let me say you can read about this.
(1:53:41) Let me say only in general terms um how it is designed. Uh let me ask you a question. Let's assume a simple question. Let let's assume we have two children and we want to train them to play chess. What should we do in this case? If I want uh uh train them to have play nicely kind of chess, right? What options do we have? Teach them to play each other. Teach them. Oh, okay. That's a smart idea. Yeah. So, we have two options.
(1:54:17) We can teach them ourself, right? We'll be supervised algorithm. We have to basically be expert. We have to supply train data and so on. We have to supply how they should do basically and and teach them. We will teach them how to do. We will be kind of supervisor. In this case, we need to have algorithm which is which is labeled one.
(1:54:37) We already have to be experts essentially. What if we don't have any any any we don't have any data set which is like labeled or if we don't really know how to play. I'm trying to teach them but I have no idea how to play chess.
(1:54:55) I don't have training data set with with correct labels or maybe I have somewhat knowledge about chess but not as much as you said. You can make them play against each other. Right. And it's interesting but they will learn. Now if you try to make one neural network play against second neural network one is trying to to kind of cheat over play the first one and second one is trying to overplay this. Second is trying to play the first one.
(1:55:24) What's going to happen? They will they both will learn. And beauty of this we don't have to have any kind of supervisor. We don't have to have any data set which is labeled one. That's the idea behind behind generative adveral networks. We make actually one network playing against another network. To be precise it's even more interesting.
(1:55:45) One part of network is going to play against second part of network. One part of network is trying to cheat second part of network. One network is trying to generate image for example or whatever some kind of you know data is called generator and second part is trying to not to be cheated.
(1:56:08) It is called discriminator and they starts playing against each other. One is trying to generate realistically looking images and second one is trying not to be fooled by those images and this is like part of single network. One is trying to cheat essentially. The second one is trying not to be cheated. One is trying to kind of minimize loss function. Second one is kind of trying to maximize loss function at the same time.
(1:56:34) During training we kind of train like one part second part one one part second part and so on. Essentially we kind of freeze part of network train one part on the next step we freeze second part train second uh second part. And it turns out that this way without any kind of you know label data set we can train network to generate realistically looking images. This idea behind the networks.
(1:57:02) Here is very simple example generator discriminator. Then we try to train this type of network. Right? Uh I will not go into specifics in this course. I just tell you that this kind of high level what happens. So one part is playing against second part of network. One part is essentially minimizes loss function. Second part is minim maximize loss function and we can generate images.
(1:57:29) This is not so maybe interesting but if you try to use for example convolutional general networks you can make a little bit more interesting images. And here we have already more advanced so-called style again style generative dial networks. Now we have to essentially uh solve some kind of issues already related to game theory.
(1:57:57) Actually what happens is um let's think about like children for example they play against each other. They learn learn and they kind of become better and better. It may happen that one of them will kind of you know using specific style right and second one will adjust to the style and they will be kind of both going into kind of maybe wrong direction and they will learn some kind of tricks which are very very specific tricks which they kind of know about about those tricks like they can play against each other and then use those tricks but it is not so maybe
(1:58:29) interesting not generalizable maybe that's exactly what happens it is like non problem in game theory basically so what happens is um there is a tendency to kind of uh let's say I'm going to generate a specific image right related to let's say realistically looking image and second part of network needs to be kind of needs to be able to understand if it is like real one or not real one and turns out that um if uh my network generates it decides at some point to generate like shoes and maybe second part never saw
(1:59:10) shoes and it will be kind of cheated and we'll we'll be fooled. We will not understand that this is this is real not realistic. This is like a fake image and we'll think that this is realistic image. Then first network immediately will realize that this is the way to go and we'll generate more and more and more images of shoes and second one will have no no choice but we'll have to be kind of spe kind of you know expert in shoes and as a result it will forget whatever was what whatever learned before and basically this kind of switches will be happening from time to
(1:59:43) time. They both will kind of you know try to focus on for example shoes then on on on cars and so on. they will be switching kind of from state to state and there are ways to actually resolve it. That's why they in invented style again. First of all, most important thing is actually uh experience replay.
(2:00:03) You'll have to from time to time make sure that your generator generates images from the history from the past whatever it used to generate before it needs to generate it going forward as well. That's why there is this cloud from where it will kind of generate from time to time our you know images and uh also some kind of random disturbance also helps and so on and let me show this is like cat which is not realistic this cat doesn't exist this person doesn't exist maybe you already know about this right so this type of uh
(2:00:34) models are quite impressive so let me ask if you have any questions remember in order to generate it we didn't have to have any label data said one part of network will play against second part of network one is trying to cheat second one is trying not to be fooled that's how how they being developed together like kids who play against each other like chess they can can can develop skills clearly without any teacher who kind of knows who is expert children can play and they will develop skills same ideas apply to
(2:01:07) networks we don't have to have any data set like labeled one we could have data set which is like fake, not fake, fake, not fake. But it will be quite difficult to actually create such data set right and train network which will perform nicely because of uh well first of all because not not not many obser observations but if it make one network play against another network then they can both develop the skills.
(2:01:42) Okay, any questions? Okay, let's stop now. Thank you. Have a good night. Thank you. Good night.