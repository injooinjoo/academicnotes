(2) 89 day2 - YouTube
https://www.youtube.com/watch?v=_xYUuhMYn5w

Transcript:
(00:01) Hello everyone. Hello Dr. Kashki. Hello. Welcome to the second class. Hello. So today uh first of all let's uh consider consider the quiz. You can see my my quiz number one, right? Yes, we can see your canvas quiz. So first question, first question is quite straightforward. You just need to basically compute this functions.
(00:49) This process is called forward propagation. In order to get output from this network, you need to compute basically all this intermediate values and then you get yhat. Let's quickly do it for the reference. So question one is basically example of neural network and what's the process of computing yhat is called forward propagation.
(01:12) So in this case we say yhat is equal to some kind of activation function f in this case is really loop apply to w 0 + w first * * u signal u1 + w 2 * u this way it is called it is called activation function applied to linear combinations Let me just adjust the sound. So now uh in this case if you sketch it basically we're talking about second layer that's why it makes sense to maybe introduce super indexes like second second this way.
(02:04) Now what is U1? What is U2? In this case U1 is basically going to be also some kind of activation function potential it could be different because because it is potentially different layer f applied to also bias w0 but since I like first signal it makes sense to denote it by using sub x1 as well bias first which goes into first plus w first which goes into first x1 + W second which goes into first U time X second and also this is like different layer that's why I will say first layer in this case this way and that's it basically now we can plug the numbers you can see in the table bias
(02:50) w01 first is equal to -1.2 two we plug it w first first in the first layer is equal to 0.1 we plug it then we say x first is just a signal we again particular point it is 1.3 for x1 and also 2 for x2 7 for x2 what about w2 second w2 second is equal to.5 right so we plug it 0.5 and we get some kind of number this quite small comparable to -1.
(03:29) 2 It means this is negative number. It means f applied to negative number because you're talking about in this case activation function is rectified linear unit. It look this way. It means if input is something negative output is going to be zero. Clearly if I apply such activation function f of z to linear combination z and by z I mean the whole thing here which I plug into this function this is called rectified linear unit. So we get zero in this case.
(04:09) Very similarly I can compute my UC and UC is F applied to W 0 let's say 0 second already actually U2 means it is second neuron 0 second from the first layer plus W1 second because of second neuron and the first layer multiply by X first plus W second because of the second first layer X second and we have to plug these numbers now.
(04:40) So basically w to first is equal to is equal to.9 we can see it on the table.9 w first second in the first layer is8 then I say x first is the same it means 1.3 is my point w second first is.3 this one is.3 so it is.3 * second value which is again 7 I compute this number I'm going to get I'm going to get uh 1.73 so it is going to be 1.
(05:22) 73 this way it is positive it means my result after I apply this function will be 1.73 as well so this is my use now final step to get my result right so my result will be f applied to already this linear combination that means again I refer to my table w is equal to 2 is equal to2 w first 2 is equal to.8 my u which I plug from here is zero and finally w second is 1.
(06:00) 2 2 I plug my new second which is 1.73 and I get f applied to 2. So it is 2 76 again I'm going to use here activation function which is really basically simply 2.276 2.276 276 this way. Any questions about this problem? So this is quite straightforward just algebra basically right but it gives you idea how forward propagation works.
(06:35) More than that this is called forward propagation right let me say forward propagation. What we did here is called forward propagation. Maybe you heard about backward propagation as well. Backward propagation. What is backward propagation? In this case, information sort of flows from the input to the output like forward.
(07:01) If I sketch, it is like X first, X then also bias which is just one. This W is being multiplied by one kind of. So it is by times by one. The next layer consist of two neurons. again U first U second output is my Y head from here next layer has bias as well and then I connect it this way every connection basically represents my W my W8 and I get my network this way so why forward you can think that we sort of compute all the things moving forward right first we compute you first then you second and so on and we move forward that's why is called forward propagation
(07:48) basically. Now during this process it is quite important to actually not waste all this intermediate results. It is important to store them somehow. Why? So let me say note write here a note. What if I decide to compute somewhat like let me take with simplicity somewhat like yhat with respect to parameter no let's let's take any of those let's take with simplicity let me take one of w's right let me take w first second the same idea is applied to any w if you take w from different layer very similar idea is going to be applied if I want to differentiate my function f of this line
(08:38) combination with respect to W. How can I do it? By chain rule. So it means F prime applied to I apply to what? Apply to the whole thing. Right? So this is my Z basically the one which I discussed before. I can plug Z into my function to get the result. Right? So Z is linear combination multiplied by by chain rule.
(08:59) I have to take this linear combination take respect to already W first second. It means I get time U1. And you see what happens. So basically this guy is very same Z which happens to be 22 276 276 right the very same guy this is my Z this is my Z exactly and you first we computed it was zero right so it means I know right away that derivative of my basically output from neural network with respect to parameter is equal to zero in this case please note that I didn't have to compute much if I know what if I know all those intermediate values during forward propagation if I store them somehow or maybe if I somehow
(09:45) nice basically store them somehow right usually they use matrix approach if I store them somehow I can do what's called back propagation which literally means compute all these derivatives of my output with respect to parameters but reuse those intermediate values which you obtained during forward propagation this process is basically called back propagation because I kind of move forward and I see what my derivative with respect to W's are why don't I need derivatives do we remember grad descent right graded descent will require us to
(10:19) know derivatives ultimately no it is like the loss function with respect to w loss function depends on yhat it means it is quite straightforward now let me say uh next step would be to compute derivative of loss function Uh let me say also note here derivative of loss function with respect to my parameter w is what ultimately needs to be used in order to get in order to get my update of ws.
(10:53) Now it is like dl with respect to yhat and then by chain rule yhat with respect to w right this way. So clearly what it means it means I I take this zero plug it in. I also need to know D with respect to Y head. How to get DL with respect to the Y head? Let me say it is very very straightforward where for example DL with respect to Y head would simply be let me say DL with respect to the yhat would simply be doubled yhat minus y observation.
(11:46) Now let's say if I choose L to be like Yhat minus YÂ² how can I differentiate this function? We know pretty well. So basically when you specify and car whatever you use right tensorflow when you specify loss function you can say it isn't going to be mean square error no it means your package will know analytical derivative analytically obtain derivative of dl with respect to yhat. So dumb formula is available.
(12:11) Once you say MSSE package will know the derivative is such. Then during back propagation it will basically take this value and plug it into this expression for derivative of L with respect to parameters and also multiply by dative of Y hat with respect to parameters which is straightforwardly obtained from your basic form of your neural network.
(12:30) More than that all the computations which you need to do are quite straightforward now because we obtained everything during forward propagation. So for propagation is not maybe so kind of difficult in this case but generally speaking it could be quite complicated to do forward and back propagation right that's why we have to efficiently compute it millions and millions of computations it means we have to efficiently compute it so this is the whole idea behind like forward propagation and also behind back propagation we not going to maybe talk more about this I gave you formals on
(13:01) the slides if you curious you can take a look but you ask questions if you have any. Okay. Now, second question. Sorry, Dr. Krok. Yeah, this may be an incorrect or simplistic question. Does the ReLU that is positive is it always just the um the value of the input or does the function for the RLU uh change to something different? So, in case of RLU we say f is equal to z for positives, right? f is equal to zero for negatives.
(13:38) That's just convention. Okay, perfect. It's not like I'm send different function with the worse. You could do different slope maybe, but this is convention. And uh the thing is since we have this w doesn't make sense much to change the slope here. Slope can be incorporated into W's if you have to change it.
(13:58) Right? If you multiply hw by two, effectively it means slope is now two. And do you are the W's considered weights hyperparameters? What are they? No, W's are trainable parameters. Sometimes sometimes you borrow architecture from someone. In that case, you actually can freeze coefficients W's. They will be not trainable, but they are not hyperparameters.
(14:22) They are potentially generally speaking they are trainable. Right? If you freeze coefficients of your network or at least part of coefficients of your network say I borrow it from someone and I freeze those coefficients for the first layer but I don't want to freeze coefficients for the next layer in that case they will be not traable actually but they are still parameters of network not hyperparameters but parameters I can fix them formally speaking but make them non-trainable or at least temporary not non-trainable but they are not hyperparameters they are trainable generally speaking during during
(14:58) optimization. That's the beauty of neural networks. You can basically suggest quite dense maybe potentially network or at least quite quite flexible in terms of uh capability to reproduce your dependence and you can actually find coefficients during optimization. It means you don't have to be involved. I mean humans will not have to be involved.
(15:22) Such things as like feature engineering is not needed anymore. you just basically minimize cost function and w will be obtained. So that's the beauty of that. So here they're not hyperparameters. So next question about number of parameters. This question is not not to compute hyper number of par number of parameters.
(15:47) It is about basically it is for you to think about architecture how it is designed. So we have clear understanding how networks are designed. Right? It is a good example to kind of practice and see that we understand how this architecture is. In this case we have fully connected connected neural network. It means we have 700 inputs. Let me sketch first neuron, second neuron and so on.
(16:14) And we have 700 inputs. X 700 is the last one. X second X second X first X first clearly we have a bunch of neurons between I'm not going to sketch it's clearly 700 so next layer consist of eight neurons as you can see eight neurons let me say first and the last one eight also bias next one consist of eight neurons as well this way bias output will have only one single neuron which will produce oh let's say Y hat or whatever you want to call it is like Y head. So now we have to connect everything because it is fully connected
(16:57) network clearly right now it says dense dense means fully connected. So we connected this way everything is connected with everything this way. Now the question is how many parameters do we have in this case? This is like you know let me say it is like first layer right? You first layer the last one.
(17:26) This is like you first layer first one. This one is you already second layer eight one U second layer first one. Of course we have between as well right which I didn't sketch but we have all eight in in each case. So now how to comput number of parameters. Basically every connection is responsible for parameter. Every connection represents W.
(17:54) It means in order to compute number of parameters you simply need to compute number of connections. How many connections will connect my access to the first hidden layer. So in that case you can see that basically we have 700 right plus one bias 71 inputs. If I had the one neuron it would be 700 to1. If I have two neurons it would be 7001 plus 7001.
(18:21) Now it means will multiply by number of actual neurons in the next layer which is eight in my case right eight neurons because they will enter eight neurons. Bias doesn't need to have any input. Bias is just a constant. We don't have to input any signal into bias. It means I don't count bias.
(18:41) In first case I count bias because we have outgo outgoing connections. But nothing inputs bias in the next letter. That's why only eight plus for the next layer we have using same logic a + one 8 + 1 * 8. And finally the very last the very last um uh layer we'll have 8 + 1 times in my case uh we have really we have simply one dimensional output you can see single neuron right single neuron here it means one that's how I sketch it so my head is clearly one dimensional because it is only one neuron and I have to compute it now if you compute you will get exactly 5 6 8 9 5 6 8 9 It is
(19:29) good kind of idea to match these results. Usually when you output summary, it is good idea to try to understand if those numbers match to your understanding. Right? If you computed manually and you match to the results which you can produce using summary command, then it is very nice.
(19:51) It means you understand how how architecture is in in all cases not only in case of full network and all cases it is nice idea it is good idea to check it any questions. So okay next one it tells me that I have 16 classes to classify 16 categories to classify what should I use in this case I should use clearly 16 neurons because of the 16 classes and I have to use soft max we define soft max at some point soft max will produce vector of length 16 those numbers those entries of my vector will be non negative will be positive to be
(20:32) to be precise and they will add adapt to one that means this is not this is exactly the choice. Next one mean square error and car is used for what for regression clearly for classification for example we will we use somewhat like let's say soft max maybe or maybe maybe sigmoid in case of two classes or maybe some kind of radial functions at some point before before soft max was introduced historically people use something different some kind of you know variation it was radial functions radial functions And and in this case the question is about mean square error. So this is used for regression precisely
(21:13) right. So as we at some point last time discussed. So now this is a question about learning rate alpha. I think some of you asked this question last time what happens if alpha is small for example if it is large right? So basically in this case if alpha is very large it means we're going to have divergence.
(21:35) Let me talk about this question a little bit because I want to make sure we understand what happens if alpha is not correctly chosen. It is quite important to build this type of intuition with respect to this hyperparameters. So why so because we try to optimize function potentially in in in highly multi-dimensional space number of parameters could be millions. You cannot really visualize anything or at least not much.
(22:05) As a result, you have to build intuition uh understanding that this is going to live in multi-dimensional space and you only have some kind of snapshot. So maybe some projections in this case we say I'm going to use some kind of gradient descent. Let me say my W. It means my W is equal to previous W minus alpha * remember vector of derivatives right denoted by this triangle J it is literally vector of derivatives of cost with respect to my with respect to my W's this way left hand side means new W right hand side uses old old W's clearly this al is what we call learning Great.
(22:59) It is kind of artificially chosen. It is exactly hyperparameter. We choose it up front. Basically, you can you can choose somewhat like let's say my alpha is 01 for example, right? Default value is often used 01 sometimes. 001 that depends on uh essentially optimizer which you are using some optimizer use 01 some use 01 that's how we can do it if I say minus gradient it could be too much if I say minus alpha* gradient is a little bit better maybe because I want to kind of scale it down to be on safe side because if it is just minus gradient I can easily overshoot clearly so now let's consider three cases first
(23:45) case is alpha is small first case alpha is small second case alpha is no kind of optimal I don't know what optimal means we have to define it right optimal is is always always means with respect to some kind of minimization problem formally speaking even in in economics right what is optimal taxes you know then the question is what do you want what do you want to get actually you want to get like what people stop smoking or what people spending more money what is optimal to bucket taxes for example whenever you say optimal it actually related to
(24:24) particular minimization problem what exactly you are trying to minimize that's why we'll say in quotes so optimal means kind of okay value right because optimal is kind of so the question is if if there is algorithm which can change alpha yes there is algorithm which can change alpha on the fly. First of all, there is such thing as learning rate scheduling.
(24:51) It means as you move forward, the more iterations you have, the less alpha is going to be very straightforward um uh kind of adjustment. But there is another adjustment. One of them uses ID that maybe we want to actually not just change alpha. It may be a little bit more interesting even maybe want to rotate the vector.
(25:15) Changing alpha means so what is alpha? This is my gradient with respect to levels right grad of j it means negative alpha time gradient is some kind of vector which points somewhat towards my minimum some somewhat towards my minimum. You say changing alpha it is very good. Yes there are techniques to change alpha.
(25:39) Basically Adam optimizer which you are using is doing exactly that. You probably use Adam optimizer. This is gradient descent. This is graded descent but you use some kind of optimizer. Last time I asked you to experiment. This is not due yet. It is due only on Sunday, right? So I ask you to experiment different with with different optimizers.
(26:08) You can see Adam optimizer for example adaptive you know kind kind of gradient descent and so on and it means all of them all of them basically idea that you can change alpha on the fly you can make it smaller for example or larger but there is also another interesting actually idea you can think about case where my levels look this This is my question mark. I want to find this location. I'm I'm over there.
(26:36) So my gradient points that way. It means negative alpha gradient points over there. It means it may take like forever to converge. How to converge towards question mark. No, it will be like zigzag, right? So it takes forever more than that. It can diverge. Actually, it can diverge. If alpha is not small enough, it can diverge. This stretching could be huge actually.
(27:00) It could be like uh ski ratio in my case like 1 to five maybe but ratio could be thousands millions that it is very wellnown problem nowadays basically it is related to idea that your W's sort of potentially could leave on different scale as you move from layer to layer W's could be on different scale it means it is quite difficult to actually optimize very deep network that's why when there is a deep network you have to do something about There's many techniques which were developed right for example so-called skip connections were developed to fight this
(27:35) issue or some kind of normalization of signal on the fly so-called batch normalization for example also Adam itself use this idea that you actually can collect information about your kind of curvature I would say right about your curvature and say if there is evidence that I can I'm consistently kind of you Now I have consistently one of the derivatives is much much much larger than second one.
(28:06) You can start not only scale your alpha but you can make it a vector kind of you can sort of assign individual alphas to different components of your gradient. The result it effectively will be even shifted that way. So there yes the answer is there are techniques many techniques to adjust alpha on the fly.
(28:30) More than that if you you already use it yourself most like if you used Adam optimizer that's it you already use it this type of idea so this is idea of add optimizer also you can just use kind of scheduling to make it like smaller iterations it means you don't rotate you just shrink it for example make it smaller smaller and smaller as you approach to the minimum maybe it makes sense to shrink your vector by which you shift every time not kind of to slow down not to overshoot basically this is important important when you have this type of you know no kind of stretch or levels of your function for example. So, so the answer
(29:01) is yes, there are techniques. We will not discuss much those techniques in in that class. You just need to basically be able to apply those optimizers. You can say add them optimizer. Okay, there are hyperparameters. You can read documentation and change this hyperparameters experiment with this. Basically, if you curious how they work, it is part of different class, part of deep learning. We talk in detail about that in deep learning class.
(29:31) Not only only I talk about this, everyone basically who teaches this talk about this. But in this class, we're not going to maybe spend too much time. But yes, the answer is there are techniques to change alpha on the fly. Your task is to experiment basically with optimizers. So next one alpha is is large, right? large optimal let me say I have uh my cost function let's say this is my cost function optimal learning rate in this case cost is denoted by J typically right so it is like J as a function of W's W's is I'm going to pretend it is a vector I sketch like one
(30:22) dimension in reality it is the vector question mark is what I want to get. So basically this is my J minimum is my goal. I want to minimize function I get I want to get J minimum. If I start somewhere and then I take my derivative compute my derivative multiplied by alpha is if alpha is optimal in some sense I'm going to shift this way then I'm here on the next time step. Okay, I'm going to shift further.
(30:57) But you see what happens next derivative is slightly smaller in absolute value. It means it becomes it kind of slows down itself. Right? Shift is now smaller. Now derivative is even smaller in absolute. It means I shift even smaller becomes smaller become smaller smaller and essentially at the bottom dative is equal to zero. I stuck there forever and everything is nice.
(31:26) So if function is convex like in this case and I choose nice optimal alpha optimal some sense then I will conversion in a limited number of steps. Let me say if this is my cost function as well but as a function of already number of iterations number of iterations now typically by iteration we mean so-called epoch one epoch means not just one single update of W's one epoch means basically when you use one data set right remember mini batch approach stas ready descent approach when you use one data set it means it may potentially consist of multiple updates of W's because you update your W's for every every mini
(32:09) batch. In this case, I'm talking about graded descent. So number of each iteration corresponds to exactly a poke because every time I use entire data set I make update of W's. It means what it means one iteration one update of W's is exactly one exactly one a book. Now if you use your data set on the chunk of your data set at a time because of mini bend for example number of updates of WS is not exactly the same as number of epochs because during one epoch you will have to update W's multiple times just
(32:42) to keep it in mind. So what happens in this case I have like jinium as well and I'm going to start over there and I'm going to quickly converge and I get my result. So I can stop basically at some point. Now of course you know that you have to plot maybe test error as well and maybe if it goes um up you have to maybe maybe stop earlier right but J solve the training one will converge and basically will stuck there forever that's how it works in case when alpha is optimal let's look at the case where alpha is too small right or alpha is
(33:22) quite small I'm going to sketch the very same function My W's my J as a function of W's same function question mark J minimum so I start here and I I say alpha is like not just not like 01 but it is 0 01 okay my step is like 1 million times smaller it means you will not even see what happens here right it will be moving very very very slowly.
(34:02) So it means after maybe thousand of steps I'm still far away from my minimum which I want to find. What does it mean? No, it means convergence will take forever in practice. That's what it means. If alpha is too small, this is my number of iterations. This is my J which I compute. Then I say okay I start somewhere as before. This is my J minimum and I'm going to basically stuck there right away at the initial choice.
(34:38) So how to understand it? No maybe if you know what's happening right you may get get idea what's happening right away if you kind of restart it for example you see what happens if you start a different location it will stuck at different location next time you initiate this optimization procedure it will stuck at different location and will not move anywhere.
(34:57) So it's not like some you probably it's not like probably not like so lucky to get your result right away and that it was already optimal and you're stuck there because it was already optimal especially if you kind of you know do it multiple times and every time you get different value it becomes quite obvious that your parameter alpha seems to be quite small right it doesn't move anywhere why it doesn't move doesn't move anywhere it doesn't move because your alpha is quite small next time you initialize this procedure w will be chosen differently and you're stuck at this point for example at different level and so on.
(35:28) No, it means it doesn't move much. Why it doesn't move much? You can already get ID probably alpha is not chosen correctly. But typically alpha is default parameter. It means you don't even have to choose it for the most part. Typically you say alpha is whatever like 01 default parameter probably it should work.
(35:51) If it doesn't work in your case most likely it means not choosing alpha not correctly. Most likely it means you didn't scale your data. Think about this. How was alpha chosen to be 01 for all kinds of problems. Maybe I'm talking about you know like price of a house as input. I'm going to use millions of dollars as input. It will be one maybe 1.5 7 of millions of dollars.
(36:17) Right? And you're using sense. How how can how can possibly my algorithm, my neural network, my optimizer for example add optimizer handle all cases uh using same hyperparameter only if you and I will put data on the same scale. What it means basically we are sort of required if you want to take advantage of hyperparameters of those default hyperparameters we are required to scale data or typically people scale inputs right doesn't hurt to scale output as well so scale input scale means place it between zero and one for example just literally like shrink and shift or you can take a
(36:59) standardization it means you compute average you compute standard deviation you Take minus average over standard deviation you get standardization like zcore basically like in statistic zcore right you can do it that way know it means effectively your data will be between -2 and two for the most part you can do it that way if you scale it everything will be nice so if you observe something like this most likely you it's not like you chose alpha to be small most likely you forgot to scale your data that's why next case
(37:29) alpha is large alpha is large means Uh on the contrary, we are going to actually have steps which are quite large. Let's say I start somewhere maybe I'm already close. I start very close and then I take all which is large. It means my step will be large and I overshoot easily.
(38:04) Next time I overshoot again, next time I overshoot and basically it becomes even worse because derivatives gets only larger and larger as I move away at least in this case, right? So it basically overshoots and it diverges. So it begins it is divergence case number of iterations J minimum which I want to find.
(38:33) I start somewhere which which is already nice and then it diverges. What it means? It means alpha is probably large again not because it is large because most likely you forgot something about you forgot to do something about your data like scaling data for example. Any questions? Uh professor this second graph you're drawing is the loss function right? It is like a cost function right cost which means it is based on all observations in this case.
(39:07) So if we draw this currently like let's say for our assignment and we notice it is a straight line then this means our alpha is too small. Most likely yes most likely if you have uh your J to be constant no matter where you start basically it is constant you restart your training procedure it starts at different locations mean starting level will be different and is constant it means basically alpha is too small again typically alpha is okay I mean default value of alpha is typically okay the problem is we need to kind of scale data if you don't scale data then default value of alpha is not
(39:48) appropriate most likely. I mean I saw this type of issues when people would simply forget scale data and alpha doesn't work. Yeah. And this one here uh this is before we uh choose the optimal uh uh approaches right if we go with optimal if the optimal is small or the optimal is the optimal value then it's it might reach to a straight line.
(40:18) So now if you're talking about optimal number of a books it is already different story when we choose optimal number of a books we basically refer to test test function right so we say there is some kind of test error goes down down down and then it can go up no I'm kind of exaggerating but you understand that it doesn't have to stay there forever it can go go up and it means this One is optimal test performance. This is some kind of test error.
(40:54) You want a smallest test error. It means in this case you have to stop earlier, right? But this is already different kind of story. We sort of minimize train function but in reality ultimately you want to get basically minimal test per minimal test error optimal test performance.
(41:12) Then yes there is also on the top of this some kind of test error you have to display or test metric of some kind and also stop at the right location. But if you talk purely about optimization of given cost function that's what we're going to have in three cases. So that's that what it means. And the alphas that we can change isn't it only the leaky uh value alpha or is it is there any other alpha uh we can me no no no I'm sorry le has its own alpha right it is different alpha that parameter is different I'm talking specifically about learning rate
(41:53) remember when we shift w we say minus gradient minus gradient we don't just take minus gradient And we say let's to be kind of safe scale it down a little bit right let's multiply by 01 it is called also alpha it is called learning rate it is different from from le but where do we where do we put this in like let's say in a program be able to change it look at the optimiz optimizer so if you look at the optimizer uh if you look at the optimizer Right? Then optimizers will have this parameter uh learning rate which you can which you
(42:38) can change for example this one learning rate is equal to 0.5. So you can change it here. This is exactly learning rate parameter or you can uh let me do it even better. Let me say example add them optimizer kas and you can open documentation and say okay learning rate alpha what is this learning rate learning rate is exactly what's called alpha parameter right that's how you change it you just say learning rate learning rate equals whatever you want basically typically this choice is okay typically as long as you remember to scale your data.
(43:24) So it helps us with shifting the values eventually. Say it again. Shift. Yeah. Scaling means shift and no basically put it on the scale between 0 and one for example. Oh maybe between like -2 and positive2. It means compute like this four minus average over standard deviation.
(43:45) It it means scaling, right? Okay. Yeah. this ad optimizer, right? So, any questions? I saw some kind of hand or whatever. Okay, so this is how Yeah. Yeah. I I had posted a note. I was repeating what's in chat. Isn't it also true that a large alpha can overshoot yet still converge though slower than the ideal? Yes, it is true. Yes.
(44:14) If you overshoot and you still potentially can converge, it means there will be some oscillations. Yes. Yes. And we actually to be honest we always see it. Why so? Because we approach minimum. I mean how how we shoot that we're going to hit precisely question mark. If you slightly overshoot we already on the other side and we go back backward and we sort of assillate around question mark. Basically in practice are sort of inevitable. That's correct.
(44:42) No, it means locally alpha was kind of you know kind of maybe not small enough but it is typically okay if is not like too large right but uh it is um it it is even in this case I I sketch it this way but if you continue think what happens will I shoot like zero derivative place probably no that means I will shoot and come back come back come back so it will be some kind of sillations but this is still optimal case so I can easily imagine that at some point I will slightly overshoot it can go up down up down up so it's not a problem right
(45:22) yeah so it is not a case where we will be concerned because it is not not not not quite large it is still convergence but if you say like in this case I choose alpha I I will shoot but no sort of you keep in mind I did that you if you can zoom it in here right zoom zoom in you kind of say let me zoom it in and see what happens so basically your idea is if I zoom it in your idea is that there is this type of you know behavior at some point slightly overshoot slightly overshoot but it is still converges so this is okay totally fine it's not a problem at
(46:04) all and we often see this type of behavior again Because how in order to be on on one side, you have to make sure that you sort of eventually hit your zero, right? If you don't, you you basically miss it. You're kind of on the other side. So now um okay, this was uh this was quiz uh now that is nice discussion.
(46:33) So it is useful. Now uh let's talk about um uh techniques which we can use to work with natural language processing right uh let's kind of agree that language can be represented by a sequence of vectors you can take a sequence of awards for example it doesn't have to be a word it could be soal token token is a kind of unit of information could be a letter or could be couple of words like two gram for example talking is quite g general notion.
(47:10) I mean it could be defined um differently depending on your application but we can think about like words for example each word is a unit unit of information. Each word is basically something which comes from a dictionary. Typically by dictionary we mean we mean we mean a list of all unique words. We have some kind of corpus. We have some kind of data set of text.
(47:34) It means we can create dictionary. So dictionary comes exactly from your data set which you use to train the model. Right? So basically uh you can say that this particular word refers to uh 57 word in my dictionary. No it means you can use some kind of dummy vector to represent it. Okay.
(47:55) This becomes like a categorical kind of variable 57. Okay. it becomes like vector of 0 0 0 then one in the 57th location and then 0 0 0 again it means any any sentence can be basically represented by a sequence of vectors. So very nice. Okay, we can do it. It means as a first step if you want to work with natural language processing, we have to understand how to work with sequence of vectors.
(48:22) Now maybe for simplicity first the sequence of numbers with some kind of time series. Basically until some point uh before transformers were developed kind of dominant technique was recurrent network that works. Nowadays it becomes a little bit not even a little bit sometimes much worse than transformers.
(48:46) Nevertheless if you have like some kind of short sequence or maybe you have uh restricted resources you want to run this kind of applications of your maybe on your uh iPhone for example. Recurrent networks can still be can be used even for natural language processing. But of course nowadays for translation and stuff like that it is better to use transformers. In order to understand transformers we still need to understand recurren network.
(49:09) That's why today we're going to spend time talking about recurrent neural networks. So recurrent networks and also modifications which are also types of recurrent network so-called LSTM a long shortterm memory cell and also gated recurrent unit. So this is planned for today. So let's now talk about recurrent um recurrent neural network.
(49:34) Again this is something which which we could use for natural language processing. So in this case uh we are talking about let me say ID right ID behind a recurrent neuron maybe first you know let me first talk about example where I uh say what kind of data we are going to work with in this case and then we introduce recurren neuron so let's say example we are talking about sequence of numbers essentially we say x first is a number x second is number observed over second interval of time the next one and so on.
(50:29) So we can later generalize it and say at every point in time I observe vector like word cat set on the mat. So cat is like one vector which represents a word and so on. So this is my sequence of numbers XT for example my sequence of numbers in such cases it is called time series basically.
(50:54) So recurren network is designed to handle time series or sequence of vectors. Generally speaking you can say this time series maybe vector time series if every x is a vector will be vector val time series. This is called time series time series. Now now the question is how to basically make predictions of the next observation. Those things are somewhat related. Now how they related? It is a question we have to investigate.
(51:22) We have to analyze time series first and try to understand basically correlations between this observation in order to make prediction. Let's say our question is what is xt + first? It is next observation which we are trying to predict based on previous observations. This is kind of a problem basically right.
(51:42) So this is like next observation which we are trying to somehow predict based on given time series. There are techniques to do it. First of all alterive process is classical approach. People say let me say people say x for example third is a linear function of x first x second x 4th is linear function of x2 x3 the very same function basically right as we slide over time series we kind of say there is a chunk of observations x1 x2 x3 x3 is some kind of function of previous ones x4th is the very same basically function of previous ones. If you believe that there is a kind of recurrency
(52:29) then we can use this type of assumption and so on. We can break our time series into chunks and we can get the central table which will look this way. So let's say xt -1 xt and then what we're going to predict is like output from that from the model is going to be xt + 1 that is like next one as I mentioned.
(52:58) So it is like x first x second output is x3r x 2 x3rd output is x4th. It becomes almost like linear regression. Almost like linear regression in this case. Well, it is like X. Now, let me let me stop there. So, you got the idea. So, all observations which we have can be placed in a table this way. It is almost like linear regression.
(53:27) We can say X3 is a function of previous two. It means we sort of run a linear model. Example XT minus one XT are inputs. XT + one is output our observations can be presented this way and we plot here all kind of fit here for example plane plane means basically so-called out regressive process if my time series is such that I assume or I can observe I have evidence that next one is a fun linear function of previous ones it is called auto reggressive process so auto reggressive process We plot time series it will look this way some kind
(54:10) of correlations between neighbors maybe right because next one is defined by previous ones so very possible that neighbors are highly correlated so they are correlated basically that's what we sort of exploit in order to make predictions we estimate correlations from time series and exploit them to make predictions kind of kind of obvious idea if you plot it this way it means we fit a plane.
(54:42) Now I want to kind of warn you if you decide to fit linear regression in this case it is not quite correct because in this case we as you can see have x3 here and also x3 over there they are exactly same right so it means they are highly highly correlated they are same in case of linear regression there is assumption where those things should not be correlated they should be independent it means fitting simply plain using kind of approach from leology or from um linear models is not good approach not good idea that's why there is different package to do it differently you can still fit alive process that means you can estimate coefficients of this plane
(55:23) please don't use don't use like linear models use something different there are techniques to estimate it turns out that this is quite simple model doesn't really doesn't really allow us to model model different types of time series. For example, in this case, my time series has constant constant constant variance over time.
(55:45) You can prove that is constant over time. It is stationary time series basically. However, sometimes time series is different. You understand that for example in finance it may happen that people trade trade trade and then some kind of news comes comes comes in and people become very nervous.
(56:09) They don't know what to expect and volatility becomes huge in this case until it gets stable again and people trade further further than again volatile and then get stable. So this process is already different as you can see variance not to be precise condition variance right variance to precise conditional variance conditional variance variance condition on the past. So variance depends on the past basically variance depends on current observation of my xt.
(56:34) So in this case um we can't use simply alterative process. Okay we can use modifications soal GACH model is designed to handle such cases. Okay. Garch is generalized auto reggressive conditional hydrosc model. We can do it as well was developed at some point for finance. Basically it it is even nowadays widely used.
(56:59) Now what what it means again it means some kind of basic resource we are trying to fit here we say next observation is going to be a function of previous ones one way or another that's what we are saying now if you say neural network what it means work means we fit here some kind of some kind of surface basically it will be neural network we can do it that way as well now if you do it using fully have that approach.
(57:29) It means you may have potentially many parameters which you have to estimate. It means trying to fit here some kind of surface which is based on maybe not on two previous observations but maybe based on 50 previous observations or you know like previous year of observations for example 365 observations. In that case your network becomes quite complicated.
(57:51) It is difficult to train especially if you are given only one time series. It means you don't have so much data anymore. So it becomes maybe not not practical. That's why people came up with idea that maybe we have to design the network in a way that there is some kind of a weight sharing.
(58:10) So weight sharing occurs in case of neural networks not just fully connected network. You could kind of do it maybe right. You could say fully connected network. Then it would be inputs then output will be next observation and a lots of maybe potentially lots of you know intermediate layers intermediate neurons and you can make predictions.
(58:31) You can easily kind of imagine that you have xtxt minus one as inputs then many many many layers many neurons xt + one according to this data will be output. The problem is again the problem is it is difficult to train especially we understand that basically those chunks of observations come from the very same time series.
(58:56) We don't have opportunity to maybe if you talk about time series which is related to for example stock market right we don't have opportunity to leave this very same uh same year multiple times just we have one time series and that's it. That's why in case when we have when we have don't don't have much data full network is not really best best approach and people developed so-called recurrent network as you can see it on the screen this is recurrent neuron so now let's talk about recurrent neur network network the idea behind the idea behind let me say a fully connected network would basically have xt
(59:33) minus one XT itself output will be XT plus first let's say head because we produce it using network it means predicted value and some kind of number of neurons in between some kind of number of layers in between and we have it this way so this connections which I sketch represent parameters it means number of parameters potentially is large.
(1:00:05) So it may be quite difficult to train such guy and is very simple network only two hidden layers. That's why we have so-called recurrent neuron. We'll talk about this in in more detail a little bit later. But recurrent neuron basically means we we assume that there is kind of let's say recurrent neuron recurrent neuron.
(1:00:35) We assume that there is a neuron some kind of input at time xt output at time xt + one right but the same signal goes back and enters the very same neuron. What it means very same neuron. So basically it means we have a number of neurons and signal as it comes out from the first neuron goes to the second neuron but weights or those connections are exactly equivalent regardless of time step.
(1:01:05) It means sort of weight specific weight sharing is going to occur in that case and it saves us basically parameters right. If we believe that time series has this feature that there is some kind of recurrency just like we assume in case of AR process for example we say x3 is kind of beta 1 x1 plus beta 2 x2 plus beta 0 x4 is very same beta 1 x2 plus beta 2 x3 and plus beta 0 very same linear model we assume it in those classical models we're going to basically assume similar stuff in case of recurrent neuron and also recurrent networks.
(1:01:39) We assume that there is some kind of uh kind of you know weight sharing across time space across time 10 10 dimensions. So idea is quite straightforward. Why we do it and how we're going to do it? Let's discuss after the break. We'll see how exactly we're going to do So now let's see how recurrent let's first say neuron is designed then we
(1:09:36) will see how recurrent uh neural network is designed Recurrent neuron. In this case, we remember we chose chunk of lens three. It means like two inputs and also one output, right? That means to length of the input is two. It is called time steps. Let me say there is number capital T which is called time steps.
(1:10:39) So basically time steps means length of the input to this time to this new work. We can maybe start with let me think this is like x let's say t minus capital t + 1 so 1 x t itself right and then next one is xt + 1 it is a chunk of our observations First capital T observations will be like input. Capital T of those will be input and this will be output.
(1:11:26) This way length of this chunk is capital T + one but number of observations which we use as input is called time step. So let me see it is like T. This is T minus capital T + one. It means uh let's say t is uh let's say t is capital t then it is first okay capital t and this is capital t minus capital t + one is first so yeah capital t observations observations right so that's what we mean by by capital t which is which is um time steps now let's see how we can design current neuron in order to handle this type of information.
(1:12:16) First neuron will input some kind of y0 which we which we set equal to zero by by default right some kind of so-called state hidden state it is called I'm sorry not not one but zero so it is called hidden state we assume that there is some kind of hidden state which we try to kind of kind of trace over time so y 0 is equal to zero it is called hidden state hidden state it will change from time to time initially I say it is equal to zero uh so I'm not sure if you have questions to me uh okay if you have questions to me you
(1:13:04) can ask me right now I have a question should that be t+1 for the output t + one for the output yes thank you t+1 one uh yeah this way. So now now let me uh for simplicity start with time one. Let let me call it x first. Next one is x capital t. Right? Just for convenience I want to do it that way. Of course it depends on on on on current time.
(1:13:42) Maybe for different time it's going to be different. Maybe in case of sentences it is actually indeed the case when you have like first through capital T and then you move to second sentence. Maybe you don't have to chop your sentence into pieces, right? You can simply move from sentence to sentence if sentence is already kind of logical piece of information. You can use it maybe.
(1:14:02) So now in this case uh let me say that uh you are going to we going to use notation x first and so on x capital t as inputs. No x first means basically x current t minus capital t + one. And I'm going to say my very first input is going to be x first. x first will enter the very first neuron.
(1:14:27) As you can see this one it will enter this way. Then I move to second time step. It means x second will be next signal but it will not enter my first neuron. Instead it will enter already second neuron this way and signal will enter only second time second neuron but output from here which I call y first it is hidden state already at time t equals to 1 is going to enter second neuron as well and so on. So I continue this way.
(1:14:58) Last one will be X capital T which will enter my last neuron here this way and I get some kind of output. Output could be called Y capital T by analogy right from second neuron X2 is in Y2 is out. It means this could be called Y capital T. So this is basically my recurrent neuron. Now the question is how is it different from just neural network.
(1:15:31) The difference is that we have to actually explicitly assume that we're going to have same parameters w you can see that this connection this connection and that connection they seem to be quite similar to each other. More than that if we assume some kind of recurrency in our data set it means we want to assume explicitly that my parameters of those connections are same right so they share the same W's this is explicit assumption more than that those connections will also share the same W's different ones but same W's across those
(1:16:09) connections that's how we assume recurren on neuron is going to be designed right that's how we we kind of explicitly explicitly say it's going to be any questions about that couple of questions professor so the first one is about the hidden state is it does it matter like with a different number or always it is zero well it is actually zero yeah it is always zero we don't change it it is just if there is no information from the start we we assume it is zero this Correct. We don't have it.
(1:16:43) Okay. So, and and okay the the model of uh recurrent uh neuron. So, is it an assumption how we are imagining or like physically or like is this actual representation? I thought that there loop it is actual representation of recurrent neuron. Correct. We specify how many time steps we have. Capital T like in previous case would be two.
(1:17:07) It means there will be only two neurons but they they considered to be copies of each other that's why we say it is like one neuron basically we say recurrent neuron this is how it is designed if you want to kind of unfold it and unfold and see how it is but no it is in reality I mean it is it is exactly what it is but people often sketch it differently let me say let me say this way first neuron second neuron and so on last neuron X first enters first neuron.
(1:17:42) X second enters next one. X capital T enters the last one. So you can think that information flows this way. Then there is output which is Y first but the very same information Y first will also enter next neuron. Right? This way we can use we can use hidden state for some reasons.
(1:18:08) If you want to for example build some kind of next layer of recurrent neurons, we could we could use not only Y capital T, we could use all intermediate hidden states as well and pass it further. But because it is like sequence of numbers could be quite useful for some reasons. Maybe what we believe that it is it is useful to input it further to the next layer not only the last one.
(1:18:26) There are different architectures. You can use only last one or you can use maybe all all of hidden states for every time time there is specification you can say return sequences is is true or is false right depending on your choice you will use different architectures if you want to build next recurrent recurrent neuron on the top of this right then you actually can say return sequences is true then you can do it that way that's why those wise generally speaking could be quite useful We don't throw them away even though we understand they are sort of passed further but they could be also useful now at
(1:19:04) least why capital T is final information we have here as output from this neuron even though everything could be used depending on your architecture we can use only last one and pass it further or we can use entire sequence and pass it further. So this is how it looks and again these neurons are copies of each other.
(1:19:28) That means every connection basically every corresponding connection basically everywhere has the same number same parameter same parameter W. This is how it is. People say it is not convenient to sketch it this way. They basically say let us sketch it has a single neuron. X at time T enters Y at the very same same same time T is output but also the signal goes back as input to the same neuron at time YT minus one at time YT minus one right you can see why this neuron for example accepts Y first and also X second so Y is 2 - one y first is by 2 - one. So this is how basically people sketch recurrent neuron
(1:20:16) often this way but in reality what it means it means this type of architecture if you want you can think this way and those parameters are same for corresponding connections and in this case we don't really see how many time steps we have we have to specify and say we have such and such number of time steps it must be always specified basically how many copies we we're talking about now it doesn't have to be specified during the during during Initialization of network if you have like data set and it will consist of specific chunks of your time series data
(1:20:50) it will know how many you want essentially. So number of time steps would be basically specified on the fly based on your data set. It will know this is this is how they sketch it but this is what they mean by this essentially it is called recurrent neuron. It is called recurrent neuron. Any questions about recurrent neuron? Hi there. I I have a question.
(1:21:16) The thing that I can't seem to wrap my head around is that it looks like every step of the way it's the past. So like if it's a time series, it's the past that's referencing the future. Whereas I keep thinking it would be like I'm I'm expecting it to be that X2 draws from X1, but it looks like it's X1 drawing from X2.
(1:21:41) any or I don't know am I wrong about what I'm saying or well well this is it's a good observation yeah so we don't say that x2 is like deliberately function of x1 what we are saying is x2 is function of u well so the question is how we going to use it basically right if I say that yt represents yt for example represents exactly my xt + one if I canot say it is xt XT + one for example then XT + one will be some kind of function of previous XT right and also some function of previous state which is function of previous XT and so on this idea basically the question is
(1:22:24) we're not going to make prediction of X second based on X first because X second is already something we have in data set it is already realized we're going to have to make prediction only of the last guy XT plus post this one oft so so this isn't necessarily a kind of auto reggressive model but but it could be is what you're saying it it could be yes exactly so the question that is very important question how we kind of want to use it in practice let me give you example and say okay this is my example how to use it first application would be to basically say my
(1:23:01) yt is essentially xt + one Can I do it? Yes, I can do it. So I say that what is yt? I can sort of match it to my xt + one directly and minimize my cost function. This is output from network. It could be matched to xt + one. So basically if I sketch it again this way my neural network, x first is input, x second as input, x capital t is input. those outputs, those connections.
(1:23:37) Now, how to kind of use it in practice? Basically, your question is how to use practice also your question is why x2 is not a function of x x first. We don't want that because we don't want to make predictions of x second is already in the data set. You want to make prediction of the very last one.
(1:23:54) So, what we do here, this one is output and we can build something on the top of this. Essentially we can have maybe different neuron for example and can and and say that output is X head capital T plus one right can we do it definitely we can do it now it is neuron which we is not part of recurrent neuron just regular full neuron basically but what we output from network is Y capital T where Y capital T could be used as input the next part of my network to make predictions will one application.
(1:24:33) Uh, professor, if we if you're keeping if you're having all the W's as the same, then uh, do we have to go through this full time series? The YT would be the same as the CMW's, right? So, I'm sorry, I'm not sure if I understood your question. If you if uh the the output of x1, x2 and x3, we have the y1, y2, y uh till yt and but everything is just the same weights.
(1:25:12) Then do we uh do we go through the whole time series? Why why why should all the w's be the same? Yes. So important question why do we assume same ws if we don't assume same ws it will be quite expensive network of course we're going to generalize it we're going to have more maybe neurons for each time step and so on x could be vector it itself as well it will be quite expensive to have different ws now why do we assume same w's so basically we assume that there is some kind of recurrence in a data set which allows us
(1:25:49) to believe That next hidden state is a function of previous state and previous signal in the very same fashion or using same function basically as for previous time step. It means regardless of time step this dependence is same that's what we assume.
(1:26:11) So the question is why why do we assume it? Because why do we use it? because we assume it explicitly. We say in the case of a recurrent network uh dependence of x second on y first and x second is exactly the same as dependence of y first on y0 and on on x first. We assume it explicitly. Does that answer your question? Yeah. Thanks for I had one one more small question.
(1:26:42) Would this would a recurrent uh network be difficult to parallelize? Like does it have to be serial? Doesn't have to be serial. Uh it is um uh it is uh if you want to kind of uh try to paralyze your uh information flow, it is difficult. I mean basically impossible. But you can still uh use uh your mini ch mini batches, right? and compute updates of your or compute your gradients independently and then make update for entire mini batch.
(1:27:15) So basically for every observation from mini batch you can compute forward propagation back propagation and then at the end you can basically average this update for particular mini batch. So you can still do it if you if you train it in many batches, but you cannot really you cannot really somehow compute you know y2 without knowing y first. In this sense you cannot parallelize it.
(1:27:42) But if you have mini base you can run it in parallel as always. Right. Cool. Thank you. Yeah. So now uh it is it is how you can use process. more than that if I want it doesn't have to be next observation this is output but what if I say I want to make predictions of something completely completely different let me say next example will be this is not not yt + 1 but this will be some kind of you know s time series let's say s at time capital t or capital t + 1 whatever you want even s at time capital t + 5 let's take s of s at time t + one. Now
(1:28:27) it means in this case basically we are going to have data set which looks this way X first X second and so on X capital T output will be not XT + one output will be some kind of S at time t + one could be completely different time series right it means recurren network allows you to actually design a dictor of some completely different time series but which potentially relates with your current time series and you have data here right you have some kind of data whatever it is 5.7 and your output 7.
(1:29:07) 9 and so on so you assume that there is some kind of data set your s t + one somehow depends on previous observations of x's it doesn't have to be t + 1 it could be t plus you know plus 7 for example you can make predictions of observation like one week from now for example that's how you use it. It doesn't have to match to your observation of the very same time series.
(1:29:36) So any questions about that? Now let's compute number of parameters. Now in this case uh people don't really sketch it but actually there is also bias. There is also like one right which enters every neuron. So there is also bias. Typically people don't sketch it. As you can see there is no any bias sketched but there is bias.
(1:30:02) So it means uh if I want to compute number of parameters I have to take into account that there is also extra connection. So what that means? It means one connection comes from X. Let me even specify from XT I get one parameter. XT enters my neuron. Also I have one parameter from Y itself. Y enters minus one as well for every time step I have this connection it means + one from Y t minus one because YT minus one enters my neuron plus also bias I don't sketch it but also bias enters my neuron basically people don't sketch they keep in mind
(1:30:42) that there is bias so this is bias and then multiplied by in this case I have single on your own right so it means multiply divide by one it is like number of neurons basically I keep it this way so it is generalizable but this is because I have only single neuron single yt is output yt could be like my hidden state could be two dimensional for example will be two two ws this y will be multiply by two essentially so in my case I have three parameters you can see my neuron current neuron has only three parameters of course by itself it's not going to do nice job but we can build already some kind of layers
(1:31:22) of recurren neurons later on maybe layer next to layer next to layer and then it may do some kind of nice predictions. Any questions about this architecture? One question. So can we calculate the gradient analytically? Yes. Okay. Let's talk about this even for the multilayer RN as you just mentioned. Yes. Yes. Yes, we can do it.
(1:31:50) Let me maybe erase uh the sketch of this network. We already understand what this representation means and let's talk about gradient and let's talk even about issues which going which we are going to have if you use recurrent neuron right let's first try to to see what is my network analytically in this case in order to get gradient we have to write down analytical expressions.
(1:32:17) So y first is equal to f activ activation function whatever I use here for this neuron applied to my bias w0 plus w first applied to my signal x. Remember y first would use would use my x first signal plus w2 and that is y0 previous hidden state is going to be used as input first first but hidden state is zero as input this way what about second time step okay y second will be fed to w + w1 * X 2 already plus W 2 * Y first and so on. You can see what happens. W is same everywhere. It is explicit assumption. Then Y capital T which is
(1:33:18) output from this neuron. F applied to again W which is exactly same W first X capital T plus W 2 Y capital T minus one this exactly why we have three parameters 1 2 three parameters nothing else this is my new network basically right this way it looks this way recurrent neuron to be specific this recurrent network consist of only single recurrent neuron now you can Say what does it mean? It means essentially that my output y capital t is going to be f applied. Let me let me take maybe particular example.
(1:34:04) Uh let me do this way. You will see w + w1x capital t + w 2. What about y capital t minus one? It is previous one. That means f applied to w 0 + w1 x already capital t -1 in this case plus w applied to y which is yt minus 2 already. Now it means f and so on. So by recurrence you understand is going to look this way right? It's kind of nested functions again.
(1:34:48) But the thing is in that case W here is same as W over there and also more W. So if you have more time steps W first W first W second W second. So you can see what happens. We have this type of recurrence. Now back to your question. Can we compute derivatives analytically? Yes, we can easily. we can easily compute it. Let's let's let's do it.
(1:35:26) Let's consider a specific example and do it let's say example where capital T is equal to two. So that means my my YC because capital T is two means capital T becomes two. Y 2. His output is F applied to W + W X 2 + W2 applied to again F multiply by F apply to W plus W first X first time step plus there is like nothing because we have Y0 to is zero.
(1:36:14) Let me simply say nothing else because d because y0 is simply zero. y0 is simply zero. That's why we have it that way. Now if the question is how to analytically differentiate it's not a problem, right? If I want to differentiate w2 I'm sorry y2 with respect to let's say w first. How do we do it? F prime some kind of point Z let me call Z2 right the whole thing here multiplied by derivative which is D respect to W first I get X second here you can see X second here but it is not the end of the story because I have also w one over there it means plus w * f prime at point z first
(1:37:13) time x first over there and I have this formula for my derivative with respect to w first very very similarly I can get y with respect to w let's say second is going to be frime z2 multiplied so it means w2 ult*lied by I can W2 * Y 2 means Y 2 plus with respect to W2 means nothing else because there is no W right now I can say it is like it is like I don't have to say it even right let me like plus Z no because because y0 is zero doesn't contribute if I have more steps will be more terms over there now
(1:38:03) it is a good question because if you look at this you can realize What happens here? Frime * frime * frime, right? So x1 is a signal. It is some kind of information basically. But contribution from x1 to my derivative will be premultiplied by derivative of my loss function activation function time w * another activation function and so on. It means if I have capital t which is like for example 100, it will be 100 derivatives.
(1:38:34) Now if you think about this let's take example if f is example sigmoid f sigmoid it looks this way remember sigmoid means like logistic regression basically right it is my sigmoid it is my f function what is f prime in that case it look this way if you check form formula for the der of sigmoid function. It will be sigma * 1 - f * 1 - f.
(1:39:11) So basically this point here is going to be 25. So it means my fp prime in this example leaves between 0 and 25. What does it tell me? It tells me that if I have like 100 of those derivatives multiplied out frime * frime * frime and so on it will be some number between 0 and 25 to power no kind of multiply different right so some kind of number between 0 and 0 255 multiply it out like 100 times it means contribution from sen x1 is going to vanish basically that's why they said that problem of recurren networks is basically related to so-called vanishing gradient. What they mean by this essentially is that signal
(1:39:57) from X first is sort of sort of multiplied by something which is potentially very close to zero. It means the signal doesn't contribute much anymore. Same about second one if you have like capital to be like 100. Same about second one it is already multiplied by derivative which is not more than 0.
(1:40:16) 25 but if you have more time steps it will multiply again by something very small. That's that's the issue with training this type of neural networks. Basically, this is one of the ma major drawbacks of recurren networks. That's yeah, that's a good question. So, how about if prime is greater than one? Can it explode the product? No, it could. Yeah, probably yes. Yes, probably it could even do that.
(1:40:43) But I don't know if it is possible because u in this case derative is always between 0 and 25. In some cases you say it could be more than one but in order to exploit it should probably be always like for all for most of them must be must be large right. Do we have such activation function where derivative is for the most part is above one probably not because some of them you say that some of them will be like will be large but some of them will be still small.
(1:41:12) It means they will compensate probably right. Um yeah but nevertheless you can see that for different time steps we have different number of products of those derivatives. So the result we may get no sort of different different contribution to the derivative as a result it means we are going to have different um uh kind of updates will be happening on different scale right it is like uh yes so this is how it is yc is like y second head essentially but we just call it y second any questions about that okay now sir What do you do in case of like you've mentioned earlier there is a
(1:41:56) stock and it's suddenly stopped becoming uh consistent then how do you predict this? Is there a way to sorry becoming stopped becoming becoming consistent? What does stop becoming consistent? Uh if suddenly like in a um in a stock market the stock went up and down too much then is it still predictable? Yes.
(1:42:27) So in depends on uh what kind of behavior you observe but in such cases typically when uh volatility changes basically one of the widely used models is Garch generalized autoresive heatastic model. In that case we assume that not only next observation is a function of previous ones but also volatility itself is a function of previous observations.
(1:42:50) So if there is like spike of some kind it will impact according to the model it will impact future volatility and that's exactly what basically people kind when they trade what people do if you see some kind of volatility people become like more nervous and they become like more maybe not nervous probably they are nervous right it is very stressful job clearly so probably nervous is correct and they become trading like uh differently behave differently until it becomes again stable.
(1:43:25) In such cases, you probably don't want to just uh use recurrent neuron, right? You want to use something else. For example, gar models. Okay. And uh another thing here when you calculated the parameters, why did you just say it's three? Why wasn't why didn't let's say we consider the number of T's we have why didn't we consider number of T's we have no I said that in this example capital T is two that's what I said no previously when we you mentioned in the uh recurring network you mentioned the number of parameters and then you calculated it to be three only yes because we have you see WW is same.
(1:44:08) It means we have only one parameter. It is same parameter clearly right. W first W first W first the same parameter and our second second the same parameter. It means three parameters. Okay. Okay. Fine. They are same. They explicitly assume to be same same bias everywhere for every time step because we want to kind of save parameters because we assume some kind of recurrency. We assume that same dependence is happening for every time step regardless of time t.
(1:44:44) So now next one let's talk about layer of recurrent neurons right we can generalize it we can say let us take uh maybe uh more than one hidden information more than one hidden state that's going to be called layer of recurrent neurons layers of recurrent neurons layer of recurrent neurons this way.
(1:45:25) So what happens is now I say maybe one hidden state is not sufficient. Maybe I want to keep track of maybe couple of hidden states for example. Maybe one hidden state is just scale or is not sufficient to handle my problem. Maybe two is two is better. That's what I say. Let's assume capital T is time step. Let's assume I have in this case two neurons. Two neurons.
(1:45:50) I assume it in this specific example I assume two neurons that is generalizable clearly. So in this case I say first neuron second neuron input is y 0 and first entry right and also y0 second entry because I have two of them already there are 0 0 anyway at this at the beginning then I say my x first what do I do with x first it will enter my first uh uh neuron will enter my first neurode.
(1:46:30) So maybe I should sketch it like before below. So this is my my x first information second time step and this information goes into second neuron into first neuron to produce two hidden states this way. Then I get as output from here I get y is already first because t is one first and then y first second. So y is like a vector now and I say how to connect those things.
(1:47:03) Um so I don't remember if I sketched why let me probably I didn't sketch it right. I want to be consistent. Sometimes people sketch like those. Maybe I want to do it consistently. Let me let me say this is my input to my neuron to neuron and this is my x first which enters the very same neurons this way.
(1:47:34) Then second time step I have to pass x second as input. The output will be next scalpel. Output is scalpel x first one first. I'm sorry y first one first. Y first second y second first y second. And they go this way. And also as usual we have also cross connections. So this way that way it's not a problem. We do it as well. Y capital T first capital T second.
(1:48:08) also this connections this way and we get basically a layer of recurrent neurons. What is layer? Layer means we have layer means we have two hidden states already. And again very corresponding connections will share the same weights. Right? That's how it is. Again clearly we can sketch it equivalently using previous strategy. We can say it is first neuron second neuron.
(1:48:39) Y first first is output from here or maybe Y probably T first YT first is output. YT second is output. In this case XT is input enters every neuron here. And YT first goes as input to the first neuron and to the second neuron. Why is second you is is is going to enter first neuron and second neuron this way that's how we could sketch it basically and people don't like sketching this way they say let us essentially pretend that there is like a box which has two neurons input is xt output is yt which is vector valued which is yt first yt second this way and
(1:49:29) it goes back at time t minus one. So this box will accept XT and also YT minus one which is already vector. It is layer of recurrent neurons is layer a layer of recurrent neurons this way. Now again if I ask you to compute number of parameters how to get it number of parameters in this case let's see one is for xt xt is still scalar plus what about yt minus one it is already two dimensional so each neuron we'll take xt first xt yt first yt second that means 2 yt minus one because it is vector valued plus also bias as before plus bias
(1:50:25) but then you see what happens now I have not one neuron I have two neurons already it means it is like 1 2 3 four inputs to one neuron 1 2 3 4 inputs to second neuron that's why I multiply by two this is what I meant before is the representation of dimens dimensions of my yt that's why we going to have eight parameters in this specific case it is already layer of recurrent neurons.
(1:50:50) Now what's next? Can I generalize it further? Yes, we can. We can say yx must be only scalar. It could be vector value actually observation at every time step. So it means we could have more than one. In that case we say let's say xt actually is uh two dimensional. Let's assume that then I can have modifications. I can say it means it is already two-dimensional.
(1:51:22) X first X first 2. On the next time step, it is also X 2 first X 2 second X capital T first X capital T second. We can do it as well. And it will enter every basic neuron and my layer of recurrent neurons this way. I'm sorry I didn't connect it correctly. Uh so it meant to be second signal right meant to be second signal this way and also second signal that way that way.
(1:52:09) It means essentially my XT will be two dimensional. XT first XT second enters every neuron which means I can simply say it is vector valued now which happens to be in my case XT first XT second because of two dimensional it means my XT is two dimensional that's why it becomes already five par um 10 parameters 10 parameters no basically two more parameters one two more parameters because of second dimension of X and we have layer of recurrent neurons which can handle already sequence of vectors. Note at first time
(1:52:52) step I have X X vector first on second time step I have X second vector and so on. I can work as a sequence of vectors. Any questions about this? Yes. So go ahead. like the the two outputs are uh yt1 and yt2 are going back uh both of them to each neuron. I was under the impression that the output of one neuron will go back to itself.
(1:53:23) No not they there are cross connections as well. Yeah. Okay. Okay. So that's why we have two in for wise. Yes. So basically hidden state accepts all previous hidden states and all signals. So if if there are 10 neurons in this layers each neuron will receive recurrent connections from the other from from the from the from the from the whole 10.
(1:53:49) Is that correct? From that's correct. Yes. If you have layer of 10 recurrent neurons number of this connections you see I have four will be much more. Everyone goes to everyone. Every Y goes to every neuron. It means every neuron will accept 10 Y's. Absolutely correct. Yeah.
(1:54:16) What would happen if we have a simple case that just the the output goes to the neuron came out from if we don't have this com like this cross connections. So isn't it just sort of disconnected stuff like to recurrent neurons? Um it is like it is like you know what like in case of full network you you you don't you don't do it that way right you don't say just that way kind of two disconnected trajectories we're following the fully connected architecture in fully connected case we don't do that way right we also connect it this way as well same same idea here if you don't do it it means that your hidden state will impact only your current hidden state and this is like less capabilities. We
(1:54:59) don't want to do it that way. Yeah. So, so basically what you're saying is let us just take two hidden states this way and only use it that way and also signal from a right. So what happens in that case that they sort of kind of copies of each other and I'm not even sure if you want to have two of them or maybe you want if you have different representations but this not how it is done if you can build some kind of you know recurrent neurons and you try to see summary you will see that for example in my case it will be 10 parameters which indicates that everything is connected to every
(1:55:41) everything. So professor so the first one the the hidden state when we start they need to be interconnected to right cross connected to right the zeros for the first uh for the first neuron you mean you mean you want to sketch those connections yes we can but they are zeros yeah they have to be maybe and the other question is so the two neurons now do they have different weight or are we going the same weight again so um actually corresponding connections will have same parameter Right? But so basically all unique connections in the
(1:56:18) second sketch will have unique weights. It means uh connection of y first with y first is different from connection of y second with y second. So they are different but as we move across time for different time steps they are same. So corresponding connections for different time steps are same but not as we move from from component of Y to component of Y it means upper connection is different from lower connection right it means in the second sketch up here in the second sketch all these connections will have unique parameters W's that's why we have 10 1 2 3 4 plus
(1:57:02) uh four more plus two biases 10 10 parameters So they in unique parameters we don't try to identify upper connection lower connection they are different right so now u this is how we can do it in caras we can say for example simple rn three means the three means uh how many hidden states we have it is like three y's basically no activation function function is something you want to specify. Number of time steps is capital T.
(1:57:42) This is number of time steps and number of features is essentially how many axis we have in that case how many dimensions every observations X is no in my case it is like 200 dimensional and even though it is quite complicated actually time series right number of time steps is 200 I'm sorry number of features that mean the dimensionality of X is two it is like 200 observations of of of vectors of X's to 2D vectors and it has only 22 parameters in this case. That's how we can do it. Again, when you train it, your output from here could be whatever
(1:58:19) you want. Technically speaking, doesn't have to be next to duration of your time series. Could be whatever. And in that case, you want to add something further. For example, dense layer like one neuron as we sketched previously to sort of, you know, handle this output.
(1:58:36) By default your recurrent layer of recurrent neurons will return not sequence. It will return only last vector of capital Y's. That's why if you don't say anything here it will return on the last vector of Y which you can use further. If you specify return sequences is equal to true it actually will return entire sequence of your Y by default.
(1:58:55) Not by default only only basically three Y's will be used as input to the next layer right here. Okay, that's why four parameters consist of only a single neuron but y itself is three dimensional that's why four parameters because we only y capital t which is three dimensional so now there is actually uh limitations of of such models right so basically gradient becomes exponentially small I think I already explained this question during back propagation we have frime* frime* frime So on it becomes exponentially slow. It means we multiply derivatives out potentially it means we
(1:59:38) have some kind of vanishation derivatives right. So and uh as a result we can't really learn we cannot really learn series of of of uh of of of long uh lens long-term dependencies will not be learned by this type of models. Right? Um no clearly it means poor performance changes of in training and so on and so forth.
(2:00:08) Now what kind of uh modifications we can actually uh suggest? We can uh suggest modifications such as long short-term memory cell. In that case we are going to say who said whatever we have inside must be only two neurons. We could actually make something more more interesting than just two neurons.
(2:00:29) We could we could suggest some kind of sub networks inside vector in vector out but how maybe internal part will be not just two neurons will be something more interesting and this is b basically idea behind so-called uh uh LSTM long short-term memory cell and we say inside of this box we're going to place something different this is what has been chosen kind of empirically essentially right they chose this type of architecture what is FC See FC means fully connected network. So sort of fully connected subn network and it consists of four sub networks X in Y out
(2:01:05) as before and we have two memories. So memory doesn't have to be on a single one anymore. This Y which is hidden state is also called memory. Right? This memory can be not only one vector but could be two vectors. So in case of LSTM we say there is C vector which passes through my memory cell with little modifications.
(2:01:32) No it means C is basically long longterm memory and H passes through some kind of networks before we get output. It means H is like short memory. people combined basically they used two memories short one and long one and they did it this way and they came up with this architectural kind of empirically right that's a specific specific design four sub networks in this case if you say LSTM will for example three three neurons it means every sub network here will have three three neurons three neurons for first one three neurons for second one three neurons for next one
(2:02:06) three neurons for next and exactly four sub networks will be will be used inside of LSTM. That's how people sort of try to to to keep track of like a long memory essentially. And also there's this kind of representation which we can definitely write down if you want because we have all the sub networks you understand fully connected means everything is connected with everything.
(2:02:31) It means we can easily instead of just sketch we can easily write down for balls and uh LTM at some point was quite quite a big deal actually it would on Android phones and so on and so forth for translation so it was quite quite quite impressive model at some point until transformers just to be clear right nowadays people don't really use it for translations but it used to be quite quite quite important model nowadays people use this type of networks only if you have maybe short time series not much data maybe or
(2:03:06) maybe some kind of computational constraints you don't want to just use transformers like everywhere right if it is on the server it is okay but if you want to have it on your cell phone maybe it is a little bit more challenging people use this type of models and those cases also if you want to do something like online in real time do this transformations maybe transformer is a little bit worse LSTM could do will perform faster than transformers. So now this is how we do it.
(2:03:36) LSTM 16 means every subnet network will have 16 neurons. That's exactly what I mean by this. If I say LSTM 16 means every subnet network over here will have 16 neurons everywhere. And this is actually idea. So people say it is good idea to have a long memory and short memory.
(2:04:02) But maybe it is still quite expensive because we have too many parameters and they started to experiment with this and say let us kind of keep the idea that every memory cell will have sub networks but let us try to combine a long memory and short memory. So basically just give me one second. Um I think it is um with this phone I have to So in this case people say let us try to combine long memory and short memory.
(2:04:48) Not not in this we don't use the simple case we use still some kind of modifications some kind of sub that works inside of this memory cell but we combine long memory and short memory. Turns out that this type of simple idea would reduce number of parameters. As a result, JU would actually perform even better than LSTM in many cases. So can also apply G recurrent unit. It is architecture.
(2:05:12) This is how we can do it. We already kind of discussed we can use only maybe output Y capital T or we can use entire sequence of vectors depending on what you kind of want to use here. You can use different architectures. If you decide that you want to for example build next layer of recurrent neur neurons on the top of on top of current one you may want to use entire sequence of y's entire sequence of hidden states.
(2:05:37) If not if you want to maybe produce only a single number of some kind you may use only last observation of y and ignore everything else different types of architectures. So maybe at some point we'll talk about this a little bit more how to implement those architectures but this is basic idea behind and finally the very final idea which I wanted to mention is so-called birectional recurrent neural networks.
(2:06:04) So the thing is in this case we sort of take time series in in in in the same kind of a way as it is uh recorded x first x second and so on. But what if it turns out that maybe maybe like be beginning of sentence is more important. For example, you can see what happens. End of my time series impacts output more than than initial observation.
(2:06:30) If you see my time series, maybe it makes sense for predicting time series. But what if you talk about like for example language? Maybe the beginning of sentence is more important, right? That's why maybe you want to actually uh reverse your time series and say first one is x capital t next one is x capital t minus one and so on until you get to the beginning of your sentence.
(2:06:56) X first will come will be used as input on the very last time step on the cont sort of. So maybe you have to flip it. You can say okay I can experiment I can use it as is I can flip the order and see what performs better. Turns out that sometimes especially if you talk about language sometimes there is even better alternative when you say let's actually use both of them at the same time.
(2:07:21) Why? So if you take like language for example German language maybe beginning of sentence is important but also end of sentence is also important. You may know that negation happens at the end in German language right? It means maybe you you want to pay attention to the beginning of sentence also to the end of sentence and then then there is this idea when they say let us try to use birectional recurrent networks.
(2:07:41) What do they do? Let's say let's take a b cde e as is and also reverse the order take one recurrent network second recurren network and then concatenate somehow together we concatenate it means essentially this is my y capital t vector right and from second path will be also y capital t vector I will just basically glue them together so I will concatenate those vectors and it will be already so called birectional recurren will not work.
(2:08:15) This slide shows you LSTM with no birection just one direction and last slide shows you birectional LSTM. You can see that number of parameters clearly changed right LSTM has so many parameters but by directional will have more parameters exactly twice more parameters clearly. So now any questions? Okay, let's now stop. Thank you.