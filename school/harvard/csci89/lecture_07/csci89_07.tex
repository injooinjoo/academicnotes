%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Harvard Academic Notes - í†µí•© ë§ˆìŠ¤í„° í…œí”Œë¦¿
% ëª¨ë“  ê°•ì˜ ë…¸íŠ¸ì— ì ìš©ë˜ëŠ” í†µì¼ëœ ìŠ¤íƒ€ì¼
% ë²„ì „: 2.1 - ê°€ë…ì„± ê°œì„  (ì„ íƒì  ìµœì í™”)
% ìµœì¢… ìˆ˜ì •ì¼: 2025-11-17
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[11pt,a4paper]{article}

%========================================================================================
% ê¸°ë³¸ íŒ¨í‚¤ì§€
%========================================================================================

% --- í•œêµ­ì–´ ì§€ì› ---
\usepackage{kotex}

% --- í˜ì´ì§€ ë ˆì´ì•„ì›ƒ ---
\usepackage[top=20mm, bottom=20mm, left=20mm, right=18mm]{geometry}
\usepackage{setspace}
\onehalfspacing                      % 1.5ë°° ì¤„ê°„ê²©
\setlength{\parskip}{0.5em}          % ë¬¸ë‹¨ ê°„ê²©
\setlength{\parindent}{0pt}          % ë“¤ì—¬ì“°ê¸° ì—†ìŒ

% --- í‘œ ê´€ë ¨ ---
\usepackage{booktabs}              % ê³ í’ˆì§ˆ í‘œ
\usepackage{tabularx}              % ìë™ ë„ˆë¹„ ì¡°ì ˆ í‘œ
\usepackage{array}                 % í‘œ ì»¬ëŸ¼ í™•ì¥
\usepackage{longtable}             % ì—¬ëŸ¬ í˜ì´ì§€ í‘œ
\renewcommand{\arraystretch}{1.1}  % í‘œ í–‰ê°„ ì¡°ì ˆ

%========================================================================================
% í—¤ë” ë° í‘¸í„°
%========================================================================================

\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\small\textit{CSCI E-89B: ìì—°ì–´ ì²˜ë¦¬ ì…ë¬¸}}
\fancyhead[R]{\small\textit{Lecture 07}}
\fancyfoot[C]{\thepage}
\renewcommand{\headrulewidth}{0.5pt}
\renewcommand{\footrulewidth}{0.3pt}

% ì²« í˜ì´ì§€ëŠ” í—¤ë” ì—†ìŒ
\fancypagestyle{firstpage}{
    \fancyhf{}
    \fancyfoot[C]{\thepage}
    \renewcommand{\headrulewidth}{0pt}
}

%========================================================================================
% ìƒ‰ìƒ ì •ì˜ (íŒŒìŠ¤í…” í†¤ + ë‹¤í¬ëª¨ë“œ í˜¸í™˜)
%========================================================================================

\usepackage[dvipsnames]{xcolor}

% ë°ì€ ë°°ê²½ìš© íŒŒìŠ¤í…” ìƒ‰ìƒ
\definecolor{lightblue}{RGB}{220, 235, 255}      % ë¶€ë“œëŸ¬ìš´ íŒŒë‘
\definecolor{lightgreen}{RGB}{220, 255, 235}     % ë¶€ë“œëŸ¬ìš´ ì´ˆë¡
\definecolor{lightyellow}{RGB}{255, 250, 220}    % ë¶€ë“œëŸ¬ìš´ ë…¸ë‘
\definecolor{lightpurple}{RGB}{240, 230, 255}    % ë¶€ë“œëŸ¬ìš´ ë³´ë¼
\definecolor{lightgray}{gray}{0.95}              % ë°ì€ íšŒìƒ‰
\definecolor{lightpink}{RGB}{255, 235, 245}      % ë¶€ë“œëŸ¬ìš´ í•‘í¬
\definecolor{boxgray}{gray}{0.95}
\definecolor{boxblue}{rgb}{0.9, 0.95, 1.0}
\definecolor{boxred}{rgb}{1.0, 0.95, 0.95}

% ì§„í•œ ìƒ‰ìƒ (í…Œë‘ë¦¬/ì œëª©ìš©)
\definecolor{darkblue}{RGB}{50, 80, 150}
\definecolor{darkgreen}{RGB}{40, 120, 70}
\definecolor{darkorange}{RGB}{200, 100, 30}
\definecolor{darkpurple}{RGB}{100, 60, 150}

%========================================================================================
% ë°•ìŠ¤ í™˜ê²½ (tcolorbox) - 6ê°€ì§€ íƒ€ì…
%========================================================================================

\usepackage[most]{tcolorbox}
\tcbuselibrary{skins, breakable}

% 1. ê°œìš” ë°•ìŠ¤ (ê°•ì˜ ì‹œì‘ ë¶€ë¶„)
\newtcolorbox{overviewbox}[1][]{
    enhanced,
    colback=lightpurple,
    colframe=darkpurple,
    fonttitle=\bfseries\large,
    title=ğŸ“š ê°•ì˜ ê°œìš”,
    arc=3mm,
    boxrule=1pt,
    left=8pt,
    right=8pt,
    top=8pt,
    bottom=8pt,
    breakable,
    #1
}

% 2. ìš”ì•½ ë°•ìŠ¤
\newtcolorbox{summarybox}[1][]{
    enhanced,
    colback=lightblue,
    colframe=darkblue,
    fonttitle=\bfseries,
    title=ğŸ“ í•µì‹¬ ìš”ì•½,
    arc=2mm,
    boxrule=0.7pt,
    left=6pt,
    right=6pt,
    top=6pt,
    bottom=6pt,
    breakable,
    #1
}

% 3. í•µì‹¬ ì •ë³´ ë°•ìŠ¤
\newtcolorbox{infobox}[1][]{
    enhanced,
    colback=lightgreen,
    colframe=darkgreen,
    fonttitle=\bfseries,
    title=ğŸ’¡ í•µì‹¬ ì •ë³´,
    arc=2mm,
    boxrule=0.7pt,
    left=6pt,
    right=6pt,
    top=6pt,
    bottom=6pt,
    breakable,
    #1
}

% 4. ì£¼ì˜ì‚¬í•­ ë°•ìŠ¤
\newtcolorbox{warningbox}[1][]{
    enhanced,
    colback=lightyellow,
    colframe=darkorange,
    fonttitle=\bfseries,
    title=âš ï¸ ì£¼ì˜ì‚¬í•­,
    arc=2mm,
    boxrule=0.7pt,
    left=6pt,
    right=6pt,
    top=6pt,
    bottom=6pt,
    breakable,
    #1
}

% 5. ì˜ˆì œ ë°•ìŠ¤
\newtcolorbox{examplebox}[1][]{
    enhanced,
    colback=lightgray,
    colframe=black!60,
    fonttitle=\bfseries,
    title=ğŸ“– ì˜ˆì œ: #1,
    arc=2mm,
    boxrule=0.7pt,
    left=6pt,
    right=6pt,
    top=6pt,
    bottom=6pt,
    breakable,
}

% 6. ì •ì˜ ë°•ìŠ¤
\newtcolorbox{definitionbox}[1][]{
    enhanced,
    colback=lightpink,
    colframe=purple!70!black,
    fonttitle=\bfseries,
    title=ğŸ“Œ ì •ì˜: #1,
    arc=2mm,
    boxrule=0.7pt,
    left=6pt,
    right=6pt,
    top=6pt,
    bottom=6pt,
    breakable,
}

% 7. ì¤‘ìš” ë°•ìŠ¤ (importantbox - warningboxì™€ ìœ ì‚¬)
\newtcolorbox{importantbox}[1][]{
    enhanced,
    colback=boxred,
    colframe=red!70!black,
    fonttitle=\bfseries,
    title=âš ï¸ ë§¤ìš° ì¤‘ìš”: #1,
    arc=2mm,
    boxrule=0.7pt,
    left=6pt,
    right=6pt,
    top=6pt,
    bottom=6pt,
    breakable,
}

% 8. cautionbox (warningboxì™€ ë™ì¼)
\let\cautionbox\warningbox
\let\endcautionbox\endwarningbox

%========================================================================================
% ì½”ë“œ ë¸”ë¡ ì„¤ì • (ë°ì€ ë°°ê²½)
%========================================================================================

\usepackage{listings}

\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.95}

\lstset{
    basicstyle=\ttfamily\small,
    backgroundcolor=\color{lightgray},
    keywordstyle=\color{darkblue}\bfseries,
    commentstyle=\color{darkgreen}\itshape,
    stringstyle=\color{purple!80!black},
    numberstyle=\tiny\color{black!60},
    numbers=left,
    numbersep=8pt,
    breaklines=true,
    breakatwhitespace=false,
    frame=single,
    frameround=tttt,
    rulecolor=\color{black!30},
    captionpos=b,
    showstringspaces=false,
    tabsize=2,
    xleftmargin=15pt,
    xrightmargin=5pt,
    escapeinside={\%*}{*)}
}

% Python ì½”ë“œ ìŠ¤íƒ€ì¼
\lstdefinestyle{pythonstyle}{
    language=Python,
    morekeywords={self, True, False, None},
}

% SQL ì½”ë“œ ìŠ¤íƒ€ì¼
\lstdefinestyle{sqlstyle}{
    language=SQL,
    morekeywords={SELECT, FROM, WHERE, JOIN, GROUP, BY, ORDER, HAVING},
}

%========================================================================================
% ëª©ì°¨ ìŠ¤íƒ€ì¼ë§
%========================================================================================

\usepackage{tocloft}
\renewcommand{\cftsecleader}{\cftdotfill{\cftdotsep}}
\setlength{\cftbeforesecskip}{0.4em}
\renewcommand{\cftsecfont}{\bfseries}
\renewcommand{\cftsubsecfont}{\normalfont}

%========================================================================================
% í‘œ ë° ê·¸ë¦¼
%========================================================================================

\usepackage{graphicx}              % ì´ë¯¸ì§€
\usepackage{adjustbox}             % í‘œ/ë°•ìŠ¤ í¬ê¸° ì¡°ì ˆ

% í‘œ ìº¡ì…˜ ìŠ¤íƒ€ì¼
\usepackage{caption}
\captionsetup[table]{
    labelfont=bf,
    textfont=it,
    skip=5pt
}
\captionsetup[figure]{
    labelfont=bf,
    textfont=it,
    skip=5pt
}

%========================================================================================
% ìˆ˜í•™
%========================================================================================

\usepackage{amsmath, amssymb, amsthm}

% ì •ë¦¬ í™˜ê²½
\theoremstyle{definition}
\newtheorem{theorem}{ì •ë¦¬}[section]
\newtheorem{lemma}[theorem]{ë³´ì¡°ì •ë¦¬}
\newtheorem{proposition}[theorem]{ëª…ì œ}
\newtheorem{corollary}[theorem]{ë”°ë¦„ì •ë¦¬}
\newtheorem{definition}{ì •ì˜}[section]
\newtheorem{example}{ì˜ˆì œ}[section]

%========================================================================================
% í•˜ì´í¼ë§í¬
%========================================================================================

\usepackage[
    colorlinks=true,
    linkcolor=blue!80!black,
    urlcolor=blue!80!black,
    citecolor=green!60!black,
    bookmarks=true,
    bookmarksnumbered=true,
    pdfborder={0 0 0}
]{hyperref}

% PDF ë©”íƒ€ë°ì´í„°ëŠ” ê° ë¬¸ì„œì—ì„œ ì„¤ì •
\hypersetup{
    pdftitle={CSCI E-89B: ìì—°ì–´ ì²˜ë¦¬ ì…ë¬¸ - Lecture 07},
    pdfauthor={ê°•ì˜ ë…¸íŠ¸},
    pdfsubject={Academic Notes}
}

%========================================================================================
% ê¸°íƒ€ ìœ ìš©í•œ íŒ¨í‚¤ì§€
%========================================================================================

\usepackage{enumitem}              % ë¦¬ìŠ¤íŠ¸ ì»¤ìŠ¤í„°ë§ˆì´ì§•
\setlist{nosep, leftmargin=*, itemsep=0.3em}

\usepackage{microtype}             % íƒ€ì´í¬ê·¸ë˜í”¼ ê°œì„ 
\usepackage{footnote}              % ê°ì£¼ ê°œì„ 
\usepackage{url}                   % URL ì¤„ë°”ê¿ˆ
\urlstyle{same}

%========================================================================================
% ì‚¬ìš©ì ì •ì˜ ëª…ë ¹ì–´
%========================================================================================

% ê°•ì¡° í…ìŠ¤íŠ¸
\newcommand{\important}[1]{\textbf{\textcolor{red!70!black}{#1}}}
\newcommand{\keyword}[1]{\textbf{#1}}
\newcommand{\term}[1]{\textit{#1}}
\newcommand{\code}[1]{\texttt{#1}}

% ìš©ì–´ ì„¤ëª… (ì¸ë¼ì¸)
\newcommand{\defterm}[2]{\textbf{#1}\footnote{#2}}

% ì„¹ì…˜ ì‹œì‘ ì „ í˜ì´ì§€ ë¶„ë¦¬
\newcommand{\newsection}[1]{\newpage\section{#1}}

%========================================================================================
% ë¬¸ì„œ ì œëª© ìŠ¤íƒ€ì¼
%========================================================================================

\usepackage{titling}
\pretitle{\begin{center}\LARGE\bfseries}
\posttitle{\par\end{center}\vskip 0.5em}
\preauthor{\begin{center}\large}
\postauthor{\end{center}}
\predate{\begin{center}\large}
\postdate{\par\end{center}}

%========================================================================================
% ì„¹ì…˜ ì œëª© ê°„ê²©
%========================================================================================

\usepackage{titlesec}
\titlespacing*{\section}{0pt}{1.5em}{0.8em}
\titlespacing*{\subsection}{0pt}{1.2em}{0.6em}
\titlespacing*{\subsubsection}{0pt}{1em}{0.5em}

%========================================================================================
% ë©”íƒ€ ì •ë³´ ë°•ìŠ¤ ëª…ë ¹ì–´
%========================================================================================

\newcommand{\metainfo}[4]{
\begin{tcolorbox}[
    colback=lightpurple,
    colframe=darkpurple,
    boxrule=1pt,
    arc=2mm,
    left=10pt,
    right=10pt,
    top=8pt,
    bottom=8pt
]
\begin{tabular}{@{}rl@{}}
â–£ \textbf{ê°•ì˜ëª…:} & #1 \\[0.3em]
â–£ \textbf{ì£¼ì°¨:} & #2 \\[0.3em]
â–£ \textbf{êµìˆ˜ëª…:} & #3 \\[0.3em]
â–£ \textbf{ëª©ì :} & \begin{minipage}[t]{0.75\textwidth}#4\end{minipage}
\end{tabular}
\end{tcolorbox}
}

%========================================================================================
% ë
%========================================================================================


\begin{document}

\maketitle
\thispagestyle{firstpage}

\metainfo{CSCI E-89B: ìì—°ì–´ ì²˜ë¦¬ ì…ë¬¸}{Lecture 07}{Dmitry Kurochkin}{Lecture 07ì˜ í•µì‹¬ ê°œë… í•™ìŠµ}


%--- ê°œìš” (í•„ìˆ˜) ---
\begin_summarybox
ì´ ë¬¸ì„œëŠ” ìì—°ì–´ ì²˜ë¦¬(NLP)ì˜ ë‘ ê°€ì§€ ì£¼ìš” ì£¼ì œë¥¼ ë‹¤ë£¹ë‹ˆë‹¤.

ì²«ì§¸, ì´ì „ í€´ì¦ˆ 6ì˜ ë³µìŠµìœ¼ë¡œ, \textbf{Autoencoder(ì˜¤í† ì¸ì½”ë”)}ì˜ ê¸°ë³¸ ì›ë¦¬ì™€ \textbf{'Undercomplete(ë¶ˆì™„ì „)'} í‘œí˜„ì˜ ì¤‘ìš”ì„±ì„ í•™ìŠµí•©ë‹ˆë‹¤. ì´ëŠ” ì •ë³´ë¥¼ ì••ì¶•í•˜ì—¬ í•µì‹¬ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ëŠ” ë°©ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤.

ë‘˜ì§¸, ì´ ê°•ì˜ì˜ í•µì‹¬ ì£¼ì œì¸ \textbf{í† í”½ ëª¨ë¸ë§(Topic Modeling)}ì„ ë°°ì›ë‹ˆë‹¤.
ì´ëŠ” ëŒ€ëŸ‰ì˜ ë¬¸ì„œì—ì„œ 'ìˆ¨ê²¨ì§„ ì£¼ì œ'ë¥¼ ë°œê²¬í•˜ëŠ” ë¹„ì§€ë„ í•™ìŠµ ê¸°ë²•ì…ë‹ˆë‹¤.
ì£¼ìš” ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ í™•ë¥  ê¸°ë°˜ì˜ \textbf{LDA(Latent Dirichlet Allocation)}ì™€ í–‰ë ¬ ë¶„í•´ ê¸°ë°˜ì˜ \textbf{NMF(Non-Negative Matrix Factorization)}ë¥¼ ë¹„êµ ë¶„ì„í•˜ê³ ,
Python/R ì‹¤ìŠµ ì½”ë“œë¥¼ í†µí•´ êµ¬í˜„ ë°©ë²•ì„ ì‚´í´ë´…ë‹ˆë‹¤.
ë§ˆì§€ë§‰ìœ¼ë¡œ, ìƒì„±ëœ í† í”½ì˜ í’ˆì§ˆì„ í‰ê°€í•˜ê³  ìµœì ì˜ í† í”½ ê°œìˆ˜(K)ë¥¼ ì°¾ëŠ” ì§€í‘œ(\textbf{ì‘ì§‘ë„, ë°°íƒ€ì„±})ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.
\end_summarybox

\tableofcontents % ëª©ì°¨ ìƒì„±

%================================
\newpage
\section{ì§€ë‚œ ì‹œê°„ ë³µìŠµ: Quiz 6 ë° Autoencoder}
%================================
ë³¸ê²©ì ì¸ í† í”½ ëª¨ë¸ë§ í•™ìŠµì— ì•ì„œ, ë°ì´í„° í‘œí˜„(Representation)ê³¼ ê´€ë ¨ëœ ì´ì „ í€´ì¦ˆ 6ì˜ ì£¼ìš” ê°œë…ë“¤ì„ ë³µìŠµí•©ë‹ˆë‹¤. ì´ëŠ” ì •ë³´ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì••ì¶•í•˜ëŠ” Autoencoder(ì˜¤í† ì¸ì½”ë”)ì— ëŒ€í•œ ì´í•´ë¥¼ ë•ìŠµë‹ˆë‹¤.

%--- 1. One-Hot Encoding ---
\subsection{One-Hot Encodingì˜ ë‹¨ì }
One-Hot Encoding(ì›-í•« ì¸ì½”ë”©)ì€ ë²”ì£¼í˜• ë°ì´í„°ë¥¼ ë²¡í„°ë¡œ í‘œí˜„í•˜ëŠ” ê¸°ë²•ì´ì§€ë§Œ, ë‹¤ìŒê³¼ ê°™ì€ ëª…í™•í•œ ë‹¨ì ì´ ìˆìŠµë‹ˆë‹¤.

\begin{itemize}
    \item \textbf{í¬ì†Œì„± (Sparsity):} ë²¡í„°ì˜ ëŒ€ë¶€ë¶„ì´ 0ìœ¼ë¡œ ì±„ì›Œì§‘ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ 10,000ê°œì˜ ë‹¨ì–´ ì‚¬ì „ì„ ì›-í•« ì¸ì½”ë”©í•˜ë©´, ê° ë‹¨ì–´ ë²¡í„°ëŠ” 9,999ê°œì˜ 0ê³¼ 1ê°œì˜ 1ì„ ê°–ê²Œ ë©ë‹ˆë‹¤.
    \item \textbf{ë†’ì€ ì°¨ì› (High Dimensionality):} ë‹¨ì–´ì˜ ê°œìˆ˜ë§Œí¼ ë²¡í„°ì˜ ì°¨ì›ì´ ì¦ê°€í•˜ì—¬ ê³„ì‚° ë¹„íš¨ìœ¨ì„±ì„ ì´ˆë˜í•©ë‹ˆë‹¤. 0ê³¼ì˜ ê³±ì…ˆ ì—°ì‚°ì´ ë§ì•„ì ¸ ë¦¬ì†ŒìŠ¤ë¥¼ ë‚­ë¹„í•˜ê²Œ ë©ë‹ˆë‹¤.
    \item \textbf{ì •ë³´ ë¹„íš¨ìœ¨ì„± (Inefficient Representation):} ì •ë³´ ìì²´ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ë‚˜íƒ€ë‚´ì§€ ëª»í•©ë‹ˆë‹¤. (ì˜ˆ: 'ê³ ì–‘ì´'ì™€ 'ê°•ì•„ì§€' ë²¡í„° ê°„ì˜ ê´€ê³„ì„±ì„ í‘œí˜„í•˜ì§€ ëª»í•¨)
\end{itemize}
ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ \textbf{Embedding(ì„ë² ë”©)}ê³¼ ê°™ì€ ì €ì°¨ì›ì˜ ë°€ì§‘ëœ(dense) ë²¡í„° í‘œí˜„ ë°©ì‹ì´ ì„ í˜¸ë©ë‹ˆë‹¤.

%--- 2. Autoencoder ---
\subsection{Autoencoder(ì˜¤í† ì¸ì½”ë”)ì™€ Bottleneck}
\textbf{Autoencoder(ì˜¤í† ì¸ì½”ë”)}ëŠ” ì…ë ¥ ë°ì´í„°ë¥¼ ë” ë‚®ì€ ì°¨ì›ì˜ ë²¡í„°ë¡œ 'ì••ì¶•'í–ˆë‹¤ê°€(Encoding), ë‹¤ì‹œ ì›ë˜ ì°¨ì›ìœ¼ë¡œ 'ë³µì›'(Decoding)í•˜ë„ë¡ í•™ìŠµë˜ëŠ” ì‹ ê²½ë§ì…ë‹ˆë‹¤.

\begin{itemize}
    \item \textbf{ëª©í‘œ:} ì…ë ¥ê³¼ ì¶œë ¥ì´ ìµœëŒ€í•œ ê°™ì•„ì§€ë„ë¡(ì˜ˆ: $Input \approx Output$) í•™ìŠµí•©ë‹ˆë‹¤.
    \item \textbf{í•µì‹¬: Bottleneck(ë³‘ëª©) ë ˆì´ì–´}
    \begin{itemize}
        \item ì¸ì½”ë”(Encoder)ì™€ ë””ì½”ë”(Decoder) ì‚¬ì´ì— ìœ„ì¹˜í•˜ëŠ” ê°€ì¥ ì°¨ì›ì´ ë‚®ì€ ì€ë‹‰ì¸µì…ë‹ˆë‹¤.
        \item ì…ë ¥ ë°ì´í„°ì˜ í•µì‹¬ì ì¸ íŠ¹ì§•(representation)ì´ ì´ 'ë³‘ëª©' ì§€ì ì— ì••ì¶•ë˜ì–´ ì €ì¥ë©ë‹ˆë‹¤.
        \item ì´ ì••ì¶•ëœ ë²¡í„°(Encoding Vector)ê°€ ë°ì´í„°ì˜ ì €ì°¨ì› í‘œí˜„ì´ ë©ë‹ˆë‹¤.
    \end{itemize}
\end{itemize}

%--- 3. Undercomplete ---
\subsection{Undercomplete Autoencoder}
AutoencoderëŠ” 'ë³‘ëª©' ë ˆì´ì–´ì˜ ì°¨ì›ì— ë”°ë¼ 'Undercomplete' ë˜ëŠ” 'Overcomplete'ë¡œ ë¶ˆë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

\begin{notebox}{Q\&A: ì™œ 'Undercomplete(ë¶ˆì™„ì „)'ë¼ê³  ë¶€ë¥´ë‚˜ìš”?}
    \textbf{Q: 'Undercomplete'ë¼ëŠ” ìš©ì–´ì˜ ì˜ë¯¸ê°€ ë¬´ì—‡ì¸ê°€ìš”? ë°ì´í„°ë¥¼ ì••ì¶•í•˜ëŠ” ê²ƒì€ ì•Œê² ìŠµë‹ˆë‹¤.}

    \textbf{A:} 'Undercomplete'ëŠ” 'ì™„ì „í•˜ì§€ ì•Šë‹¤'ëŠ” ì˜ë¯¸ë¡œ, ì…ë ¥ ë°ì´í„°ì˜ ì°¨ì›ë³´ë‹¤ \textbf{ë” ë‚®ì€ ì°¨ì›}ì˜ í‘œí˜„(representation)ì„ ì‚¬ìš©í•œë‹¤ëŠ” ëœ»ì…ë‹ˆë‹¤.

    ì˜ˆë¥¼ ë“¤ì–´, 3ì°¨ì› ê³µê°„($x_1, x_2, x_3$)ì— ë¶„í¬í•˜ëŠ” ë°ì´í„°ê°€ ìˆë‹¤ê³  ê°€ì •í•´ ë´…ì‹œë‹¤. ì´ ë°ì´í„°ë¥¼ 'ì™„ì „í•˜ê²Œ(complete)' í‘œí˜„í•˜ë ¤ë©´ 3ì°¨ì› ê³µê°„ì´ ê·¸ëŒ€ë¡œ í•„ìš”í•©ë‹ˆë‹¤.

    í•˜ì§€ë§Œ ë§Œì•½ ìš°ë¦¬ê°€ ì´ ë°ì´í„°ë¥¼ 2ì°¨ì› í‰ë©´ì— ê°•ì œë¡œ 'ì••ì¶•'(íˆ¬ì˜)í•˜ì—¬ í‘œí˜„í•˜ë ¤ í•œë‹¤ë©´, ì´ëŠ” ì›ë³¸ ë°ì´í„°ë¥¼ í‘œí˜„í•˜ê¸°ì— ì°¨ì›ì´ 'ë¶€ì¡±'í•©ë‹ˆë‹¤. ì´ë¥¼ \textbf{Undercomplete Representation}ì´ë¼ê³  ë¶€ë¦…ë‹ˆë‹¤.

    \begin{itemize}
        \item \textbf{Undercomplete:} ì…ë ¥ ì°¨ì› (ì˜ˆ: 100) > ë³‘ëª© ì°¨ì› (ì˜ˆ: 10)
        \item \textbf{Overcomplete:} ì…ë ¥ ì°¨ì› (ì˜ˆ: 100) < ë³‘ëª© ì°¨ì› (ì˜ˆ: 200)
    \end{itemize}

    Autoencoderì˜ ì£¼ëœ ëª©ì  ì¤‘ í•˜ë‚˜ëŠ” ì´ Undercomplete í‘œí˜„, ì¦‰ ì €ì°¨ì›ì˜ í•µì‹¬ íŠ¹ì§• ë²¡í„°ë¥¼ í•™ìŠµí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
\end{notebox}

%--- 4. Stacked Autoencoder ---
\subsection{Stacked Autoencoder (ì ì¸µ ì˜¤í† ì¸ì½”ë”)}
\textbf{Stacked Autoencoder(ì ì¸µ ì˜¤í† ì¸ì½”ë”)}ëŠ” ì—¬ëŸ¬ ê°œì˜ ì€ë‹‰ì¸µì„ 'ìŒ“ì•„ì„œ(stack)' ë§Œë“  ê¹Šì€(deep) ì‹ ê²½ë§ êµ¬ì¡°ì˜ ì˜¤í† ì¸ì½”ë”ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.

\begin{itemize}
    \item \textbf{Shallow Network (ì–•ì€ ì‹ ê²½ë§):} ì€ë‹‰ì¸µì´ 1ê°œì¸ ê²½ìš°.
    \item \textbf{Deep Network (ê¹Šì€ ì‹ ê²½ë§):} ì€ë‹‰ì¸µì´ 2ê°œ ì´ìƒì¸ ê²½ìš°. ì ì¸µ ì˜¤í† ì¸ì½”ë”ëŠ” ì •ì˜ìƒ Deep Networkì…ë‹ˆë‹¤.
\end{itemize}

ê³¼ê±°ì—ëŠ” ê¹Šì€ ì‹ ê²½ë§ì„ í•œ ë²ˆì— í•™ìŠµì‹œí‚¤ê¸° ì–´ë ¤ì› ìŠµë‹ˆë‹¤. (ì˜ˆ: Gradient Vanishing/Exploding ë¬¸ì œ)
ê·¸ë˜ì„œ 'Stacked'ë¼ëŠ” ì´ë¦„ì²˜ëŸ¼, í•œ ë²ˆì— í•œ ì¸µì”©(Shallow Autoencoder) í•™ìŠµì‹œí‚¤ê³  ê·¸ ê°€ì¤‘ì¹˜ë¥¼ ê³ ì •(freeze)í•œ ë’¤, ë‹¤ìŒ ì¸µì„ ìƒŒë“œìœ„ì¹˜ì²˜ëŸ¼ ìŒ“ì•„ ì˜¬ë¦¬ëŠ” ë°©ì‹(Layer-wise training)ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.

\begin{notebox}{ì°¸ê³ : í˜„ëŒ€ì˜ Deep Network í•™ìŠµ}
    í˜„ì¬ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ê¸°ìˆ ë“¤ ë•ë¶„ì— ê¹Šì€ ì‹ ê²½ë§ë„ í•œ ë²ˆì—(end-to-end) íš¨ê³¼ì ìœ¼ë¡œ í•™ìŠµí•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.
    \begin{itemize}
        \item \textbf{Adam Optimizer:} Gradientì˜ ìŠ¤ì¼€ì¼ì„ ì¡°ì ˆí•˜ì—¬ íš¨ìœ¨ì ìœ¼ë¡œ ìµœì ì ì„ ì°¾ì•„ê°‘ë‹ˆë‹¤.
        \item \textbf{Batch Normalization (ë°°ì¹˜ ì •ê·œí™”):} ê° ì¸µì„ í†µê³¼í•˜ëŠ” ì‹ í˜¸(signal)ë¥¼ êµ­ì†Œì ìœ¼ë¡œ ì •ê·œí™”í•˜ì—¬ í•™ìŠµì„ ì•ˆì •ì‹œí‚µë‹ˆë‹¤.
        \item \textbf{Shortcut Connections (ì˜ˆ: ResNet):} ì¸µì„ ê±´ë„ˆë›°ëŠ” ì—°ê²°ì„ ë§Œë“¤ì–´ ì‹ í˜¸(Gradient)ê°€ ì˜ ì „íŒŒë˜ë„ë¡ ë•ìŠµë‹ˆë‹¤.
    \end{itemize}
\end{notebox}

%--- 5. Autoencoder for Sequences ---
\subsection{ì‹œí€€ìŠ¤(Sequence)ë¥¼ ìœ„í•œ Autoencoder}
AutoencoderëŠ” ì´ë¯¸ì§€ë¿ë§Œ ì•„ë‹ˆë¼ ì‹œí€€ìŠ¤ ë°ì´í„°(ì˜ˆ: ë¬¸ì¥)ì—ë„ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì£¼ë¡œ \textbf{LSTM(Long Short-Term Memory)}ê³¼ ê°™ì€ RNN(Recurrent Neural Network)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

\begin{itemize}
    \item \textbf{Encoder:} ì‹œí€€ìŠ¤(ë¬¸ì¥)ë¥¼ ì…ë ¥ë°›ì•„ ì „ì²´ ë¬¸ë§¥ì„ ì••ì¶•í•œ \textbf{ë‹¨ì¼ ë²¡í„°}(Context Vector)ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. (Bottleneck ì—­í• )
    \item \textbf{Decoder:} ì´ ë‹¨ì¼ ë²¡í„°ë¥¼ ì…ë ¥ë°›ì•„ ì›ë˜ì˜ ì‹œí€€ìŠ¤(ë¬¸ì¥)ë¥¼ ë‹¤ì‹œ ìƒì„±(ë³µì›)í•˜ë„ë¡ í•™ìŠµë©ë‹ˆë‹¤.
\end{itemize}

\begin{warnbox}{ì´ˆì‹¬ìì˜ ì˜¤í•´ vs. ì˜¬ë°”ë¥¸ ì´í•´: Autoencoderì˜ ì§„ì§œ ëª©ì }
    \textbf{Q: ë°ì´í„°ë¥¼ ì••ì¶•í–ˆë‹¤ê°€ ë‹¤ì‹œ ë³µì›í•  ê±°ë©´ ì™œ êµ³ì´ ì••ì¶•ì„ í•˜ë‚˜ìš”? ì™„ë²½í•˜ê²Œ ë³µì›(Reconstruction)í•˜ë ¤ë©´ ê·¸ëƒ¥ ì›ë³¸ì„ ì“°ë©´ ë˜ì§€ ì•Šë‚˜ìš”?}

    \textbf{A: ì•„ì£¼ í›Œë¥­í•œ ì§ˆë¬¸ì…ë‹ˆë‹¤. Autoencoderì˜ ëª©ì ì€ 'ì™„ë²½í•œ ë³µì›' ê·¸ ìì²´ê°€ ì•„ë‹™ë‹ˆë‹¤.}

    \begin{itemize}
        \item \textbf{ì˜ëª»ëœ ì˜¤í•´:} AutoencoderëŠ” ë°ì´í„°ë¥¼ ì†ì‹¤ ì—†ì´ ì••ì¶•í–ˆë‹¤ê°€ ë³µì›í•˜ëŠ” 'íŒŒì¼ ì••ì¶•(zip)' í”„ë¡œê·¸ë¨ ê°™ì€ ê²ƒì´ë‹¤.
        \item \textbf{ì˜¬ë°”ë¥¸ ì´í•´:} Autoencoderì˜ ì§„ì§œ ëª©ì ì€ ë³µì› ê³¼ì •(Decoder)ì„ 'ë¯¸ë¼'ë¡œ ì‚¬ìš©í•˜ì—¬, ì…ë ¥ ë°ì´í„°ì˜ í•µì‹¬ íŠ¹ì§•ì„ ì••ì¶•í•œ \textbf{'ì €ì°¨ì› í‘œí˜„(Encoding)'}ì„ ì–»ëŠ” ê²ƒì…ë‹ˆë‹¤.
    \end{itemize}

    ìš°ë¦¬ëŠ” ì´ë ‡ê²Œ ì–»ì–´ë‚¸ 'ì••ì¶•ëœ ë²¡í„°'(Encoderì˜ ì¶œë ¥)ë¥¼ \textbf{ë¶„ë¥˜(Classification)}ë‚˜ \textbf{êµ°ì§‘í™”(Clustering)} ê°™ì€ ë‹¤ë¥¸ ì‘ì—…(Downstream Task)ì˜ ì…ë ¥ê°’ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.

    ì˜ˆë¥¼ ë“¤ì–´, 10,000ì°¨ì›ì˜ í¬ì†Œí•œ í…ìŠ¤íŠ¸ ë²¡í„°ë¥¼ 100ì°¨ì›ì˜ ë°€ì§‘ëœ ë²¡í„°ë¡œ ì••ì¶•(Encoding)í•œ ë’¤, ì´ 100ì°¨ì› ë²¡í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œ ë¶„ë¥˜ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ëŠ” ê²ƒì´ í›¨ì”¬ íš¨ìœ¨ì ì…ë‹ˆë‹¤.
    ëª‡ ì°¨ì›ìœ¼ë¡œ 'ì§œëŠ”(squeeze)' ê²ƒì´ ê°€ì¥ ì¢‹ì€ì§€ëŠ” \textbf{ì‹¤í—˜ì (experimental)ìœ¼ë¡œ ê²°ì •}í•´ì•¼ í•©ë‹ˆë‹¤. ì¦‰, ìµœì¢… ì‘ì—…(ì˜ˆ: ë¶„ë¥˜)ì˜ ì„±ëŠ¥ì´ ê°€ì¥ ì¢‹ê²Œ ë‚˜ì˜¤ëŠ” ì°¨ì›ì„ ì„ íƒí•©ë‹ˆë‹¤.
\end{warnbox}


%================================
\newpage
\section{í† í”½ ëª¨ë¸ë§ (Topic Modeling) ì†Œê°œ}
%================================
\textbf{í† í”½ ëª¨ë¸ë§(Topic Modeling)}ì€ ëŒ€ê·œëª¨ í…ìŠ¤íŠ¸ ëª¨ìŒ(Corpus)ì—ì„œ ìë™ìœ¼ë¡œ 'ìˆ¨ê²¨ì§„ ì£¼ì œ(Latent Topics)'ë¥¼ ë°œê²¬í•˜ëŠ” \textbf{ë¹„ì§€ë„ í•™ìŠµ(Unsupervised Learning)} ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.

ì—¬ê¸°ì„œ 'ë¹„ì§€ë„ í•™ìŠµ'ì´ë€, ë°ì´í„°ì— 'ì •ë‹µ(Label)'ì´ ì£¼ì–´ì§€ì§€ ì•Šì•„ë„(ì˜ˆ: 'ì´ ë¬¸ì„œëŠ” ìŠ¤í¬ì¸  ê¸°ì‚¬ë‹¤'ë¼ëŠ” ì •ë‹µì´ ì—†ìŒ) ê¸°ê³„ê°€ ìŠ¤ìŠ¤ë¡œ ë°ì´í„° ë‚´ë¶€ì˜ êµ¬ì¡°ë‚˜ íŒ¨í„´ì„ ì°¾ì•„ë‚´ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.

\subsection{í† í”½ ëª¨ë¸ë§ì˜ í•„ìš”ì„±: í´ëŸ¬ìŠ¤í„°ë§ê³¼ì˜ ì°¨ì´}
"ë¬¸ì„œì—ì„œ ì£¼ì œë¥¼ ì°¾ëŠ”ë‹¤"ëŠ” ê°œë…ì€ 'í´ëŸ¬ìŠ¤í„°ë§(Clustering)'ê³¼ í˜¼ë™í•˜ê¸° ì‰½ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ í…ìŠ¤íŠ¸ ë°ì´í„°ì˜ íŠ¹ì„±ìƒ í´ëŸ¬ìŠ¤í„°ë§ë§Œìœ¼ë¡œëŠ” í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤.

\begin{itemize}
    \item \textbf{í´ëŸ¬ìŠ¤í„°ë§ (ì˜ˆ: K-Means):} ë¬¸ì„œë¥¼ \textbf{ë‹¨ í•˜ë‚˜ì˜} ì£¼ì œ(í´ëŸ¬ìŠ¤í„°)ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤. (Hard Assignment)
    \item \textbf{í˜„ì‹¤ì˜ ë¬¸ì„œ:} í•˜ì§€ë§Œ í˜„ì‹¤ì˜ ë¬¸ì„œëŠ” ì—¬ëŸ¬ ì£¼ì œë¥¼ ë™ì‹œì— ë‹¤ë£¹ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, 'ì• í”Œì˜ ì‹ í˜• ì•„ì´í° ì¶œì‹œ' ê¸°ì‚¬ëŠ” 'IT(ê¸°ìˆ )', 'ê²½ì œ(ì£¼ê°€)', 'ë””ìì¸' ë“± ì—¬ëŸ¬ ì£¼ì œë¥¼ í¬í•¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    \item \textbf{í† í”½ ëª¨ë¸ë§ (ì˜ˆ: LDA):} ì´ í•œê³„ë¥¼ ê·¹ë³µí•©ë‹ˆë‹¤. ë¬¸ì„œë¥¼ ë‹¨ í•˜ë‚˜ì˜ ì£¼ì œë¡œ ë¶„ë¥˜í•˜ëŠ” ëŒ€ì‹ , \textbf{ì—¬ëŸ¬ í† í”½ì˜ 'í˜¼í•©(Mixture)'}ìœ¼ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤. (Soft Assignment)
\end{itemize}

\begin{notebox}{ë¹„ìœ : ê³¼ì¼ ë°”êµ¬ë‹ˆ vs. ìŠ¤ë¬´ë””}
    \begin{itemize}
        \item \textbf{í´ëŸ¬ìŠ¤í„°ë§ (Clustering):} ë¬¸ì„œë¥¼ 'ì‚¬ê³¼ ìƒì', 'ë°”ë‚˜ë‚˜ ìƒì' ë“± ëª…í™•íˆ êµ¬ë¶„ëœ ìƒìì— \textbf{í•˜ë‚˜ì”©} ì§‘ì–´ë„£ëŠ” ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤. (ë¬¸ì„œ 1 $\rightarrow$ ìƒì A)
        \item \textbf{í† í”½ ëª¨ë¸ë§ (Topic Modeling):} ë¬¸ì„œë¥¼ 'ì‚¬ê³¼ 60%, ë°”ë‚˜ë‚˜ 30%, ë”¸ê¸° 10%'ë¡œ êµ¬ì„±ëœ \textbf{ìŠ¤ë¬´ë””}ë¡œ ë³´ëŠ” ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤. (ë¬¸ì„œ 1 $\rightarrow$ [í† í”½ A: 60\%, í† í”½ B: 30\%, ...])
    \end{itemize}
\end{notebox}

ì•„ë˜ëŠ” ë‘ ì ‘ê·¼ ë°©ì‹ì˜ ì°¨ì´ì ì„ ìš”ì•½í•œ í‘œì…ë‹ˆë‹¤.

\begin{table}[h!]
\centering
\caption{í´ëŸ¬ìŠ¤í„°ë§ê³¼ í† í”½ ëª¨ë¸ë§ì˜ ë¹„êµ}
\label{tab:cluster_vs_topic}
\begin{adjustbox}{width=\textwidth}
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{íŠ¹ì§•} & \textbf{í´ëŸ¬ìŠ¤í„°ë§ (ì˜ˆ: K-Means)} & \textbf{í† í”½ ëª¨ë¸ë§ (ì˜ˆ: LDA)} \\ \midrule
\textbf{ë¬¸ì„œ ì†Œì†} & ë¬¸ì„œëŠ” \textbf{í•˜ë‚˜ì˜} í´ëŸ¬ìŠ¤í„°ì—ë§Œ ì†í•¨. & ë¬¸ì„œëŠ” \textbf{ì—¬ëŸ¬} í† í”½ì˜ í™•ë¥ ì  ì¡°í•©ìœ¼ë¡œ í‘œí˜„ë¨. \\
\textbf{ê²°ê³¼ ì˜ˆì‹œ} & "ë¬¸ì„œ AëŠ” 'ìŠ¤í¬ì¸ ' ê·¸ë£¹ì— ì†í•œë‹¤." & "ë¬¸ì„œ AëŠ” 'ìŠ¤í¬ì¸ ' 60\%, 'ê²½ì œ' 30\%, 'IT' 10\%ë¡œ êµ¬ì„±ëœë‹¤." \\
\textbf{ì ‘ê·¼ ë°©ì‹} & Hard Assignment (ì—„ê²©í•œ í• ë‹¹) & Soft Assignment (ìœ ì—°í•œ í• ë‹¹) \\
\textbf{ì£¼ìš” ëª©ì } & ë¬¸ì„œë¥¼ ìƒí˜¸ ë°°íƒ€ì ì¸ ê·¸ë£¹ìœ¼ë¡œ ë¶„ë¥˜. & ë¬¸ì„œ ì§‘í•© ë‚´ì— ìˆ¨ê²¨ì§„ ì£¼ì œ(Latent Topics)ë“¤ì˜ ë¶„í¬ë¥¼ ë°œê²¬. \\ \bottomrule
\end{tabular}
\end{adjustbox}
\end{table}

í† í”½ ëª¨ë¸ë§ì˜ ëª©í‘œëŠ” ì´ 'ìˆ¨ê²¨ì§„(Latent)' ì£¼ì œë“¤ê³¼, ê° ë¬¸ì„œê°€ ì´ ì£¼ì œë“¤ì„ ì–¼ë§ˆë‚˜ í¬í•¨í•˜ê³  ìˆëŠ”ì§€(ë¹„ìœ¨)ë¥¼ ì•Œì•„ë‚´ëŠ” ê²ƒì…ë‹ˆë‹¤.

\textbf{ì ê¹! 'ìˆ¨ê²¨ì§„(Latent)'ì´ë€ ë¬´ìŠ¨ ëœ»ì¸ê°€ìš”?}

'Latent'ëŠ” 'ì ì¬ì ì¸', 'ìˆ¨ê²¨ì§„'ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. í† í”½ ëª¨ë¸ë§ì—ì„œ ëª¨ë¸ì€ "ì´ ë‹¨ì–´ë“¤ì€ 'ì£¼ì œ 1'ì— ì†í•œë‹¤"ê³  ì•Œë ¤ì£¼ì§€ë§Œ, ê·¸ 'ì£¼ì œ 1'ì´ ì¸ê°„ì˜ ì–¸ì–´ë¡œ 'ê²½ì œ'ì¸ì§€ 'ì •ì¹˜'ì¸ì§€ëŠ” ì•Œë ¤ì£¼ì§€ ì•ŠìŠµë‹ˆë‹¤.
ëª¨ë¸ì´ ì°¾ì•„ë‚¸ ì£¼ì œ(ë‹¨ì–´ë“¤ì˜ ì§‘í•©)ë¥¼ ë³´ê³  \textbf{ì‚¬ëŒì´ ì§ì ‘} "ì•„, ì´ í† í”½ì€ 'ê²½ì œ'ì— ê´€í•œ ê²ƒì´êµ¬ë‚˜"ë¼ê³  ë¼ë²¨ì„ ë¶™ì—¬ì•¼ í•©ë‹ˆë‹¤.

ì£¼ìš” í† í”½ ëª¨ë¸ë§ ë°©ë²•ë¡ ìœ¼ë¡œëŠ” \textbf{LDA(Latent Dirichlet Allocation)}ì™€ \textbf{NMF(Non-Negative Matrix Factorization)}ê°€ ìˆìŠµë‹ˆë‹¤.

%================================
\newpage
\section{Latent Dirichlet Allocation (LDA)}
%================================
\textbf{LDA(Latent Dirichlet Allocation, ì ì¬ ë””ë¦¬í´ë ˆ í• ë‹¹)}ëŠ” ê°€ì¥ ëŒ€í‘œì ì¸ í† í”½ ëª¨ë¸ë§ ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤. LDAëŠ” \textbf{ìƒì„± í™•ë¥  ëª¨ë¸(Generative Probabilistic Model)}ì…ë‹ˆë‹¤.

"ìƒì„± ëª¨ë¸"ì´ë€, 'ì´ ë¬¸ì„œë“¤ì€ ì–´ë–»ê²Œ ìƒì„±ë˜ì—ˆì„ê¹Œ?'ë¼ëŠ” ê³¼ì •ì„ ì—­ìœ¼ë¡œ ì¶”ì í•˜ëŠ” ëª¨ë¸ì´ë¼ëŠ” ëœ»ì…ë‹ˆë‹¤. LDAëŠ” ë¬¸ì„œê°€ ë‹¤ìŒê³¼ ê°™ì€ ë‘ ê°€ì§€ í•µì‹¬ ê°€ì • í•˜ì— ì‘ì„±ë˜ì—ˆë‹¤ê³  ë´…ë‹ˆë‹¤.

\begin{enumerate}
    \item \textbf{ë¬¸ì„œëŠ” í† í”½ì˜ í˜¼í•©ì´ë‹¤.} (A document is a mixture of topics.)
    \item \textbf{í† í”½ì€ ë‹¨ì–´ì˜ í˜¼í•©ì´ë‹¤.} (A topic is a mixture of words.)
\end{enumerate}

\subsection{LDAì˜ ë¬¸ì„œ ìƒì„± ìŠ¤í† ë¦¬ (ì§ê´€ì  ë¹„ìœ )}
LDAëŠ” ë§ˆì¹˜ ë¡œë´‡ì´ ë‹¤ìŒê³¼ ê°™ì€ í™•ë¥ ì ì¸ ê³¼ì •ì„ ê±°ì³ ë¬¸ì„œë¥¼ 'ì‘ì„±'í•œë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤. ì´ ê³¼ì •ì„ ì´í•´í•˜ëŠ” ê²ƒì´ LDAì˜ í•µì‹¬ì…ë‹ˆë‹¤.

\begin{notebox}{LDAì˜ ê°€ìƒ ë¬¸ì„œ ì‘ì„± ê³¼ì •}
    ì–´ë–¤ ì‚¬ëŒì´ $M$ê°œì˜ ë¬¸ì„œë¡œ ì´ë£¨ì–´ì§„ ì½”í¼ìŠ¤(Corpus)ë¥¼ ì‘ì„±í•˜ë ¤ í•˜ê³ , ì´ ì½”í¼ìŠ¤ì—ëŠ” ì´ $K$ê°œì˜ í† í”½(ì˜ˆ: ê²½ì œ, ì •ì¹˜, ìŠ¤í¬ì¸ )ì´ ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.

    \textbf{1. (ë¬¸ì„œ ê¸¸ì´ ê²°ì •)}
    ì²« ë²ˆì§¸ ë¬¸ì„œ($m=1$)ì˜ ê¸¸ì´ë¥¼ ëª‡ ë‹¨ì–´($N$)ë¡œ í• ì§€ ì •í•©ë‹ˆë‹¤. (ì˜ˆ: í¬ì•„ì†¡ ë¶„í¬ $N \sim Poisson(\xi)$ì—ì„œ ìˆ«ì 100ì„ ë½‘ìŒ $\rightarrow$ 100ë‹¨ì–´ì§œë¦¬ ë¬¸ì„œ)

    \textbf{2. (ë¬¸ì„œì˜ í† í”½ ë¶„í¬ ê²°ì •)}
    ì´ 100ë‹¨ì–´ì§œë¦¬ ë¬¸ì„œì˜ 'ì£¼ì œ ë°°í•© ë¹„ìœ¨'($\theta_m$)ì„ ì •í•©ë‹ˆë‹¤.
    (ì˜ˆ: ë””ë¦¬í´ë ˆ ë¶„í¬ $\theta_m \sim Dirichlet(\alpha)$ì—ì„œ [ê²½ì œ 60\%, ì •ì¹˜ 30\%, ìŠ¤í¬ì¸  10\%]ë¼ëŠ” ë¹„ìœ¨ì„ ë½‘ìŒ)
    \textit{* ì´ $\theta_m$ì€ ì´ ë¬¸ì„œê°€ ëë‚  ë•Œê¹Œì§€ ê³ ì •ë©ë‹ˆë‹¤.}

    \textbf{3. (ê°œë³„ ë‹¨ì–´ ìƒì„±)}
    ì´ì œ 100ê°œì˜ ë‹¨ì–´ë¥¼ í•˜ë‚˜ì”© ì±„ì›Œ ë„£ìŠµë‹ˆë‹¤. ( $n=1$ ë¶€í„° $N=100$ ê¹Œì§€ ë°˜ë³µ)
    \begin{itemize}
        \item \textbf{3a. (ì´ ë‹¨ì–´ì˜ í† í”½ ì„ íƒ)}:
        ë°©ê¸ˆ ì •í•œ ë¬¸ì„œì˜ í† í”½ ë¶„í¬([ê²½ì œ 60\%, ì •ì¹˜ 30\%, ...])ì— ë”°ë¼, \textbf{ì´ë²ˆ ë‹¨ì–´ í•˜ë‚˜}ì— í• ë‹¹í•  í† í”½($z_n$)ì„ ë½‘ìŠµë‹ˆë‹¤.
        (ì˜ˆ: ë‹¤í•­ ë¶„í¬ $z_n \sim Multinomial(\theta_m)$ì—ì„œ 'ê²½ì œ'ê°€ ë½‘í˜)
        
        \item \textbf{3b. (í† í”½ì—ì„œ ë‹¨ì–´ ì„ íƒ)}:
        'ê²½ì œ' í† í”½ì— ë¯¸ë¦¬ ì •í•´ì§„ ë‹¨ì–´ ë¶„í¬(ì˜ˆ: $\beta_k = $[ì£¼ì‹ 40\%, ê¸ˆë¦¬ 30\%, ...])ì— ë”°ë¼, ì‹¤ì œ ë‹¨ì–´($w_n$)ë¥¼ ë½‘ìŠµë‹ˆë‹¤.
        (ì˜ˆ: ë‹¤í•­ ë¶„í¬ $w_n \sim Multinomial(\beta_{z_n})$ì—ì„œ 'ì£¼ì‹'ì´ ë½‘í˜)
    \end{itemize}

    \textbf{4. (ë°˜ë³µ)}
    ë‘ ë²ˆì§¸ ë‹¨ì–´ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•´ 3a, 3b ê³¼ì •ì„ ë°˜ë³µí•©ë‹ˆë‹¤. (ì´ë²ˆì—ëŠ” 'ì •ì¹˜'ê°€ ë½‘íˆê³ , 'ì •ì¹˜' í† í”½ì—ì„œ 'ì„ ê±°'ë¼ëŠ” ë‹¨ì–´ê°€ ë½‘í ìˆ˜ ìˆìŠµë‹ˆë‹¤.)

    \textbf{5. (ëª¨ë“  ë¬¸ì„œì— ëŒ€í•´ ë°˜ë³µ)}
    $M$ê°œì˜ ëª¨ë“  ë¬¸ì„œì— ëŒ€í•´ 1~4 ê³¼ì •ì„ ë°˜ë³µí•©ë‹ˆë‹¤.
\end{notebox}

\textbf{ì¤‘ìš”í•œ ì :} ì´ ëª¨ë¸ì€ 'Bag-of-Words(ë‹¨ì–´ ì£¼ë¨¸ë‹ˆ)' ê°€ì •ì„ ë”°ë¥´ë¯€ë¡œ, ë‹¨ì–´ì˜ ìˆœì„œ($on$ ë‹¤ìŒì— $maximization$ì´ ë‚˜ì™”ëŠ”ì§€)ëŠ” ì „í˜€ ê³ ë ¤í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

\subsection{LDAì˜ ìˆ˜í•™ì  í”„ë ˆì„ì›Œí¬}
ìœ„ì˜ ìƒì„± ê³¼ì •ì„ ìˆ˜í•™ì  ê¸°í˜¸ë¡œ í‘œí˜„í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

\begin{itemize}
    \item $M$: ì´ ë¬¸ì„œì˜ ìˆ˜
    \item $K$: ì´ í† í”½ì˜ ìˆ˜ (ì‚¬ìš©ìê°€ ì§€ì •í•˜ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„°)
    \item $N$: $m$ë²ˆì§¸ ë¬¸ì„œì˜ ë‹¨ì–´ ìˆ˜ ( $N_m \sim Poisson(\xi)$ )
    \item $\alpha$: ë””ë¦¬í´ë ˆ ë¶„í¬ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° (ë¬¸ì„œ-í† í”½ ë¶„í¬ $\theta$ì— ì˜í–¥)
    \item $\beta$: ë””ë¦¬í´ë ˆ ë¶„í¬ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° (í† í”½-ë‹¨ì–´ ë¶„í¬ $\phi$ì— ì˜í–¥)
    \item $\theta_m$: $m$ë²ˆì§¸ ë¬¸ì„œì˜ í† í”½ ë¶„í¬ (Kì°¨ì› ë²¡í„°, $\theta_m \sim Dirichlet(\alpha)$)
    \item $\phi_k$: $k$ë²ˆì§¸ í† í”½ì˜ ë‹¨ì–´ ë¶„í¬ (Vì°¨ì› ë²¡í„°, V=ì–´íœ˜ ìˆ˜, $\phi_k \sim Dirichlet(\beta)$)
    \item $z_{m,n}$: $m$ë²ˆì§¸ ë¬¸ì„œì˜ $n$ë²ˆì§¸ ë‹¨ì–´ì— í• ë‹¹ëœ í† í”½ ( $z_{m,n} \sim Multinomial(\theta_m)$ )
    \item $w_{m,n}$: $m$ë²ˆì§¸ ë¬¸ì„œì˜ $n$ë²ˆì§¸ ë‹¨ì–´ (ê´€ì°°ëœ ê°’, $w_{m,n} \sim Multinomial(\phi_{z_{m,n}})$ )
\end{itemize}

ìš°ë¦¬ê°€ ì‹¤ì œë¡œ ê´€ì°°í•˜ëŠ” ê²ƒì€ $w$ (ë‹¨ì–´ë“¤) ë¿ì…ë‹ˆë‹¤.
LDAì˜ ëª©í‘œëŠ” ê´€ì°°ëœ $w$ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ìˆ¨ê²¨ì§„ ë³€ìˆ˜ì¸ $\theta$ (ë¬¸ì„œë³„ í† í”½ ë¶„í¬)ì™€ $\phi$ (í† í”½ë³„ ë‹¨ì–´ ë¶„í¬)ë¥¼ ì¶”ì •í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

\subsection{íŒŒë¼ë¯¸í„° ì¶”ì •: ìµœëŒ€ ê°€ëŠ¥ë„ ì¶”ì • (MLE)}
ëª¨ë¸ì€ ìš°ë¦¬ê°€ ê°€ì§„ ì‹¤ì œ ë¬¸ì„œë“¤(ê´€ì°°ëœ $w$)ì´ ë°©ê¸ˆ ì„¤ëª…í•œ 'LDA ë¬¸ì„œ ìƒì„± ìŠ¤í† ë¦¬'ì—ì„œ ë‚˜ì™”ì„ \textbf{í™•ë¥ (Likelihood)}ì„ ê³„ì‚°í•©ë‹ˆë‹¤.

ê·¸ë¦¬ê³  ì´ í™•ë¥ ì´ \textbf{ìµœëŒ€}ê°€ ë˜ë„ë¡ í•˜ëŠ” íŒŒë¼ë¯¸í„°($\alpha, \beta$, ê·¸ë¦¬ê³  ê·¸ë¡œë¶€í„° ìœ ë„ë˜ëŠ” $\theta, \phi$)ë¥¼ ì°¾ëŠ” ê³¼ì •ì„ ê±°ì¹©ë‹ˆë‹¤. ì´ë¥¼ \textbf{ìµœëŒ€ ê°€ëŠ¥ë„ ì¶”ì •(Maximum Likelihood Estimation, MLE)}ì´ë¼ê³  í•©ë‹ˆë‹¤.

\begin{notebox}{ê°œë… ì´í•´: ìµœëŒ€ ê°€ëŠ¥ë„ ì¶”ì • (MLE) ë¹„ìœ }
    ì—¬ëŸ¬ë¶„ì˜ ì†ì— íŠ¹ì • í™•ë¥ ë¶„í¬(ì˜ˆ: ì •ê·œë¶„í¬)ë¥¼ ë”°ë¥´ëŠ” ë°ì´í„°(ê´€ì°°ê°’)ê°€ ì£¼ì–´ì¡Œë‹¤ê³  ê°€ì •í•´ ë´…ì‹œë‹¤. í•˜ì§€ë§Œ ì´ ë¶„í¬ì˜ íŒŒë¼ë¯¸í„°(ì˜ˆ: í‰ê·  $\mu$, ë¶„ì‚° $\sigma^2$)ëŠ” ëª¨ë¦…ë‹ˆë‹¤.

    \begin{center}
        \includegraphics[width=0.8\textwidth]{example-image-c} % Placeholder
        \captionof{figure}{ê´€ì°°ëœ ë°ì´í„°(íˆìŠ¤í† ê·¸ë¨)ì™€ ë‹¤ë¥¸ íŒŒë¼ë¯¸í„°(A, B, C)ë¥¼ ê°€ì§„ ëª¨ë¸}
        \label{fig:mle_concept}
    \end{center}

    \begin{itemize}
        \item \textbf{ê°€ì • A (ëª¨ë¸ A):} "ì´ ë°ì´í„°ëŠ” í‰ê· ì´ ì•„ì£¼ ë‚®ì€ ê³³(A)ì— ìˆëŠ” ì •ê·œë¶„í¬ì—ì„œ ë‚˜ì™”ì„ ê²ƒì´ë‹¤."
        $\rightarrow$ \textit{íŒë‹¨:} "ë‚´ê°€ ê°€ì§„ ë°ì´í„°(ê°€ìš´ë° ëª°ë ¤ìˆìŒ)ê°€ Aì—ì„œ ë‚˜ì™”ì„ í™•ë¥ (Likelihood)ì€ ë§¤ìš° ë‚®ë‹¤."

        \item \textbf{ê°€ì • B (ëª¨ë¸ B):} "ì´ ë°ì´í„°ëŠ” í‰ê· ì´ ì•½ê°„ ì˜¤ë¥¸ìª½(B)ì— ìˆëŠ” ì •ê·œë¶„í¬ì—ì„œ ë‚˜ì™”ì„ ê²ƒì´ë‹¤."
        $\rightarrow$ \textit{íŒë‹¨:} "Aë³´ë‹¤ëŠ” í™•ë¥ ì´ ë†’ì§€ë§Œ, ì—¬ì „íˆ ë‚®ë‹¤."

        \item \textbf{ê°€ì • C (ëª¨ë¸ C):} "ì´ ë°ì´í„°ëŠ” í‰ê· ì´ ë°ì´í„°ì˜ ì¤‘ì‹¬(C)ì— ìˆëŠ” ì •ê·œë¶„í¬ì—ì„œ ë‚˜ì™”ì„ ê²ƒì´ë‹¤."
        $\rightarrow$ \textit{íŒë‹¨:} "ë‚´ê°€ ê°€ì§„ ë°ì´í„°ê°€ Cì—ì„œ ë‚˜ì™”ì„ í™•ë¥ ì´ \textbf{ê°€ì¥ ë†’ë‹¤(Maximum Likelihood)}."
    \end{itemize}

    MLEëŠ” ì´ì²˜ëŸ¼ 'ê´€ì°°ëœ ë°ì´í„°ë¥¼ ê°€ì¥ ì˜ ì„¤ëª…í•˜ëŠ”' ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„°(ì´ ê²½ìš° C)ë¥¼ ì°¾ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.
    LDAë„ ë§ˆì°¬ê°€ì§€ë¡œ, ìš°ë¦¬ê°€ ê°€ì§„ ìˆ˜ë§ì€ ë¬¸ì„œë¥¼ ìƒì„±í–ˆì„ í™•ë¥ ì´ ê°€ì¥ ë†’ì€ í† í”½ ë¶„í¬($\theta, \phi$)ë¥¼ ì—­ìœ¼ë¡œ ì¶”ì •í•´ëƒ…ë‹ˆë‹¤.
    (ì‹¤ì œë¡œëŠ” $z$ì™€ ê°™ì€ ì ì¬ ë³€ìˆ˜ê°€ ë§ì•„ \textbf{EM(Expectation-Maximization)} ì•Œê³ ë¦¬ì¦˜ì´ë‚˜ ê¹ìŠ¤ ìƒ˜í”Œë§ ë“±ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.)
\end{notebox}

\subsection{LDAì˜ í™œìš©}
LDAë¥¼ í†µí•´ ì¶”ì •ëœ ë¬¸ì„œë³„ í† í”½ ë¶„í¬($\theta$)ì™€ í† í”½ë³„ ë‹¨ì–´ ë¶„í¬($\phi$)ëŠ” ë‹¤ì–‘í•˜ê²Œ í™œìš©ë©ë‹ˆë‹¤.
\begin{itemize}
    \item \textbf{ë¬¸ì„œ ë¶„ë¥˜ (Document Classification):} ë¬¸ì„œì˜ í† í”½ ë¶„í¬(ì˜ˆ: [ê²½ì œ 60\%, ...]) ìì²´ë¥¼ ë¬¸ì„œì˜ ìƒˆë¡œìš´ íŠ¹ì§•(Feature)ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ ë¶„ë¥˜ ëª¨ë¸ì„ í•™ìŠµì‹œí‚µë‹ˆë‹¤.
    \item \textbf{ì¶”ì²œ ì‹œìŠ¤í…œ (Recommendation Systems):} ìœ ì‚¬í•œ í† í”½ ë¶„í¬ë¥¼ ê°€ì§„ ë¬¸ì„œ(ì˜ˆ: ê¸°ì‚¬, ìƒí’ˆ)ë¥¼ ì‚¬ìš©ìì—ê²Œ ì¶”ì²œí•©ë‹ˆë‹¤.
    \item \textbf{ì½˜í…ì¸  ë¶„ì„ (Content Analysis):} ëŒ€ëŸ‰ì˜ í…ìŠ¤íŠ¸ì—ì„œ ì£¼ìš” ì£¼ì œì˜ ë™í–¥(Trend)ì„ íŒŒì•…í•©ë‹ˆë‹¤.
\end{itemize}

%================================
\newpage
\section{Non-Negative Matrix Factorization (NMF)}
%================================
\textbf{NMF(Non-Negative Matrix Factorization, ë¹„ìŒìˆ˜ í–‰ë ¬ ë¶„í•´)}ëŠ” í† í”½ ëª¨ë¸ë§ì— ì‚¬ìš©ë˜ëŠ” ë˜ ë‹¤ë¥¸ ì£¼ìš” ê¸°ë²•ì…ë‹ˆë‹¤.
NMFëŠ” LDAì™€ ë‹¬ë¦¬ í™•ë¥  ëª¨ë¸ì´ ì•„ë‹ˆë¼, \textbf{í–‰ë ¬ ë¶„í•´(Matrix Decomposition)}ë¼ëŠ” ëŒ€ìˆ˜ì (Algebraic) ì ‘ê·¼ ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

\subsection{NMFì˜ í•µì‹¬ ì•„ì´ë””ì–´}
NMFëŠ” ì›ë³¸ ë¬¸ì„œ-ë‹¨ì–´ í–‰ë ¬($V$)ì„ ë‘ ê°œì˜ ë” ì‘ì€ í–‰ë ¬($W, H$)ì˜ ê³±ìœ¼ë¡œ ê·¼ì‚¬(Approximate)í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

$$ V \approx W \times H $$

\begin{itemize}
    \item \textbf{$V$ (ì›ë³¸ í–‰ë ¬):} \textbf{[ë¬¸ì„œ $\times$ ë‹¨ì–´]} í¬ê¸°ì˜ í–‰ë ¬.
    (ì˜ˆ: $m$ë²ˆì§¸ ë¬¸ì„œì˜ $n$ë²ˆì§¸ ë‹¨ì–´ ë¹ˆë„ìˆ˜)
    \item \textbf{$W$ (ë¬¸ì„œ-í† í”½ í–‰ë ¬):} \textbf{[ë¬¸ì„œ $\times$ í† í”½ ê°œìˆ˜ $K$]} í¬ê¸°ì˜ í–‰ë ¬.
    (ê° ë¬¸ì„œê°€ $K$ê°œì˜ í† í”½ì„ ì–¼ë§ˆë‚˜ í¬í•¨í•˜ëŠ”ì§€ ë‚˜íƒ€ë‚´ëŠ” ê°€ì¤‘ì¹˜)
    \item \textbf{$H$ (í† í”½-ë‹¨ì–´ í–‰ë ¬):} \textbf{[í† í”½ ê°œìˆ˜ $K$ $\times$ ë‹¨ì–´]} í¬ê¸°ì˜ í–‰ë ¬.
    (ê° í† í”½ì´ ì–´ë–¤ ë‹¨ì–´ë“¤ë¡œ êµ¬ì„±ë˜ëŠ”ì§€ ë‚˜íƒ€ë‚´ëŠ” ê°€ì¤‘ì¹˜)
\end{itemize}

ì—¬ê¸°ì„œ "ë¹„ìŒìˆ˜(Non-Negative)"ë¼ëŠ” ì´ë¦„ì´ ë¶™ì€ ì´ìœ ëŠ”, í–‰ë ¬ $V, W, H$ì˜ \textbf{ëª¨ë“  ì›ì†Œê°€ 0 ì´ìƒ($\ge 0$)}ì´ì–´ì•¼ í•œë‹¤ëŠ” ì œì•½ ì¡°ê±´ ë•Œë¬¸ì…ë‹ˆë‹¤.
ì´ëŠ” 'ë‹¨ì–´ì˜ ë¹ˆë„'ë‚˜ 'í† í”½ì˜ ê°€ì¤‘ì¹˜'ê°€ ìŒìˆ˜ê°€ ë  ìˆ˜ ì—†ë‹¤ëŠ” í˜„ì‹¤ì ì¸ ì§ê´€ê³¼ ì˜ ë¶€í•©í•˜ì—¬, ê²°ê³¼ë¥¼ í•´ì„í•˜ê¸° ì‰½ê²Œ ë§Œë“­ë‹ˆë‹¤.

\subsection{NMF ì˜ˆì‹œ}
ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ë°ì´í„°ë¡œ NMFê°€ ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ì§€ ì‚´í´ë´…ì‹œë‹¤.

\begin{itemize}
    \item \textbf{í…ìŠ¤íŠ¸ ë°ì´í„°:}
    \begin{itemize}
        \item Doc 1: "cats meow"
        \item Doc 2: "dogs bark"
        \item Doc 3: "cats purr, dogs growl"
    \end{itemize}
    \item \textbf{ì–´íœ˜ (Vocabulary):} "cats", "dogs", "meow", "bark", "purr", "growl"
\end{itemize}

ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì›ë³¸ í–‰ë ¬ $V$ (3ê°œ ë¬¸ì„œ $\times$ 6ê°œ ë‹¨ì–´)ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.
$$ V = \begin{bmatrix}
1 & 0 & 1 & 0 & 0 & 0 \\
0 & 1 & 0 & 1 & 0 & 0 \\
1 & 1 & 0 & 0 & 1 & 1 
\end{bmatrix} $$

NMFëŠ” ì´ $V$ë¥¼ $K=2$ (í† í”½ 2ê°œ)ë¡œ ë¶„í•´í•˜ì—¬ $W$ (3 $\times$ 2)ì™€ $H$ (2 $\times$ 6)ë¥¼ ì°¾ìŠµë‹ˆë‹¤.

$$ V \approx W \times H $$
$$ \begin{bmatrix}
1 & 0 & 1 & 0 & 0 & 0 \\
0 & 1 & 0 & 1 & 0 & 0 \\
1 & 1 & 0 & 0 & 1 & 1 
\end{bmatrix} \approx 
\underbrace{\begin{bmatrix} 1 & 0 \\ 0 & 1 \\ 0.5 & 0.5 \end{bmatrix}}_{W \text{: ë¬¸ì„œ-í† í”½}}
\times
\underbrace{\begin{bmatrix} 1 & 0 & 1 & 0 & 1 & 0 \\ 0 & 1 & 0 & 1 & 0 & 1 \end{bmatrix}}_{H \text{: í† í”½-ë‹¨ì–´}}
$$

\textbf{ê²°ê³¼ í•´ì„:}
\begin{itemize}
    \item \textbf{$H$ (í† í”½-ë‹¨ì–´):}
    \begin{itemize}
        \item í† í”½ 1 (Hì˜ ì²« í–‰) = [1, 0, 1, 0, 1, 0] $\rightarrow$ "cats", "meow", "purr"ì™€ ê°•í•˜ê²Œ ì—°ê´€ $\rightarrow$ \textbf{"ê³ ì–‘ì´" í† í”½}
        \item í† í”½ 2 (Hì˜ ë‘ í–‰) = [0, 1, 0, 1, 0, 1] $\rightarrow$ "dogs", "bark", "growl"ì™€ ê°•í•˜ê²Œ ì—°ê´€ $\rightarrow$ \textbf{"ê°•ì•„ì§€" í† í”½}
    \end{itemize}
    \item \textbf{$W$ (ë¬¸ì„œ-í† í”½):}
    \begin{itemize}
        \item Doc 1 (Wì˜ ì²« í–‰) = [1, 0] $\rightarrow$ "ê³ ì–‘ì´" í† í”½ 100\%, "ê°•ì•„ì§€" í† í”½ 0\%
        \item Doc 2 (Wì˜ ë‘ í–‰) = [0, 1] $\rightarrow$ "ê³ ì–‘ì´" í† í”½ 0\%, "ê°•ì•„ì§€" í† í”½ 100\%
        \item Doc 3 (Wì˜ ì„¸ í–‰) = [0.5, 0.5] $\rightarrow$ "ê³ ì–‘ì´" í† í”½ 50\%, "ê°•ì•„ì§€" í† í”½ 50\%
    \end{itemize}
\end{itemize}
NMFëŠ” $V \approx WH$ê°€ ë˜ë„ë¡ í•˜ëŠ” $W, H$ë¥¼ (ìˆ˜ì¹˜ ìµœì í™”ë¥¼ í†µí•´) ê·¼ì‚¬ì ìœ¼ë¡œ ì°¾ì•„ëƒ„ìœ¼ë¡œì¨, LDAì™€ ìœ ì‚¬í•˜ê²Œ ë¬¸ì„œì˜ í† í”½ êµ¬ì„±ì„ ë°œê²¬í•´ëƒ…ë‹ˆë‹¤.

\subsection{LDA vs. NMF ë¹„êµ}
ë‘ ì•Œê³ ë¦¬ì¦˜ì€ í† í”½ ëª¨ë¸ë§ì´ë¼ëŠ” ë™ì¼í•œ ëª©í‘œë¥¼ ê°–ì§€ë§Œ, ê·¼ë³¸ì ì¸ ì ‘ê·¼ ë°©ì‹ì´ ë‹¤ë¦…ë‹ˆë‹¤.

\begin{table}[h!]
\centering
\caption{LDAì™€ NMFì˜ ë¹„êµ}
\label{tab:lda_vs_nmf}
\begin{adjustbox}{width=\textwidth}
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{íŠ¹ì§•} & \textbf{LDA (Latent Dirichlet Allocation)} & \textbf{NMF (Non-Negative Matrix Factorization)} \\ \midrule
\textbf{ì ‘ê·¼ ë°©ì‹} & \textbf{í™•ë¥ ì  (Probabilistic)} & \textbf{ëŒ€ìˆ˜ì  / í–‰ë ¬ ë¶„í•´ (Algebraic)} \\
\textbf{ê¸°ë³¸ ê°€ì •} & ë¬¸ì„œ ìƒì„± ê³¼ì •ì— ëŒ€í•œ ë³µì¡í•œ í™•ë¥  ë¶„í¬ (Dirichlet, Multinomial)ë¥¼ ê°€ì •í•¨. & $V \approx WH$ ë¼ëŠ” ë¹„êµì  ë‹¨ìˆœí•œ í–‰ë ¬ ë¶„í•´(ì°¨ì› ì¶•ì†Œ)ë¥¼ ê°€ì •í•¨. \\
\textbf{ê²°ê³¼ ì¼ê´€ì„±} & ì‹¤í–‰í•  ë•Œë§ˆë‹¤ ê²°ê³¼ê°€ ì•½ê°„ì”© ë‹¤ë¥¼ ìˆ˜ ìˆìŒ. (Stochastic) & ë™ì¼í•œ ì¡°ê±´ì—ì„œëŠ” (ëŒ€ì²´ë¡œ) ë™ì¼í•œ ê²°ê³¼. (Deterministic) \\
\textbf{ê²°ê³¼ í•´ì„} & í† í”½ì˜ \textbf{'í™•ë¥ '} ë¶„í¬ë¡œ í•´ì„ë¨. & í† í”½ì˜ \textbf{'ê°€ì¤‘ì¹˜'}ë¡œ í•´ì„ë¨. \\
\textbf{ê³„ì‚°} & ìƒëŒ€ì ìœ¼ë¡œ ë³µì¡í•˜ê³  ëŠë¦´ ìˆ˜ ìˆìŒ. (MCMC, Variational Inference) & ìƒëŒ€ì ìœ¼ë¡œ ë‹¨ìˆœí•˜ê³  ë¹ ë¥¼ ìˆ˜ ìˆìŒ. (ë‹¨, $K$ê°€ ì»¤ì§€ë©´ ë³µì¡) \\ \bottomrule
\end{tabular}
\end{adjustbox}
\end{table}


%================================
\newpage
\section{ì‹¤ìŠµ: Python ë° R êµ¬í˜„}
%================================
LDAì™€ NMFëŠ” Pythonì˜ \texttt{scikit-learn} ë¼ì´ë¸ŒëŸ¬ë¦¬ë‚˜ Rì˜ \texttt{topicmodels} ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í†µí•´ ì‰½ê²Œ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

\subsection{Python (scikit-learn) êµ¬í˜„ ì˜ˆì œ}
ë¨¼ì € ë¬¸ì„œë¥¼ ë‹¨ì–´ ë¹ˆë„ í–‰ë ¬(Document-Term Matrix, DTM)ë¡œ ë³€í™˜í•´ì•¼ í•©ë‹ˆë‹¤. \texttt{CountVectorizer}ê°€ ì´ ì—­í• ì„ í•©ë‹ˆë‹¤.

\begin{lstlisting}[language=Python, caption={Python scikit-learnì„ ì´ìš©í•œ LDA êµ¬í˜„}, label={lst:lda_python}, breaklines=true]
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.decomposition import LatentDirichletAllocation

# ìƒ˜í”Œ ë¬¸ì„œ
documents = [
    "Cats purr gently and climb high trees. Chasing a mouse is fun for cats.",
    "Independent creatures, cats enjoy solitude and love their nap time.",
    "Dogs bark loudly at strangers and fetch sticks with enthusiasm.",
    "Loyal dogs accompany humans on hikes and love to chase balls.",
    "When the energetic dog spotted a squirrel, it barked energetically.",
    "A purring cat climbed the bookshelf, watching over the room.",
    "Regularly, dogs enjoy long walks, sniffing and exploring their environment.",
    "Cats meow softly and purr when content, loving to stretch in the sun."
]

# 1. ë¬¸ì„œ-ë‹¨ì–´ í–‰ë ¬(DTM) ìƒì„± (ë¶ˆìš©ì–´ ì œê±°)
vectorizer = CountVectorizer(stop_words='english')
X = vectorizer.fit_transform(documents)

# 2. LDA ëª¨ë¸ í•™ìŠµ (í† í”½ ê°œìˆ˜ K=2ë¡œ ì„¤ì •)
# random_stateëŠ” ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œê°’
lda = LatentDirichletAllocation(n_components=2, random_state=0)
lda.fit(X)

# 3. ê²°ê³¼ ì¶œë ¥: í† í”½ë³„ ìƒìœ„ 5ê°œ ë‹¨ì–´
feature_names = vectorizer.get_feature_names_out()
for index, topic in enumerate(lda.components_):
    print(f"Topic {index + 1}:")
    # topic.argsort()[:-6:-1] : ìƒìœ„ 5ê°œ ë‹¨ì–´ì˜ ì¸ë±ìŠ¤ë¥¼ ë½‘ëŠ” êµ¬ë¬¸
    top_words = [feature_names[i] for i in topic.argsort()[:-6:-1]]
    print(top_words)

# --- ê²°ê³¼ ì˜ˆì‹œ ---
# Topic 1:
# ['dogs', 'enjoy', 'long', 'walks', 'exploring']
# Topic 2:
# ['cats', 'purr', 'love', 'trees', 'mouse']
\end{lstlisting}

\begin{lstlisting}[language=Python, caption={Python scikit-learnì„ ì´ìš©í•œ NMF êµ¬í˜„}, label={lst:nmf_python}, breaklines=true]
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.decomposition import NMF

# ìƒ˜í”Œ ë¬¸ì„œ (ìœ„ì™€ ë™ì¼)
documents = [
    "Cats purr gently and climb high trees. Chasing a mouse is fun for cats.",
    # ... (ì¤‘ëµ) ...
    "Cats meow softly and purr when content, loving to stretch in the sun."
]

# 1. DTM ìƒì„±
vectorizer = CountVectorizer(stop_words='english')
X = vectorizer.fit_transform(documents)

# 2. NMF ëª¨ë¸ í•™ìŠµ (í† í”½ ê°œìˆ˜ K=2ë¡œ ì„¤ì •)
nmf_model = NMF(n_components=2, random_state=0, init='nndsvd')
# W: ë¬¸ì„œ-í† í”½ í–‰ë ¬, H: í† í”½-ë‹¨ì–´ í–‰ë ¬
W = nmf_model.fit_transform(X)
H = nmf_model.components_

# 3. ê²°ê³¼ ì¶œë ¥: í† í”½ë³„ ìƒìœ„ 5ê°œ ë‹¨ì–´
feature_names = vectorizer.get_feature_names_out()
for index, topic in enumerate(H):
    print(f"Topic {index + 1}:")
    top_words = [feature_names[i] for i in topic.argsort()[:-6:-1]]
    print(top_words)

# --- ê²°ê³¼ ì˜ˆì‹œ ---
# Topic 1:
# ['cats', 'purr', 'high', 'trees', 'climb']
# Topic 2:
# ['dogs', 'love', 'enjoy', 'humans', 'loyal']
\end{lstlisting}

\subsection{R (topicmodels) êµ¬í˜„ ì˜ˆì œ}
Rì—ì„œëŠ” \texttt{tm} íŒ¨í‚¤ì§€ë¡œ í…ìŠ¤íŠ¸ë¥¼ ì „ì²˜ë¦¬í•˜ê³ , \texttt{topicmodels} íŒ¨í‚¤ì§€ì˜ \texttt{LDA()} í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

\begin{lstlisting}[language=R, caption={Rì„ ì´ìš©í•œ LDA êµ¬í˜„}, label={lst:lda_r}, breaklines=true]
# install.packages("tm")
# install.packages("topicmodels")
library(tm)
library(topicmodels)

# ìƒ˜í”Œ ë¬¸ì„œ
documents <- c(
  "Cats purr gently and climb high trees. Chasing a mouse is fun for cats.",
  "Independent creatures, cats enjoy solitude and love their nap time.",
  "Dogs bark loudly at strangers and fetch sticks with enthusiasm.",
  "Loyal dogs accompany humans on hikes and love to chase balls.",
  "When the energetic dog spotted a squirrel, it barked energetically.",
  "A purring cat climbed the bookshelf, watching over the room.",
  "Regularly, dogs enjoy long walks, sniffing and exploring their environment.",
  "Cats meow softly and purr when content, loving to stretch in the sun."
)

# 1. í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (Corpus ìƒì„±)
corpus <- Corpus(VectorSource(documents))
corpus <- tm_map(corpus, content_transformer(tolower)) # ì†Œë¬¸ì
corpus <- tm_map(corpus, removePunctuation) # êµ¬ë‘ì 
corpus <- tm_map(corpus, removeNumbers) # ìˆ«ì
corpus <- tm_map(corpus, removeWords, stopwords("english")) # ë¶ˆìš©ì–´
corpus <- tm_map(corpus, stripWhitespace) # ê³µë°±

# 2. DTM ìƒì„±
dtm <- DocumentTermMatrix(corpus)

# 3. LDA ëª¨ë¸ í•™ìŠµ (K=2)
lda_model <- LDA(dtm, k = 2, control = list(seed = 1234))

# 4. ê²°ê³¼ ì¶œë ¥: í† í”½ë³„ ìƒìœ„ 5ê°œ ë‹¨ì–´
terms_lda <- terms(lda_model, 5)
print(terms_lda)

# --- ê²°ê³¼ ì˜ˆì‹œ ---
#      Topic 1      Topic 2   
# [1,] "dogs"       "cats"    
# [2,] "enjoy"      "purr"    
# [3,] "love"       "chasing" 
# [4,] "bark"       "climb"   
# [5,] "enthusiasm" "fun"
\end{lstlisting}

\begin{notebox}{ì°¸ê³ : R Markdown (.RMD)}
    R í™˜ê²½ì—ì„œëŠ” ì½”ë“œ, ì¶œë ¥ ê²°ê³¼, ì„¤ëª…ì„ í•˜ë‚˜ì˜ ë¬¸ì„œë¡œ í†µí•© ê´€ë¦¬í•  ìˆ˜ ìˆëŠ” \textbf{R Markdown (.RMD)} í˜•ì‹ì„ ìì£¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    ì´ëŠ” Python í™˜ê²½ì˜ Jupyter Notebookê³¼ ë§¤ìš° ìœ ì‚¬í•˜ë©°, \texttt{knit} ë²„íŠ¼ì„ ëˆŒëŸ¬ HTML, PDF, Word ë“± ì›í•˜ëŠ” í˜•ì‹ì˜ ë³´ê³ ì„œë¥¼ ì†ì‰½ê²Œ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
\end{notebox}


%================================
\newpage
\section{í† í”½ ëª¨ë¸ë§ ê²°ê³¼ í•´ì„ ë° í‰ê°€}
%================================
í† í”½ ëª¨ë¸ë§ì€ ë¹„ì§€ë„ í•™ìŠµì´ë¯€ë¡œ, ëª¨ë¸ì´ 'ì•Œì•„ì„œ' í† í”½ì„ ì°¾ì•„ì¤ë‹ˆë‹¤.
í•˜ì§€ë§Œ ì´ ê²°ê³¼ê°€ ìœ ìš©í•œì§€, ê·¸ë¦¬ê³  ê°€ì¥ ì¤‘ìš”í•œ ì§ˆë¬¸ì¸ \textbf{"ê·¸ë˜ì„œ í† í”½ ê°œìˆ˜(K)ë¥¼ ëª‡ ê°œë¡œ ì •í•´ì•¼ í•˜ëŠ”ê°€?"}ëŠ” ì „ì ìœ¼ë¡œ ë¶„ì„ê°€ì˜ ëª«ì…ë‹ˆë‹¤.

\subsection{í† í”½ í•´ì„í•˜ê¸° (Labeling)}
ëª¨ë¸ì€ 'í† í”½ 1', 'í† í”½ 2'ì™€ ê°™ì´ ë²ˆí˜¸ë§Œ ë¶€ì—¬í•©ë‹ˆë‹¤. ì´ í† í”½ì´ ì‹¤ì œë¡œ ë¬´ì—‡ì„ ì˜ë¯¸í•˜ëŠ”ì§€(ì˜ˆ: "ê°•ì•„ì§€ í† í”½") ë¼ë²¨ì„ ë¶™ì´ëŠ” ê²ƒì€ ì‚¬ëŒì´ í•´ì•¼ í•©ë‹ˆë‹¤. ë‘ ê°€ì§€ ë°©ë²•ì´ ì£¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.

\begin{notebox}{ë°©ë²• 1: í† í”½ë³„ ìƒìœ„ ë‹¨ì–´ í™•ì¸ (Top Words per Topic)}
    ê°€ì¥ ì§ê´€ì ì¸ ë°©ë²•ì…ë‹ˆë‹¤. ìœ„ ì½”ë“œ ì˜ˆì œì²˜ëŸ¼ ê° í† í”½ì„ êµ¬ì„±í•˜ëŠ” í™•ë¥ (ê°€ì¤‘ì¹˜)ì´ ë†’ì€ ìƒìœ„ ë‹¨ì–´ë“¤ì„ ì‚´í´ë´…ë‹ˆë‹¤.
    
    \textbf{ì˜ˆì‹œ:}
    \begin{itemize}
        \item \textbf{Topic 1:} 'dogs', 'walks', 'enjoy', 'bark', 'loyal' ...
        $\rightarrow$ \textit{í•´ì„:} 'ê°•ì•„ì§€' ê´€ë ¨ í† í”½
        \item \textbf{Topic 2:} 'cats', 'purr', 'climb', 'mouse', 'meow' ...
        $\rightarrow$ \textit{í•´ì„:} 'ê³ ì–‘ì´' ê´€ë ¨ í† í”½
    \end{itemize}
    \textbf{ë‹¨ì :} ë§Œì•½ ë¶ˆìš©ì–´ ì²˜ë¦¬ê°€ ë¯¸í¡í•˜ê±°ë‚˜ ì—¬ëŸ¬ ì£¼ì œì— ê³µí†µì ìœ¼ë¡œ ë“±ì¥í•˜ëŠ” ë‹¨ì–´(ì˜ˆ: 'love', 'enjoy')ê°€ ìƒìœ„ê¶Œì— ë‚˜ì˜¤ë©´ í† í”½ì˜ ì˜ë¯¸ë¥¼ íŒŒì•…í•˜ê¸° ëª¨í˜¸í•´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
\end{notebox}

\begin{notebox}{ë°©ë²• 2: í† í”½ë³„ ìƒìœ„ ë¬¸ì„œ í™•ì¸ (Top Documents per Topic)}
    ë”ìš± ê°•ë ¥í•˜ê³  ì •í™•í•œ ë°©ë²•ì…ë‹ˆë‹¤. ê° í† í”½ì´ \textbf{ê°€ì¥ ë†’ì€ ë¹„ìœ¨(Prevalence)}ë¡œ ë‚˜íƒ€ë‚œ ë¬¸ì„œë“¤ì„ ì§ì ‘ ì½ì–´ë³´ëŠ” ê²ƒì…ë‹ˆë‹¤.

    Pythonì—ì„œëŠ” \texttt{lda.transform(X)}ë¥¼ í†µí•´ ê° ë¬¸ì„œì˜ í† í”½ ë¶„í¬ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

    \textbf{ì˜ˆì‹œ:}
    \begin{itemize}
        \item (ë¬¸ì„œ 3) $\rightarrow$ [Topic 1: 93\%, Topic 2: 7\%]
        \item (ë¬¸ì„œ 7) $\rightarrow$ [Topic 1: 94\%, Topic 2: 6\%]
    \end{itemize}

    \textbf{í•´ì„:}
    'í† í”½ 1'ì˜ ë¹„ìœ¨ì´ 90\% ì´ìƒìœ¼ë¡œ ì••ë„ì ì¸ 'ë¬¸ì„œ 3'ê³¼ 'ë¬¸ì„œ 7'ì„ ì‹¤ì œë¡œ ì½ì–´ë´…ë‹ˆë‹¤.
    \begin{itemize}
        \item \textit{ë¬¸ì„œ 3 ë‚´ìš©:} "Dogs bark loudly at strangers..."
        \item \textit{ë¬¸ì„œ 7 ë‚´ìš©:} "Regularly, dogs enjoy long walks..."
    \end{itemize}
    $\rightarrow$ \textit{ìµœì¢… ê²°ë¡ :} ë‘ ë¬¸ì„œ ëª¨ë‘ 'ê°•ì•„ì§€'ì— ëŒ€í•´ ì´ì•¼ê¸°í•˜ë¯€ë¡œ, 'í† í”½ 1'ì€ \textbf{'ê°•ì•„ì§€' í† í”½}ì´ë¼ê³  í™•ì‹ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
\end{notebox}

\subsection{ìµœì ì˜ í† í”½ ê°œìˆ˜ (K) ê²°ì •í•˜ê¸°}
í† í”½ ê°œìˆ˜ $K$ëŠ” ëª¨ë¸ë§ ì„±ëŠ¥ì— ê°€ì¥ í° ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” \textbf{í•˜ì´í¼íŒŒë¼ë¯¸í„°}ì…ë‹ˆë‹¤. $K$ê°€ ë„ˆë¬´ ì‘ìœ¼ë©´ ì—¬ëŸ¬ ì£¼ì œê°€ í•˜ë‚˜ë¡œ ë­‰ê°œì§€ê³ , $K$ê°€ ë„ˆë¬´ í¬ë©´ í•˜ë‚˜ì˜ ì£¼ì œê°€ ì—¬ëŸ¬ ê°œë¡œ ë¶ˆí•„ìš”í•˜ê²Œ ìª¼ê°œì§‘ë‹ˆë‹¤.

ìµœì ì˜ $K$ë¥¼ ì°¾ê¸° ìœ„í•´ \textbf{ì‘ì§‘ë„(Coherence)}ì™€ \textbf{ë°°íƒ€ì„±(Exclusivity)}ì´ë¼ëŠ” ë‘ ê°€ì§€ í•µì‹¬ ì§€í‘œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

\begin{warnbox}{í•µì‹¬ í‰ê°€ ì§€í‘œ: ì‘ì§‘ë„(Coherence)ì™€ ë°°íƒ€ì„±(Exclusivity)}
    \textbf{1. ì‘ì§‘ë„ (Coherence)}
    \begin{itemize}
        \item \textbf{ì˜ë¯¸:} "í•˜ë‚˜ì˜ í† í”½ ë‚´ì— ìˆëŠ” ìƒìœ„ ë‹¨ì–´ë“¤ì´, ì‹¤ì œ ì›ë³¸ ë¬¸ì„œì—ì„œë„ \textbf{ìì£¼ í•¨ê»˜} ë“±ì¥í•˜ëŠ”ê°€?"
        \item \textbf{ì§ê´€:} ì¢‹ì€ í† í”½ì´ë¼ë©´ (ì˜ˆ: 'ë†êµ¬' í† í”½), ìƒìœ„ ë‹¨ì–´ì¸ 'ë†êµ¬', 'ì„ ìˆ˜', 'ì½”íŠ¸', 'ìŠ›'ì´ ì‹¤ì œ ë¬¸ì„œì—ì„œë„ ìì£¼ ê°™ì´ ë“±ì¥í•´ì•¼ í•©ë‹ˆë‹¤.
        \item \textbf{íŒë‹¨:} ë†’ì„ìˆ˜ë¡ ì¢‹ìŠµë‹ˆë‹¤.
    \end{itemize}

    \textbf{2. ë°°íƒ€ì„± (Exclusivity)}
    \begin{itemize}
        \item \textbf{ì˜ë¯¸:} "í•˜ë‚˜ì˜ í† í”½ì— ì†í•œ ìƒìœ„ ë‹¨ì–´ë“¤ì´, \textbf{ë‹¤ë¥¸ í† í”½}ë“¤ê³¼ ì–¼ë§ˆë‚˜ ê²¹ì¹˜ì§€ ì•Šê³  \textbf{ê³ ìœ }í•˜ê²Œ ì¡´ì¬í•˜ëŠ”ê°€?"
        \item \textbf{ì§ê´€:} 'ë†êµ¬' í† í”½ì˜ ìƒìœ„ ë‹¨ì–´ê°€ 'ì¶•êµ¬' í† í”½ì—ë„ ë˜‘ê°™ì´ ë‚˜íƒ€ë‚œë‹¤ë©´(ì˜ˆ: 'ì„ ìˆ˜', 'ê²½ê¸°'), ë‘ í† í”½ì€ ë³€ë³„ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.
        \item \textbf{íŒë‹¨:} ë†’ì„ìˆ˜ë¡ ì¢‹ìŠµë‹ˆë‹¤.
    \end{itemize}

    \textbf{The Trade-off (íŠ¸ë ˆì´ë“œì˜¤í”„):}
    ì•ˆíƒ€ê¹ê²Œë„ ë‘ ì§€í‘œëŠ” ì¢…ì¢… ë°˜ë¹„ë¡€ ê´€ê³„ì— ìˆìŠµë‹ˆë‹¤.
    \begin{itemize}
        \item $K$ê°€ ë„ˆë¬´ ì‘ìœ¼ë©´ (ì˜ˆ: $K=2$), í† í”½ì´ ë„ˆë¬´ ê´‘ë²”ìœ„í•´ì ¸ ì‘ì§‘ë„ëŠ” ë†’ì§€ë§Œ ë°°íƒ€ì„±ì´ ë‚®ì•„ì§‘ë‹ˆë‹¤. (ì˜ˆ: 'ìŠ¤í¬ì¸ ' í† í”½ í•˜ë‚˜)
        \item $K$ê°€ ë„ˆë¬´ í¬ë©´ (ì˜ˆ: $K=100$), í† í”½ì´ ë§¤ìš° ì„¸ë¶„í™”ë˜ì–´ ë°°íƒ€ì„±ì€ ë†’ì§€ë§Œ ì‘ì§‘ë„ê°€ ë‚®ì•„ì§‘ë‹ˆë‹¤. (ì˜ˆ: 'Aì„ ìˆ˜' í† í”½, 'Bì„ ìˆ˜' í† í”½)
    \end{itemize}

    \textbf{ìµœì ì˜ K ì°¾ê¸°:}
    ì¼ë°˜ì ìœ¼ë¡œ $K$ì˜ ê°’ì„ 2ë¶€í„° 50ê¹Œì§€(ì˜ˆ: 2, 5, 10, 15...) ë³€í™”ì‹œí‚¤ë©´ì„œ ì—¬ëŸ¬ ëª¨ë¸ì„ ì‹¤í–‰í•œ ë’¤, \textbf{ì‘ì§‘ë„(xì¶•)ì™€ ë°°íƒ€ì„±(yì¶•)ì„ 2D ê·¸ë˜í”„}ë¡œ ê·¸ë¦½ë‹ˆë‹¤.
    
    ë‘ ì§€í‘œê°€ ëª¨ë‘ 'ì ì ˆí•˜ê²Œ' ë†’ìœ¼ë©´ì„œ(ê·¸ë˜í”„ì˜ ìš°ì¸¡ ìƒë‹¨) ì•ˆì •í™”ë˜ëŠ” ì§€ì , ì¦‰ \textbf{'ì—˜ë³´ìš° í¬ì¸íŠ¸(Elbow Point)'}ì— í•´ë‹¹í•˜ëŠ” $K$ë¥¼ ìµœì ì˜ ê°’ìœ¼ë¡œ ì„ íƒí•©ë‹ˆë‹¤.
\end{warnbox}


%================================
\newpage
\section{ë‹¤ìŒ í•™ìŠµ: êµ¬ì¡°ì  í† í”½ ëª¨ë¸ë§ (STM)}
%================================
LDAëŠ” ê°•ë ¥í•˜ì§€ë§Œ, ì˜¤ì§ 'í…ìŠ¤íŠ¸ ë³¸ë¬¸'ë§Œì„ ì‚¬ìš©í•˜ì—¬ í† í”½ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
í•˜ì§€ë§Œ ì‹¤ì œë¡œëŠ” í…ìŠ¤íŠ¸ ì™¸ì— \textbf{ë©”íƒ€ë°ì´í„°(Metadata)}ê°€ í•¨ê»˜ ì£¼ì–´ì§€ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤.

\begin{itemize}
    \item ê¸°ì‚¬ (ë³¸ë¬¸ + ê¸°ì, ì‘ì„±ì¼, ì–¸ë¡ ì‚¬)
    \item ìƒí’ˆí‰ (ë³¸ë¬¸ + ì‚¬ìš©ì ì„±ë³„, ì—°ë ¹ëŒ€, í‰ì )
    \item êµìˆ˜ í‰ê°€ (ë³¸ë¬¸ + êµìˆ˜ ì„±ë³„, ê°œì„¤ í•™ê³¼, ê³¼ëª©)
\end{itemize}

\textbf{STM(Structural Topic Modeling, êµ¬ì¡°ì  í† í”½ ëª¨ë¸ë§)}ì€ LDAë¥¼ í™•ì¥í•˜ì—¬, ì´ëŸ¬í•œ \textbf{ë©”íƒ€ë°ì´í„°(Covariates, ê³µë³€ëŸ‰)}ê¹Œì§€ ëª¨ë¸ë§ì— í•¨ê»˜ í¬í•¨ì‹œí‚¤ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤. (ì£¼ë¡œ Rì˜ \texttt{stm} íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©)

\begin{notebox}{STM í™œìš© ì˜ˆì‹œ: êµìˆ˜ í‰ê°€ ë°ì´í„° ë¶„ì„}
    ì•½ 100ë§Œ ê±´ì˜ êµìˆ˜ í‰ê°€ í…ìŠ¤íŠ¸ì™€ ë©”íƒ€ë°ì´í„°(êµìˆ˜ ì„±ë³„, í•™ê³¼ ë“±)ë¥¼ STMìœ¼ë¡œ ë¶„ì„í•œ ì—°êµ¬ ì‚¬ë¡€ê°€ ìˆìŠµë‹ˆë‹¤.

    \textbf{ë¶„ì„:}
    LDAì²˜ëŸ¼ í…ìŠ¤íŠ¸ë§Œìœ¼ë¡œ í† í”½(ì˜ˆ: 'í¥ë¯¸ë¡œìš´ ê°•ì˜', 'ê³µì •í•œ í”¼ë“œë°±', 'ë°°ë ¤ì‹¬')ì„ ì¶”ì¶œí•  ë¿ë§Œ ì•„ë‹ˆë¼, ì´ í† í”½ë“¤ì´ \textbf{ë©”íƒ€ë°ì´í„°ì™€ ì–´ë–¤ ìƒê´€ê´€ê³„}ê°€ ìˆëŠ”ì§€ í•¨ê»˜ ë¶„ì„í•©ë‹ˆë‹¤.

    \textbf{ë°œê²¬ (ì˜ˆì‹œ):}
    \begin{itemize}
        \item \textbf{ì—¬ì„± êµìˆ˜}ì˜ í‰ê°€ëŠ” 'ë°°ë ¤ì‹¬(caring)', 'íš¨ê³¼ì ì¸ í† ë¡  ìœ ë„', 'ì‹œê¸°ì ì ˆí•œ í”¼ë“œë°±'ê³¼ ê°™ì€ í† í”½ì˜ ë¹„ì¤‘ì´ ë” ë†’ê²Œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.
        \item \textbf{ë‚¨ì„± êµìˆ˜}ì˜ í‰ê°€ëŠ” 'ìœ ë¨¸', 'í¥ë¯¸ë¡­ê³  ê´€ë ¨ì„± ë†’ì€ ê°•ì˜'ì™€ ê°™ì€ í† í”½ì˜ ë¹„ì¤‘ì´ ë” ë†’ê²Œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.
    \end{itemize}

    \textbf{ì˜ì˜:}
    ì´ëŸ¬í•œ ê²°ê³¼ëŠ” í•™ìƒë“¤ì´ êµìˆ˜ì˜ ì„±ë³„ì— ë”°ë¼ ê¸°ëŒ€í•˜ê±°ë‚˜ í‰ê°€í•˜ëŠ” ë°©ì‹ì— ì ì¬ì ì¸ í¸í–¥(bias)ì´ ì¡´ì¬í•  ìˆ˜ ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤. STMì€ ì´ì²˜ëŸ¼ í…ìŠ¤íŠ¸ì™€ êµ¬ì¡°ì  ë°ì´í„°ë¥¼ ê²°í•©í•˜ì—¬ í›¨ì”¬ ë” ê¹Šì´ ìˆëŠ” ì‚¬íšŒê³¼í•™ì  ë¶„ì„ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.
\end{notebox}


%================================
% APPENDICES
%================================
\newpage
\appendix
\section{ë¶€ë¡ A: ì£¼ìš” ìš©ì–´ ì •ë¦¬}

\begin{table}[h!]
\centering
\caption{ì£¼ìš” ìš©ì–´ ì •ë¦¬í‘œ}
\label{tab:glossary}
\begin{adjustbox}{width=\textwidth}
\begin{tabular}{@{}llll@{}}
\toprule
\textbf{ìš©ì–´} & \textbf{ì›ì–´} & \textbf{ì‰¬ìš´ ì„¤ëª…} & \textbf{ë¹„ê³ } \\ \midrule
\textbf{ì›-í•« ì¸ì½”ë”©} & One-Hot Encoding & ë‹¨ì–´ ì‚¬ì „ì— ìˆëŠ” ë‹¨ í•˜ë‚˜ì˜ ë‹¨ì–´ë§Œ 1ë¡œ, ë‚˜ë¨¸ì§€ëŠ” 0ìœ¼ë¡œ í‘œì‹œí•˜ëŠ” ë²¡í„°. & í¬ì†Œ(Sparse)í•˜ê³  ì°¨ì›ì´ ë†’ìŒ. \\
\textbf{ì˜¤í† ì¸ì½”ë”} & Autoencoder & ì…ë ¥ì„ ì €ì°¨ì›ìœ¼ë¡œ ì••ì¶•(Encoder)í–ˆë‹¤ê°€ ë‹¤ì‹œ ì›ë³¸ìœ¼ë¡œ ë³µì›(Decoder)í•˜ëŠ” ì‹ ê²½ë§. & ë¹„ì§€ë„ í•™ìŠµ. \\
\textbf{ë³‘ëª©} & Bottleneck & ì˜¤í† ì¸ì½”ë”ì—ì„œ ì°¨ì›ì´ ê°€ì¥ ë‚®ì€ ì€ë‹‰ì¸µ. ì…ë ¥ì˜ í•µì‹¬ íŠ¹ì§•ì´ ì••ì¶•ë¨. & Encoding Vectorê°€ ìƒì„±ë˜ëŠ” ê³³. \\
\textbf{ì–¸ë”ì»´í”Œë¦¬íŠ¸} & Undercomplete & ì…ë ¥ ì°¨ì›ë³´ë‹¤ ë³‘ëª©(í‘œí˜„) ì°¨ì›ì´ ë” ë‚®ì€ ìƒíƒœ. (ì˜ˆ: 100ì°¨ì› $\rightarrow$ 10ì°¨ì›) & ë°ì´í„° ì••ì¶•ì´ ëª©ì . \\
\textbf{ì ì¸µ ì˜¤í† ì¸ì½”ë”} & Stacked Autoencoder & ì€ë‹‰ì¸µì„ ì—¬ëŸ¬ ê°œ ê¹Šê²Œ ìŒ“ì€(Stacked) ì˜¤í† ì¸ì½”ë”. & Deep Network. \\
\textbf{í† í”½ ëª¨ë¸ë§} & Topic Modeling & ë¬¸ì„œ ì§‘í•©ì—ì„œ ìˆ¨ê²¨ì§„(Latent) ì£¼ì œ(Topic)ë¥¼ ì°¾ì•„ë‚´ëŠ” ë¹„ì§€ë„ í•™ìŠµ. & \\
\textbf{ì ì¬/ìˆ¨ê²¨ì§„} & Latent & ë°ì´í„°ì— ì§ì ‘ ë“œëŸ¬ë‚˜ì§€ ì•Šê³  ìˆ¨ì–´ìˆëŠ” ë³€ìˆ˜ë‚˜ êµ¬ì¡°. (ì˜ˆ: Latent Topic) & \\
\textbf{LDA} & Latent Dirichlet Allocation & 'ë¬¸ì„œëŠ” í† í”½ì˜ í˜¼í•©, í† í”½ì€ ë‹¨ì–´ì˜ í˜¼í•©'ì´ë¼ ê°€ì •í•˜ëŠ” ìƒì„± í™•ë¥  ëª¨ë¸. & í† í”½ ëª¨ë¸ë§ì˜ ëŒ€í‘œ ì£¼ì. \\
\textbf{NMF} & Non-Negative Matrix Factorization & ì›ë³¸ í–‰ë ¬(V)ì„ ë‘ ê°œì˜ ë¹„ìŒìˆ˜ í–‰ë ¬(W, H)ì˜ ê³±ìœ¼ë¡œ ë¶„í•´í•˜ëŠ” ê¸°ë²•. & $V \approx WH$. ëŒ€ìˆ˜ì  ì ‘ê·¼. \\
\textbf{ì‘ì§‘ë„} & Coherence & í† í”½ ë‚´ ìƒìœ„ ë‹¨ì–´ë“¤ì´ ì‹¤ì œ ë¬¸ì„œì—ì„œ ì–¼ë§ˆë‚˜ ìì£¼ í•¨ê»˜ ë“±ì¥í•˜ëŠ”ì§€ì— ëŒ€í•œ ì§€í‘œ. & ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ. \\
\textbf{ë°°íƒ€ì„±} & Exclusivity & í† í”½ ë‚´ ìƒìœ„ ë‹¨ì–´ë“¤ì´ ë‹¤ë¥¸ í† í”½ê³¼ ì–¼ë§ˆë‚˜ ê²¹ì¹˜ì§€ ì•ŠëŠ”ì§€ì— ëŒ€í•œ ì§€í‘œ. & ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ. \\
\textbf{STM} & Structural Topic Modeling & LDAì— ë©”íƒ€ë°ì´í„°(ì„±ë³„, ë‚ ì§œ ë“±)ë¥¼ ê²°í•©í•˜ì—¬ í† í”½ì„ ë¶„ì„í•˜ëŠ” í™•ì¥ ëª¨ë¸. & \\
\textbf{MLE} & Maximum Likelihood Estimation & ê´€ì°°ëœ ë°ì´í„°ë¥¼ ê°€ì¥ ì˜ ì„¤ëª…í•˜ëŠ”(ë“±ì¥ í™•ë¥ ì´ ìµœëŒ€ê°€ ë˜ëŠ”) íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ëŠ” ë°©ë²•. & \\ \bottomrule
\end{tabular}
\end{adjustbox}
\end{table}

\section{ë¶€ë¡ B: R ë° RStudio ì„¤ì¹˜ ê°€ì´ë“œ}
STM(êµ¬ì¡°ì  í† í”½ ëª¨ë¸ë§) ë“± ì¼ë¶€ ê³ ê¸‰ NLP íŒ¨í‚¤ì§€ëŠ” Pythonë³´ë‹¤ Rì—ì„œ ë” ì•ˆì •ì ìœ¼ë¡œ ì§€ì›ë©ë‹ˆë‹¤. Rì„ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ê¸°ë³¸ í™˜ê²½ ì„¤ì¹˜ ë‹¨ê³„ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

\begin{enumerate}
    \item \textbf{1ë‹¨ê³„: R (ì–¸ì–´ ë³¸ì²´) ì„¤ì¹˜}
    \begin{itemize}
        \item Rì€ í†µê³„ ê³„ì‚°ê³¼ ê·¸ë˜í”½ì„ ìœ„í•œ í”„ë¡œê·¸ë˜ë° 'ì–¸ì–´'ì´ì 'í™˜ê²½'ì…ë‹ˆë‹¤.
        \item ë¨¼ì € R ê³µì‹ ì›¹ì‚¬ì´íŠ¸(CRAN)ì— ì ‘ì†í•˜ì—¬ ë³¸ì¸ì˜ ìš´ì˜ì²´ì œ(Windows, Mac, Linux)ì— ë§ëŠ” Rì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ì„¤ì¹˜í•©ë‹ˆë‹¤.
        \item \url{https://www.r-project.org/}
    \end{itemize}
    
    \item \textbf{2ë‹¨ê³„: RStudio (IDE) ì„¤ì¹˜}
    \begin{itemize}
        \item RStudioëŠ” R ì–¸ì–´ë¥¼ ë” ì‰½ê³  í¸ë¦¬í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ëŠ” \textbf{í†µí•© ê°œë°œ í™˜ê²½(IDE)}ì…ë‹ˆë‹¤. (Pythonì˜ VS Codeë‚˜ PyCharmê³¼ ìœ ì‚¬)
        \item RStudioë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ë°˜ë“œì‹œ 1ë‹¨ê³„ì˜ Rì´ \textbf{ë¨¼ì €} ì„¤ì¹˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
        \item Posit (êµ¬ RStudio) ì›¹ì‚¬ì´íŠ¸ì—ì„œ RStudio Desktop (ë¬´ë£Œ ë²„ì „)ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ì„¤ì¹˜í•©ë‹ˆë‹¤.
        \item \url{https://posit.co/download/rstudio-desktop/}
    \end{itemize}
    
    \item \textbf{3ë‹¨ê³„: íŒ¨í‚¤ì§€ ì„¤ì¹˜}
    \begin{itemize}
        \item RStudioë¥¼ ì‹¤í–‰í•œ ë’¤, ì½˜ì†” ì°½ì— \texttt{install.packages("íŒ¨í‚¤ì§€ëª…")} ëª…ë ¹ì–´ë¥¼ ì…ë ¥í•˜ì—¬ í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.
        \item ì˜ˆ: \texttt{install.packages("topicmodels")}, \texttt{install.packages("stm")}
        \item ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ëŠ” \texttt{library(íŒ¨í‚¤ì§€ëª…)} ëª…ë ¹ì–´ë¡œ ì„¸ì…˜ì— ë¡œë“œí•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤.
    \end{itemize}
\end{enumerate}

\begin{notebox}{Cloud ë²„ì „ ì‚¬ìš©}
    ì„¤ì¹˜ê°€ ë²ˆê±°ë¡­ë‹¤ë©´, ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ ë°”ë¡œ Rì„ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” Posit Cloud (êµ¬ RStudio Cloud) ë²„ì „ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒë„ ì¢‹ì€ ëŒ€ì•ˆì…ë‹ˆë‹¤.
\end{notebox}

\section{ë¶€ë¡ C: 1í˜ì´ì§€ ìš”ì•½ (Quick Overview)}

\begin{notebox}{Autoencoder ë³µìŠµ}
    \begin{itemize}
        \item \textbf{One-Hot Encoding}ì€ í¬ì†Œì„±(Sparsity)ê³¼ ê³ ì°¨ì› ë¬¸ì œë¡œ ë¹„íš¨ìœ¨ì .
        \item \textbf{Autoencoder}ëŠ” ì…ë ¥ì„ ì €ì°¨ì›(Bottleneck)ìœ¼ë¡œ ì••ì¶•($\rightarrow$ Encoder)í–ˆë‹¤ê°€ ë³µì›($\rightarrow$ Decoder)í•˜ëŠ” ì‹ ê²½ë§.
        \item \textbf{í•µì‹¬ ëª©ì :} ì™„ë²½í•œ ë³µì›ì´ ì•„ë‹ˆë¼, ìœ ìš©í•œ \textbf{ì €ì°¨ì› í‘œí˜„(Encoding)}ì„ ì–»ëŠ” ê²ƒ.
        \item \textbf{Undercomplete:} ì…ë ¥ ì°¨ì› > ë³‘ëª© ì°¨ì›. (ê°€ì¥ ì¼ë°˜ì ì¸ í˜•íƒœ)
    \end{itemize}
\end{notebox}

\begin{notebox}{Topic Modeling ì´ë€?}
    \begin{itemize}
        \item \textbf{ì •ì˜:} ë¬¸ì„œ ì§‘í•©ì—ì„œ ìˆ¨ê²¨ì§„(Latent) ì£¼ì œë¥¼ ì°¾ëŠ” ë¹„ì§€ë„ í•™ìŠµ.
        \item \textbf{Clusteringê³¼ ì°¨ì´:} ë¬¸ì„œë¥¼ í•˜ë‚˜ì˜ ì£¼ì œë¡œ ë¶„ë¥˜í•˜ëŠ” ëŒ€ì‹  (Hard Assignment), \textbf{ì—¬ëŸ¬ í† í”½ì˜ í˜¼í•©(Mixture)}ìœ¼ë¡œ í‘œí˜„í•¨ (Soft Assignment).
        \item \textbf{ì˜ˆ:} "ì´ ë¬¸ì„œëŠ” [ì •ì¹˜ 70\%, ê²½ì œ 30\%]ì´ë‹¤."
    \end{itemize}
\end{notebox}

\begin{notebox}{LDA (Latent Dirichlet Allocation)}
    \begin{itemize}
        \item \textbf{ì ‘ê·¼:} \textbf{ìƒì„± í™•ë¥  ëª¨ë¸ (Probabilistic)}.
        \item \textbf{ê°€ì • 1:} ë¬¸ì„œëŠ” í† í”½ì˜ í™•ë¥  ë¶„í¬ ( $\theta \sim Dirichlet$ )
        \item \textbf{ê°€ì • 2:} í† í”½ì€ ë‹¨ì–´ì˜ í™•ë¥  ë¶„í¬ ( $\phi \sim Dirichlet$ )
        \item \textbf{ì¶”ì •:} MLE ë˜ëŠ” EM ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©.
        \item \textbf{ë‹¨ì :} í…ìŠ¤íŠ¸ ì™¸ì˜ ë©”íƒ€ë°ì´í„°(ì‘ì„±ì, ë‚ ì§œ ë“±)ë¥¼ ê³ ë ¤í•˜ì§€ ëª»í•¨.
    \end{itemize}
\end{notebox}

\begin{notebox}{NMF (Non-Negative Matrix Factorization)}
    \begin{itemize}
        \item \textbf{ì ‘ê·¼:} \textbf{í–‰ë ¬ ë¶„í•´ (Algebraic)}.
        \item \textbf{ê°€ì •:} $V \approx W \times H$
        \item $V$: [ë¬¸ì„œ $\times$ ë‹¨ì–´] ì›ë³¸ í–‰ë ¬
        \item $W$: [ë¬¸ì„œ $\times$ í† í”½] ê°€ì¤‘ì¹˜ í–‰ë ¬
        \item $H$: [í† í”½ $\times$ ë‹¨ì–´] ê°€ì¤‘ì¹˜ í–‰ë ¬
        \item \textbf{íŠ¹ì§•:} ëª¨ë“  í–‰ë ¬ì´ ë¹„ìŒìˆ˜(Non-Negative)ë¼ì„œ í•´ì„ì´ ì§ê´€ì ì„.
    \end{itemize}
\end{notebox}

\begin{notebox}{ëª¨ë¸ í‰ê°€ ë° ì„ íƒ (K ì •í•˜ê¸°)}
    \begin{itemize}
        \item \textbf{ë‚œê´€:} ìµœì ì˜ í† í”½ ê°œìˆ˜ $K$ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„°ì„.
        \item \textbf{ì§€í‘œ 1: ì‘ì§‘ë„ (Coherence):} í† í”½ ë‚´ ë‹¨ì–´ë“¤ì´ ì‹¤ì œë¡œ í•¨ê»˜ ìì£¼ ë“±ì¥í•˜ëŠ”ê°€? (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
        \item \textbf{ì§€í‘œ 2: ë°°íƒ€ì„± (Exclusivity):} í† í”½ ë‚´ ë‹¨ì–´ë“¤ì´ ë‹¤ë¥¸ í† í”½ê³¼ ê²¹ì¹˜ì§€ ì•ŠëŠ”ê°€? (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
        \item \textbf{ì„ íƒ:} ë‘ ì§€í‘œê°€ ëª¨ë‘ 'ì ì ˆíˆ' ë†’ì•„ì§€ëŠ” $K$ê°’ì„ ì„ íƒ (Trade-off ì¡´ì¬).
    \end{itemize}
\end{notebox}

\end{document}
