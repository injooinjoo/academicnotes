%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Harvard Academic Notes - 통합 마스터 템플릿
% 모든 강의 노트에 적용되는 통일된 스타일
% 버전: 2.1 - 가독성 개선 (선택적 최적화)
% 최종 수정일: 2025-11-17
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[11pt,a4paper]{article}

%========================================================================================
% 기본 패키지
%========================================================================================

% --- 한국어 지원 ---
\usepackage{kotex}

% --- 페이지 레이아웃 ---
\usepackage[top=20mm, bottom=20mm, left=20mm, right=18mm]{geometry}
\usepackage{setspace}
\onehalfspacing                      % 1.5배 줄간격
\setlength{\parskip}{0.5em}          % 문단 간격
\setlength{\parindent}{0pt}          % 들여쓰기 없음

% --- 표 관련 ---
\usepackage{booktabs}              % 고품질 표
\usepackage{tabularx}              % 자동 너비 조절 표
\usepackage{array}                 % 표 컬럼 확장
\usepackage{longtable}             % 여러 페이지 표
\renewcommand{\arraystretch}{1.1}  % 표 행간 조절

%========================================================================================
% 헤더 및 푸터
%========================================================================================

\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\small\textit{CS109A: 데이터 과학 입문}}
\fancyhead[R]{\small\textit{Lecture 20}}
\fancyfoot[C]{\thepage}
\renewcommand{\headrulewidth}{0.5pt}
\renewcommand{\footrulewidth}{0.3pt}

% 첫 페이지는 헤더 없음
\fancypagestyle{firstpage}{
    \fancyhf{}
    \fancyfoot[C]{\thepage}
    \renewcommand{\headrulewidth}{0pt}
}

%========================================================================================
% 색상 정의 (파스텔 톤 + 다크모드 호환)
%========================================================================================

\usepackage[dvipsnames]{xcolor}

% 밝은 배경용 파스텔 색상
\definecolor{lightblue}{RGB}{220, 235, 255}      % 부드러운 파랑
\definecolor{lightgreen}{RGB}{220, 255, 235}     % 부드러운 초록
\definecolor{lightyellow}{RGB}{255, 250, 220}    % 부드러운 노랑
\definecolor{lightpurple}{RGB}{240, 230, 255}    % 부드러운 보라
\definecolor{lightgray}{gray}{0.95}              % 밝은 회색
\definecolor{lightpink}{RGB}{255, 235, 245}      % 부드러운 핑크
\definecolor{boxgray}{gray}{0.95}
\definecolor{boxblue}{rgb}{0.9, 0.95, 1.0}
\definecolor{boxred}{rgb}{1.0, 0.95, 0.95}

% 진한 색상 (테두리/제목용)
\definecolor{darkblue}{RGB}{50, 80, 150}
\definecolor{darkgreen}{RGB}{40, 120, 70}
\definecolor{darkorange}{RGB}{200, 100, 30}
\definecolor{darkpurple}{RGB}{100, 60, 150}

%========================================================================================
% 박스 환경 (tcolorbox) - 6가지 타입
%========================================================================================

\usepackage[most]{tcolorbox}
\tcbuselibrary{skins, breakable}

% 1. 개요 박스 (강의 시작 부분)
\newtcolorbox{overviewbox}[1][]{
    enhanced,
    colback=lightpurple,
    colframe=darkpurple,
    fonttitle=\bfseries\large,
    title=📚 강의 개요,
    arc=3mm,
    boxrule=1pt,
    left=8pt,
    right=8pt,
    top=8pt,
    bottom=8pt,
    breakable,
    #1
}

% 2. 요약 박스
\newtcolorbox{summarybox}[1][]{
    enhanced,
    colback=lightblue,
    colframe=darkblue,
    fonttitle=\bfseries,
    title=📝 핵심 요약,
    arc=2mm,
    boxrule=0.7pt,
    left=6pt,
    right=6pt,
    top=6pt,
    bottom=6pt,
    breakable,
    #1
}

% 3. 핵심 정보 박스
\newtcolorbox{infobox}[1][]{
    enhanced,
    colback=lightgreen,
    colframe=darkgreen,
    fonttitle=\bfseries,
    title=💡 핵심 정보,
    arc=2mm,
    boxrule=0.7pt,
    left=6pt,
    right=6pt,
    top=6pt,
    bottom=6pt,
    breakable,
    #1
}

% 4. 주의사항 박스
\newtcolorbox{warningbox}[1][]{
    enhanced,
    colback=lightyellow,
    colframe=darkorange,
    fonttitle=\bfseries,
    title=⚠️ 주의사항,
    arc=2mm,
    boxrule=0.7pt,
    left=6pt,
    right=6pt,
    top=6pt,
    bottom=6pt,
    breakable,
    #1
}

% 5. 예제 박스
\newtcolorbox{examplebox}[1][]{
    enhanced,
    colback=lightgray,
    colframe=black!60,
    fonttitle=\bfseries,
    title=📖 예제: #1,
    arc=2mm,
    boxrule=0.7pt,
    left=6pt,
    right=6pt,
    top=6pt,
    bottom=6pt,
    breakable,
}

% 6. 정의 박스
\newtcolorbox{definitionbox}[1][]{
    enhanced,
    colback=lightpink,
    colframe=purple!70!black,
    fonttitle=\bfseries,
    title=📌 정의: #1,
    arc=2mm,
    boxrule=0.7pt,
    left=6pt,
    right=6pt,
    top=6pt,
    bottom=6pt,
    breakable,
}

% 7. 중요 박스 (importantbox - warningbox와 유사)
\newtcolorbox{importantbox}[1][]{
    enhanced,
    colback=boxred,
    colframe=red!70!black,
    fonttitle=\bfseries,
    title=⚠️ 매우 중요: #1,
    arc=2mm,
    boxrule=0.7pt,
    left=6pt,
    right=6pt,
    top=6pt,
    bottom=6pt,
    breakable,
}

% 8. cautionbox (warningbox와 동일)
\let\cautionbox\warningbox
\let\endcautionbox\endwarningbox

%========================================================================================
% 코드 블록 설정 (밝은 배경)
%========================================================================================

\usepackage{listings}

\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.95}

\lstset{
    basicstyle=\ttfamily\small,
    backgroundcolor=\color{lightgray},
    keywordstyle=\color{darkblue}\bfseries,
    commentstyle=\color{darkgreen}\itshape,
    stringstyle=\color{purple!80!black},
    numberstyle=\tiny\color{black!60},
    numbers=left,
    numbersep=8pt,
    breaklines=true,
    breakatwhitespace=false,
    frame=single,
    frameround=tttt,
    rulecolor=\color{black!30},
    captionpos=b,
    showstringspaces=false,
    tabsize=2,
    xleftmargin=15pt,
    xrightmargin=5pt,
    escapeinside={\%*}{*)}
}

% Python 코드 스타일
\lstdefinestyle{pythonstyle}{
    language=Python,
    morekeywords={self, True, False, None},
}

% SQL 코드 스타일
\lstdefinestyle{sqlstyle}{
    language=SQL,
    morekeywords={SELECT, FROM, WHERE, JOIN, GROUP, BY, ORDER, HAVING},
}

%========================================================================================
% 목차 스타일링
%========================================================================================

\usepackage{tocloft}
\renewcommand{\cftsecleader}{\cftdotfill{\cftdotsep}}
\setlength{\cftbeforesecskip}{0.4em}
\renewcommand{\cftsecfont}{\bfseries}
\renewcommand{\cftsubsecfont}{\normalfont}

%========================================================================================
% 표 및 그림
%========================================================================================

\usepackage{graphicx}              % 이미지
\usepackage{adjustbox}             % 표/박스 크기 조절

% 표 캡션 스타일
\usepackage{caption}
\captionsetup[table]{
    labelfont=bf,
    textfont=it,
    skip=5pt
}
\captionsetup[figure]{
    labelfont=bf,
    textfont=it,
    skip=5pt
}

%========================================================================================
% 수학
%========================================================================================

\usepackage{amsmath, amssymb, amsthm}

% 정리 환경
\theoremstyle{definition}
\newtheorem{theorem}{정리}[section]
\newtheorem{lemma}[theorem]{보조정리}
\newtheorem{proposition}[theorem]{명제}
\newtheorem{corollary}[theorem]{따름정리}
\newtheorem{definition}{정의}[section]
\newtheorem{example}{예제}[section]

%========================================================================================
% 하이퍼링크
%========================================================================================

\usepackage[
    colorlinks=true,
    linkcolor=blue!80!black,
    urlcolor=blue!80!black,
    citecolor=green!60!black,
    bookmarks=true,
    bookmarksnumbered=true,
    pdfborder={0 0 0}
]{hyperref}

% PDF 메타데이터는 각 문서에서 설정
\hypersetup{
    pdftitle={CS109A: 데이터 과학 입문 - Lecture 20},
    pdfauthor={강의 노트},
    pdfsubject={Academic Notes}
}

%========================================================================================
% 기타 유용한 패키지
%========================================================================================

\usepackage{enumitem}              % 리스트 커스터마이징
\setlist{nosep, leftmargin=*, itemsep=0.3em}

\usepackage{microtype}             % 타이포그래피 개선
\usepackage{footnote}              % 각주 개선
\usepackage{url}                   % URL 줄바꿈
\urlstyle{same}

%========================================================================================
% 사용자 정의 명령어
%========================================================================================

% 강조 텍스트
\newcommand{\important}[1]{\textbf{\textcolor{red!70!black}{#1}}}
\newcommand{\keyword}[1]{\textbf{#1}}
\newcommand{\term}[1]{\textit{#1}}
\newcommand{\code}[1]{\texttt{#1}}

% 용어 설명 (인라인)
\newcommand{\defterm}[2]{\textbf{#1}\footnote{#2}}

% 섹션 시작 전 페이지 분리
\newcommand{\newsection}[1]{\newpage\section{#1}}

%========================================================================================
% 문서 제목 스타일
%========================================================================================

\usepackage{titling}
\pretitle{\begin{center}\LARGE\bfseries}
\posttitle{\par\end{center}\vskip 0.5em}
\preauthor{\begin{center}\large}
\postauthor{\end{center}}
\predate{\begin{center}\large}
\postdate{\par\end{center}}

%========================================================================================
% 섹션 제목 간격
%========================================================================================

\usepackage{titlesec}
\titlespacing*{\section}{0pt}{1.5em}{0.8em}
\titlespacing*{\subsection}{0pt}{1.2em}{0.6em}
\titlespacing*{\subsubsection}{0pt}{1em}{0.5em}

%========================================================================================
% 메타 정보 박스 명령어
%========================================================================================

\newcommand{\metainfo}[4]{
\begin{tcolorbox}[
    colback=lightpurple,
    colframe=darkpurple,
    boxrule=1pt,
    arc=2mm,
    left=10pt,
    right=10pt,
    top=8pt,
    bottom=8pt
]
\begin{tabular}{@{}rl@{}}
▣ \textbf{강의명:} & #1 \\[0.3em]
▣ \textbf{주차:} & #2 \\[0.3em]
▣ \textbf{교수명:} & #3 \\[0.3em]
▣ \textbf{목적:} & \begin{minipage}[t]{0.75\textwidth}#4\end{minipage}
\end{tabular}
\end{tcolorbox}
}

%========================================================================================
% 끝
%========================================================================================


\begin{document}

\maketitle
\thispagestyle{firstpage}

\metainfo{CS109A: 데이터 과학 입문}{Lecture 20}{Pavlos Protopapas, Kevin Rader, Chris Gumb}{Lecture 20의 핵심 개념 학습}


\tableofcontents
\newpage




\begin{summarybox}
이 문서는 데이터 분석의 두 가지 큰 장애물인 \textbf{결측치(Missingness)}와 \textbf{블랙박스 모델(Black Box Models)}을 다루는 방법을 설명합니다.

1.  \textbf{결측치 처리:} 데이터에 구멍(NaN)이 있을 때 발생하는 문제를 이해하고, 단순 삭제나 평균값 대체의 위험성(편향)을 배웁니다. MCAR, MAR, MNAR이라는 세 가지 결측 유형을 구분하고, '결측치 표시자'나 '모델 기반 대체' (특히, 불확실성을 고려한 대체)와 같은 고급 기법들을 살펴봅니다.
2.  \textbf{모델 시각화:} k-NN이나 의사결정나무처럼 해석이 어려운 '블랙박스' 모델의 작동 방식을 이해하기 위해 \textbf{부분 의존성 플롯(Partial Dependence Plots, PDP)}을 사용하는 방법을 배웁니다. PDP를 통해 특정 변수가 모델의 예측에 어떤 영향을 미치는지, 변수 간 상호작용은 없는지 시각적으로 확인할 수 있습니다.
\end{summarybox}

\newpage

%===================================
\section{용어 정리}
%===================================

주요 용어들을 표로 정리했습니다.

\begin{table}[h!]
    \centering
    \begin{adjustbox}{width=\textwidth}
        \begin{tabular}{@{}llp{6cm}l@{}}
            \toprule
            용어 & 원어 & 쉬운 설명 & 비고 \\
            \midrule
            결측치 & Missingness & 데이터셋에 값이 누락된 '구멍'이 있는 상태 또는 그 값. & \texttt{NaN} (Not a Number)로 표시됨. \\
            편향 & Bias & 모델의 예측이나 추정치가 체계적으로 한쪽으로 치우치는 경향. & 예: 저울이 항상 500g 높게 측정하는 것. \\
            대체 (대치) & Imputation & 누락된 결측치를 추정된 값으로 채워 넣는 과정. & 가장 간단한 예는 '평균값'으로 채우기. \\
            \midrule
            MCAR & Missing Completely at Random & \textbf{완전 임의 결측.} 결측이 다른 어떤 변수와도 상관없이 무작위로 발생. & (예: 데이터 입력 중 무작위 오타) \\
            MAR & Missing at Random & \textbf{임의 결측.} 결측 여부가 *다른 관측된* 변수와 관련 있음. & (예: 남성이 여성보다 '소득' 문항 응답률이 낮음) \\
            MNAR & Missing Not at Random & \textbf{비임의 결측.} 결측 여부가 *누락된 값 자체* 또는 *관측되지 않은* 변수와 관련 있음. & (예: 고소득자가 '소득' 문항 응답을 거부함) \\
            \midrule
            블랙박스 모델 & Black Box Model & 모델의 내부 작동 원리를 이해하기 어려운 복잡한 모델. & 예: k-NN, 랜덤 포레스트, 딥러닝 \\
            PDP & Partial Dependence Plot & \textbf{부분 의존성 플롯.} 다른 변수들을 고정한 채, 특정 변수 하나가 모델 예측에 미치는 영향을 보여주는 그래프. & 모델 해석의 핵심 도구. \\
            \bottomrule
        \end{tabular}
    \end{adjustbox}
    \caption{결측치 및 모델 해석 관련 핵심 용어}
    \label{tab:terms}
\end{table}

\newpage

%===================================
\section{결측치(Missingness)란 무엇인가?}
%===================================

%-----------------------------------
\subsection{결측치의 정의와 문제점}
%-----------------------------------

\textbf{결측치(Missingness)}란 데이터셋에 값이 존재하지 않는 '구멍'이 있는 것을 의미합니다. Pandas에서는 주로 \texttt{NaN} (Not a Number)로 표시됩니다.

데이터에 결측치가 있으면 두 가지 큰 문제가 발생합니다.

1.  \textbf{모델 학습 불가:} 대부분의 머신러닝 라이브러리(예: \texttt{sklearn})는 데이터에 \texttt{NaN} 값이 하나라도 포함되어 있으면 오류를 발생시키며 모델 학습을 거부합니다.
2.  \textbf{심각한 편향(Bias) 발생:} 결측치를 처리하기 위해 순진한 방법을 사용하면, 모델이 현실을 체계적으로 잘못 예측하는 '편향'이 발생할 수 있습니다.

\begin{warningbox}
\textbf{편향(Bias)이란?}

    편향은 모델의 예측이 지속적으로 한쪽으로 치우치는 것입니다.

    * \textbf{직관적 예시:} 어떤 저울이 항상 실제 무게보다 1kg을 더 높게 보여준다면, 이 저울은 '편향'되어 있습니다. 몇 번을 측정하든 항상 1kg 높은 값이 나옵니다.
    * \textbf{데이터 예시:} 결측치를 단순히 '0'으로 채웠다고 가정해봅시다. 만약 '0'이라는 값이 실제 데이터에서는 매우 드문 값이라면, 모델은 '0'이라는 값을 과도하게 학습하여 현실과 동떨어진 예측을 하게 될 수 있습니다.
\end{warningbox}

%-----------------------------------
\subsection{결측치 처리의 순진한 접근법 (과 그 위험성)}
%-----------------------------------

결측치를 만났을 때 가장 먼저 떠올리는 간단한 두 가지 방법과 그 위험성은 다음과 같습니다.

1.  \textbf{관측치(행) 삭제:} 결측치가 하나라도 있는 행(row)을 모두 삭제합니다.
    * \textbf{위험성:} 만약 결측치가 무작위로 발생한 것이 아니라 특정 그룹(예: 특정 연령대)에서만 집중적으로 발생했다면, 해당 그룹의 데이터가 통째로 사라집EBF니다. 이는 모델이 해당 그룹을 아예 학습하지 못하게 만들어 심각한 편향을 유발합니다.
2.  \textbf{단순 값 대체 (Mean/Median/Mode):}
    * \textbf{수치형 변수:} 전체 데이터의 '평균(mean)'이나 '중앙값(median)'으로 모든 \texttt{NaN}을 채웁니다.
    * \textbf{범주형 변수:} 가장 빈번하게 등장한 '최빈값(mode)'으로 모든 \texttt{NaN}을 채웁니다.
    * \textbf{위험성:} 모든 결측치에 똑같은 값을 넣으면, 해당 값 주변에 데이터가 비정상적으로 몰리게 됩니다. 이는 데이터의 실제 분포를 왜곡하며, 변수 간의 관계를 약화시키거나 왜곡시킵니다.

이러한 순진한 방법들은 데이터의 귀중한 정보를 손실시키고 편향을 유발하므로, 왜 결측치가 발생했는지 먼저 파악하는 것이 중요합니다.

\newpage

%===================================
\section{결측의 3가지 유형 (MCAR, MAR, MNAR)}
%===================================

결측치를 제대로 처리하기 위해서는 결측치가 "왜" 발생했는지 그 원인을 파악해야 합니다. 통계학에서는 이 원인을 세 가지 유형으로 분류합니다.

%-----------------------------------
\subsection{1. MCAR (Missing Completely at Random, 완전 임의 결측)}
%-----------------------------------

\textbf{"결측이 완전히 무작위로 발생했다"}는 의미입니다.

이는 결측 여부가 데이터셋의 그 어떤 변수(관측된 변수, 누락된 변수)와도 아무런 관련이 없는 경우입니다.

* \textbf{비유:} 설문지 데이터를 엑셀에 입력하다가, 직원이 피곤해서 아무 데나 랜덤하게 몇 개를 빠뜨리고 입력한 상황입니다.
* \textbf{특징:} 가장 이상적이고 다루기 쉬운 케이스입니다.
* \textbf{처리:} 데이터가 충분히 많다면, MCAR인 경우는 결측치가 있는 행을 삭제해도 편향이 발생하지 않습니다. (단, 데이터 손실은 감수해야 함)

%-----------------------------------
\subsection{2. MAR (Missing at Random, 임의 결측)}
%-----------------------------------

\textbf{"결측 여부가 \textit{관측된 다른 변수}와 관련이 있다"}는 의미입니다.

결측이 발생한 변수(\(X_1\)) 자체와는 관련이 없지만, 우리가 관측할 수 있는 다른 변수(\(X_2\))와는 관련이 있는 경우입니다.

* \textbf{예시:} 직장 내 괴롭힘에 대한 설문조사에서 '괴롭힘 경험' 문항에 결측치가 많습니다. 이 결측 여부가 '괴롭힘 경험' 자체와는 관련이 없을 수 있지만, '성별' 변수와는 관련이 있을 수 있습니다. (예: 남성이 여성보다 해당 문항 응답을 더 꺼림)
* \textbf{특징:} '성별'이라는 관측된 변수를 활용하면 결측의 패턴을 설명할 수 있습니다.
* \textbf{처리:} 모델링을 통해 결측치를 잘 처리할 수 있습니다. (예: 성별을 예측 변수로 사용하여 결측치 대체 모델 생성)

%-----------------------------------
\subsection{3. MNAR (Missing Not at Random, 비임의 결측)}
%-----------------------------------

\textbf{"결측 여부가 \textit{누락된 값 자체} 또는 \textit{관측되지 않은 변수}와 관련이 있다"}는 의미입니다.

* \textbf{예시 1 (누락된 값 자체):} '소득' 설문에서, 고소득자일수록 자신의 소득을 밝히기 꺼려 해서 응답을 하지 않는 경우. 즉, '소득'이라는 값 자체가 높을수록 결측이 될 확률이 높습니다.
* \textbf{예시 2 (관측되지 않은 변수):} 임상시험에서 부작용이 심한 환자들이(관측되지 않은 '부작용' 변수) 시험을 중도 포기하여(결과값 결측) 데이터에서 누락되는 경우.
* \textbf{특징:} 가장 다루기 어렵고 심각한 편향을 유발합니다. 우리가 그 이유를 알 수 없기 때문입니다.
* \textbf{처리:} 통계적으로 완벽하게 해결하기 매우 어렵습니다.

\begin{warningbox}
    \textbf{Q: 내 데이터가 어떤 유형인지 어떻게 알 수 있나요?}

    \textbf{A: 알 수 없습니다.}

    안타깝게도 우리는 데이터만 보고 이 결측치가 MCAR, MAR, MNAR 중 무엇인지 통계적으로 완벽하게 증명할 수 없습니다. MNAR은 "관측되지 않은" 변수에 의해 발생할 수 있기 때문입니다.

    따라서 데이터 분석가들은 \textbf{"우리의 데이터가 최소한 MAR이라고 가정하고, 관측된 다른 변수들을 최대한 활용하여 결측치를 모델링하자"}라는 실용적인 접근 방식을 취합니다.
\end{warningbox}

\begin{table}[h!]
    \centering
    \begin{tabular}{@{}llll@{}}
        \toprule
        특징 & MCAR (완전 임의 결측) & MAR (임의 결측) & MNAR (비임의 결측) \\
        \midrule
        결측 원인 & 완전 무작위 & \textbf{관측된} 다른 변수 & \textbf{누락된 값 자체} 또는 \textbf{숨겨진} 변수 \\
        예시 & 데이터 입력 실수 & 성별에 따라 소득 응답률 다름 & 고소득자가 소득 응답 거부 \\
        해결 난이도 & 쉬움 (삭제 가능) & 중간 (모델링으로 해결 가능) & 매우 어려움 (편향 피하기 힘듦) \\
        \bottomrule
    \end{tabular}
    \caption{결측 3유형 비교}
    \label{tab:mar_types}
\end{table}

\newpage

%===================================
\section{결측치 처리(Imputation) 방법론}
%===================================

결측치를 단순히 삭제하거나 평균값으로 채우는 대신, 더 정교한 방법들을 사용해야 합니다.

%-----------------------------------
\subsection{처리 전 고려사항}
%-----------------------------------

1.  \textbf{결측치가 어디에 있는가? (Y vs X)}
    * \textbf{예측 변수(X)에 결측:} 대부분의 처리 기법이 여기에 초점을 맞춥니다.
    * \textbf{반응 변수(Y)에 결측:} 매우 다루기 어렵습니다. Y값을 예측하는 것이 모델의 최종 목표인데, 그 Y값이 없기 때문입니다. 이 경우 해당 행을 삭제하는 것이 일반적입니다.
2.  \textbf{변수 유형 (수치형 vs 범주형):} 처리 방법이 달라집니다. (예: 수치형은 k-NN, 범주형은 로지스틱 회귀)
3.  \textbf{결측량 (Amount):} 만약 특정 변수가 60\% 이상 결측치라면, 이 변수를 대체하는 것은 오히려 새로운 노이즈를 만드는 것일 수 있습니다. 이 경우 해당 변수(열)를 삭제하는 것을 고려할 수 있습니다.

%-----------------------------------
\subsection{방법 1: 결측치 표시자 변수 (Missingness Indicator)}
%-----------------------------------

이 방법은 결측치가 발생했다는 '사실 자체'가 중요한 정보를 담고 있을 수 있다고 가정합니다. (특히 MNAR의 경우에 유용)

* \textbf{아이디어:} "응답 거부"라는 제3의 그룹을 만듭니다.
* \textbf{방법:}
    1.  결측치가 있는 변수 \(X_1\)을 복사하여 두 개의 변수를 만듭니다.
    2.  \(X_1^*\) (대체 변수): \(X_1\)의 결측치를 0이나 평균 등 특정 값으로 모두 대체합니다.
    3.  \(X_{1,miss}\) (표시자 변수): \(X_1\)에서 값이 누락되었으면 1, 아니면 0을 갖는 이진(binary) 변수를 만듭니다.
    4.  모델을 학습시킬 때, 원래 변수인 \(X_1\) 대신 이 두 변수(\(X_1^*\)와 \(X_{1,miss}\))를 함께 사용합니다.

\begin{examplebox}{예제}
    \textbf{예시: 결측치 표시자 변수 생성}

    아래 표는 \texttt{X1}과 \texttt{X2}의 결측치를 0으로 대체하고, 결측 여부를 \texttt{X1\_miss}, \texttt{X2\_miss}로 표시한 예입니다.
    \begin{table}[h!]
        \centering
        \begin{adjustbox}{width=\textwidth}
            \begin{tabular}{@{}cc|cc|cc@{}}
                \toprule
                \multicolumn{2}{c}{원본 데이터} & \multicolumn{2}{c}{1. 값 대체 (\(X^*\))} & \multicolumn{2}{c}{2. 표시자 생성 (\(X_{miss}\))} \\
                \cmidrule(r){1-2} \cmidrule(r){3-4} \cmidrule(r){5-6}
                X1 & X2 & X1* & X2* & X1\_miss & X2\_miss \\
                \midrule
                10 & 0 & 10 & 0 & 0 & 0 \\
                5 & 1 & 5 & 1 & 0 & 0 \\
                21 & \textbf{NaN} & 21 & \textbf{0} & 0 & \textbf{1} \\
                15 & 0 & 15 & 0 & 0 & 0 \\
                16 & \textbf{NaN} & 16 & \textbf{0} & 0 & \textbf{1} \\
                \textbf{NaN} & 0 & \textbf{0} & 0 & \textbf{1} & 0 \\
                21 & 1 & 21 & 1 & 0 & 0 \\
                12 & \textbf{NaN} & 12 & \textbf{0} & 0 & \textbf{1} \\
                \textbf{NaN} & 1 & \textbf{0} & 1 & \textbf{1} & 0 \\
                \bottomrule
            \end{tabular}
        \end{adjustbox}
        \caption{결측치 표시자 변수 생성 과정}
        \label{tab:indicator}
    \end{table}

    이제 모델은 \(X_1^*\)와 \(X_{1,miss}\)를 보고, 'X1\_miss가 1일 때(즉, X1이 누락되었을 때)'는 \(X_1^*\)의 0을 '관측된 0'과 다르게 취급할 수 있게 됩니다.
\end{examplebox}

%-----------------------------------
\subsection{방법 2: 모델 기반 대체 (Model-based Imputation)}
%-----------------------------------

결측치를 '예측' 문제로 접근하는 방식입니다.

* \textbf{아이디어:} \(X_1\) 변수에 결측치가 있다면, 나머지 관측된 변수들(\(X_2, X_3, ...\))을 독립 변수로, \(X_1\)을 종속 변수로 하는 예측 모델을 만듭니다.
* \textbf{절차:}
    1.  데이터를 두 그룹으로 나눕니다.
        * \textbf{학습용(Train):} \(X_1\)이 관측된 모든 행.
        * \textbf{예측용(Test):} \(X_1\)이 누락된 모든 행.
    2.  학습용 데이터로 \(X_2, X_3, ... \to X_1\)을 예측하는 모델(예: k-NN, 선형 회귀, 의사결정나무)을 학습시킵니다.
    3.  학습된 모델을 예측용 데이터에 적용하여, 누락된 \(X_1\) 값을 예측하고 그 값으로 채워 넣습니다.

\begin{examplebox}{예제}
    \textbf{예시: k-NN을 사용한 대체}

    색깔(X, 관측됨)을 이용해 Y값(결측 존재)을 대체해봅시다. (k=2, 즉 가장 가까운 2개 사용)

    \textit{[참고 이미지: k-NN 대체 시각화 - 색깔 기반으로 가장 가까운 2개 이웃의 평균값 사용]}
    * \textbf{첫 번째 물음표 (?):} 색깔이 '중간 빨강'입니다. 가장 가까운 2개는 '진한 빨강'(Y=1)과 '밝은 빨강'(Y=0.5)입니다.
    * \textbf{대체:} 두 값의 평균인 \((1 + 0.5) / 2 = 0.75\)를 채워 넣습니다.
    * \textbf{두 번째 물음표 (?):} 색깔이 '노랑'입니다. 가장 가까운 2개는 '주황'(Y=0.1)과 '연두'(Y=10)입니다.
    * \textbf{대체:} 두 값의 평균인 \((0.1 + 10) / 2 = 5.05\)를 채워 넣습니다.
\end{examplebox}

%-----------------------------------
\subsection{방법 3: 불확실성을 고려한 모델 기반 대체}
%-----------------------------------

위의 '모델 기반 대체'는 한 가지 큰 문제점을 가집니다. 바로 \textbf{"너무 완벽한"} 값을 채워 넣는다는 것입니다.

\begin{warningbox}
    \textbf{결정론적 대체(Deterministic Imputation)의 함정}

    선형 회귀 모델로 결측치를 대체한다고 상상해봅시다. 예측된 값들은 모두 회귀선 \textit{위에} 완벽하게 놓이게 됩니다. (아래 그림의 왼쪽)

    하지만 실제 데이터는 어떻습니까? 항상 회귀선 주변에 흩어져 있습니다. (아래 그림의 오른쪽, 회색 점)

    만약 우리가 모든 결측치를 회귀선 위의 완벽한 값으로만 채운다면, 데이터의 실제 '불확실성(분산)'이 사라지고 매우 인위적으로 좁은 분포를 갖게 됩니다. 이는 모델이 현실을 과도하게 확신하게 만듭니다.
\end{warningbox}

\textit{[참고 이미지: 결정론적 vs. 확률적 예측 시각화 - 확률 모델은 예측에 불확실성을 반영]}

\textbf{해결책: 예측에 무작위성(불확실성)을 더하자!}

* \textbf{k-NN 대체 시:} k개의 이웃을 찾은 뒤, 그 값들을 '평균'내는 대신 k개 중 하나를 \textbf{무작위로 샘플링}하여 채워 넣습니다.
    * (위의 '노랑' 예시: 5.05를 채우는 대신, 50\% 확률로 0.1, 50\% 확률로 10을 뽑아 넣습니다.)
* \textbf{선형 회귀 대체 시:} 예측값 \(\hat{y}\)을 구한 뒤, 학습 데이터의 실제 잔차(residual, \(\epsilon\)) 중 하나를 \textbf{무작위로 샘플링}하여 \(\hat{y} + \epsilon\)을 채워 넣습니다.
* \textbf{의사결정나무 대체 시:} 예측값이 속한 최종 노드(leaf)에 여러 개의 학습 데이터가 있다면, 그 값들을 '평균'내는 대신 그중 하나를 \textbf{무작위로 샘플링}하여 채워 넣습니다.

이러한 '불확실성을 고려한 대체'는 데이터의 원래 분포와 분산을 보존하는 데 훨씬 효과적입니다.

%-----------------------------------
\subsection{여러 변수에 결측치가 있는 경우 (Iterative Imputation)}
%-----------------------------------

만약 \(X_1, X_2, X_3\) 모두에 결측치가 있다면 어떻게 해야 할까요? 이는 "닭과 달걀의 문제"와 같습니다. \(X_1\)을 예측하려면 \(X_2, X_3\)가 필요한데, \(X_2, X_3\)에도 결측치가 있습니다.

\textbf{해결책: 반복적(Iterative)으로 예측합니다.}

1.  \textbf{초기화:} \(X_1, X_2, X_3\)의 모든 결측치를 일단 '평균값'으로 채웁니다.
2.  \textbf{1라운드 (X1 예측):} (평균으로 채워진) \(X_2, X_3\)를 이용해 \(X_1\)의 결측치를 예측하고 업데이트합니다.
3.  \textbf{1라운드 (X2 예측):} (방금 업데이트된) \(X_1\)과 (평균으로 채워진) \(X_3\)를 이용해 \(X_2\)의 결측치를 예측하고 업데이트합니다.
4.  \textbf{1라운드 (X3 예측):} (업데이트된) \(X_1, X_2\)를 이용해 \(X_3\)의 결측치를 예측하고 업데이트합니다.
5.  \textbf{2라운드 이후:} 1~4의 과정을 \(X_1, X_2, X_3\)의 대체값들이 더 이상 크게 변하지 않을 때까지 (수렴, converge) 여러 번 반복합니다.

%-----------------------------------
\subsection{Sklearn을 사용한 구현}
%-----------------------------------

이러한 복잡한 과정들은 \texttt{sklearn.impute} 모듈에 구현되어 있습니다.

\begin{lstlisting}[caption={sklearn의 주요 Imputer}, label={lst:imputers}, breaklines=true]
from sklearn.impute import SimpleImputer
from sklearn.impute import IterativeImputer
from sklearn.impute import KNNImputer
from sklearn.impute import MissingIndicator

# 1. 단순 대체 (평균, 중앙값, 최빈값 등)
imputer_simple = SimpleImputer(strategy='mean')

# 2. 결측치 표시자
indicator = MissingIndicator()

# 3. k-NN 기반 대체 (모델 기반)
imputer_knn = KNNImputer(n_neighbors=5)

# 4. 반복적 대체 (가장 정교한 방법)
# 다른 모든 피처를 사용하여 각 피처의 결측치를 예측
imputer_iterative = IterativeImputer(max_iter=10, random_state=0)
\end{lstlisting}

\newpage

%===================================
\section{블랙박스 모델 해석 및 시각화}
%===================================

%-----------------------------------
\subsection{시각화의 목표}
%-----------------------------------

데이터 시각화는 여러 목표를 갖습니다.

* (모델링 전) 데이터 탐색 및 가설 수립 (EDA)
* (모델링 후) \textbf{모델 결과 커뮤니케이션}

모델이 복잡해질수록 "모델이 왜 이런 예측을 했는가?"를 설명하기 어려워집니다. 이 섹션은 모델링 후의 커뮤니케이션에 초점을 맞춥니다.

%-----------------------------------
\subsection{왜 모델 해석이 필요한가? (Parametric vs. Non-parametric)}
%-----------------------------------

1.  \textbf{파라메트릭 모델 (Parametric Models):}
    * 예: 선형 회귀, 로지스틱 회귀
    * 모델이 \(Y = \beta_0 + \beta_1 X_1 + ...\)처럼 간단한 수식으로 정의됩니다.
    * 우리는 계수(coefficient) \(\beta_1\)을 보고 "X1이 1단위 증가할 때 Y는 \(\beta_1\)만큼 증가(또는 감소)한다"라고 명확하게 해석할 수 있습니다. (화이트박스 모델)
2.  \textbf{비파라메트릭 모델 (Non-parametric Models):}
    * 예: k-NN, 의사결정나무, 랜덤 포레스트
    * 모델이 복잡한 규칙(Tree)이나 거리 계산(k-NN)의 조합으로 이루어집니다.
    * "\(\beta_1\)"처럼 해석할 수 있는 간단한 계수가 없습니다.
    * 이처럼 내부 작동 원리를 직관적으로 파악하기 어려운 모델을 \textbf{블랙박스(Black Box)} 모델이라고 부릅니다.

블랙박스 모델이라도, 우리는 모델이 '어떻게' 예측하는지 이해해야 합니다. 이때 사용하는 기법이 \textbf{부분 의존성 플롯(PDP)}입니다.

%-----------------------------------
\subsection{부분 의존성 플롯 (Partial Dependence Plots, PDP)}
%-----------------------------------

\textbf{PDP}는 "다른 모든 변수들을 평균(또는 특정 값)으로 고정했을 때, 내가 관심 있는 변수 하나(\(X_1\))를 변화시키면 모델의 예측값이 어떻게 변하는가?"를 보여주는 그래프입니다.

\begin{examplebox}{예제}
    \textbf{PDP의 직관적 비유: 오디오 믹서}

    PDP는 오디오 믹서(Mixer)와 같습니다. 훌륭한 음악(모델 예측)은 보컬, 드럼, 베이스(여러 변수)가 조합된 결과입니다.

    PDP는 이 음악에서 \textbf{'베이스(X1)'가 전체 사운드에 어떤 영향을 주는지} 알고 싶을 때, '보컬'과 '드럼'(다른 변수)의 볼륨을 '중간'으로 고정해 놓고, '베이스'의 볼륨만 0에서 100까지 싹 돌려보면서 소리의 변화(Y 예측값)를 녹음하는 것과 같습니다.
\end{examplebox}

\vspace{0.5cm}\hrule\vspace{0.5cm}
\subsubsection{예제 1: 단일 변수 모델 시각화}

먼저 간단한 모델로 시작합니다. 심장병(AHD, 0 or 1)을 최대 심박수(MaxHR) 하나만으로 예측하는 k-NN(k=50) 모델을 만들었습니다.

* \textbf{모델:} \texttt{AHD ~ MaxHR}
* \textbf{시각화:} `MaxHR` 값을 70부터 200까지 촘촘하게 만들고(synthetic X), 각 값에 대해 모델이 예측하는 '심장병 확률'을 계산하여 점을 찍어 연결합니다.

\textit{[참고 이미지: PDP 시각화 - MaxHR vs. 심장병 확률의 부정적 관계]}

* \textbf{해석:} 이 그래프(PDP)는 `MaxHR`이 낮을수록 심장병 확률이 70\% 이상으로 높고, `MaxHR`이 높을수록(즉, 건강할수록) 확률이 20\% 근처로 낮아지는 \textbf{부정적(negative) 관계}를 모델이 학습했음을 보여줍니다.

\vspace{0.5cm}\hrule\vspace{0.5cm}
\subsubsection{예제 2: 다중 변수 모델의 PDP (상호작용이 없는 경우)}

이제 더 복잡한 모델을 만듭니다. `MaxHR`뿐만 아니라 `Age`, `Sex`, `RestBP` 등 10개의 변수를 사용했습니다.

* \textbf{모델:} \texttt{AHD ~ MaxHR + Age + Sex + ...}
* \textbf{시각화 (PDP):} `MaxHR`의 영향을 보기 위해, 다른 9개 변수(`Age`, `Sex` 등)를 모두 \textbf{"전체 데이터의 중앙값(median)"}으로 고정합니다. (즉, '평균적인 환자'를 가정)
* 그런 다음, 이 '평균적인 환자'의 `MaxHR`만 70에서 200으로 바꾸면서 심장병 확률을 예측합니다.

\textit{[참고 이미지: 다중 변수 PDP - 평균 환자에 대한 MaxHR 영향력 시각화]}

* \textbf{해석:} 여러 변수를 추가했지만, '평균적인 환자'에 대한 `MaxHR`의 영향력은 예제 1과 거의 유사한 부정적 관계를 보입니다.

\vspace{0.5cm}\hrule\vspace{0.5cm}
\subsubsection{예제 3: PDP를 이용한 상호작용(Interaction) 발견}

PDP의 진정한 힘은 '평균적인 환자'가 아닌 '특정 그룹'에 대한 예측을 비교할 때 나옵니다.

* \textbf{가설:} `MaxHR`이 심장병에 미치는 영향은 `Age` (나이)에 따라 다르지 않을까?
* \textbf{시각화 (PDP 비교):} 3개의 PDP를 한꺼번에 그립니다.
    1.  (주황색) `Age` = \textbf{중앙값} (약 55세), 다른 변수도 중앙값
    2.  (초록색) `Age` = \textbf{최대값} (약 77세), 다른 변수는 중앙값
    3.  (빨간색) `Age` = \textbf{최소값} (약 29세), 다른 변수는 중앙값

\textit{[참고 이미지: 상호작용 PDP - 다양한 Age 값에 따른 MaxHR 효과 변화]}

* \textbf{해석:}
    * 그래프가 세 그룹(다른 나이)에 대해 다르게 그려집니다! 이는 모델이 \textbf{`MaxHR`와 `Age` 간의 상호작용}을 학습했다는 뜻입니다.
    * `MaxHR`이 낮을 때는 (왼쪽, < 110) 나이와 상관없이 모두 확률이 높습니다.
    * `MaxHR`이 높을 때는 (오른쪽, > 160) 나이의 영향이 커집니다. 젊은 환자(빨간색, 최소값)는 확률이 15\%까지 떨어지지만, 나이 많은 환자(초록색, 최대값)는 확률이 25\% 정도로 상대적으로 높게 유지됩니다.
    * \textbf{결론:} 이 모델에 따르면, 최대 심박수가 높은 것(운동)은 젊은 사람에게 더 큰 심장병 예방 효과가 있습니다.

\newpage

%===================================
\section{효과적인 시각화의 원칙 (부록)}
%===================================

%-----------------------------------
\subsection{나쁜 시각화의 예}
%-----------------------------------

모델 해석뿐만 아니라 모든 데이터 시각화에서 '나쁜 시각화'는 의미를 왜곡합니다.
\textit{[참고 이미지: 잘못된 시각화 예시 - 하버드 GPA 인플레이션을 왜곡한 차트]}

위 차트는 하버드의 GPA 인플레이션을 보여주려 했으나, 최악의 시각화 중 하나입니다.

* \textbf{문제점:} 2005년부터 2017년까지의 '3.67'과 2017년 이후의 '4.00'은 완전히 다른 척도(하나는 숫자, 하나는 등급)를 의미할 수 있으며, 막대그래프로 수치를 표현했지만 모든 막대의 높이가 동일하여 시각적 정보를 전혀 주지 못합니다. 이는 데이터를 조작하고 청중을 속이는 행위입니다.

%-----------------------------------
\subsection{좋은 시각화의 원칙}
%-----------------------------------

역사적으로 가장 위대한 데이터 시각화들은 다음과 같은 원칙을 따릅니다.
(예: 존 스노우의 콜레라 지도, 나이팅게일의 로즈 차트, 미나르의 나폴레옹 행군도)

1.  \textbf{그래픽 무결성 (Graphical Integrity):} 데이터를 왜곡하거나 속이지 않아야 합니다. (예: Y축을 0에서 시작하기, 척도 통일하기)
2.  \textbf{단순함 (Keep it simple):} 불필요한 장식(3D 효과, 그림자, 과도한 색상)을 제거하여 '데이터 잉크 비율'을 높여야 합니다.
3.  \textbf{올바른 디스플레이 사용 (Use the right display):}
    * (Good) \textbf{위치(Position), 길이(Length):} 사람이 가장 정확하게 인지. (예: 막대 차트, 산점도)
    * (Bad) \textbf{각도(Angle), 면적(Area):} 사람이 크기를 과소/과대평가하기 쉬움. (예: 파이 차트, 도넛 차트)
4.  \textbf{전략적인 색상 사용 (Use color strategically):}
    * \textbf{범주형(Qualitative):} 서로 구분이 명확한 색상 사용 (예: 정당, 과일 종류)
    * \textbf{순차형(Sequential):} 하나의 색상을 연한색~진한색으로 표현 (예: 인구 밀도 0 \to 100)
    * \textbf{발산형(Diverging):} 중간(0)을 기준으로 두 가지 색상이 진해짐 (예: 수익 -100 \to 0 \to +100)
    * 색맹/색약 사용자를 고려해야 합니다.
5.  \textbf{청중 파악 (Know your audience):} 청중이 무엇을 알고 싶어 하는지에 따라 설명의 수준과 깊이를 조절해야 합니다.
6.  \textbf{스토리텔링 (Tell a story):} 시각화에는 '시작-중간-끝'의 흐름이 있어야 합니다. 청중의 눈길을 어디로 이끌지(Annotations, Call Out Boxes) 설계해야 합니다.

\newpage

%===================================
\section{빠르게 훑어보기 (1-Page Summary)}
%===================================

\begin{tcolorbox}[title=1. 결측치(Missingness)란?]
데이터에 값이 누락된 '구멍' (\texttt{NaN}).
그냥 삭제하거나 평균값으로 채우면 \textbf{편향(Bias)}이 발생하여 모델이 현실을 잘못 예측하게 됨.
\end{tcolorbox}

\begin{tcolorbox}[title=2. 결측의 3유형 (원인)]
    \begin{itemize}
        \item \textbf{MCAR (완전 임의):} 완전 무작위 (예: 오타). 삭제해도 편향 없음 (데이터는 손실됨).
        \item \textbf{MAR (임의):} \textit{관측된} 변수(예: 성별)와 관련됨. 모델링으로 해결 가능.
        \item \textbf{MNAR (비임의):} \textit{값 자체}(예: 고소득) 또는 \textit{숨겨진} 변수(예: 부작용)와 관련됨. 해결 매우 어려움.
    \end{itemize}
    \textbf{현실:} 어떤 유형인지 증명 불가. 보통 MAR로 가정하고 모델링.
\end{tcolorbox}

\begin{tcolorbox}[title=3. 결측치 처리(Imputation) 전략]
    \begin{itemize}
        \item \textbf{표시자 변수 (Indicator):} "결측됨" 자체를 정보로 활용. (결측=1, 아닌=0인 새 변수 추가)
        \item \textbf{모델 기반 대체 (k-NN, Regression):} 다른 변수들로 결측치를 '예측'하여 채움.
        \item \textbf{불확실성 고려 대체 (Best):} 예측값(\(\hat{y}\))에 무작위성(예: 잔차 \(\epsilon\))을 더해 \(\hat{y}+\epsilon\)로 채움. (데이터의 실제 분포를 보존하기 위해)
        \item \textbf{반복적 대체 (Iterative):} 여러 변수에 결측치가 있을 때, 수렴할 때까지 서로를 예측하며 반복적으로 채움 (\texttt{IterativeImputer}).
    \end{itemize}
\end{tcolorbox}

\begin{tcolorbox}[title=4. 블랙박스 모델 해석 (PDP)]
    \textbf{PDP (부분 의존성 플롯):} 복잡한 모델(k-NN, 트리 등)을 해석하는 도구.

    "다른 변수들은 '평균'으로 고정하고, 관심 변수 X 하나만 바꿨을 때 모델의 예측 Y가 어떻게 변하는지" 보여주는 그래프.

    만약 '나이(A) 그룹'별로 그린 PDP와 '나이(B) 그룹'별로 그린 PDP의 모양이 다르다면, 모델이 '나이'와 '관심 변수 X' 간의 \textbf{상호작용(Interaction)}을 학습했다는 의미.
\end{tcolorbox}

\end{document}
