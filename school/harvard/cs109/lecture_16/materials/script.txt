(3) 109 day 16 - YouTube
https://www.youtube.com/watch?v=pV-YWawHuJE

Transcript:
(00:01) I mean, I checked, but yeah. Tuesday. Okay. It's on campus. They got All right. Check. Check. Check. Are we good online? Great. Welcome, welcome to another edition of data science. Good to see you all. Thanks for coming.
(01:12) Uh today we're going to talk about where we left off last time. That's applying bays in the world of categorical outcomes, logistic regression modeling, things of that nature. Um couple announcements. First, there's been a little bit of griping online on Ed about the project and what's due next on the project. It was our fault.
(01:39) We didn't release the next milestone until I think today. Um, I apologize for that or we apologize for that. But realize it's not as much of an ask as what a lot of people thought it was. It doesn't have a huge data collection EDA portion of it yet. We're getting there. But if you look at the milestone, we've now pushed back the due date until Tuesday, I believe. Tuesday.
(02:07) And all we want you to do is redefine the question. Okay? you selected a topic and that topic was proposed by some group and it's really your job to look at the data see what's possible and repropose the the question. So it doesn't have to match be completely in alignment to the original project proposal. Okay.
(02:33) So just realize it's should take a couple hours you know 2 three hours by just looking playing with the data getting a feel for it and come up with questions that part of the data science process if you're overwhelmed with the one that was selected then you have to redefine the project which might still be the same definition that you originally gave. Yeah.
(03:03) Yeah. But yeah. Yeah. So re restructure, you know, make it a little bit more specific based on what was measured. You got it. Okay. So that's one thing. What's the other thing that's due? Paid three. That's been out there forever. Um and so if you haven't started it, I highly suggest you start it. So um if you haven't started it, you're behind. So, make sure you start working on that.
(03:28) That's still working with everything from before. Nothing to do with logistic regression. That's homework four. Great questions for where we stand right now or sit. Hopefully, you're not here for 244 because you should have left 10 minutes ago. Okay, let's get into today's topic. It is logistic regression extended uh into the bay paradigm and one of those use cases is something called hierarchical models which are one of my favorites uh in real life.
(04:06) It has this like blended frequentist and Beijian perspective on it which is kind of nice. So we'll talk about where that comes from in a bit. First we are talking about a little bit of review something that might be helpful for your homework and then we'll get into that beta binomial model which we kind of ended with last time.
(04:32) Talk about hierarchical modeling and some other important things to think about in the Bay paradigm and then get into doing some sampling for the purposes of sampling from a posterior distribution. Okay, quick review. We haven't had much chance. You haven't had a chance really to do this on a problem set yet. So, here's a concrete example as I play Jenga again. Concrete example to figure out what the heck is a logistic regression model doing.
(05:04) Get out of here. Okay, so our model, simple one. I sent Pavlo and the rest of the NBA players, told them to take some shots from distance. Oh, we good. We good. Told them to take some shots from distance. No, this is actual NBA data. So, we're looking at players in the NBA, professional basketball players, and their shots in games, asking whether or not that shot was successful.
(05:37) Okay, right now, really simple. We're just looking at distance from the hoop. Okay. So, putting us on a basketball court, you can shoot from zero or one ft a layup real close to the hoop. You can shoot from three-point line. Anybody know how far away the three-point line is? 20 something feet.
(05:58) Depends on where you are. So, about 24 feet down to 21 feet, I think, in the corner, something like that. Um, and then half court is like 45 ft. You could shoot full distance, 80 ft, something like that. So, shots coming from distance and we're trying to predict whether or not it's going to go in as a field goal. And so, that response variable is a success or not.
(06:19) It's a zero or one. One meaning yes, you got some points. Zero, no, you missed based on a predictor solely of distance. Okay, this is all of the NBA shots from last year. And we fit our model and we print out our output. Okay, simple enough. What's this model telling us? How do we interpret the results of a model like this? I see this model.
(06:51) What's the first thing to do? A conceptually why was a logistic regression model a good thing to fit the outcome's binary and our predictor is numeric right standard simple logistic regression model. So let's write out the model statement. How do you write out the model statement in logistic regression? You say y = b 0 + b1 * x. Oh, wait. That's my stat 104 showing. I apologize.
(07:31) Beta 0 and beta 1 hat. Not quite. What's wrong? Yeah, the response isn't just y, it's the log odds that y equals 1. So we can say that the natural log of the probability that y = 1 over 1 minus the probability that y = 1 has that functional form log odds of the response. Okay.
(08:03) And we can just pull off our estimates 0.796 minus 0.0474 0474 times x which is distance in feet. Hopefully I pulled off all the right numbers. Okay, great. Interpret those estimates. What does 0.796 mean? percent. The field goal percentage when distance is zero is 79.6%. The log odds of a field goal being successful is 796. So how do we turn that into something we care about? Yeah, you can. So the odds of success is e to the 0.
(09:08) 796 for when x is zero. A shot a layup right by the basket. Okay. Hopefully that has high probability. This is odds. I don't like odds. What should we turn it into? A probability. And so how do you turn a probability into an odds? The probability that y equals 1.
(09:35) This is the odds that y equals 1 is odds over 1 plus odds. And that's just e to the junk. 0.796 over 1 + e to the 0.796. Okay. And hopefully that's a high number, right? Something over 50%. In basketball layups, something like 80% success probability is my guess. What's the number? Anybody plug it in their calculator? 69%. Great number. 39 roughly. Okay. Good. Happy, right? All right.
(10:14) Now, let's interpret the slope. What did we say the odds was, by the way? E to this number. 2.22. Another good number. Fine. Just don't take three of them. So 2.22 is the odds. 69% is the estimated probability. And then how do we interpret0.0474? It's negative. Which means what? The further you are from the hoop, your chance of being successful goes down.
(10:53) Not surprising, right? Longer shots are harder to make. Like everybody understands that even if you don't know sports. Okay. And so it's negative. But how do you interpret the actual value? You see you take multip. You take e to the0.0474. We call that the estimated odds ratio.
(11:27) estimated odds ratio. The multiplicative change in the odds multiplicative change in the odds for every foot further the shot is taken from. Right. And e to that negative power becomes anybody plug it in? It's 0.9 something I'm sure. Who's got a calculator running? Who's got Python running? Come on.
(12:22) Who's got Google running? I know everybody has Google up, right? What is it? Yeah. Yeah. 0.9. What? 0.95. Great. Less than one. Because multiplicative changes that are being multiplied by less than one, you see decreases. Not surprising. With me? Okay. At some point, when you're close, there's a better than 50% chance of making the shot. At some point when you get far enough away the chance of making the shot drops below 50%.
(13:02) What do we call that distance? In this class, when probabilities go from predicting a success to predicting a failure, we call that the classification boundary. All right? And so at some distance far enough away we can define the classification boundary. When will the predicted probability be 50%. Solve for X in which this equality becomes zero.
(13:32) Right? So on the law god scale a log gods of zero is that magical threshold where you go from above 50 to below 50 in this problem. Okay? It's a single x. It's not like a pretty picture, a two-dimensional uh diagram, but it's pretty simple to work out. 796 divided by 474. Can you do that in your head? 17.
(14:00) So about 17 feet away is where it goes from success predicted on average to failure predicted more commonly. Right with me? Great. That's how I interpret a logistic regression model. Write out the equation, write out the formula, start thinking about what all that represents. Okay? And if you know basketball, kind of all makes sense. Great.
(14:24) If you put Kevin Rider into this equation, my coefficient would be about 0.5 and my slope would be like negative one. So at about five feet is where I got about a 50/50 shot of making the shot. Okay, a different model. We've seen these data before. We're looking at predicting the selling price of homes in the Harvard Square area. And we look at here price in millions of dollars square footage and we draw the scatter plot.
(15:05) What do you notice about the scatter plot? Yeah, the constant variance assumption is violent, right? We've seen this before. We've talked about it before, but the line generally describes the relationship. How can we improve this model? If we wanted to perform inferences, go ahead, fit the line. Just don't use the coefficients and their standard errors specifically to build confidence intervals.
(15:24) The standard error is off. So, what should you do instead? Bootstrap. Okay? And so you do some bootstrapping to estimate the uncertainty in your coefficient estimates. Another approach would be to fit the model in a different scale. And so if you look at X and you look at Y, they're both only positive values.
(15:47) They're both, if you looked at their histograms, right skewed. And so one possible alternative model would be to log x log y and fit a line on the log scales. Okay. And so we can look at the scatter plot on the log scale. I chose log base 2 because I'm weird because it's fun. And then we can fit a line to the log log scale. Okay. Hopefully we've improved that heteroscadasticity. We've improved some of those issues, those assumptions.
(16:19) And on the log scale things seem to be working a little bit better. The line still looks pretty good and the heteroscadasticity has been improved with me. Okay. So then what would we do? We turn to sklearn. We fit some models. We estimate on the regular scale the intercept and the slope.
(16:44) What's the interpretation of the slope? 589 dollars is the associated change in price for every square foot change in the house. Okay, we can fit it on the log base 2 scale really easily. Just do a quick log transform of both x and y and p.log 2 for me. And then we get output here. And then I ask the trickier question.
(17:08) Interpret the results of this model. Why would we want to do this? Financial data often changes multiplicatively. And if you think financial data is changing multiplicatively, it looks makes sense to handle it on the log scale. Okay, so let's write out the model. Let's saying log 2 of price is predicted based on an intercept 12.46 plus 0.
(17:55) 722 time log base 2 of x where x is square footage and y is price. All right. So what's the interpretation of 12.46 when x is zero? That's the predicted atom. When x is zero though it's log two is zero. And when is log two zero? When x is one. And so this would be the predicted price on the log scale of a home with one square foot. Not very useful. It's an extrapolation.
(18:35) If you looked at the scatter plot, we don't have anything near zero. Okay, on the log scale. More importantly, how do you interpret this 0.722 knee-jerk reaction linear regression? A one unitit change in X. But here, what is X? Log two of X is associated with a 0.722 change in y. But it's not y, it's log 2 y. Okay, so that's the knee-jerk reaction.
(19:21) But what does it actually mean? What's a one unit change in log 2 square foot? What does that mean in lay terms? When log two changes one unit, what does that mean for the original x? Thank you. All right. Doubling in square foot. Doubling in x. Doubling in square foot. So when you double the size of the house, you get this much of a change in log two price.
(20:01) What does a 0.722 change in log two price mean? Take two to that power. What's 2 to the 0.722 power? I don't know. You got a calculator. Anybody have a calculator on them? Do that calculation for me. 0.74 1.64. Great. So when you double the square foot in the house, you get about a 64% increase in the selling price of the home. That's what the model's telling us. A 1.
(20:57) 64 multiplicative change in the response with me kind of. Okay, great. So it's a multiplicative model. Now, when you do things on the log scale, it made sense to log both X and Y here. In some situations, it might make sense to just log one or the other if you want that nice interpretive model. It can also help with better fitting. If you actually have some model that there's a relationship with X that's on the log scale, it might improve prediction and you can always cross validate to see whether you should handle an X on the log scale or on the original scale.
(21:31) Questions on that? I think one of your homework problems was kind of based on this one increase in x. So 72% small 1% increase in x is a roughly 722% increase in y. Yes, that is roughly an approximation. Yeah, roughly an approximation. Yeah. Yeah, that's true. Because when this changes by a tiny bit, this is kind of the multiplicative change in y for small changes. Yep.
(22:03) That's how I think in econometrics they would tell you to interpret that result. Okay. So a small change not a doubling but a small change in X is approximated by that much of a percentage change in Y. And remember those percentage changes that are small when you start to multiply them together 1.722 they uh telescope out. Okay. So that's what they say here. I like this one more.
(22:37) I like this one more. So yes, if you know that one already, fine. I like this one more. Is the amount that 1.64 64 times increase the price of the house size. You got it. That's why I chose base two. I chose base two because I know I can feel what a doubling is.
(23:05) If I did a base e, then I have to say, oh, an e increase, efold increase, and that's no good. Tfold maybe. Okay, great. This is what the rter scale is based off of base 10. Okay, so that's a bit of an aside. Let's get back to where we were. We were talking about logistic regression. We were talking about categorical outcomes, binary outcomes.
(23:26) And we started applying the Beijian paradigm to performing inferences in that world. Okay, we were dealing with a binomial response variable or a Berni response variable more specifically and we started talking about the beta distribution introduced that and we said oh that's a useful prior to use when we have a response a likelihood that's based on a Bernoli okay and so we can write out that general format if our data are coming from a Berni distribution and we put a prior distrib distribution on that parameter P. We can talk about parameters and hyperparameters. The parameter here is P. The hyperparameters
(24:08) are A 0 and B 0. That's the belief we had use as analysts going into the actual data analysis. What values of A Z and B 0 should you use? If you have little belief going in, you use small values of a z b 0. If you have a lot of belief, you use large values of a zero, b 0. Why? We'll show it in a second. Okay. So, we can write down the prior.
(24:40) The prior is based on essentially that beta distribution. And we have kind of some ugliness here. But note what's important is P shows up in the form here. P to something, one minus P to something. Okay, why is that important? Because we are linking this prior with the likelihood.
(25:00) They are both can be thought of as functions of P when we're looking at it from the perspective of the posterior. Okay, so here's a prior, here's the likelihood, a product of those PMF evaluations because we think our data are independent. Okay. And so how do we get from a prior and a likelihood to a posterior? What kind of inference do we call this? Basian inference.
(25:30) So what formula are we using? Baze formula. Okay. And so you can write out B formula. You know posterior equals prior times likelihood divided by that normalizing constant. Okay. And that normalizing constant we throw out and we essentially just say in the end we have a proportional function here.
(25:53) the posterior where we think P is and its distribution dependent on the data depends on the likelihood we're using of the data given that prior and then the prior parameter itself's distribution and you just multiply through it's proportional to this which is then drop this normalizing constant the prior times the likelihood drop this out and so we can just say proportional to p to the oh look a 0 minus one p to the summation of x in exponent they add up.
(26:21) 1 minus p shows up twice in exponents. They add up. Just a little bit of math. Okay, we see this posterior distribution. We're thinking of what random variable in the posterior distribution. Why are we doing all of this business? We're performing inference for the unknown P. Okay. And as a Beijian analyst, we're thinking of P as a random variable.
(26:54) And so our random variable P shows up twice. P to something time 1 minus P to something. P is the random variable. P to the something 1 - P to the something has the form the mathematical form of what distribution? Why did we start with a beta? Because it's a conjugate prior.
(27:21) we result in the posterior distribution essentially here that is also beta distribution. So what distribution of P does this have the general form of? We return a beta and it's that beta binomial conjugacy that beta Berni conjugacy. All right. And so the posterior distribution is what? It's beta distributed. Now we have a new parameter for the alpha term.
(27:47) We have a new parameter for the beta term for that beta distribution. And we want to kind of dissect what this is telling us. What went into the beta an analyst's approach? Beta analyst. Baze analyst approach. Lots of B's out there. Okay. So the Beijian analyst says, "All right, I'm coming in with prior belief where I think P is. I collect a whole lot of data.
(28:13) Flip a whole lot of coins and I say, "All right, let's update that belief to what the data is suggesting." Okay, what does the whole distribution look like now? It looks like a beta distribution with a with a lower bound and an upper bound or an a it's not an upper bound, lower bound, but an a term and a b term. Okay? And that beta distribution we saw has a mean.
(28:35) So we can talk about summarizing this whole distribution of possible values for P into simply the posterior mean estimate. Okay, the mean of that beta distribution has this form. And so let's dissect that form a little bit. A 0 plus summation of yi's a 0 plus b 0 plus n in the denominator. What do those terms all represent? Summation of yi, number of successes, number of heads, n, number of trials, number of data points.
(29:06) What does a z act like? What is a z? The hyperparameter we used in our prior. What does it act like in the posterior? It acts like a success. The number of successes a 0 plus b 0 shows up in the denominator. What does a z and b 0 act like? b 0 acts like the number of failures.
(29:36) So we're going into this procedure with a beta distribution that we set up to say all right before we come into it it's as if we had already done a couple of experiments where we had a successes and b failures going into the problem and then we collect our data and we update it. Okay, that's the intuition behind this model. It's essentially sort of a weighted average between the mean of that prior distribution and the observed maximum likelihood estimator sample proportion.
(30:05) Okay, you're just pulling it towards where the beta prior distribution said it probably was. Why would you want to do this at a high level? It's a really simple model. We just have one outcome. But going into a problem, what a baze model allows you to do is shrink what your data says to some pre-specified value.
(30:30) Where do we often shrink our estimates to some pre-specified value? What's our pre-specified value? Why might we want to shrink estimates, pull estimates to some value? Sometimes we pull our OS estimates towards zero when we perform ridge and lasso. It's kind of the beige perspective on that.
(31:00) Maybe you want to pull your estimates not to zero but pull your estimates in this case to 50/50 because maybe going in you don't know what's more likely a success or a failure. Okay? Maybe going in there's some reaction to think the probability the old treatment effect if I'm coming into an experiment in clinical trials I know roughly the past history 70% of patients survive and maybe that would be my prior my beta says I want it to be shrunk towards what the prior distribution prior standard of care would have and now I am able to control that through the use of a zero and b 0
(31:39) okay Great. We can extend this to the logistic regression model. The whole general idea in the logistic regression model is now we still have this Bernoli distribution P. We're going to eventually put a prior distribution on it, but that Berni distributions P is related to a linear form of betas on the log odd scale.
(32:04) Okay, we already wrote this kind of on the board for that one example. All right, let's dissect this a little bit. What are the unknown parameters when we set up logistic regression? The betas. How many betas do we have? One intercept and all of the slopes associated with the predictor variables. So P plus one of them if we have P predictors. All right.
(32:33) And so if we're doing a full baze approach to this, we have to put a prior distribution to each of those. What prior distribution do you want to use? What would be a reasonable preference? A normal distribution. Sure. Why aren't you picking a beta distribution? When we had binomial and berni's before, we used a beta berni conjugacy that gave us a nice resulting posterior distribution.
(33:22) Why aren't we just putting beta priors on our on our betas? Our betas a are unrestricted. Right? And so we want them to go between negative infinity and positive infinity. And what's the support of a beta distribution between zero and one? So it doesn't really make sense. Okay. Another perspective is think about it on what scale are my betas? My betas are on the law god scale.
(33:45) And so there's no reason to put a beta distribution on my unknown parameters because that held when my unknown parameters were on the scale of p. And so this conjugacy doesn't hold if my betas show up on some other scaling of the unknown parameter P. Okay? And it's linked to that unbounded support of what we expect beta to be.
(34:09) And so let's put a normal distribution on it. And that's what we're going to do. Okay, great. Can we simply put beta prior on our unknown parameters? Nope. Anybody everybody see the nope cap before as a mean? That's always fun. All right.
(34:29) So, conventionally, we're going to use those betas that are going to be approximately normal. We're going to shrink them towards zero. We're going to give them a prior variance, and then this shrinks us towards zero just like we would have in a ridge model. What do I mean by shrink towards zero? The standard logistic regression model estimates a beta.
(34:50) If we put some sort of prior centered at zero, we're going to shrink the coefficient like 0.722 toward zero, right? You probably want to do something different with the intercept with me kind of. Okay, how are we actually going to do this? Well, we don't have a nice closed form solution. Since we don't have conjugacy to rely on, we can't solve the functional form of that posterior distribution.
(35:18) And so to write out what the mean of that posterior distribution is going to be will be a challenge. And so we need to take a different approach to do great. Okay. So that's where we sat. The extension of these models are a beautiful thing. Talk like our president. It's beautiful thing. Hierarchical modeling is the approach in which we're going to illustrate the use of bays and its practical use of bays.
(35:45) Okay, unfortunately the example I have is we're going to go back to basketball. But remember that beta binomial distribution we basically said that our response variable is Berni and here we're I call it beta binomial but it holds for the Berni too and special case of the binomial. Our response depends on P and our P's are followed by beta. We call these hyperparameters.
(36:10) We can complicate things even more because we could put priors on our hyperparameters. We can layer extra prior distributions on our hyperparameters. We can treat them like random variables as well. Why would you want to do that? Because maybe you don't really know what beta distribution to use as a prior and so you put even more layering on top of it.
(36:35) This is called a hyper prior distribution. And we could think about reasonable hyperprior value v variables and what their distributions would be. We would need to think about the support. What range of values apply? And in this case, the beta distribution a 0 has to be positive. B 0 has to be positive. And so let's choose a distribution that has that support. Gamma exponential something like that.
(37:01) Okay? And we can continue on putting priors on our hyper prior make a hyper hyperprior distribution. And makes me think of the question of looking at mirrors infinitely. You can constantly layer on extra layers on the hierarchy of these prior distributions. I have a kid or two kids that are of the age.
(37:28) Anybody know what movie this is from? Nobody's eight years old in this class. missing it. Smallfoot. Never heard of Small Foot. No. Oh, that's a great movie. If you like, you know, Disney movies, go ahead and watch it. It bombed because it came out right around the time of the pandemic, unfortunately. But there's a bunch of yetis up on a mountain.
(37:54) There's clouds and they're not connected to the people underneath the world, which are called the small feet or they call the small feet. They have big feet. And they're trying to figure out what holds up their mountain. And so the myth is what's holding up the mountain are some mammoths. What's holding up those mammoths? I don't know. It's just mammoths all the way down. Okay.
(38:15) Well, the main characters in this were played by Zena and somebody else too. I forget. So anyway, if you got a chance, go ahead and watch. All right. Why are we going to bother putting these hyperparameter priors on our priors? We may be uncertain about the hyperparameters to use in our prior, but more commonly the data is going to tell us why.
(38:33) It's going to be based on the structure of the data. If our data is structured hierarchically, we're going to include that into our model. Okay, here are some examples. In the world of government, some of you may work in the domain of government. A lot of time data might come at different levels. You might have one data structure data set that has individual measurements.
(38:58) That individual might be individual voters, individual households. I'm not sure. Depends on the problem. Those individuals might reside within counties. And you have measurements at the county level that have certain governments and policies and those counties reide reside within states. Those states have their own measurements and states reside within regions, within countries, etc.
(39:21) You have all these different data sets that are connected or you want to connect but the measurements rely uh reside at different levels. Okay. The data itself is hierarchically structured. Education there's students within schools within districts within states. Medicine patients that I use all the time. Patients come from doctors who might be in hospitals. Biology cells from tissues from organs from individuals. And the example today we're going to use is sports.
(39:46) Going back to that basketball shooting example. Okay, going back to the NBA. For those of you who know anything about basketball, I'm sure you've seen or heard of a few basketball players from the NBA. Who are the best players in the NBA? Let's hear from a non basketball fan. Who is the best player in the NBA? I heard one name. LeBron. Well, maybe back in the day. Jokic.
(40:17) What was that? Jeremy Lynn. And he's retired. Giannis. All right. Some great names. Some great names. Well, I could think a lot of you might suspect LeBron as an older statesman might be one of the best players in the NBA. There's a more recent thing. He's probably not best anymore. Who's this? Steph Curry. A lot of you have probably heard of Steph Curry.
(40:43) If you ask a basketball fan, this is the reigning MVP, SGA, Shay Gilis Alexander, and then the upand cominging stud. I can't say his name. Wembi Wana from from the Spurs. He's like still growing. He's 75 and still growing. He's eating eating his uh Flintston's gummies. What we're trying to do is we're going to model the chance of a field goal attempt going in going back to the NBA shot data, but we're going to control for player ability.
(41:26) We're going to look at distance and control for player ability. What's the data going to look like? Why is a hierarchical model a reasonable one? What's a row in this data frame going to have measured? What's the response? Success or failure? Did the shot go in the basket? Go in the hoop. What are the predictors? Two predictors. Distance.
(42:05) distance from the hoop and the player who took the shot. Yeah, we can complicate it more than that, but a simple model to assess which player might be best at shooting offensively. Okay, that predictor of who took the shot, we can want might want to think about taking this as a hierarchical model approach. And I'll explain that in a second.
(42:30) But really, I mean, for those who know, who are in the know, there's your best player. All right, here's what a basketball shot data look like. We have rows, we have coordinates where on the court it took. We can convert that into distance and angle. That angle is essentially zero means it's a straight-on shot. Any other angle, negative means you're to the left, positive means to the right. And so a greater angle, think this is in radians.
(42:55) A greater angle means you're at like a higher degree. Okay? And you can think about visualizing what those shots look like. Here we have a scoring play. True are the made shots, oranges are the missed shots, and put it on a plot. You see a lot of three-point shots. Okay, there might be some misalignment here, but it's close enough. Okay, this is how we think about it in the world of the NBA, predicting shot success.
(43:17) All right, so let's put some uh mathematical framework to this. We're going to talk about yigj as our response variable. There's now two subscripts here because I represents the shot attempt within a player and the j represents the player who took the shot. Okay, so there's this natural hierarchy of data.
(43:41) we have to worry about who's taking the shot and then we have shot within player. Okay. And so that's the natural hierarchy here. We're also going to include a predictor for everybody treat it the same for everybody the distance in which the shot was taken. And so what would be the standard parametric approach for fitting a model to these data that incorporates the player and the distance as predictors.
(44:11) The response variable is binary. So what frame of parametric model are we going to use? Logistic regression. Okay. And then our predictors are distance and player ID. And well, how are we going to handle player ID? It's categorical. What are we going to do with it? Somebody yell it out. One hot encoding.
(44:42) Make a list of dummy variables, binary variables to indicate, was that shot from Jokic? Was a shot from SGA, was the shot from some scrub on the bottom of the Sixers roster because that's the team I would cheer for. All right. They weren't very good. Sorry for the typo here. A logistic regression model of course with lots of predictors.
(45:01) We're trying to model Y to be Berni based on the log gods of an intercept a slope with distance. Beta 2 for an indicator for the J person is Lebron etc etc etc. So we have this long list of indicators. I just picked LeBron because uh you might have heard of him before. All right.
(45:23) So what are some issues in taking this approach? This is your standard logistic regression model to fit shots to player IDs and distance. There's a lot of like 20 players per team have shots and there's 30 teams. There are 600 different players. Some of those players have lots of shots. Some of those players just have a handful of shots. And so now you've just automatically created a matrix that has 600 columns in it.
(45:52) And maybe that's not what you want to do. If you have that, what's going to tend to happen? Lots of predictors, you might overfit to the data. Okay? And so we want to prevent overfitting to the data. All right? We'll come back to some issues that show up here. Naturally, the data is clustered. We have shots from within players, and we're going to model that hierarchically.
(46:17) So we're going to build a hierarchical logistic regression model. I'm going to write out the model statement and let's try to decompose what's going on. Okay, our response variable is still trying to predict whether or not a success is a shot is successful based on a Berni distribution log odds where we now change the intercept to an alpha term instead of beta 0 just to denote it differently from a slope beta 1. Beta 1 is that indicate or sorry that distance measure.
(46:42) But now my alpha intercept term has a J coefficient or sub subscript on it. Why does it have a subscript on it? J because we're thinking everybody's relationship with distance gets shifted up or down on the log out scale depending on what player we're dealing with. Okay.
(47:07) And that distribution of alpha intercept terms, we're going to put a normal distribution too centered at some overall average intercept with some variability around it. Okay. And so what are the unknown parameters in this model? There's a lot of them still. But at the base of it, we have one relationship of distance to shot making ability.
(47:38) We have one overall intercept, average intercept across all players. We have the variance of players abilities around that. And then we have all of these alpha terms to talk about how the different players abilities vary around the average player ability with me kind of. Okay. It's the analog to fitting that standard logistic regression model with all of the binary indicators for player ID. Okay.
(48:12) So we can think of this as a semibasian approach but it's not fully bay. Why is it not fully bes? What would we have to do to be fully beige in here? We have to set a prior to all of our unknown parameters. What are all of our unknown parameters? Well, we got a beta 1. We got an alpha 0ero and we got an alpha squared or sigma squared alpha.
(48:43) We should put some priors to those as well. Okay. And so you could put make this fully beijian by putting priors on those grand overall parameters unknown parameters. This is approach is essentially the blend of a standard frequentist approach with a basian approach.
(49:04) This is an improper prior that we're putting on these pri on these unknown parameters. Okay. probability. Yep. The probability standard C standard for the only outcomes. So we can put odds as oh okay. So so so the the randomly should be P. And so I'm being a little sloppy here.
(49:43) So yes, technically it's P, but how are we using P in this version? So the parameter in the Bernoli is the P. And so you're right. I probably should write this as PI J equals E to this over 1 plus E to this. But to me, mathematically, I'm thinking that's the same idea. But yeah, I I realize that might be confusing. Okay, I'll see if I can correct that. I'll see if I can correct that. Great. So what's the posterior? How do you write a posterior? You got a prior and you got a likelihood.
(50:09) You've got a likelihood function. You've got this prior distribution. And so you are looking at how that distribution would look. Part of our functional form is based on a Berni. So we got a P to the junk and one minus P to the junk. And that P to the junk is in terms of E to the alpha J plus beta 1 J. And the alpha J is normal.
(50:28) So we're thinking those are based on some exponentially squared terms. Those things don't combine very well. All right. So, we're not going to really write it down. It's not going to match a natural distribution that we know. And so, what we're going to have to do in order to estimate that posterior distribution is go through sampling from that posterior. We're going to have to sample from it.
(50:53) Just as an aside, this is essentially putting improper priors on our unknown parameters. We're not fully Beijian here. This is called the empirical beijian approach. Essentially, we're putting a uniform distribution on those prior parameters. All right. So, here's sort of the result. We fit this model. Yes. Do I have to put a prior on P or is it absorbed by the priors on the other parameters? That was the question. So, do I have to put a prior on P directly? No. No, the answer is no.
(51:33) Okay, P is just a transformation of the parameters I'm putting prior on. Okay, it's just a mathematical transformation. And so we're putting a prior on P through the priors we place on our betas. Okay, it's not explicitly a separate thing for P. Thank you for slowing me down. All right, we fit these models. We can fit it as an ordinary le squares model.
(52:06) This is for the basketball fans out there. So, and this going to highlight something important too. So, we fit an ordinary le squares model where we have distance as a predictor and all of our coefficients for those binary indicators. Okay, out of that model, every player has an estimated coefficient.
(52:26) Okay, this is including the intercept in it. So they can essentially be interpreted directly as that player's intercept. Okay. Anybody heard hear of Alandis Williams before? There might be one person out there in this world. Okay. I haven't heard of them. I don't know who Alandis Williams is. And a whole bunch of names I've never recognized before.
(52:50) And I'm a moderate to uh pretty close follower of basketball. And they all have are estimated to have the highest coefficient. So I extracted out the five highest coefficients for the players and I extracted out the five lowest coefficients for players. So these are the five players who we are estimated to have the best chance of making a zero foot shot.
(53:14) These are the five players that have the worst chance of making a zero foot shot. Okay, plug it into the equation for the logistic regression model. You get e to the 10 over 1 + e to the 10. What's the predicted probability that Williams will make a shot from zero ft? 100%. I've yet to hear of Williams. Okay, this is a player we s are predicting to make 100% of their shots.
(53:42) They're the best NBA player ever. Okay, the issue with the OS is we're overfitit to the data. this player took one shot and made it. Okay, we're predicting them from that data to be 100% at all times. Okay, similarly, all of these players, I have only heard of one of them, and that's M. McClung.
(54:07) Who's Mac McClung for those of you who are basketball fans? Yeah, he's the dunk champion for the slam dunk contest, but he basically never plays in an NBA game. Why? He's not any good, but he has really nice shots when he dunks the ball, but he shows up as a negative effect here as one of the worst five players from the OS model.
(54:33) Why? He took two shots in the data set and he missed them both. Okay, he's not that's not much evidence that he's bad. Just the OS estimate for best fit says let's make their coefficient as close to negative infinity as possible. All right, if we fit this full Beijian hierarchal model, we get estimated similar coefficients for every single player.
(55:03) So these are the estimated top five players from this model and worst five players from this model. These are the players predicted probability of making a shot from 0 feet after you do the conversion. E to the junk over 1 plus E to the junk. Okay. And so Jared Allen, Shay Gilis Alexander, Damen Lillard. I've heard a lot of these names. Okay. Why? These are some of the best players, best shooters in the NBA.
(55:31) It's shrunk down the OS estimates based on how many observations they were they had. It's a natural way of doing the shrinkage based on the evidence supported in the data. Okay. And then yes, these are some of the worst players in the NBA that have enough attempts to show up as worst players. The mechanics of the Bal model where the B hierarchal model where does the sample size come into account? The great question here is that since we have alpha j bas based on a normal distribution and we have yigj's conditional on all of these note the yigj's is repeated for every player j and so if it shows up one time there's
(56:24) not going to be a whole lot of evidence supported from that bernoli distribution if that y shows up for the j player hundreds of times or thous thousands of times. Now, there's a lot of evidence for that player's true ability. Okay, it's through the repeated rows all attached to that same player. Great question. The beta shows it really nice.
(56:56) is large. I wish I could annoy. We can handle this differently based on the different betas if we chose different beta priors for each player. Yeah. Okay. And this is just illustrating that Mac. Mcclung took two shots, missed them both.
(57:20) And so one issue that happens in standard logistic regression when you have perfect prediction of all successes or perfect prediction of all failures in a logistic regression model the best coefficient to estimate would be a negative infinity or a positive infinity. And so when you're trying to actually do this estimation and make this algorithm converge to get your estimates, it wants to make these values as negative as possible and these values as pos well this one at least as positive as possible and it just eventually stops based on numeric precision. And the algorithm converges never fully converges and just stops because it says we're close enough.
(58:01) Okay. All right. If we look at that distribution of coefficients as a box plot. So the bay approach, here's my distribution of coefficients for my OOS approach. Here's my distribution of all the player ability coefficients. Note, there was five people who did really poorly and then got really negative values.
(58:24) If we just zoom in, it's not just the severe players that get shrunk. It's essentially all players. So this is just the zoomed in version of these box plots. Okay. throwing out the outliers, restricting it from negative 1 to positive2. Okay, not surprising. What is it doing? It's shrinking the coefficients towards the average of those coefficients.
(58:48) Not towards zero, but towards the average of the players coefficients intercepts here. Okay, great. It was shut set up as such by allowing the intercept of varicos players. We're saying each player has a numeric shooting ability that applies the same for all distances. But what about this beta 1 term in this model? What is the effect of distance? If Steph Curry takes a shot from 30 feet, if Shay Gilis Alexander takes a shot from 30 feet, if Mac Mcclung takes a shot from 30 feet, the decrease in all of their law gods is estimated to be the same. Okay? And if you know anything about basketball, some players are good
(59:35) at distance, some players are bad at distance. All right? And so watch out for maybe that effect of slope, the effect of distance might vary across players as well. And so we can put a distribution on that distance effect too. And so we can allow the intercepts to vary across players. We can allow the slopes to vary across players. And how distance relates to the response. Okay.
(1:00:05) Couple notes. We can model these effects jointly as a multivariable normal and then we can put priors on those coefficients and I think I might have all of those to be fully bays here. Okay. Did I write on the back? I probably did. Running out of space. Today's secret secret word is tractor. Tractor. Where the hell are these things coming from? Why is Kevin always writing things about farms? It's really weird. All right.
(1:00:59) When we do a Beijian modeling approach, one of the inferences we might want to perform just like what we performed, if you're taking the picture for this, I don't know why you're taking a picture, it's just simply typing it in. When you're performing a Beijian model, what do you do in a Beijian model? Sometimes you might want to predict a future observation.
(1:01:29) When you predict a future observation in a standard linear regression model, you might want to put bounds of uncertainty around it. In a standard linear regression model, when you predict a future observation, how would you perform that calculation? How do you do predictions using a linear regression model? Well, eventually a prediction interval, but you just plug in your x's and predict what yhat would be.
(1:02:00) If you want bounds around that, you do a prediction interval, right? We have the formulas for performing predictions with bounds of uncertainty. And we know there's that inherent irreducible error in doing those predictions. Okay. When we do this approach to predict future observations in the Beijian paradigm, we got to be a little bit more careful.
(1:02:24) Why? In linear regression, when we did the prediction, we just simply said, "Oh, I need to erase stuff. linear regression prediction. Simple enough. Let's just talk about linear regression prediction. We say that y hat equals beta 0 plus beta 1 plus beta 2. Let's just imagine we have two predictors. We've estimated them and we put hats on things. Okay, give me an X1, give me an X2.
(1:03:12) I can predict what the Y is going to be. Okay, if we want the variance of that predicted prediction, we need the variance of beta 0 plus beta 1 hat X1 plus beta 2 hat X2. But we also want the variance of the residual as well involved. Those are two independent versions of variance.
(1:03:48) And this is why in the end when we predict with uncertainty a new observation, we have to take into account that stochastic irreducible variability. Okay. So we do the prediction, we want to add bounds, we have to figure out what the variances will be, right? When we do this in the Bay paradigm and we do a prediction, if we just simply get estimates of our betas and try to do the prediction for a new observation, call it y tilda, what's the issue of just trying to plug it into this equation? Take a step back as a Beijian analyst.
(1:04:32) What's the issue? What is beta 0? What is beta 1? How do we treat beta 0, beta 1, and beta 2? Are they fixed unknown parameters? We're treating them like they're random variables. And so if we want to fully encapsulate the uncertainty in predicting a new observation, we have to incorporate the uncertainty of the random variables it involves.
(1:05:13) Right? And so if our goal is to do predictions of a new future observation, we have to worry about the distributions of our unknown parameters. So if we want to do this prediction, don't act like Nostradamus. Let's do the posterior predictive distribution. And the issue is we might want to predict the probability of a future SE shot being successful in our basketball shooting model possibly for a new rookie.
(1:05:39) What inputs do we need in order to do this? Well, we need to know our X's, who the player is, what the distance is, and we also need to have specific values for our beta parameters. That's the issue when we do this prediction. We're going to call it the posterior predictive value. We're going to condition if we know a particular value of a parameter to predict a future observation. It's still just going to be based on the likelihood equation. Okay.
(1:06:04) So give me a theta in this case a set of betas and I can predict or provide a distribution for y hat through the likelihood. The problem is after fitting it on the original data set, now I have a whole distribution of thetas. I'm conditioning on a random variable. And when I condition on a random variable, I want to marginalize it out.
(1:06:30) And so to find the overall probability distribution of Y, we have to go through the entire posterior distribution of theta given the original data set. What's a data scientist to do? You got to consider all the possible values of all the parameters in the model. You got to consider their whole distribution.
(1:06:51) You're going to have to integrate across all of those mathematically. What does this mean? If this makes sense to you, great. Just realize there's extra uncertainty involved in order to predict where a new response variable would be given the data you saw already. Well, the data you saw already we're thinking is following this posterior distribution. And so the link here is through the posterior.
(1:07:15) To predict where a new observation will be, we'll have to use the likelihood of that new observation given any particular value of theta. The beta's here. And then we're going to multiply that by the chance of seeing that beta. It's just applying one extra step. And then to marginalize out across all possible values of beta, we just integrate out.
(1:07:39) All right? We combine all of those predictive distributions into one by marginalizing across all the values. Right? Just realize this positive predictive posterior predictive value. Sorry, I keep saying that adds a little bit of complication to it. And we get a whole distribution and we can use that distribution in the future like anything else.
(1:08:01) We can build a 95% prediction interval for where we think those future observations will be. Great. We're almost out of time. We're going to catch our breath before we get into the last bit of detail here that we'll finish off next time. So, what is what have we learned in the Beijian paradigm? When deriving these posterior distributions, it's nice and convenient.
(1:08:26) A lot of times we don't have to worry ourselves with that normalizing constant. We can just look at the functional form of the parameter involved that we care in the posterior distribution and that's going to show up and simply the multiplication of the likelihood with the prior. All right. And we can kind of ignore that scaling constant.
(1:08:45) We can just assume that distribution needs to sum up to one by combining that posterior with our data generating process the likelihood. Then we can derive that posterior predictive distribution which is nice to have and that's that helpful tool for forecasting in the future. Often a common inference you might want to perform for our various choices of likelihood prior.
(1:09:09) The posterior has been often the same type of distribution of the prior as before. What did we call that property? You start off with a prior distribution. The posterior follows the same family of distributions. We call that property conjugacy. Okay, it's a nice mathematical uh result. Lots of examples of conjugate distributions and those conjugate distributions give us nice posterior predictive distributions as well.
(1:09:35) And go ahead and check it out on the Wikipedia page for that whole list. What are the two? We know the beta binomial for when we have Berni outcomes or binomial outcomes. The other one we know the normal normal or the normal gamma it depending on whether or not we want that uh variance term to be treated like a random variable as well. All right.
(1:09:58) By combining these posteriors with our data generating process again that gives us our predictive distribution that conditional structure of Beijian models will allow us eventually to produce integrals through our estimation through simulation. And this is where we're headed in that logistic regression model.
(1:10:22) When we lost that conjugacy property and we resulted in a posterior distribution, we couldn't write out easily. We're going to have to take a different approach to guess or figure out what that posterior distribution really looks like. To get point estimates and interval estimates, credible intervals, posterior modes and means, we're going to have to simulate our data. And that Monte Carlo method is going to allow us to do it. Okay.
(1:10:51) When we can use math and use conacy, let's do it. When we can't, we take a computational approach. And that's going to be the rest of these slides. We'll talk about that next time and try to finish these up uh next week. Don't forget project stuff due on Tuesday. Problem work three due on Tuesday. Thanks.