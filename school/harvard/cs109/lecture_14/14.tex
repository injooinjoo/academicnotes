%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Harvard Academic Notes - í†µí•© ë§ˆìŠ¤í„° í…œí”Œë¦¿
% ëª¨ë“  ê°•ì˜ ë…¸íŠ¸ì— ì ìš©ë˜ëŠ” í†µì¼ëœ ìŠ¤íƒ€ì¼
% ë²„ì „: 2.0
% ìµœì¢… ìˆ˜ì •ì¼: 2025-10-26
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[11pt,a4paper]{article}

%========================================================================================
% ê¸°ë³¸ íŒ¨í‚¤ì§€
%========================================================================================

% --- í•œêµ­ì–´ ì§€ì› ---
\usepackage{kotex}

% --- í˜ì´ì§€ ë ˆì´ì•„ì›ƒ ---
\usepackage[margin=25mm]{geometry}
\usepackage{setspace}
\onehalfspacing                      % 1.5ë°° ì¤„ê°„ê²©
\setlength{\parskip}{0.6em}          % ë¬¸ë‹¨ ê°„ê²©
\setlength{\parindent}{0pt}          % ë“¤ì—¬ì“°ê¸° ì—†ìŒ

% --- í‘œ ê´€ë ¨ ---
\usepackage{booktabs}              % ê³ í’ˆì§ˆ í‘œ
\usepackage{tabularx}              % ìë™ ë„ˆë¹„ ì¡°ì ˆ í‘œ
\usepackage{array}                 % í‘œ ì»¬ëŸ¼ í™•ì¥
\usepackage{longtable}             % ì—¬ëŸ¬ í˜ì´ì§€ í‘œ
\renewcommand{\arraystretch}{1.2}  % í‘œ í–‰ê°„ ì¡°ì ˆ

%========================================================================================
% í—¤ë” ë° í‘¸í„°
%========================================================================================

\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\small\textit{CS109A: ë°ì´í„° ê³¼í•™ ì…ë¬¸}}
\fancyhead[R]{\small\textit{Lecture 14}}
\fancyfoot[C]{\thepage}
\renewcommand{\headrulewidth}{0.5pt}
\renewcommand{\footrulewidth}{0.3pt}

% ì²« í˜ì´ì§€ëŠ” í—¤ë” ì—†ìŒ
\fancypagestyle{firstpage}{
    \fancyhf{}
    \fancyfoot[C]{\thepage}
    \renewcommand{\headrulewidth}{0pt}
}

%========================================================================================
% ìƒ‰ìƒ ì •ì˜ (íŒŒìŠ¤í…” í†¤ + ë‹¤í¬ëª¨ë“œ í˜¸í™˜)
%========================================================================================

\usepackage[dvipsnames]{xcolor}

% ë°ì€ ë°°ê²½ìš© íŒŒìŠ¤í…” ìƒ‰ìƒ
\definecolor{lightblue}{RGB}{220, 235, 255}      % ë¶€ë“œëŸ¬ìš´ íŒŒë‘
\definecolor{lightgreen}{RGB}{220, 255, 235}     % ë¶€ë“œëŸ¬ìš´ ì´ˆë¡
\definecolor{lightyellow}{RGB}{255, 250, 220}    % ë¶€ë“œëŸ¬ìš´ ë…¸ë‘
\definecolor{lightpurple}{RGB}{240, 230, 255}    % ë¶€ë“œëŸ¬ìš´ ë³´ë¼
\definecolor{lightgray}{gray}{0.95}              % ë°ì€ íšŒìƒ‰
\definecolor{lightpink}{RGB}{255, 235, 245}      % ë¶€ë“œëŸ¬ìš´ í•‘í¬
\definecolor{boxgray}{gray}{0.95}
\definecolor{boxblue}{rgb}{0.9, 0.95, 1.0}
\definecolor{boxred}{rgb}{1.0, 0.95, 0.95}

% ì§„í•œ ìƒ‰ìƒ (í…Œë‘ë¦¬/ì œëª©ìš©)
\definecolor{darkblue}{RGB}{50, 80, 150}
\definecolor{darkgreen}{RGB}{40, 120, 70}
\definecolor{darkorange}{RGB}{200, 100, 30}
\definecolor{darkpurple}{RGB}{100, 60, 150}

%========================================================================================
% ë°•ìŠ¤ í™˜ê²½ (tcolorbox) - 6ê°€ì§€ íƒ€ì…
%========================================================================================

\usepackage[most]{tcolorbox}
\tcbuselibrary{skins, breakable}

% 1. ê°œìš” ë°•ìŠ¤ (ê°•ì˜ ì‹œì‘ ë¶€ë¶„)
\newtcolorbox{overviewbox}[1][]{
    enhanced,
    colback=lightpurple,
    colframe=darkpurple,
    fonttitle=\bfseries\large,
    title=ğŸ“š ê°•ì˜ ê°œìš”,
    arc=3mm,
    boxrule=1pt,
    left=8pt,
    right=8pt,
    top=8pt,
    bottom=8pt,
    breakable,
    #1
}

% 2. ìš”ì•½ ë°•ìŠ¤
\newtcolorbox{summarybox}[1][]{
    enhanced,
    colback=lightblue,
    colframe=darkblue,
    fonttitle=\bfseries,
    title=ğŸ“ í•µì‹¬ ìš”ì•½,
    arc=2mm,
    boxrule=0.7pt,
    left=6pt,
    right=6pt,
    top=6pt,
    bottom=6pt,
    breakable,
    #1
}

% 3. í•µì‹¬ ì •ë³´ ë°•ìŠ¤
\newtcolorbox{infobox}[1][]{
    enhanced,
    colback=lightgreen,
    colframe=darkgreen,
    fonttitle=\bfseries,
    title=ğŸ’¡ í•µì‹¬ ì •ë³´,
    arc=2mm,
    boxrule=0.7pt,
    left=6pt,
    right=6pt,
    top=6pt,
    bottom=6pt,
    breakable,
    #1
}

% 4. ì£¼ì˜ì‚¬í•­ ë°•ìŠ¤
\newtcolorbox{warningbox}[1][]{
    enhanced,
    colback=lightyellow,
    colframe=darkorange,
    fonttitle=\bfseries,
    title=âš ï¸ ì£¼ì˜ì‚¬í•­,
    arc=2mm,
    boxrule=0.7pt,
    left=6pt,
    right=6pt,
    top=6pt,
    bottom=6pt,
    breakable,
    #1
}

% 5. ì˜ˆì œ ë°•ìŠ¤
\newtcolorbox{examplebox}[1][]{
    enhanced,
    colback=lightgray,
    colframe=black!60,
    fonttitle=\bfseries,
    title=ğŸ“– ì˜ˆì œ: #1,
    arc=2mm,
    boxrule=0.7pt,
    left=6pt,
    right=6pt,
    top=6pt,
    bottom=6pt,
    breakable,
}

% 6. ì •ì˜ ë°•ìŠ¤
\newtcolorbox{definitionbox}[1][]{
    enhanced,
    colback=lightpink,
    colframe=purple!70!black,
    fonttitle=\bfseries,
    title=ğŸ“Œ ì •ì˜: #1,
    arc=2mm,
    boxrule=0.7pt,
    left=6pt,
    right=6pt,
    top=6pt,
    bottom=6pt,
    breakable,
}

% 7. ì¤‘ìš” ë°•ìŠ¤ (importantbox - warningboxì™€ ìœ ì‚¬)
\newtcolorbox{importantbox}[1][]{
    enhanced,
    colback=boxred,
    colframe=red!70!black,
    fonttitle=\bfseries,
    title=âš ï¸ ë§¤ìš° ì¤‘ìš”: #1,
    arc=2mm,
    boxrule=0.7pt,
    left=6pt,
    right=6pt,
    top=6pt,
    bottom=6pt,
    breakable,
}

% 8. cautionbox (warningboxì™€ ë™ì¼)
\let\cautionbox\warningbox
\let\endcautionbox\endwarningbox

%========================================================================================
% ì½”ë“œ ë¸”ë¡ ì„¤ì • (ë°ì€ ë°°ê²½)
%========================================================================================

\usepackage{listings}

\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.95}

\lstset{
    basicstyle=\ttfamily\small,
    backgroundcolor=\color{lightgray},
    keywordstyle=\color{darkblue}\bfseries,
    commentstyle=\color{darkgreen}\itshape,
    stringstyle=\color{purple!80!black},
    numberstyle=\tiny\color{black!60},
    numbers=left,
    numbersep=8pt,
    breaklines=true,
    breakatwhitespace=false,
    frame=single,
    frameround=tttt,
    rulecolor=\color{black!30},
    captionpos=b,
    showstringspaces=false,
    tabsize=2,
    xleftmargin=15pt,
    xrightmargin=5pt,
    escapeinside={\%*}{*)}
}

% Python ì½”ë“œ ìŠ¤íƒ€ì¼
\lstdefinestyle{pythonstyle}{
    language=Python,
    morekeywords={self, True, False, None},
}

% SQL ì½”ë“œ ìŠ¤íƒ€ì¼
\lstdefinestyle{sqlstyle}{
    language=SQL,
    morekeywords={SELECT, FROM, WHERE, JOIN, GROUP, BY, ORDER, HAVING},
}

%========================================================================================
% ëª©ì°¨ ìŠ¤íƒ€ì¼ë§
%========================================================================================

\usepackage{tocloft}
\renewcommand{\cftsecleader}{\cftdotfill{\cftdotsep}}
\setlength{\cftbeforesecskip}{0.4em}
\renewcommand{\cftsecfont}{\bfseries}
\renewcommand{\cftsubsecfont}{\normalfont}

%========================================================================================
% í‘œ ë° ê·¸ë¦¼
%========================================================================================

\usepackage{graphicx}              % ì´ë¯¸ì§€
\usepackage{adjustbox}             % í‘œ/ë°•ìŠ¤ í¬ê¸° ì¡°ì ˆ

% í‘œ ìº¡ì…˜ ìŠ¤íƒ€ì¼
\usepackage{caption}
\captionsetup[table]{
    labelfont=bf,
    textfont=it,
    skip=5pt
}
\captionsetup[figure]{
    labelfont=bf,
    textfont=it,
    skip=5pt
}

%========================================================================================
% ìˆ˜í•™
%========================================================================================

\usepackage{amsmath, amssymb, amsthm}

% ì •ë¦¬ í™˜ê²½
\theoremstyle{definition}
\newtheorem{theorem}{ì •ë¦¬}[section]
\newtheorem{lemma}[theorem]{ë³´ì¡°ì •ë¦¬}
\newtheorem{proposition}[theorem]{ëª…ì œ}
\newtheorem{corollary}[theorem]{ë”°ë¦„ì •ë¦¬}
\newtheorem{definition}{ì •ì˜}[section]
\newtheorem{example}{ì˜ˆì œ}[section]

%========================================================================================
% í•˜ì´í¼ë§í¬
%========================================================================================

\usepackage[
    colorlinks=true,
    linkcolor=blue!80!black,
    urlcolor=blue!80!black,
    citecolor=green!60!black,
    bookmarks=true,
    bookmarksnumbered=true,
    pdfborder={0 0 0}
]{hyperref}

% PDF ë©”íƒ€ë°ì´í„°ëŠ” ê° ë¬¸ì„œì—ì„œ ì„¤ì •
\hypersetup{
    pdftitle={CS109A: ë°ì´í„° ê³¼í•™ ì…ë¬¸ - Lecture 14},
    pdfauthor={ê°•ì˜ ë…¸íŠ¸},
    pdfsubject={Academic Notes}
}

%========================================================================================
% ê¸°íƒ€ ìœ ìš©í•œ íŒ¨í‚¤ì§€
%========================================================================================

\usepackage{enumitem}              % ë¦¬ìŠ¤íŠ¸ ì»¤ìŠ¤í„°ë§ˆì´ì§•
\setlist{nosep, leftmargin=*, itemsep=0.3em}

\usepackage{microtype}             % íƒ€ì´í¬ê·¸ë˜í”¼ ê°œì„ 
\usepackage{footnote}              % ê°ì£¼ ê°œì„ 
\usepackage{url}                   % URL ì¤„ë°”ê¿ˆ
\urlstyle{same}

%========================================================================================
% ì‚¬ìš©ì ì •ì˜ ëª…ë ¹ì–´
%========================================================================================

% ê°•ì¡° í…ìŠ¤íŠ¸
\newcommand{\important}[1]{\textbf{\textcolor{red!70!black}{#1}}}
\newcommand{\keyword}[1]{\textbf{#1}}
\newcommand{\term}[1]{\textit{#1}}
\newcommand{\code}[1]{\texttt{#1}}

% ìš©ì–´ ì„¤ëª… (ì¸ë¼ì¸)
\newcommand{\defterm}[2]{\textbf{#1}\footnote{#2}}

% ì„¹ì…˜ ì‹œì‘ ì „ í˜ì´ì§€ ë¶„ë¦¬
\newcommand{\newsection}[1]{\newpage\section{#1}}

%========================================================================================
% ë¬¸ì„œ ì œëª© ìŠ¤íƒ€ì¼
%========================================================================================

\usepackage{titling}
\pretitle{\begin{center}\LARGE\bfseries}
\posttitle{\par\end{center}\vskip 0.5em}
\preauthor{\begin{center}\large}
\postauthor{\end{center}}
\predate{\begin{center}\large}
\postdate{\par\end{center}}

%========================================================================================
% ì„¹ì…˜ ì œëª© ê°„ê²©
%========================================================================================

\usepackage{titlesec}
\titlespacing*{\section}{0pt}{1.5em}{0.8em}
\titlespacing*{\subsection}{0pt}{1.2em}{0.6em}
\titlespacing*{\subsubsection}{0pt}{1em}{0.5em}

%========================================================================================
% ë©”íƒ€ ì •ë³´ ë°•ìŠ¤ ëª…ë ¹ì–´
%========================================================================================

\newcommand{\metainfo}[4]{
\begin{tcolorbox}[
    colback=lightpurple,
    colframe=darkpurple,
    boxrule=1pt,
    arc=2mm,
    left=10pt,
    right=10pt,
    top=8pt,
    bottom=8pt
]
\begin{tabular}{@{}rl@{}}
â–£ \textbf{ê°•ì˜ëª…:} & #1 \\[0.3em]
â–£ \textbf{ì£¼ì°¨:} & #2 \\[0.3em]
â–£ \textbf{êµìˆ˜ëª…:} & #3 \\[0.3em]
â–£ \textbf{ëª©ì :} & \begin{minipage}[t]{0.75\textwidth}#4\end{minipage}
\end{tabular}
\end{tcolorbox}
}

%========================================================================================
% ë
%========================================================================================


\begin{document}

\maketitle
\thispagestyle{firstpage}

\metainfo{CS109A: ë°ì´í„° ê³¼í•™ ì…ë¬¸}{Lecture 14}{Pavlos Protopapas, Kevin Rader, Chris Gumb}{Lecture 14ì˜ í•µì‹¬ ê°œë… í•™ìŠµ}


\thispagestyle{fancy} % ì²« í˜ì´ì§€ì—ë„ fancy ìŠ¤íƒ€ì¼ ì ìš©

\begin{summarybox}
ë³¸ ë¬¸ì„œëŠ” ë¡œì§€ìŠ¤í‹± íšŒê·€ì˜ ì‹¬í™” ì£¼ì œë¥¼ ë‹¤ë£¹ë‹ˆë‹¤.
ë‹¨ìˆœ ëª¨ë¸ì„ ë„˜ì–´ ë‹¤ì¤‘ ë¡œì§€ìŠ¤í‹± íšŒê·€, ìƒí˜¸ì‘ìš© í•­ì˜ í•´ì„, ì •ê·œí™”(Ridge)ë¥¼ í†µí•œ ê³¼ì í•© ë°©ì§€ ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤.

ë˜í•œ, ë¡œì§€ìŠ¤í‹± íšŒê·€ë¥¼ ë¶„ë¥˜(Classification) ë¬¸ì œì— í™œìš©í•˜ëŠ” ë°©ë²•,
ì¦‰ ê²°ì • ê²½ê³„(Decision Boundary)ì˜ ê°œë…ê³¼ ë‹¤ì¤‘ í´ë˜ìŠ¤(K>2) ë¶„ë¥˜ë¥¼ ìœ„í•œ OvR, ë‹¤í•­ ë¡œì§€ìŠ¤í‹± íšŒê·€(Softmax)ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.

ë§ˆì§€ë§‰ìœ¼ë¡œ, ë¶„ë¥˜ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” í•µì‹¬ ì§€í‘œì¸ í˜¼ë™ í–‰ë ¬(Confusion Matrix),
ë¯¼ê°ë„, íŠ¹ì´ë„, ROC ì»¤ë¸Œ, AUCì˜ ê°œë…ì„ ìƒì„¸íˆ ì„¤ëª…í•©ë‹ˆë‹¤.
\end{summarybox}

\tableofcontents

\newpage

%================================================================================
\section{ë¡œì§€ìŠ¤í‹± íšŒê·€ ë³µìŠµ (Review)}
%================================================================================

\subsection{ì™œ ë¡œì§€ìŠ¤í‹± íšŒê·€ì¸ê°€?}

ì„ í˜• íšŒê·€(Linear Regression)ëŠ” ì˜ˆì¸¡ ê°’ì´ ì—°ì†ì ì¸ ìˆ«ì(ì˜ˆ: ì§‘ê°’, ì˜¨ë„)ì¼ ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
í•˜ì§€ë§Œ ìš°ë¦¬ê°€ ì˜ˆì¸¡í•˜ë ¤ëŠ” ëŒ€ìƒ($Y$)ì´ 'ì„±ê³µ/ì‹¤íŒ¨', 'í•©ê²©/ë¶ˆí•©ê²©', 'ìƒì¡´/ì‚¬ë§'ì²˜ëŸ¼ ë‘ ê°€ì§€ ë²”ì£¼ ì¤‘ í•˜ë‚˜ë¼ë©´(Binary) ì„ í˜• íšŒê·€ëŠ” ì í•©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

ë¡œì§€ìŠ¤í‹± íšŒê·€(Logistic Regression)ëŠ” $Y$ê°€ ë²”ì£¼í˜•ì¼ ë•Œ,
íŠ¹íˆ ì´ì§„(binary) ë¶„ë¥˜ ë¬¸ì œì—ì„œ ì‚¬ìš©ë©ë‹ˆë‹¤.

\begin{warningbox}
  \textbf{ì˜¤í•´ í”¼í•˜ê¸°: ì„ í˜• íšŒê·€ë¥¼ ì´ì§„ ë¶„ë¥˜ì— ì“°ë©´ ì•ˆ ë˜ëŠ” ì´ìœ }

  ì„ í˜• íšŒê·€ ëª¨ë¸($Y = \beta_0 + \beta_1 X$)ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ë©´ ë‘ ê°€ì§€ í° ë¬¸ì œê°€ ë°œìƒí•©ë‹ˆë‹¤.
  \begin{itemize}
    \item \textbf{ë²”ìœ„ ì´ˆê³¼:} $Y$ëŠ” 0 ë˜ëŠ” 1ì´ì–´ì•¼ í•˜ì§€ë§Œ, ì„ í˜• íšŒê·€ì˜ ì˜ˆì¸¡ ê°’ì€ 1ì„ ë„˜ê±°ë‚˜ 0ë³´ë‹¤ ì‘ì•„ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” 'í™•ë¥ 'ë¡œ í•´ì„í•  ìˆ˜ ì—†ê²Œ ë§Œë“­ë‹ˆë‹¤.
    \item \textbf{ê´€ê³„ ì™œê³¡:} 0ê³¼ 1 ì‚¬ì´ì˜ ê´€ê³„ê°€ ì§ì„ ì (linear)ì´ë¼ê³  ê°€ì •í•˜ì§€ë§Œ, ì‹¤ì œë¡œëŠ” íŠ¹ì • ì§€ì ì—ì„œ ê¸‰ê²©íˆ ë³€í•˜ëŠ” Sì í˜•íƒœ(ë¹„ì„ í˜•)ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.
  \end{itemize}
\end{warningbox}

\subsection{í•µì‹¬ ì•„ì´ë””ì–´: í™•ë¥ ì„ ì§ì ‘ ëª¨ë¸ë§í•˜ì§€ ì•ŠëŠ”ë‹¤}

ë¡œì§€ìŠ¤í‹± íšŒê·€ëŠ” $P(Y=1|X)$ (ì„±ê³µ í™•ë¥ )ì„ ì§ì ‘ ëª¨ë¸ë§í•˜ëŠ” ëŒ€ì‹ ,
'í™•ë¥ 'ì„ ë³€í˜•í•œ **'ë¡œê·¸-ì˜¤ì¦ˆ(Log-Odds)'**ë¥¼ ì„ í˜• íšŒê·€ í˜•íƒœë¡œ ëª¨ë¸ë§í•©ë‹ˆë‹¤.

\begin{enumerate}
  \item \textbf{í™•ë¥  (Probability, $P$):} 0ê³¼ 1 ì‚¬ì´ì˜ ê°’. (ì˜ˆ: $P = 0.8$)
  \item \textbf{ì˜¤ì¦ˆ (Odds):} ì„±ê³µ í™•ë¥  / ì‹¤íŒ¨ í™•ë¥ . (ì˜ˆ: $Odds = 0.8 / (1-0.8) = 4$). 0ë¶€í„° ë¬´í•œëŒ€($\infty$)ê¹Œì§€ì˜ ê°’ì„ ê°€ì§‘ë‹ˆë‹¤. "ì‹¤íŒ¨ë³´ë‹¤ ì„±ê³µí•  í™•ë¥ ì´ 4ë°° ë†’ë‹¤"ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤.
      $$ \text{Odds} = \frac{P(Y=1)}{1 - P(Y=1)} = \frac{P}{1-P} $$
  \item \textbf{ë¡œê·¸-ì˜¤ì¦ˆ (Log-Odds) ë˜ëŠ” ë¡œì§“(Logit):} ì˜¤ì¦ˆì— ìì—°ë¡œê·¸($\ln$)ë¥¼ ì·¨í•œ ê°’. (ì˜ˆ: $\ln(4) \approx 1.386$). ìŒì˜ ë¬´í•œëŒ€($-\infty$)ë¶€í„° ì–‘ì˜ ë¬´í•œëŒ€($+\infty$)ê¹Œì§€ ëª¨ë“  ê°’ì„ ê°€ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
      $$ \text{Logit}(P) = \ln(\text{Odds}) = \ln\left(\frac{P}{1-P}\right) $$
\end{enumerate}

ë¡œê·¸-ì˜¤ì¦ˆëŠ” ì„ í˜• íšŒê·€ì˜ ì˜ˆì¸¡ ê°’ì²˜ëŸ¼ ë²”ìœ„ì— ì œí•œì´ ì—†ìœ¼ë¯€ë¡œ,
ì´ë¥¼ $X$ì— ëŒ€í•œ ì„ í˜• ê²°í•©ìœ¼ë¡œ ëª¨ë¸ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

$$ \underbrace{\ln\left(\frac{P}{1-P}\right)}_{\text{Log-Odds}} = \beta_0 + \beta_1 X_1 + \dots + \beta_p X_p $$

\subsection{ì¶”ì •: ìµœëŒ€ê°€ëŠ¥ë„ ì¶”ì •ë²• (MLE)}

ì„ í˜• íšŒê·€ëŠ” $\beta$ë¥¼ ì°¾ê¸° ìœ„í•´ ì˜¤ì°¨ì œê³±í•©(SSE)ì„ ìµœì†Œí™”í–ˆìŠµë‹ˆë‹¤ (ìµœì†Œì œê³±ë²•, OLS).

ë¡œì§€ìŠ¤í‹± íšŒê·€ëŠ” **ìµœëŒ€ê°€ëŠ¥ë„ ì¶”ì •ë²• (Maximum Likelihood Estimation, MLE)**ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
ì§ê´€ì ìœ¼ë¡œ, "ìš°ë¦¬ê°€ ê°€ì§„ ë°ì´í„°($Y$ ê°’ë“¤)ê°€ ê´€ì°°ë  í™•ë¥ ì„ ê°€ì¥ ë†’ê²Œ ë§Œë“œëŠ” $\beta$ ê°’ì„ ì°¾ì"ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤.

ì´ëŠ” ìˆ˜í•™ì ìœ¼ë¡œ **'ìŒì˜ ë¡œê·¸-ê°€ëŠ¥ë„(Negative Log-Likelihood)'**ë¥¼ ìµœì†Œí™”í•˜ëŠ” ê²ƒê³¼ ê°™ìœ¼ë©°,
ì´ ì†ì‹¤ í•¨ìˆ˜(Loss Function)ë¥¼ **'ì´ì§„ êµì°¨ ì—”íŠ¸ë¡œí”¼ (Binary Cross-Entropy)'**ë¼ê³  ë¶€ë¦…ë‹ˆë‹¤.

$$ \text{Loss (Binary Cross-Entropy)} = - \sum_{i=1}^{n} \left[ y_i \ln(p_i) + (1-y_i) \ln(1-p_i) \right] $$

* $y_i$: ì‹¤ì œ ê°’ (0 ë˜ëŠ” 1)
* $p_i$: ëª¨ë¸ì´ ì˜ˆì¸¡í•œ $P(Y_i=1)$ í™•ë¥ 

ì„ í˜• íšŒê·€ì™€ ë‹¬ë¦¬ í•œ ë²ˆì— í’€ë¦¬ëŠ” í•´(Closed-form solution)ê°€ ì—†ìœ¼ë©°,
**ê²½ì‚¬ í•˜ê°•ë²•(Gradient Descent)**ê³¼ ê°™ì€ ìˆ˜ì¹˜ ìµœì í™”(Numerical Optimization) ê¸°ë²•ì„ ì‚¬ìš©í•´ $\beta$ ê°’ì„ ë°˜ë³µì ìœ¼ë¡œ ì°¾ì•„ë‚˜ê°‘ë‹ˆë‹¤.

\newpage

%================================================================================
\section{ë¡œì§€ìŠ¤í‹± íšŒê·€ì˜ ì¶”ë¡  (Inference)}
%================================================================================

ì¶”ë¡ (Inference)ì˜ ëª©ì ì€ ëª¨ë¸ì˜ ê³„ìˆ˜($\beta$)ê°€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œì§€,
ê·¸ë¦¬ê³  ê·¸ ê°’ì˜ ì‹ ë¢°êµ¬ê°„(Confidence Interval)ì´ ì–´ëŠ ì •ë„ì¸ì§€ íŒŒì•…í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

\subsection{ì„ í˜• íšŒê·€(t-ë¶„í¬) vs ë¡œì§€ìŠ¤í‹± íšŒê·€(Z-ë¶„í¬)}

\begin{itemize}
  \item \textbf{ì„ í˜• íšŒê·€:} ì˜¤ì°¨í•­ì˜ ë¶„ì‚°($\sigma^2$)ì„ ë³„ë„ë¡œ 'ì¶”ì •'í•´ì•¼ í•©ë‹ˆë‹¤. ì´ ë¶ˆí™•ì‹¤ì„± ë•Œë¬¸ì— $\beta$ì˜ ë¶„í¬ëŠ” $t$-ë¶„í¬ë¥¼ ë”°ë¦…ë‹ˆë‹¤.
  \item \textbf{ë¡œì§€ìŠ¤í‹± íšŒê·€:} $Y$ê°€ ë² ë¥´ëˆ„ì´ ë¶„í¬($Y \sim \text{Bernoulli}(P)$)ë¥¼ ë”°ë¦…ë‹ˆë‹¤.
  ë² ë¥´ëˆ„ì´ ë¶„í¬ì˜ ë¶„ì‚°ì€ $P(1-P)$ë¡œ, í‰ê· ($P$)ì´ ì •í•´ì§€ë©´ ë¶„ì‚°ì´ 'ê³µì§œë¡œ' ê²°ì •ë©ë‹ˆë‹¤.
  ë³„ë„ë¡œ ì¶”ì •í•  ë¶„ì‚°ì´ ì—†ìœ¼ë¯€ë¡œ, (ìƒ˜í”Œì´ ì¶©ë¶„íˆ í¬ë‹¤ë©´) $\beta$ëŠ” ì •ê·œë¶„í¬($Z$-ë¶„í¬)ë¥¼ ë”°ë¥¸ë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.
\end{itemize}

\begin{examplebox}
  \textbf{Z-ë¶„í¬ vs t-ë¶„í¬ì˜ ì‹¤ì œì  ì°¨ì´}

  95\% ì‹ ë¢°êµ¬ê°„ì„ ê³„ì‚°í•  ë•Œ,
  \begin{itemize}
    \item \textbf{Z-ë¶„í¬ (ë¡œì§€ìŠ¤í‹±):} $\hat{\beta} \pm \mathbf{1.96} \times (\text{í‘œì¤€ì˜¤ì°¨})$
    \item \textbf{t-ë¶„í¬ (ì„ í˜•):} $\hat{\beta} \pm \mathbf{t_{\alpha/2, df}} \times (\text{í‘œì¤€ì˜¤ì°¨})$ (ë³´í†µ 2ì— ê°€ê¹Œìš´ ê°’)
  \end{itemize}
  ì‹¤ì œ ê³„ì‚°ì—ì„œëŠ” í° ì°¨ì´ê°€ ì—†ìœ¼ë‚˜, í†µê³„ì  ê·¼ê±°ê°€ ë‹¤ë¦…ë‹ˆë‹¤.
  `statsmodels` ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ì´ëŸ¬í•œ Z-í†µê³„ëŸ‰, p-value, ì‹ ë¢°êµ¬ê°„ì„ ì œê³µí•´ì¤ë‹ˆë‹¤.
\end{examplebox}

\subsection{ê³„ìˆ˜(Coefficient) í•´ì„í•˜ê¸°}

$\beta$ ê°’ ìì²´ë³´ë‹¤ $e^{\beta}$ (ì§€ìˆ˜ ë³€í™˜) ê°’ì´ í›¨ì”¬ ì§ê´€ì ì…ë‹ˆë‹¤.

\begin{itemize}
  \item $\boldsymbol{\beta_j}$: $X_j$ê°€ 1ë‹¨ìœ„ ì¦ê°€í•  ë•Œ, \textbf{ë¡œê·¸-ì˜¤ì¦ˆ(Log-Odds)}ê°€ $\beta_j$ë§Œí¼ \textbf{ì¦ê°€(ë§ì…ˆ)}í•©ë‹ˆë‹¤.
  \item $\boldsymbol{e^{\beta_j}}$: $X_j$ê°€ 1ë‹¨ìœ„ ì¦ê°€í•  ë•Œ, \textbf{ì˜¤ì¦ˆ(Odds)}ê°€ $e^{\beta_j}$ë§Œí¼ \textbf{ê³±í•´ì§‘ë‹ˆë‹¤(ë°°ìˆ˜)}.
\end{itemize}

ì´ë¥¼ **ì˜¤ì¦ˆë¹„ (Odds Ratio, OR)**ë¼ê³  ë¶€ë¦…ë‹ˆë‹¤.
* $e^{\beta_j} > 1$: $X_j$ê°€ ì¦ê°€í•˜ë©´ ì„±ê³µ ì˜¤ì¦ˆê°€ ì¦ê°€í•©ë‹ˆë‹¤. (ê¸ì •ì  ê´€ê³„)
* $e^{\beta_j} = 1$: $X_j$ëŠ” ì„±ê³µ ì˜¤ì¦ˆì™€ ê´€ê³„ ì—†ìŠµë‹ˆë‹¤. ($\beta_j=0$)
* $e^{\beta_j} < 1$: $X_j$ê°€ ì¦ê°€í•˜ë©´ ì„±ê³µ ì˜¤ì¦ˆê°€ ê°ì†Œí•©ë‹ˆë‹¤. (ë¶€ì •ì  ê´€ê³„)

\begin{examplebox}
  \textbf{ì˜ˆ: ì´ì§„ ì˜ˆì¸¡ë³€ìˆ˜ (Binary Predictor) í•´ì„ (ì„±ë³„ê³¼ ì‹¬ì¥ë³‘)}

  ì‹¬ì¥ë³‘ ë°œë³‘($Y=1$) ì—¬ë¶€ë¥¼ ì„±ë³„ë¡œ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ ê°€ì •í•©ë‹ˆë‹¤.
  (ê¸°ì¤€ ê·¸ë£¹: ë‚¨ì„±)

  $$ \ln(\text{Odds}) = \beta_0 + \beta_1 \cdot \text{Female} \quad (\text{Female}=1, \text{Male}=0) $$

  ì—¬ê¸°ì„œ $\beta_0 = 0.214$ì´ê³  $\beta_1 = -1.272$ë¼ê³  ê°€ì •í•©ì‹œë‹¤.

  \begin{enumerate}
    \item \textbf{$\beta_0$ì˜ í•´ì„ (ê¸°ì¤€ ê·¸ë£¹):}
        \begin{itemize}
          \item $\beta_0 = 0.214$ëŠ” \textbf{ë‚¨ì„±(ê¸°ì¤€ ê·¸ë£¹)}ì˜ \textbf{ë¡œê·¸-ì˜¤ì¦ˆ}ì…ë‹ˆë‹¤.
          \item $e^{\beta_0} = e^{0.214} \approx 1.24$ëŠ” \textbf{ë‚¨ì„±}ì˜ \textbf{ì˜¤ì¦ˆ}ì…ë‹ˆë‹¤.
          \item (ì‹¬ì¥ë³‘ì— ê±¸ë¦´ ì˜¤ì¦ˆê°€ ì•ˆ ê±¸ë¦´ ì˜¤ì¦ˆë³´ë‹¤ 1.24ë°° ë†’ë‹¤.)
        \end{itemize}

    \item \textbf{$\beta_1$ì˜ í•´ì„ (ì°¨ì´):}
        \begin{itemize}
          \item $\beta_1 = -1.272$ëŠ” \textbf{ì—¬ì„±}ì˜ ë¡œê·¸-ì˜¤ì¦ˆê°€ \textbf{ë‚¨ì„±}ë³´ë‹¤ 1.272ë§Œí¼ \textbf{ë‚®ë‹¤}ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤.
          \item $e^{\beta_1} = e^{-1.272} \approx 0.28$ì€ \textbf{ì˜¤ì¦ˆë¹„(Odds Ratio)}ì…ë‹ˆë‹¤.
          \item \textbf{í•´ì„:} "ë‹¤ë¥¸ ì¡°ê±´ì´ ê°™ë‹¤ë©´, ì—¬ì„±ì˜ ì‹¬ì¥ë³‘ ë°œë³‘ \textbf{ì˜¤ì¦ˆ}ëŠ” ë‚¨ì„±ì˜ \textbf{0.28ë°° (ì¦‰, 72\% ë‚®ë‹¤)}."
        \end{itemize}
  \end{enumerate}
\end{examplebox}

\begin{warningbox}
  \textbf{ì˜¤ì¦ˆ(Odds)ì™€ í™•ë¥ (Probability)ì„ í˜¼ë™í•˜ì§€ ë§ˆì„¸ìš”!}

  ê³„ìˆ˜($\beta$) í•´ì„ì€ í•­ìƒ \textbf{ì˜¤ì¦ˆ(Odds)} ê´€ì ì—ì„œ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤.
  "ì—¬ì„±ì˜ ì‹¬ì¥ë³‘ ë°œë³‘ \textit{í™•ë¥ }ì´ 72\% ë‚®ë‹¤"ë¼ê³  í•´ì„í•˜ë©´ \textbf{í‹€ë¦½ë‹ˆë‹¤}.
  í™•ë¥ ë¡œ ë³€í™˜í•˜ë ¤ë©´ $P = \text{Odds} / (1 + \text{Odds})$ ê³µì‹ì„ ì‚¬ìš©í•´ì•¼ í•˜ë©°,
  ì´ëŠ” ê¸°ì¤€ì´ ë˜ëŠ” í™•ë¥ (baseline probability)ì— ë”°ë¼ ê·¸ ë³€í™”ëŸ‰ì´ ë‹¬ë¼ì§€ëŠ” ë¹„ì„ í˜•(non-linear) ê´€ê³„ì…ë‹ˆë‹¤.
\end{warningbox}

\newpage

%================================================================================
\section{ë‹¤ì¤‘ ë¡œì§€ìŠ¤í‹± íšŒê·€ì™€ ìƒí˜¸ì‘ìš©}
%================================================================================

\subsection{ë‹¤ì¤‘ ë¡œì§€ìŠ¤í‹± íšŒê·€ (Multiple Logistic Regression)}

ì„ í˜• íšŒê·€ì™€ ë§ˆì°¬ê°€ì§€ë¡œ, ì—¬ëŸ¬ ê°œì˜ ì˜ˆì¸¡ ë³€ìˆ˜($X_1, \dots, X_p$)ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

$$ \ln\left(\frac{P}{1-P}\right) = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \dots + \beta_p X_p $$

\textbf{í•´ì„:} $\beta_j$ (ë˜ëŠ” $e^{\beta_j}$)ì˜ ì˜ë¯¸ëŠ”, \textbf{"ë‹¤ë¥¸ ëª¨ë“  ì˜ˆì¸¡ ë³€ìˆ˜($X_k$)ë¥¼ í†µì œ(ì¼ì •í•˜ê²Œ ìœ ì§€)í–ˆì„ ë•Œ"} $X_j$ê°€ 1ë‹¨ìœ„ ë³€í•  ë•Œì˜ ë¡œê·¸-ì˜¤ì¦ˆ (ë˜ëŠ” ì˜¤ì¦ˆë¹„) ë³€í™”ëŸ‰ì…ë‹ˆë‹¤.

\textbf{ì£¼ì˜ì :} ì„ í˜• íšŒê·€ì™€ ë™ì¼í•œ ë¬¸ì œë“¤, ì¦‰ \textbf{ë‹¤ì¤‘ê³µì„ ì„±(Multicollinearity)}ê³¼ \textbf{ê³¼ì í•©(Overfitting)}ì´ ì—¬ê¸°ì„œë„ ë™ì¼í•˜ê²Œ ë°œìƒí•©ë‹ˆë‹¤.

\subsection{ìƒí˜¸ì‘ìš© (Interactions)}

ìƒí˜¸ì‘ìš© í•­ì€ "í•œ ë³€ìˆ˜($X_1$)ê°€ ê²°ê³¼($Y$)ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì´ ë‹¤ë¥¸ ë³€ìˆ˜($X_2$)ì˜ ê°’ì— ë”°ë¼ ë‹¬ë¼ì§ˆ ë•Œ" ì‚¬ìš©ë©ë‹ˆë‹¤.

\begin{examplebox}
  \textbf{ì˜ˆ: ìƒí˜¸ì‘ìš© í•´ì„ (Age $\times$ Female)}

  ì‹¬ì¥ë³‘ ëª¨ë¸ì— ë‚˜ì´(Age)ì™€ ì„±ë³„(Female), ê·¸ë¦¬ê³  ë‘˜ì˜ ìƒí˜¸ì‘ìš© í•­ì„ ì¶”ê°€í•©ë‹ˆë‹¤.

  $$ \ln(\text{Odds}) = \beta_0 + \beta_1 \text{Age} + \beta_2 \text{Female} + \beta_3 (\text{Age} \times \text{Female}) $$

  ì´ ëª¨ë¸ì€ ì„±ë³„ì— ë”°ë¼ ë‘ ê°œì˜ ë‹¤ë¥¸ ëª¨ë¸ë¡œ ë¶„ë¦¬ë©ë‹ˆë‹¤.

  \begin{enumerate}
    \item \textbf{ë‚¨ì„± (Male, Female=0)ì˜ ëª¨ë¸:}
        Female=0ì„ ëŒ€ì…í•˜ë©´ $\beta_2, \beta_3$ í•­ì´ ì‚¬ë¼ì§‘ë‹ˆë‹¤.
        $$ \ln(\text{Odds})_{\text{Male}} = \beta_0 + \beta_1 \text{Age} $$
        (ì ˆí¸: $\beta_0$, ë‚˜ì´ì˜ ê¸°ìš¸ê¸°: $\beta_1$)

    \item \textbf{ì—¬ì„± (Female, Female=1)ì˜ ëª¨ë¸:}
        Female=1ì„ ëŒ€ì…í•©ë‹ˆë‹¤.
        $$ \ln(\text{Odds})_{\text{Female}} = \beta_0 + \beta_1 \text{Age} + \beta_2(1) + \beta_3 (\text{Age} \times 1) $$
        $$ \ln(\text{Odds})_{\text{Female}} = (\beta_0 + \beta_2) + (\beta_1 + \beta_3) \text{Age} $$
        (ì ˆí¸: $\beta_0 + \beta_2$, ë‚˜ì´ì˜ ê¸°ìš¸ê¸°: $\beta_1 + \beta_3$)
  \end{enumerate}

  \textbf{ê³„ìˆ˜ í•´ì„:}
  \begin{itemize}
    \item $\beta_1$: \textbf{ë‚¨ì„±(ê¸°ì¤€ ê·¸ë£¹)}ì˜ ë‚˜ì´ 1ì‚´ ì¦ê°€ì— ë”°ë¥¸ ë¡œê·¸-ì˜¤ì¦ˆ ë³€í™”ëŸ‰.
    \item $\beta_3$: \textbf{ì—¬ì„±}ì˜ ë‚˜ì´ 1ì‚´ ì¦ê°€ì— ë”°ë¥¸ ë¡œê·¸-ì˜¤ì¦ˆ ë³€í™”ëŸ‰ì´ \textbf{ë‚¨ì„± ëŒ€ë¹„} ì–¼ë§ˆë‚˜ \textbf{ë‹¤ë¥¸ì§€ (ê·¸ ì°¨ì´)}
  \end{itemize}
  ë§Œì•½ $\beta_3$ê°€ 0ì´ë¼ë©´ (ìƒí˜¸ì‘ìš©ì´ ì—†ë‹¤ë©´), ë‘ ê·¸ë£¹ì˜ ë‚˜ì´ ê¸°ìš¸ê¸°ëŠ” $\beta_1$ë¡œ ë™ì¼í•  ê²ƒì…ë‹ˆë‹¤.
\end{examplebox}

\newpage

%================================================================================
\section{ë¶„ë¥˜ì™€ ê²°ì • ê²½ê³„ (Classification \& Decision Boundary)}
%================================================================================

\subsection{í™•ë¥ ì—ì„œ ë¶„ë¥˜ë¡œ: ì„ê³„ê°’ (Threshold)}

ë¡œì§€ìŠ¤í‹± íšŒê·€ëŠ” $P(Y=1|X)$ í™•ë¥ ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
ì´ë¥¼ 0 ë˜ëŠ” 1ì˜ ë¶„ë¥˜ë¡œ ë°”ê¾¸ë ¤ë©´ **'ì„ê³„ê°’(Threshold)'** (ë³´í†µ 0.5)ì„ ì •í•´ì•¼ í•©ë‹ˆë‹¤.

\begin{itemize}
  \item $P(Y=1) \ge 0.5$ ì´ë©´, $\hat{Y} = 1$ (ì„±ê³µ)ìœ¼ë¡œ ë¶„ë¥˜í•œë‹¤.
  \item $P(Y=1) < 0.5$ ì´ë©´, $\hat{Y} = 0$ (ì‹¤íŒ¨)ë¡œ ë¶„ë¥˜í•œë‹¤.
\end{itemize}

\subsection{ê²°ì • ê²½ê³„ (Decision Boundary)}

ê²°ì • ê²½ê³„ëŠ” ëª¨ë¸ì˜ ì˜ˆì¸¡ì´ $\hat{Y}=0$ì—ì„œ $\hat{Y}=1$ë¡œ ë°”ë€ŒëŠ” ì§€ì , ì¦‰ $P(Y=1) = 0.5$ê°€ ë˜ëŠ” ì§€ì ì˜ ì„  ë˜ëŠ” ë©´ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.

$P=0.5$ë¼ëŠ” ê²ƒì€ ì–´ë–¤ ì˜ë¯¸ì¼ê¹Œìš”?
\begin{itemize}
  \item $P = 0.5$
  \item $\text{Odds} = P / (1-P) = 0.5 / 0.5 = 1$
  \item $\ln(\text{Odds}) = \ln(1) = 0$
\end{itemize}

ì¦‰, ê²°ì • ê²½ê³„ëŠ” **ë¡œê·¸-ì˜¤ì¦ˆê°€ 0ì´ ë˜ëŠ” ì§€ì **ì…ë‹ˆë‹¤.
$$ \ln(\text{Odds}) = \beta_0 + \beta_1 X_1 + \dots + \beta_p X_p = 0 $$

\begin{warningbox}
  \textbf{ì˜¤í•´ í”¼í•˜ê¸°: ê²°ì • ê²½ê³„ëŠ” í•­ìƒ ì„ í˜•ì¸ê°€?}

  ê²°ì • ê²½ê³„ê°€ ì„ í˜•(ì§ì„ , í‰ë©´)ì¼ ìˆ˜ë„ ìˆê³ , ë¹„ì„ í˜•(ê³¡ì„ , ê³¡ë©´)ì¼ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
  ì´ëŠ” \textbf{ëª¨ë¸ì— ì–´ë–¤ í•­ì„ í¬í•¨í–ˆëŠ”ì§€}ì— ë‹¬ë ¤ìˆìŠµë‹ˆë‹¤.

  \begin{itemize}
    \item \textbf{ì„ í˜• ê²½ê³„:}
        ëª¨ë¸ì´ $\beta_0 + \beta_1 X_1 + \beta_2 X_2 = 0$ ì²˜ëŸ¼ $X$ì˜ 1ì°¨í•­ë§Œ í¬í•¨í•˜ë©´,
        ê²°ì • ê²½ê³„ëŠ” $X_1$ê³¼ $X_2$ ê³µê°„ì—ì„œ \textbf{ì§ì„ }ì´ ë©ë‹ˆë‹¤.

    \item \textbf{ë¹„ì„ í˜• ê²½ê³„:}
        ëª¨ë¸ì´ $X_1^2, X_2^2, X_1 X_2$ ê°™ì€ \textbf{ë‹¤í•­ì‹(Polynomial) í•­ì´ë‚˜ ìƒí˜¸ì‘ìš© í•­}ì„ í¬í•¨í•˜ë©´,
        (ì˜ˆ: $\beta_0 + \beta_1 X_1 + \beta_2 X_2 + \beta_3 X_1^2 + \beta_4 X_2^2 = 0$)
        ê²°ì • ê²½ê³„ëŠ” $X_1$ê³¼ $X_2$ ê³µê°„ì—ì„œ \textbf{ê³¡ì„  (ì›, íƒ€ì› ë“±)}ì´ ë©ë‹ˆë‹¤.
  \end{itemize}
  ë¹„ì„ í˜• í•­ì„ ì¶”ê°€í•¨ìœ¼ë¡œì¨ ë¡œì§€ìŠ¤í‹± íšŒê·€ëŠ” ë³µì¡í•œ ë°ì´í„° íŒ¨í„´ë„ ë¶„ë¥˜í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤.
\end{warningbox}

% \begin{figure}[h]
%   \centering
%   % \includegraphics[width=0.45\textwidth]{linear_boundary.png}
%   % \includegraphics[width=0.45\textwidth]{nonlinear_boundary.png}
%   \caption{ê²°ì • ê²½ê³„ì˜ ì˜ˆì‹œ: (ì™¼ìª½) ì„ í˜• í•­ë§Œ ì‚¬ìš©í•œ ì„ í˜• ê²½ê³„, (ì˜¤ë¥¸ìª½) ë‹¤í•­ì‹ í•­ì„ ì‚¬ìš©í•œ ë¹„ì„ í˜• ê²½ê³„}
%   \label{fig:boundary}
% \end{figure}

\textit{[ì´ë¯¸ì§€ ì‚½ì…: ì™¼ìª½ì€ ì§ì„ ìœ¼ë¡œ ë‘ í´ë˜ìŠ¤ë¥¼ ë‚˜ëˆ„ëŠ” ê²°ì • ê²½ê³„, ì˜¤ë¥¸ìª½ì€ ê³¡ì„ (ì›í˜•)ìœ¼ë¡œ ë‘ í´ë˜ìŠ¤ë¥¼ ë‚˜ëˆ„ëŠ” ê²°ì • ê²½ê³„ë¥¼ ë³´ì—¬ì¤Œ]}

\newpage

%================================================================================
\section{ì •ê·œí™” (Regularization)}
%================================================================================

ëª¨ë¸ì— ë‹¤í•­ì‹ í•­ì´ë‚˜ ìƒí˜¸ì‘ìš© í•­ì„ ë§ì´ ì¶”ê°€í•˜ë©´ ê²°ì • ê²½ê³„ê°€ ë§¤ìš° ë³µì¡í•´ì§€ë©´ì„œ í›ˆë ¨ ë°ì´í„°ì—ë§Œ ê¼­ ë§ëŠ” \textbf{ê³¼ì í•©(Overfitting)}ì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

\textbf{ì •ê·œí™”(Regularization)}ëŠ” ëª¨ë¸ì˜ ë³µì¡ë„ì— í˜ë„í‹°ë¥¼ ë¶€ê³¼í•˜ì—¬ ê³¼ì í•©ì„ ë°©ì§€í•˜ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤.
ê³„ìˆ˜($\beta$)ì˜ í¬ê¸°ê°€ ë„ˆë¬´ ì»¤ì§€ì§€ ì•Šë„ë¡ ì†ì‹¤ í•¨ìˆ˜(Loss Function)ì— **í˜ë„í‹° í•­(Penalty Term)**ì„ ì¶”ê°€í•©ë‹ˆë‹¤.

\subsection{ì†ì‹¤ í•¨ìˆ˜ + L2 (Ridge) í˜ë„í‹°}

ë¡œì§€ìŠ¤í‹± íšŒê·€ì˜ ì†ì‹¤ í•¨ìˆ˜(Binary Cross-Entropy)ì— L2 í˜ë„í‹°(ê³„ìˆ˜ ì œê³±ì˜ í•©, Ridge)ë¥¼ ë”í•©ë‹ˆë‹¤.

$$ \text{Loss}_{\text{Regularized}} = \underbrace{\text{Loss (Binary Cross-Entropy)}}_{\text{ëª¨ë¸ì´ ë°ì´í„°ì— ì–¼ë§ˆë‚˜ ì˜ ë§ëŠ”ì§€}} + \underbrace{\lambda \sum_{j=1}^{p} \beta_j^2}_{\text{ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ ë³µì¡í•œì§€ (í˜ë„í‹°)}} $$

\begin{itemize}
  \item $\lambda$ (ëŒë‹¤): ì •ê·œí™”ì˜ ê°•ë„ë¥¼ ì¡°ì ˆí•˜ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„°ì…ë‹ˆë‹¤.
    \begin{itemize}
      \item $\lambda=0$: í˜ë„í‹° ì—†ìŒ (í‘œì¤€ ë¡œì§€ìŠ¤í‹± íšŒê·€).
      \item $\lambda \to \infty$: í˜ë„í‹°ê°€ ë§¤ìš° ê°•í•´ì ¸ ëª¨ë“  $\beta$ê°€ 0ì— ê°€ê¹Œì›Œì§‘ë‹ˆë‹¤ (ëª¨ë¸ì´ ë§¤ìš° ë‹¨ìˆœí•´ì§).
    \end{itemize}
  \item í˜ë„í‹°ëŠ” ë³´í†µ ì ˆí¸($\beta_0$)ì„ ì œì™¸í•˜ê³  ì ìš©ë©ë‹ˆë‹¤.
\end{itemize}

\begin{warningbox}
  \textbf{sklearnì˜ `C` íŒŒë¼ë¯¸í„° ì´í•´í•˜ê¸°}

  `sklearn.linear_model.LogisticRegression`ì—ì„œëŠ” $\lambda$ ëŒ€ì‹  $C$ë¼ëŠ” íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
  $C$ëŠ” $\lambda$ì˜ ì—­ìˆ˜ ($C = 1/\lambda$) ê°œë…ì…ë‹ˆë‹¤.

  \begin{itemize}
    \item \textbf{ë†’ì€ `C` (ì˜ˆ: $C=100$) $\implies$ ë‚®ì€ $\lambda$:}
        ì •ê·œí™”(í˜ë„í‹°)ê°€ \textbf{ì•½í•©ë‹ˆë‹¤}. ëª¨ë¸ì´ ë³µì¡í•´ì§€ê³  í›ˆë ¨ ë°ì´í„°ì— ë” ê°•í•˜ê²Œ ë§ì¶°ì§‘ë‹ˆë‹¤ (ê³¼ì í•© ìœ„í—˜).

    \item \textbf{ë‚®ì€ `C` (ì˜ˆ: $C=0.01$) $\implies$ ë†’ì€ $\lambda$:}
        ì •ê·œí™”(í˜ë„í‹°)ê°€ \textbf{ê°•í•©ë‹ˆë‹¤}. ëª¨ë¸ì´ ë‹¨ìˆœí•´ì§€ê³  $\beta$ ê³„ìˆ˜ë“¤ì´ 0ì— ê°€ê¹Œì›Œì§‘ë‹ˆë‹¤ (ê³¼ì†Œì í•© ìœ„í—˜).
  \end{itemize}

  ìµœì ì˜ $C$ ê°’ì€ \textbf{êµì°¨ ê²€ì¦(Cross-Validation)}ì„ í†µí•´ ì°¾ì•„ì•¼ í•©ë‹ˆë‹¤.
\end{warningbox}

\begin{lstlisting}[language=Python, caption={sklearnì—ì„œ Ridge ì •ê·œí™”ë¥¼ ì ìš©í•œ ë¡œì§€ìŠ¤í‹± íšŒê·€}, label={lst:sklearn_c}]
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV

# C ê°’ì´ ë‚®ì„ìˆ˜ë¡ ì •ê·œí™”ê°€ ê°•í•´ì§
logreg = LogisticRegression(penalty='l2', C=0.1)

# êµì°¨ ê²€ì¦ìœ¼ë¡œ ìµœì ì˜ C ê°’ì„ ì°¾ì„ ìˆ˜ë„ ìˆìŒ
params = {'C': [0.01, 0.1, 1, 10, 100]}
grid_search = GridSearchCV(LogisticRegression(penalty='l2'), params, cv=5)
# grid_search.fit(X_train, y_train)
# print(grid_search.best_params_)
\end{lstlisting}

\newpage

%================================================================================
\section{ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¡œì§€ìŠ¤í‹± íšŒê·€ (Multiclass)}
%================================================================================

$Y$ì˜ ë²”ì£¼ê°€ 3ê°œ ì´ìƒì¼ ë•Œ (ì˜ˆ: 'CS', 'Stat', 'Other') ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.
ì—¬ê¸°ì„œëŠ” ìˆœì„œê°€ ì—†ëŠ” **ëª…ëª©í˜•(Nominal)** ë²”ì£¼ë¥¼ ê°€ì •í•©ë‹ˆë‹¤.

\subsection{ì ‘ê·¼ë²• 1: One-vs-Rest (OvR)}

ê°€ì¥ ê°„ë‹¨í•˜ê³  ì§ê´€ì ì¸ ë°©ë²•ì…ë‹ˆë‹¤. ë²”ì£¼ê°€ $K$ê°œì¼ ë•Œ, $K$ê°œì˜ ë…ë¦½ì ì¸ ì´ì§„ ë¶„ë¥˜ê¸°ë¥¼ ë§Œë“­ë‹ˆë‹¤.

\begin{itemize}
  \item \textbf{ë¶„ë¥˜ê¸° 1:} 'CS' vs 'Not CS' (ì¦‰, 'Stat' + 'Other')
  \item \textbf{ë¶„ë¥˜ê¸° 2:} 'Stat' vs 'Not Stat' (ì¦‰, 'CS' + 'Other')
  \item \textbf{ë¶„ë¥˜ê¸° 3:} 'Other' vs 'Not Other' (ì¦‰, 'CS' + 'Stat')
\end{itemize}

ìƒˆë¡œìš´ ë°ì´í„°ê°€ ë“¤ì–´ì˜¤ë©´, 3ê°œì˜ ë¶„ë¥˜ê¸°ë¥¼ ëª¨ë‘ ëŒë ¤ì„œ ê°ê°ì˜ í™•ë¥ (ë˜ëŠ” ì ìˆ˜)ì„ ê³„ì‚°í•œ ë’¤, ê°€ì¥ ë†’ì€ í™•ë¥ (ì ìˆ˜)ì„ ë³´ì¸ í´ë˜ìŠ¤ë¡œ ì˜ˆì¸¡í•©ë‹ˆë‹¤. (`sklearn`ì˜ `multi_class='ovr'`)

\subsection{ì ‘ê·¼ë²• 2: ë‹¤í•­ ë¡œì§€ìŠ¤í‹± íšŒê·€ (Multinomial)}

OvRê³¼ ë‹¬ë¦¬, $K$ê°œì˜ í´ë˜ìŠ¤ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬í•˜ëŠ” ë‹¨ì¼ ëª¨ë¸ì„ ë§Œë“­ë‹ˆë‹¤.
í•˜ë‚˜ì˜ í´ë˜ìŠ¤(ì˜ˆ: 'Other')ë¥¼ **ê¸°ì¤€(Reference) í´ë˜ìŠ¤**ë¡œ ì •í•©ë‹ˆë‹¤.
ê·¸ë¦¬ê³  $K-1$ê°œì˜ ë¡œê·¸-ì˜¤ì¦ˆ ëª¨ë¸ì„ ë§Œë“­ë‹ˆë‹¤.

\begin{itemize}
  \item \textbf{ëª¨ë¸ 1:} $\ln\left(\frac{P(\text{CS})}{P(\text{Other})}\right) = \beta_0^{(1)} + \beta_1^{(1)} X + \dots$
  \item \textbf{ëª¨ë¸ 2:} $\ln\left(\frac{P(\text{Stat})}{P(\text{Other})}\right) = \beta_0^{(2)} + \beta_1^{(2)} X + \dots$
\end{itemize}
(`sklearn`ì˜ `multi_class='multinomial'`)

\subsection{Softmax: ì ìˆ˜ë¥¼ í™•ë¥ ë¡œ ë³€í™˜í•˜ê¸°}

OvRì´ë“  ë‹¤í•­ ë¡œì§€ìŠ¤í‹±ì´ë“ , ê° í´ë˜ìŠ¤ $k$ì— ëŒ€í•œ 'ì ìˆ˜(Score)' ë˜ëŠ” 'ë¡œì§“(Logit)' $s_k$ê°€ ë‚˜ì˜µë‹ˆë‹¤.
ì´ ì ìˆ˜ë“¤ì€ í•©ì³ë„ 1ì´ ë˜ì§€ ì•Šê¸° ë•Œë¬¸ì— í™•ë¥ ë¡œ ì‚¬ìš©í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤.

**ì†Œí”„íŠ¸ë§¥ìŠ¤(Softmax)** í•¨ìˆ˜ëŠ” ì´ ì ìˆ˜($s_k$)ë“¤ì„ 0ê³¼ 1 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ ë³€í™˜í•˜ê³ ,
ëª¨ë“  í´ë˜ìŠ¤ì˜ í™•ë¥  ì´í•©ì´ 1ì´ ë˜ë„ë¡ ì •ê·œí™”í•´ì¤ë‹ˆë‹¤.

$$ P(Y=k|X) = \frac{e^{s_k}}{\sum_{j=1}^{K} e^{s_j}} $$

\subsection{ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ (K>2)}

ì„ê³„ê°’ 0.5ëŠ” ë” ì´ìƒ ì˜ë¯¸ê°€ ì—†ìŠµë‹ˆë‹¤.
ëŒ€ì‹  **'ë‹¤ìˆ˜ê²° ì›ì¹™(Plurality Wins)'**ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
Softmaxë¥¼ í†µí•´ ê³„ì‚°ëœ $K$ê°œì˜ í™•ë¥  ì¤‘, **ê°€ì¥ ë†’ì€ í™•ë¥ ì„ ê°€ì§„ í´ë˜ìŠ¤**ë¡œ ì˜ˆì¸¡í•©ë‹ˆë‹¤.

ì˜ˆ: $P(\text{CS})=0.2$, $P(\text{Stat})=0.4$, $P(\text{Other})=0.4$
$\implies$ ê°€ì¥ ë†’ì€ í™•ë¥ ì´ 0.4ë¡œ ë‘ ê°œì´ë¯€ë¡œ, ë‘˜ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒ (í˜¹ì€ ì¶”ê°€ ê·œì¹™ ì ìš©).
ë§Œì•½ $P(\text{Stat})=0.41$, $P(\text{Other})=0.39$ ì˜€ë‹¤ë©´ $\hat{Y} = \text{Stat}$ë¡œ ì˜ˆì¸¡.

\newpage

%================================================================================
\section{ë¶„ë¥˜ ëª¨ë¸ í‰ê°€ (Evaluation)}
%================================================================================

ëª¨ë¸ì„ ë§Œë“¤ì—ˆë‹¤ë©´, ì´ ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ 'ì¢‹ì€' ë¶„ë¥˜ê¸°ì¸ì§€ í‰ê°€í•´ì•¼ í•©ë‹ˆë‹¤.
ë‹¨ìˆœ ì •í™•ë„(Accuracy)ëŠ” íŠ¹íˆ ë°ì´í„°ê°€ ë¶ˆê· í˜•í•  ë•Œ(ì˜ˆ: 99\%ê°€ 'No', 1\%ê°€ 'Yes') ì„±ëŠ¥ì„ ì˜¤í•´í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤.

\subsection{í˜¼ë™ í–‰ë ¬ (Confusion Matrix)}

ë¶„ë¥˜ ê²°ê³¼(ì˜ˆì¸¡)ì™€ ì‹¤ì œ ê°’ì„ $2 \times 2$ í‘œë¡œ ì •ë¦¬í•œ ê²ƒì…ë‹ˆë‹¤.

\begin{center}
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{cc|cc}
\multicolumn{2}{c}{} & \multicolumn{2}{c}{\textbf{ëª¨ë¸ì˜ ì˜ˆì¸¡ (Predicted)}} \\
\multicolumn{2}{c}{} & \textbf{Negative (0)} & \textbf{Positive (1)} \\ \hline
\textbf{ì‹¤ì œ ê°’} & \textbf{Negative (0)} & \textbf{True Negative (TN)} & \textbf{False Positive (FP)} \\
\textbf{(Actual)} & \textbf{Positive (1)} & \textbf{False Negative (FN)} & \textbf{True Positive (TP)} \\
\end{tabular}
\end{adjustbox}
\end{center}

\begin{itemize}
  \item \textbf{True Positive (TP):} \textbf{ì •ë‹µ.} ì‹¤ì œ Positive, ì˜ˆì¸¡ Positive (ì˜ˆ: ì•”í™˜ìë¥¼ ì•”ìœ¼ë¡œ ì§„ë‹¨)
  \item \textbf{True Negative (TN):} \textbf{ì •ë‹µ.} ì‹¤ì œ Negative, ì˜ˆì¸¡ Negative (ì˜ˆ: ê±´ê°•í•œ ì‚¬ëŒì„ ê±´ê°•í•˜ë‹¤ê³  ì§„ë‹¨)
  \item \textbf{False Positive (FP):} \textbf{1ì¢… ì˜¤ë¥˜.} ì‹¤ì œ Negative, ì˜ˆì¸¡ Positive (ì˜ˆ: ê±´ê°•í•œ ì‚¬ëŒì„ ì•”ìœ¼ë¡œ ì˜¤ì§„)
  \item \textbf{False Negative (FN):} \textbf{2ì¢… ì˜¤ë¥˜.} ì‹¤ì œ Positive, ì˜ˆì¸¡ Negative (ì˜ˆ: ì•”í™˜ìë¥¼ ê±´ê°•í•˜ë‹¤ê³  ì˜¤ì§„) $\leftarrow$ \textit{ì¹˜ëª…ì  ì˜¤ë¥˜!}
\end{itemize}

\subsection{í•µì‹¬ í‰ê°€ì§€í‘œ}

\begin{enumerate}
  \item \textbf{ë¯¼ê°ë„ (Sensitivity) = ì¬í˜„ìœ¨ (Recall) = True Positive Rate (TPR)}
      $$ \text{Sensitivity} = \frac{TP}{TP + FN} \quad (\text{ì‹¤ì œ Positive ì¤‘ ë§ì¶˜ ë¹„ìœ¨}) $$
      \textbf{ì˜ë¯¸:} ì‹¤ì œ ì•”í™˜ì ì¤‘ ëª‡ \%ë¥¼ 'ì•”'ì´ë¼ê³  ì¡ì•„ëƒˆëŠ”ê°€? (FNì„ ì¤„ì´ëŠ” ë° ì´ˆì )
      ì˜ë£Œ ì§„ë‹¨ì—ì„œ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤. (ë†“ì¹˜ë©´ ì•ˆ ë¨)

  \item \textbf{íŠ¹ì´ë„ (Specificity) = True Negative Rate (TNR)}
      $$ \text{Specificity} = \frac{TN}{TN + FP} \quad (\text{ì‹¤ì œ Negative ì¤‘ ë§ì¶˜ ë¹„ìœ¨}) $$
      \textbf{ì˜ë¯¸:} ì‹¤ì œ ê±´ê°•í•œ ì‚¬ëŒ ì¤‘ ëª‡ \%ë¥¼ 'ê±´ê°•'ì´ë¼ê³  íŒë‹¨í–ˆëŠ”ê°€? (FPë¥¼ ì¤„ì´ëŠ” ë° ì´ˆì )
      FPì˜ ë¹„ìš©ì´ í´ ë•Œ (ì˜ˆ: ìŠ¤íŒ¸ í•„í„°ê°€ ì¤‘ìš”í•œ ë©”ì¼ì„ ìŠ¤íŒ¸ ì²˜ë¦¬) ì¤‘ìš”í•©ë‹ˆë‹¤.

  \item \textbf{ì •ë°€ë„ (Precision) = Positive Predictive Value (PPV)}
      $$ \text{Precision} = \frac{TP}{TP + FP} \quad (\text{ì˜ˆì¸¡ Positive ì¤‘ ë§ì¶˜ ë¹„ìœ¨}) $$
      \textbf{ì˜ë¯¸:} ëª¨ë¸ì´ 'ì•”'ì´ë¼ê³  ì˜ˆì¸¡í•œ ì‚¬ëŒë“¤ ì¤‘, ì‹¤ì œ ì•”í™˜ìëŠ” ëª‡ \%ì¸ê°€?

  \item \textbf{False Positive Rate (FPR)}
      $$ \text{FPR} = 1 - \text{Specificity} = \frac{FP}{TN + FP} \quad (\text{ì‹¤ì œ Negative ì¤‘ í‹€ë¦° ë¹„ìœ¨}) $$
      \textbf{ì˜ë¯¸:} ê±´ê°•í•œ ì‚¬ëŒ ì¤‘ ëª‡ \%ë¥¼ 'ì•”'ì´ë¼ê³  ì˜ëª» ì˜ˆì¸¡í–ˆëŠ”ê°€?
\end{enumerate}

\begin{warningbox}
  \textbf{ë² ì´ì¦ˆ ì •ë¦¬ì™€ ë‚®ì€ ìœ ë³‘ë¥ (Prevalence) ë¬¸ì œ}

  ë² ì´ì¦ˆ ì •ë¦¬ì— ë”°ë¥´ë©´, ì•„ë¬´ë¦¬ í…ŒìŠ¤íŠ¸ê¸°(ëª¨ë¸)ì˜ ë¯¼ê°ë„(99\%)ì™€ íŠ¹ì´ë„(99\%)ê°€ ë†’ì•„ë„,
  ì§ˆë³‘ ìì²´ê°€ ë§¤ìš° í¬ê·€í•˜ë‹¤ë©´(ì˜ˆ: ìœ ë³‘ë¥  0.1\%),
  í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ 'ì–‘ì„±(Positive)'ì´ ë‚˜ì™”ë”ë¼ë„ ì‹¤ì œ í™˜ìì¼ í™•ë¥ (PPV/ì •ë°€ë„)ì€ ë§¤ìš° ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
  ëŒ€ë¶€ë¶„ì´ False Positiveì´ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.
\end{warningbox}

\newpage

\subsection{ì„ê³„ê°’(Threshold)ì˜ íŠ¸ë ˆì´ë“œì˜¤í”„}

ë¶„ë¥˜ ì„ê³„ê°’ 0.5ëŠ” ì ˆëŒ€ì ì¸ ê¸°ì¤€ì´ ì•„ë‹™ë‹ˆë‹¤.
ì„ê³„ê°’ì„ ì¡°ì ˆí•˜ë©´ ë¯¼ê°ë„(TPR)ì™€ íŠ¹ì´ë„(1-FPR)ê°€ ë°˜ë¹„ë¡€ ê´€ê³„(Trade-off)ë¡œ ì›€ì§ì…ë‹ˆë‹¤.

\begin{itemize}
  \item \textbf{ì„ê³„ê°’ì„ ë‚®ì¶”ë©´ (ì˜ˆ: 0.5 $\to$ 0.3):}
      ëª¨ë¸ì´ 'Positive'ë¼ê³  ë” ì‰½ê²Œ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
      TP $\uparrow$ (ì¢‹ìŒ), FN $\downarrow$ (ì¢‹ìŒ) $\implies$ \textbf{ë¯¼ê°ë„(TPR) ìƒìŠ¹}
      FP $\uparrow$ (ë‚˜ì¨), TN $\downarrow$ (ë‚˜ì¨) $\implies$ \textbf{FPR ìƒìŠ¹ (íŠ¹ì´ë„ í•˜ë½)}
      (ì˜ˆ: "ì¼ë‹¨ ì•”ì¼ ê°€ëŠ¥ì„±ì´ ì¡°ê¸ˆë§Œ ìˆì–´ë„ ì–‘ì„±ìœ¼ë¡œ íŒì •" $\to$ FNì€ ì¤„ì§€ë§Œ FPê°€ ëŠ˜ì–´ë‚¨)

  \item \textbf{ì„ê³„ê°’ì„ ë†’ì´ë©´ (ì˜ˆ: 0.5 $\to$ 0.7):}
      ëª¨ë¸ì´ 'Positive'ë¼ê³  ë” ë³´ìˆ˜ì ìœ¼ë¡œ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
      TP $\downarrow$ (ë‚˜ì¨), FN $\uparrow$ (ë‚˜ì¨) $\implies$ \textbf{ë¯¼ê°ë„(TPR) í•˜ë½}
      FP $\downarrow$ (ì¢‹ìŒ), TN $\uparrow$ (ì¢‹ìŒ) $\implies$ \textbf{FPR í•˜ë½ (íŠ¹ì´ë„ ìƒìŠ¹)}
      (ì˜ˆ: "í™•ì‹¤íˆ ì•”ì¼ ë•Œë§Œ ì–‘ì„±ìœ¼ë¡œ íŒì •" $\to$ FPëŠ” ì¤„ì§€ë§Œ FNì´ ëŠ˜ì–´ë‚¨)
\end{itemize}

\subsection{ROC ì»¤ë¸Œì™€ AUC}

\textbf{ROC ì»¤ë¸Œ (Receiver Operating Characteristic Curve)}ëŠ”
ì´ íŠ¸ë ˆì´ë“œì˜¤í”„ë¥¼ ì‹œê°í™”í•œ ê·¸ë˜í”„ì…ë‹ˆë‹¤.

\begin{itemize}
  \item \textbf{Xì¶•:} False Positive Rate (FPR) (1 - íŠ¹ì´ë„)
  \item \textbf{Yì¶•:} True Positive Rate (TPR) (ë¯¼ê°ë„)
\end{itemize}

ëª¨ë“  ê°€ëŠ¥í•œ ì„ê³„ê°’(0ì—ì„œ 1ê¹Œì§€)ì— ëŒ€í•´ (FPR, TPR) ì¢Œí‘œë¥¼ ì°ì–´ì„œ ì—°ê²°í•œ ì„ ì…ë‹ˆë‹¤.

% \begin{figure}[h]
%   \centering
%   % \includegraphics[width=0.6\textwidth]{roc_curve.png}
%   \caption{ROC ì»¤ë¸Œì˜ ì˜ˆì‹œ}
%   \label{fig:roc}
% \end{figure}

\textit{[ì´ë¯¸ì§€ ì‚½ì…: ROC ì»¤ë¸Œ ê·¸ë˜í”„. (0,0)ì—ì„œ (1,1)ì„ ì‡ëŠ” ì ì„ (Random Classifier),
(0,0)ì—ì„œ (0,1)ì„ ê±°ì³ (1,1)ë¡œ ê°€ëŠ” ì‹¤ì„ (Perfect Classifier),
ê·¸ë¦¬ê³  ê·¸ ì‚¬ì´ë¥¼ ì§€ë‚˜ëŠ” ì‹¤ì œ ëª¨ë¸ì˜ ROC ì»¤ë¸Œë¥¼ ë³´ì—¬ì¤Œ]}

\begin{itemize}
  \item \textbf{ì™„ë²½í•œ ëª¨ë¸ (Perfect Classifier):} (0, 1) ì§€ì ì„ í†µê³¼í•©ë‹ˆë‹¤ (FPR=0, TPR=1).
  \item \textbf{ëœë¤ ëª¨ë¸ (Random Classifier):} $y=x$ ëŒ€ê°ì„ . (FPRê³¼ TPRì´ ê°™ìŒ)
  \item \textbf{ì¢‹ì€ ëª¨ë¸:} ì»¤ë¸Œê°€ ì™¼ìª½ ìœ„ (0, 1)ì— ìµœëŒ€í•œ ê°€ê¹Œì´ ë¶™ìŠµë‹ˆë‹¤.
\end{itemize}

\textbf{AUC (Area Under the Curve)}ëŠ” ì´ ROC ì»¤ë¸Œ ì•„ë˜ì˜ ë©´ì ì…ë‹ˆë‹¤.
0ë¶€í„° 1 ì‚¬ì´ì˜ ê°’ì„ ê°€ì§€ë©°, ëª¨ë¸ì˜ ì „ì²´ì ì¸ ì„±ëŠ¥ì„ í•˜ë‚˜ì˜ ìˆ«ìë¡œ ìš”ì•½í•´ì¤ë‹ˆë‹¤.

\begin{itemize}
  \item \textbf{AUC = 1.0:} ì™„ë²½í•œ ë¶„ë¥˜ê¸°
  \item \textbf{AUC = 0.5:} ì“¸ëª¨ì—†ëŠ” ë¶„ë¥˜ê¸° (ëœë¤ ì¶”ì¸¡)
  \item \textbf{AUC $\approx$ 0.8\textasciitilde{}0.9:} ë§¤ìš° ì¢‹ì€ ë¶„ë¥˜ê¸°
\end{itemize}
AUCëŠ” ì„ê³„ê°’ì— ìƒê´€ì—†ì´ ëª¨ë¸ì´ 'Positive' ìƒ˜í”Œì„ 'Negative' ìƒ˜í”Œë³´ë‹¤ ì–¼ë§ˆë‚˜ ë” ë†’ì€ í™•ë¥ ë¡œ ì˜ˆì¸¡í•˜ëŠ”ì§€(ìˆœì„œ)ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì§€í‘œì…ë‹ˆë‹¤.

\newpage

%================================================================================
\section{í•µì‹¬ ìš©ì–´ ì •ë¦¬}
%================================================================================

\begin{table}[h]
\caption{ë¡œì§€ìŠ¤í‹± íšŒê·€ ë° ë¶„ë¥˜ í‰ê°€ í•µì‹¬ ìš©ì–´}
\label{tab:glossary}
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{ìš©ì–´} & \textbf{ì›ì–´} & \textbf{ì‰¬ìš´ ì„¤ëª…} \\ \midrule
ì˜¤ì¦ˆ & Odds & ì„±ê³µ í™•ë¥  / ì‹¤íŒ¨ í™•ë¥ . ($P/(1-P)$) \\
ë¡œê·¸-ì˜¤ì¦ˆ & Log-Odds & ì˜¤ì¦ˆì— ìì—°ë¡œê·¸ë¥¼ ì·¨í•œ ê°’. $\ln(P/(1-P)$). ë¡œì§€ìŠ¤í‹± íšŒê·€ì˜ $Y$ê°’. \\
ì˜¤ì¦ˆë¹„ & Odds Ratio (OR) & $X$ê°€ 1ë‹¨ìœ„ ì¦ê°€í•  ë•Œ, ì˜¤ì¦ˆê°€ ëª‡ 'ë°°' ë³€í•˜ëŠ”ì§€. ($e^\beta$) \\
MLE & Max Likelihood Estimation & ë°ì´í„°ê°€ ê´€ì°°ë  í™•ë¥ ì„ ìµœëŒ€í™”í•˜ëŠ” $\beta$ë¥¼ ì°¾ëŠ” ì¶”ì • ë°©ì‹. \\
ì´ì§„ êµì°¨ ì—”íŠ¸ë¡œí”¼ & Binary Cross-Entropy & ë¡œì§€ìŠ¤í‹± íšŒê·€ì˜ ì†ì‹¤ í•¨ìˆ˜(Loss Function). ìŒì˜ ë¡œê·¸-ê°€ëŠ¥ë„. \\
ê²°ì • ê²½ê³„ & Decision Boundary & ì˜ˆì¸¡ í´ë˜ìŠ¤ê°€ 0ì—ì„œ 1ë¡œ ë°”ë€ŒëŠ” ê²½ê³„ì„ . $P=0.5$ (ì¦‰, Log-Odds=0)ì¸ ì§€ì . \\
ì •ê·œí™” & Regularization & ëª¨ë¸ ë³µì¡ë„ì— í˜ë„í‹°ë¥¼ ì£¼ì–´ ê³¼ì í•©ì„ ë§‰ëŠ” ê¸°ë²•. (ì˜ˆ: L2/Ridge) \\
C íŒŒë¼ë¯¸í„° & C (in sklearn) & $1/\lambda$. ì •ê·œí™” ê°•ë„ì˜ ì—­ìˆ˜. (Cê°€ ë‚®ì„ìˆ˜ë¡ ì •ê·œí™”ê°€ ê°•í•¨) \\
OvR & One-vs-Rest & Kê°œ í´ë˜ìŠ¤ ë¶„ë¥˜ ì‹œ, Kê°œì˜ ì´ì§„ ë¶„ë¥˜ê¸°('A' vs 'Not A')ë¥¼ ë§Œë“¦. \\
ë‹¤í•­ íšŒê·€ & Multinomial Regression & Kê°œ í´ë˜ìŠ¤ ë¶„ë¥˜ ì‹œ, 1ê°œì˜ ê¸°ì¤€ í´ë˜ìŠ¤ ëŒ€ë¹„ K-1ê°œ ëª¨ë¸ì„ ë§Œë“¦. \\
ì†Œí”„íŠ¸ë§¥ìŠ¤ & Softmax & Kê°œì˜ í´ë˜ìŠ¤ ì ìˆ˜(Logit)ë¥¼ ì´í•© 1ì¸ í™•ë¥ ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜. \\
í˜¼ë™ í–‰ë ¬ & Confusion Matrix & ëª¨ë¸ì˜ ì˜ˆì¸¡(TP, FP, FN, TN)ê³¼ ì‹¤ì œ ê°’ì„ ë¹„êµí•œ í‘œ. \\
ë¯¼ê°ë„ (ì¬í˜„ìœ¨) & Sensitivity (Recall) & ì‹¤ì œ 'ì„±ê³µ' ì¤‘ ëª¨ë¸ì´ 'ì„±ê³µ'ìœ¼ë¡œ ë§ì¶˜ ë¹„ìœ¨. ($TP / (TP+FN)$) \\
íŠ¹ì´ë„ & Specificity & ì‹¤ì œ 'ì‹¤íŒ¨' ì¤‘ ëª¨ë¸ì´ 'ì‹¤íŒ¨'ë¡œ ë§ì¶˜ ë¹„ìœ¨. ($TN / (TN+FP)$) \\
ì •ë°€ë„ & Precision & ëª¨ë¸ì´ 'ì„±ê³µ' ì˜ˆì¸¡ ì¤‘ ì‹¤ì œ 'ì„±ê³µ'ì¸ ë¹„ìœ¨. ($TP / (TP+FP)$) \\
ROC ì»¤ë¸Œ & ROC Curve & ëª¨ë“  ì„ê³„ê°’ì— ëŒ€í•´ (FPR, TPR)ì„ ê·¸ë¦° ê·¸ë˜í”„. \\
AUC & Area Under the Curve & ROC ì»¤ë¸Œ ì•„ë˜ ë©´ì . 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ì€ ëª¨ë¸. \\ \bottomrule
\end{tabular}
\end{adjustbox}
\end{table}

\newpage

%================================================================================
\section{í•™ìŠµ ì²´í¬ë¦¬ìŠ¤íŠ¸}
%================================================================================

\begin{tcolorbox}{title=ìµœì¢… ì ê²€ ì²´í¬ë¦¬ìŠ¤íŠ¸}
\begin{itemize}
    \item[$\square$] ì™œ ì´ì§„ ë¶„ë¥˜ ë¬¸ì œì— ì„ í˜• íšŒê·€ ëŒ€ì‹  ë¡œì§€ìŠ¤í‹± íšŒê·€ë¥¼ ì¨ì•¼ í•˜ëŠ”ì§€ ì„¤ëª…í•  ìˆ˜ ìˆëŠ”ê°€?
    \item[$\square$] í™•ë¥ (P), ì˜¤ì¦ˆ(Odds), ë¡œê·¸-ì˜¤ì¦ˆ(Log-Odds)ì˜ ê´€ê³„ë¥¼ ì„¤ëª…í•  ìˆ˜ ìˆëŠ”ê°€?
    \item[$\square$] $\beta_1$ ê³„ìˆ˜ì™€ $e^{\beta_1}$ (ì˜¤ì¦ˆë¹„)ì˜ í•´ì„ìƒ ì°¨ì´ë¥¼ ì„¤ëª…í•  ìˆ˜ ìˆëŠ”ê°€?
    \item[$\square$] ë‹¤ì¤‘ ë¡œì§€ìŠ¤í‹± íšŒê·€ì—ì„œ $\beta_j$ë¥¼ í•´ì„í•  ë•Œ "ë‹¤ë¥¸ ë³€ìˆ˜ë¥¼ í†µì œí•  ë•Œ"ë¼ëŠ” ì¡°ê±´ì´ ì™œ ë¶™ëŠ”ì§€ ì•„ëŠ”ê°€?
    \item[$\square$] ìƒí˜¸ì‘ìš© í•­($X_1 \times X_2$)ì´ ëª¨ë¸ì˜ ì ˆí¸ê³¼ ê¸°ìš¸ê¸°ì— ê°ê° ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ ì„¤ëª…í•  ìˆ˜ ìˆëŠ”ê°€?
    \item[$\square$] ê²°ì • ê²½ê³„(Decision Boundary)ê°€ $P=0.5$ ì§€ì , ì¦‰ $X\beta=0$ ì§€ì ê³¼ ê°™ë‹¤ëŠ” ê²ƒì„ ìˆ˜í•™ì ìœ¼ë¡œ ìœ ë„í•  ìˆ˜ ìˆëŠ”ê°€?
    \item[$\square$] ëª¨ë¸ì— ë‹¤í•­ì‹ í•­ì„ ì¶”ê°€í•˜ë©´ ê²°ì • ê²½ê³„ê°€ ì–´ë–»ê²Œ ë³€í•˜ëŠ”ì§€ ì•„ëŠ”ê°€?
    \item[$\square$] ì •ê·œí™”(Regularization)ê°€ í•„ìš”í•œ ì´ìœ (ê³¼ì í•© ë°©ì§€)ë¥¼ ì„¤ëª…í•  ìˆ˜ ìˆëŠ”ê°€?
    \item[$\square$] sklearnì˜ `C` íŒŒë¼ë¯¸í„°ê°€ ë‚®ì„ìˆ˜ë¡ ì •ê·œí™”ê°€ ê°•í•´ì§„ë‹¤ëŠ” ê²ƒì„ ì•„ëŠ”ê°€? (C $\approx 1/\lambda$)
    \item[$\square$] ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ì˜ 2ê°€ì§€ ì ‘ê·¼ë²• (OvR, Multinomial)ì„ ë¹„êµí•  ìˆ˜ ìˆëŠ”ê°€?
    \item[$\square$] Softmax í•¨ìˆ˜ì˜ ì—­í• (ì ìˆ˜ $\to$ í™•ë¥  ì •ê·œí™”)ì„ ì•„ëŠ”ê°€?
    \item[$\square$] í˜¼ë™ í–‰ë ¬ì˜ TP, FP, FN, TNì´ ê°ê° ë¬´ì—‡ì„ ì˜ë¯¸í•˜ëŠ”ì§€ ì•„ëŠ”ê°€?
    \item[$\square$] ë¯¼ê°ë„(ì¬í˜„ìœ¨), íŠ¹ì´ë„, ì •ë°€ë„ì˜ ì°¨ì´ë¥¼ (ê³µì‹ê³¼ ì˜ë¯¸) ì„¤ëª…í•  ìˆ˜ ìˆëŠ”ê°€?
    \item[$\square$] ë¶„ë¥˜ ì„ê³„ê°’(Threshold)ì„ ì¡°ì ˆí•˜ë©´ ë¯¼ê°ë„ì™€ íŠ¹ì´ë„ê°€ ì–´ë–»ê²Œ ë³€í•˜ëŠ”ì§€(Trade-off) ì•„ëŠ”ê°€?
    \item[$\square$] ROC ì»¤ë¸Œì˜ Xì¶•(FPR)ê³¼ Yì¶•(TPR)ì´ ë¬´ì—‡ì´ë©°, AUCê°€ ì™œ 0.5ë©´ 'ëœë¤'ì¸ì§€ ì„¤ëª…í•  ìˆ˜ ìˆëŠ”ê°€?
\end{itemize}
\end{tcolorbox}

\newpage

%================================================================================
\section{1í˜ì´ì§€ ìš”ì•½ (1-Page Summary)}
%================================================================================

\begin{tcolorbox}{title=1. ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸}
$Y$ê°€ 0 ë˜ëŠ” 1ì¼ ë•Œ, ì„±ê³µ í™•ë¥  $P$ë¥¼ ì§ì ‘ ëª¨ë¸ë§í•˜ì§€ ì•Šê³ , \textbf{ë¡œê·¸-ì˜¤ì¦ˆ}ë¥¼ $X$ì— ëŒ€í•œ ì„ í˜•ì‹ìœ¼ë¡œ ëª¨ë¸ë§í•©ë‹ˆë‹¤.
$$ \ln\left(\frac{P}{1-P}\right) = \beta_0 + \beta_1 X_1 + \dots + \beta_p X_p $$
$\beta$ëŠ” MLE (ìµœëŒ€ê°€ëŠ¥ë„ ì¶”ì •ë²•) ë˜ëŠ” ê²½ì‚¬í•˜ê°•ë²•ìœ¼ë¡œ ì¶”ì •í•©ë‹ˆë‹¤.
\end{tcolorbox}

\begin{tcolorbox}{title=2. ê³„ìˆ˜ í•´ì„}
$\beta_j$ëŠ” $X_j$ê°€ 1ë‹¨ìœ„ ì¦ê°€í•  ë•Œ \textbf{ë¡œê·¸-ì˜¤ì¦ˆ}ì˜ \textbf{ë§ì…ˆ} ë³€í™”ëŸ‰ì…ë‹ˆë‹¤.
$e^{\beta_j}$ (ì˜¤ì¦ˆë¹„)ëŠ” $X_j$ê°€ 1ë‹¨ìœ„ ì¦ê°€í•  ë•Œ \textbf{ì˜¤ì¦ˆ}ì˜ \textbf{ê³±ì…ˆ} ë³€í™”ëŸ‰ (ë°°ìˆ˜)ì…ë‹ˆë‹¤.
\end{tcolorbox}

\begin{tcolorbox}{title=3. ê²°ì • ê²½ê³„ (Decision Boundary)}
ë¶„ë¥˜ ì„ê³„ê°’ì„ $P=0.5$ë¡œ ë‘ë©´, ê²°ì • ê²½ê³„ëŠ” $\ln(\text{Odds})=0$ì´ ë˜ëŠ” ì§€ì ,
ì¦‰ $\beta_0 + \beta_1 X_1 + \dots + \beta_p X_p = 0$ì´ ë©ë‹ˆë‹¤.
$X$ì˜ 1ì°¨í•­ë§Œ ìˆìœ¼ë©´ ì§ì„ , ë‹¤í•­ì‹/ìƒí˜¸ì‘ìš© í•­ì´ ìˆìœ¼ë©´ ê³¡ì„ ì´ ë©ë‹ˆë‹¤.
\end{tcolorbox}

\begin{tcolorbox}{title=4. ì •ê·œí™” (Regularization)}
ê³¼ì í•©ì„ ë§‰ê¸° ìœ„í•´ ì†ì‹¤ í•¨ìˆ˜(ì´ì§„ êµì°¨ ì—”íŠ¸ë¡œí”¼)ì— í˜ë„í‹° í•­ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
(L2/Ridge) $\text{Loss}_{\text{Reg}} = \text{Loss} + \lambda \sum \beta_j^2$.
`sklearn`ì—ì„œëŠ” $C \approx 1/\lambda$ë¥¼ ì‚¬ìš©í•˜ë©°, $C$ê°€ ë‚®ì„ìˆ˜ë¡ ì •ê·œí™”ê°€ ê°•í•©ë‹ˆë‹¤.
ìµœì ì˜ $C$ëŠ” êµì°¨ ê²€ì¦(Cross-Validation)ìœ¼ë¡œ ì°¾ìŠµë‹ˆë‹¤.
\end{tcolorbox}

\begin{tcolorbox}{title=5. ë‹¤ì¤‘ í´ë˜ìŠ¤ (Multiclass) K>2}
\begin{itemize}
    \item \textbf{OvR (One-vs-Rest):} Kê°œì˜ ì´ì§„ ë¶„ë¥˜ê¸°('A' vs 'Not A')ë¥¼ ë§Œë“¦.
    \item \textbf{Multinomial:} 1ê°œì˜ ê¸°ì¤€ í´ë˜ìŠ¤ ëŒ€ë¹„ K-1ê°œ ëª¨ë¸ì„ ë§Œë“¦.
    \item \textbf{Softmax:} Kê°œì˜ ì ìˆ˜(Logit)ë¥¼ ì´í•© 1ì¸ í™•ë¥ ë¡œ ë³€í™˜.
    \item \textbf{ë¶„ë¥˜:} ê°€ì¥ ë†’ì€ í™•ë¥ ì„ ê°€ì§„ í´ë˜ìŠ¤ë¡œ ì˜ˆì¸¡ (Plurality Wins).
\end{itemize}
\end{tcolorbox}

\begin{tcolorbox}{title=6. ë¶„ë¥˜ í‰ê°€ (Evaluation)}
\begin{itemize}
    \item \textbf{í˜¼ë™ í–‰ë ¬:} TP, FP, FN, TN
    \item \textbf{ë¯¼ê°ë„(TPR):} $\frac{TP}{TP+FN}$ (ì‹¤ì œ P ì¤‘ ì˜ˆì¸¡ P)
    \item \textbf{íŠ¹ì´ë„(TNR):} $\frac{TN}{TN+FP}$ (ì‹¤ì œ N ì¤‘ ì˜ˆì¸¡ N)
    \item \textbf{ì •ë°€ë„(PPV):} $\frac{TP}{TP+FP}$ (ì˜ˆì¸¡ P ì¤‘ ì‹¤ì œ P)
    \item \textbf{ROC ì»¤ë¸Œ:} Xì¶•=FPR (1-íŠ¹ì´ë„), Yì¶•=TPR (ë¯¼ê°ë„). ëª¨ë“  ì„ê³„ê°’ì—ì„œì˜ ì„±ëŠ¥ ì‹œê°í™”.
    \item \textbf{AUC:} ROC ì»¤ë¸Œ ì•„ë˜ ë©´ì . 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ì€ ë¶„ë¥˜ê¸°.
\end{itemize}
\end{tcolorbox}

\end{document}
