(3) 109 day 18 - YouTube
https://www.youtube.com/watch?v=ZjvbE_P9MEo

Transcript:
(00:01) Considering Wait. Yeah, I know. All right. Test test test. One, two, one, two. Can you hear me up
(01:09) there? Can you hear me? Too loud or good? Too low now? A little bit better. Okay. How about now? All right. I'm going to be speaking louder. Uh, welcome, welcome, welcome. I am your lecturer today, Pablo Protobabas. Uh, Kevin was supposed to be doing missing data or missing students. Where are the students? Uh, I'm counting. Before you leave today, you're going to have to sign a paper.
(01:46) Uh, I'm going to give you paper to sign. So, don't share the code today because if you get caught, you'll be reported. I promise you. If I see any IP leaving this room with a secret code, I'll report you. I already gave two warnings. So, do not dare to share the code today. Okay. Uh, so I am Pablo Protoas and I'll be lecturing. Today was supposed to be Kevin.
(02:09) Unfortunately, the family dog has to be put down and they're very distressed. So, I have 45 minutes to prepare the lecture. Uh, so be nice to me if it's not everything as smooth as uh possible. Couple of things while everybody's getting in. Uh, Kevin already pend the results for the midterm. I look at them last night.
(02:37) The mean and the median is exactly the same as last year, which tells me that you guys are learning better because last year they have open books. This year was no open book and the exam was a little bit more difficult this year. So I think that you're learning better. So that's good. Uh but let's keep moving. So today we're going to switch gear and we're going to start talking about decision trees.
(02:57) There's about five six lectures on that. I'm going to start very simple my usual style simple and easy so everybody follows me and then as we progress through this series of lectures I'm going to turn on the complexity of the of the concepts okay so today will be nice easy with couple of games just to get the basic ideas I think with decompress for all these basian things that you'll be doing start with something very simple ready to rock and roll yeah okay So, by the way, the the I still have photos from you. If you send me more, I'll use them for the next lectures. Today, it is the northern line
(03:38) lights. Can you see the nor How many of you have seen northern lights? By the way, believe it or not, it's one thing I never seen. So, it's kind of my dream to see the northern lights. This is the northern lights from Teton National Park. Can you hear me up there or shall I speak louder? Yeah, a little bit louder.
(03:58) I'm going to warm up as as I go. Okay, now better. All right. So, decision trees. Today we're going to be doing classification. Since we all ready for classification, we'll be doing classification. So, I'm going to continue with classification. So, let's look what I'm going to cover today.
(04:16) Uh first I'm going to start with the motivation. Then I'm going to be talking about decision trees proclassification. And then I'm going to of course start with the intuition. Just simple concepts as I said. Then we're going to talk about prediction using decision trees. And then I'm going to actually go the other way around. I'm going to tell you how you predict. And then I'm going to tell you how to build a decision tree.
(04:41) Okay? And then we're going to go part two on stopping criteria, which is the second part for today. All right. So let's start with the motivation. I start I'm back. Memes and gips are back, babe. So uh here it is. I like this one. You can read it. All right. So let's start uh thinking about classification, thinking about logistic regression.
(05:02) Okay, you can think about KN&N, but let's just think about logistic regression. On the right, we have some data. What I have is two predictors, two features, the longitude and latitude and we have some data points. Uh white means dry land and green means agricultural land.
(05:27) Okay, so logistic regression will work very nicely for this kind of data. Why? Because they're nicely separable, right? So the classes are well separated in the future space. You can see that these green ones are over here and the white ones are over here. Okay, good. The other thing that logistic regression will work very well is when the decision boundary has a very nice geometry, simple geometry.
(05:59) Let me explain this a little more. So when the model is changing his mind, let's think where does the model change his mind? changing his mind means I'm going to go from probability of y is equal to one higher than a half which you're going to translate into a prediction of label one. Yeah.
(06:30) To an area that the probability will be less than a half which will translate to label zero. But there is somewhere in that space that the model will change its mind. It will go from one to zero. And what do we call that? Very good decision bound. Okay. So how do we find the decision boundary? Let's just go step by step. It is when the probability of y = 1 is equal to the probability of y is equal to zero.
(06:58) Now or 1 minus probability of y= 1. That's it. now which is equivalent to the log odds being equal to zero. Okay, that's what defines the decision bound. Okay, this equation but you may wonder why. So I put some explanation there. Let's look at it. When P of Y is equal to a half and P of Y is equal to 0 is equal to a half. Sorry, let me repeat this.
(07:30) When the probability of y is equal to 1 is equal to the probability of y is equal to 0. Both probabilities have to be half. Right? And therefore the odds will be equal to this down here. The probability of y is = 1 and the probability of y is equal to 0 are the same. And therefore the odds are equal to one and the log of one is zero.
(08:02) And therefore since we know that the log odds are x * beta then that means the x * beta is equal to zero. Let me see faces. He knows that. Okay. Is it he or she? She she she knows. Okay. All right. So I hope that's clear. So let's look at example. So again remember I said if the data are such that the decision boundary is simple we get this kind of decision boundary.
(08:30) What does it mean? It means for example if it's a linear it means that something depends on something linearly. So let's look at it. So for this example I said the latitude is equal to8 time longitude plus.1. Now I'm rewriting it in this way and just want you to think about it. I I just put everything on one side. So I have a * longitude plus latitude minus.1 is equal to zero. Okay let's think about what are the betas here. What is beta 0.
(09:02) 1 negative.1 again and beta 1 let's say beta longitude is minus.8 and beta latitude is equal to 1. So you can see this is x * b sorry x * beta is equal to zero. Is that clear to everyone? Yeah. Okay. All right. So far so good. Yeah. All right. Now, this works very well. If you think about if the decision boundary we decide is a linear line, then if the data don't have a decision boundary that is linear, then what we run into troubles, right? So, let's look some examples. So, on the left, same kind of again I have agricultural land and dry land. And what
(09:49) we see is in the middle we have the green points and outside the white points. Can logistic regression model this? No. Your name John. Okay. John says no. But why not? Um is that decision boundary which go right to the middle and it would capture equally the agricultural land. So the distinctive value we say that be a straight line. There's no straight line you can separate two.
(10:22) What else can we do still stay within logistic regression? I give you the first letter P polomial. So we can do polomial regression and we get it done. Well maybe getting a circle is not so easy but it's principle. Now let's look at the one on the right. How about that? Can I get polomial or logistic regression to fit that? You're not smiling today? Most likely not, right? It's going to be really hard. We have to put some square roots to have two solutions. I mean, you can see this gets really tricky.
(11:07) Okay, let's push it a little bit further. How about this? This is even worse. I don't know if you can see the colors. The light is a little bit bright here from my taste but so okay. So at least now we identify where logistic regression won't do it for us. Okay. And I did say at the beginning of the course we're going to be playing this game.
(11:32) We get to the point and we say okay the model we have before is not adequate. Let's up. Okay. So we are at that state now. We know logistic regression would not do for this state. What shall I do? Let's come with a different model. Right? Okay. So this is just to summarize. Let's start with a different model. I said this we can do it to polomial. Uh so we like to have models. Let's just put the wish list. Oh, I got a coffee. Thank you Chris. You're my best friend.
(12:06) As I said for people they came late. Uh Kevin has some family emergencies. So I'm filling in and I didn't get a coffee in the morning. So I'm going to be sipping coffee every now and then. All right. So what would you like to have? Let's just put a wish list.
(12:25) What we want this model to do simple, right? So the first one I want to allow to do complex decision uh boundaries as we describe. Number two, I want it to be easy to interpret it. Kevin is not here, but he likes interpretations a lot and you do too. And we want to be able to explain our model. Number two. Number three, I want it to be straightforward and efficient.
(12:50) I don't want to be running neural networks and wait for two days to train. So we want simple, interpretable, and being able to do that. A lot of things in my wish list. The fourth one is I want a pony too. Sorry. So let's get an example that we do this all the time. Is there something wrong? No. Okay. So, let's get a very simple example that we all do and you do too all every day.
(13:18) You have a party to go to and you have two homeworks. What do you do in your when you think about a problem like that? Party is fun. Watching a TV show is fun. Doing the homework will get you a better grade. What do you do? you make some decisions. You say, "Oh, if I maybe push and start at 10:00, I have enough time, right? And then if I get there, I do this." Right? There's all these decisions we make.
(13:48) So, let's start with this very simple idea. We all can understand and we all have experience and then we're going to move it into uh machine learning mod. Okay. So, I'm going to show you the engineering flowchart which goes like that. transitions, jeeps, memes, and back. So, we ask a question. Does it move? Yes.
(14:14) Should it move? Yes. No problem, right? It moves and it should move. So, that's not a problem. Yep. So, no problem. Let's now go. Does it move? Yes. Should it move? No. We just use duct tape to stop it from moving. Okay. All right. So now let's go to the other branch. Does he move? No. Should it move? No.
(14:41) There's no problem, right? And if we go to the other branch, does it move? No. Should it? Yes. What should I do? WD40. You've seen this before. Yeah. Okay. WD40 to make it move. All right. So, let's look at this for a second and understand it. So, what do I do here? I make binary decisions at every step. Easy.
(15:06) There is no posteriors, there's no priors, there's no posterior predictives, there's nothing of that, right? I see your anxiety is going down. That's good. Okay. So, we have a very simple approach, something we're very familiar, and now we want to do it to formalize it and make it into a model. Okay. Okay. So, let's do that. So now if you think about this this simple flowchart has it is interpretable.
(15:37) I can explain why I used WD40 because it wasn't moving and it was supposed to move and I can explain why I used that K because it was moving and it wasn't supposed to. Right? Uh it has sufficiently complex decision boundaries because you can imagine this branches I can make a lot of different decisions. So I can just right I can make a very complex decision boundaries and we're going to see in a second how that's going to do and the decision boundaries are very linear.
(16:06) It's a yes or a no which it means it's very simple and mathematically very simple and computationally very simple. All right so I convince you. Yep. Okay. So that was the first part. Now let's go to the intuition. Now I'm going to get the this problem instead of flowchart I'm going to make it a little bit more realistic and then a little more realistic and eventually it's going to be a homework or something right all right so let's say we try to identify lemons and oranges right so two fruit and I need to decide if it's a lemon or an orange I have two predictors the height and the weight of the fruit so
(16:46) the first question I ask is the height larger than 6.5 Yes. Is the width larger than 9.5? Yes. What fruit is that? Let's see if you know your fruits. It's a lemon. Okay. The height is 6.5 and the width is 9.5. Yep. If it's the other way, it's an orange. Now, if the height is less than 6.5, but the width is bigger is a lemon.
(17:15) And no, it's an orange. Okay. It's a toy example. Okay. So, I didn't study lemons and oranges, but you got the idea, right? All right. So now we have a pretty nice flowchart. Making decisions, classifying, right? This is a classification problem. Lemons and orange, dogs or cats, usual stuff, right? All right. So now we have to define few things. First of all, we're talking about the top one.
(17:39) We're going to be calling it the root node. Uh the other one's going to call internal nodes. And at the very end, we're going to call them leaves. Right? This is a tree after all. Right? Left notes. Okay, leave notes is when we make a decision. Everything else is a final decision, right? So we say it's an orange, it's a lemon. That's a leaf node. Is the bottom of the tree.
(18:03) Well, the top of the tree, right? Upside down tree. Okay. Good. All right. All right. Now, let's look at it in two dimension more. Now we getting more to data to things you're used to. So what I'm going to do, I'm going to do the same story. So the first uh split I make is on the height, right? Height 6.
(18:30) 5 larger or smaller, that means I'm splitting the data. And this is very key into the I am splitting the because if it's larger than 6.5, I'm on the right. If it's less than 6.5, I'm on the left. So now I'm going to be dealing with the data only. If it's yes, I'm only dealing with the data on the right. And if it's smaller, I'm dealing with the data on the left. Okay, cool.
(18:57) So now the next decision I'm making is the width was larger than 9.5. Again, I'm splitting the data in this region, right? So if it's larger than 9.5, I'm only dealing with this data. If is longer boom smaller than 9.5 I'm dealing with the data in this region.
(19:21) So boom boom now what I did here I'm in this region here and I make a decision is a lemon why remember this is training data this is the examples I have it's a supervised learning that means I have examples right yep so why did I decide it's a lemon there because every example in that region is a lemon right so there's no doubt about Yep.
(19:49) So on the other side I'm deciding it's an orange because the majority of the examples I see in that region is an orange. Now let's go to the other side and it's going to be the same story. I split it again at six um with six. On the top we have lemons and on the bottom we have orange. Okay. Now you can see that as a way to model your data.
(20:15) I hope so. So there's two few questions here you may ask how did I decide to split how did I find this split we're going to talk later but for now I want you to understand this is the model that's it there's nothing more than that as I said there's no distribution there's nothing is just splitting right just splitting okay the only thing we have to do is to learn how to split but before we do that I want by the way this is the final decision boundary Right. Above this red line is lemon and below that red line is
(20:50) orange. But look at this decision boundary. It ends straight. Okay. It has jiggly shape. And you can imagine I can make a lot of decision boundaries as I want. I can go up, down, left, right. You can do anything you want, right? Yep. Okay. All right.
(21:15) So before I tell you how we split and we're going to go into details how we split, uh we're going to be talking about prediction. How do if I give you a tree, how do I predict if it's a lemon or orange, right? So let's say we have this this tree that I build using my training data. Remember the training data is when I decide it's a lemon or an orange. Yeah. Now let's see how I predict.
(21:38) So let's say I have an example which has a fruit that I don't know. It has height of 5.9 and width 5.8. What is it? So fast. Oh my god. All right, let's do step by step. Okay, how did you do that? All right. Is it bigger than 6.5? No. So, I'm going to the left. Is it larger than six? No. And it's an orange. Good job. I don't know how he did it so fast.
(22:07) Okay. But it is an orange, right? Is that clear? This traversing, this is called traversing the tree. Um, so it is an orange and this is called traversing the tree. Okay, so let's just recap for a second. We start with a very simple intuition, simple uh way of thinking. We kind of translate into a model.
(22:32) We make some splits and now we saw how to uh actually do inference or prediction. Yeah. Next is to ask the big question. How do I decide how to split? Right? For now, I gave you just gave it to you, right? But at one point, you're going to decide how to split. And this is going to be called training the model, right? The same way we train the models for logistic regression or linear regression and the likes by minimizing some loss. Here we're going to train the model to find the splitties.
(23:07) We're not going to have a loss exactly, but we're going to put some criteria. Okay, so splitting criteria is the next topic that I'm going to be talking. All right, so I have this data now. X1 and X2 is not orange. It's just general data. And the question is how do we split? Let's use let's think about it before I show you. Let's use our intuition.
(23:32) The best way to remember a model is to actually do it yourself and think about it and then it's just you're never going to forget. Okay. How would you split it? What what thing you will see you're going to try to measure? I mean I can do this there or here anywhere or I can just split that way.
(24:00) So I have many choices to split split so parallel one like horizontal down here. Good. How did you figure that? I mean the majority of the red orange triangle are above the majority of the blue square circles says look if I put it somewhere here the majority of oranges are above and the majority of oranges are below excellent let's quantify that the majority means let's give it a name Right.
(24:42) Maybe is a correct answers meaning that if I put it there and I call orange how many I make I have correct. Yeah. And if I below since the majority will be blue how many do I have correct? Right. Good. So one way of thinking about it is to put the split somewhere that I have the highest correct answers.
(25:07) Okay. Good. I agree now. I'm going to change the wording, Joavanni, but there's not a correct way of doing it. Right? But there's some guidelines. Let's look at the guidelines. Things that they make sense. Number one, I'm going to create regions that they're purer. The same thing you said in different words, right? Pure means the majority of the points will be the same, right? Okay. Number two, I don't want to have empty regions.
(25:44) That would make no sense, right? If I split it somewhere and there's nothing in the in one of the two regions, it makes no sense. Number three, it doesn't exist. If you look at ch actually changed it used to say you want it to be differentiable, but I insist that's not a condition.
(26:08) And now I think ChachiBT is following my instructions and he doesn't say differentiable. I think it's what is called the zero internet theorem or the Bablos internet theorem everything converges to my slides. So so uh it doesn't have to be differentiable. Okay. And even though in some books they would say you have to be differentiable it does not have to be different. Okay. So we have these two things. Let's do it. Okay. Easy peasy.
(26:32) So Jovanni when you say I want to find a line that is the most pure means you're gonna try everything right perfect okay so I'm gonna go again I promise you today is going to be slow and nice so you can digest it let's go step by step right enjoying it all right so let's say I split there right I have two regions region to the left region one and one to the right let's measure the classification error Okay, the classification is going to tell me how many errors I make, right? The percentage of the errors I make. Okay, cool. Easy. So, it's the number of
(27:12) minority class data divided by the total number of days. So, in the region two, which is here, is basically is the blue because the blue is the minority divided by the total number of data points. I'm going to do some little manipulations here. Pay just follow me line by line per leader line by line to get it.
(27:43) So instead of saying the number of errors divided by the total number, I can easily say one minus the number of majority divided by the total number. Okay, that should be clear. Um, so I'm going to use a Greek letter because I like Greek letters. So I'm going to call it s or c. Okay, whatever you prefer. Uh where is panos c. Okay. All right.
(28:10) So it's one minus c of the orange versus in the region two meaning the majority because I do one minus the correct ones. Yeah. Okay. So since in every region I won't know the majority I don't want to go and put orange. So I'm going to do the maximum over all the classes of that because the majority will have the maximum proportion. Right? All right.
(28:36) So now I have one minus maximum of that ratio. Uh okay this is for notes for you when you study. So let's do in this in this example in region one we have six blue and zero oranges. So 1 minus the maximum of the orange uh which is 0 / 6 here and this is the other class the blue 6 over 6. Do you do you see that right? Yeah. So that means the maximum of that is 6 / 6 which is 1. 1 - 1 is zero.
(29:12) Look that region is very pure. So in some ways what I do I measure impurity right zero impurity it means so zero purity maximum impurity yeah let's go to region two now I have 1 minus maximum of the two classes the blue is 5 over 13 the orange is 8 over3 so the maximum is 8 over 13 1 minus 8 over 13 is 5 over 13 is 38 all right So now what I'm going to do, I can move this threshold left to right and keep measuring this and I can move it up and down.
(29:55) I can try everything every possible scenario and I find which way I should split and where this way or this way and where. Okay, cool. So if we have pip predictors or features and k classes suppose we select a bit predictor to split we can assess the quality of the split by calculating this classification error okay which is this now I can also um maximize this right so this is my final metric I do now notice and I'm not before I go notice one thing when we do linear regression or logistic regression what did we do let's remind ourselves of
(30:37) the basic steps of machine learning. We started with a model. The next thing we did what? We defined the the loss, right? And then we did what? We minimize the loss, right? You should shake your head. Say yes, we know that, right? Okay, let's repeat. Model loss, minimize the loss. That's that's all there is to it.
(31:04) Right? Notice here I don't have an exact loss that I minimize but I do if you think about it this classification error I minimize it in a greedy way because at every step I'm finding the split that will minimize the classification error right and I keep doing it so I don't have one loss that I'm going to minimize I do it at every step at every step.
(31:27) And that's called greedy. Remember we talk once upon that if I don't do the full minimization at every step I trying to do the best I can that's what we define as greedy algorith okay so I do that I minimize some loss but instead of writing all the the loss down and try every possible scenario which is going to be intractable I just do it step by step right cool all right now let's do another example again I split where the red vertical line is let's calculate the classification error on R1. I have only one blue and zero orange. So now I have zero there of
(32:06) course is very pure. And on the other side I do my calculation. I have three blues out of 17 and 14 oranges out of 17. One minus that is 3 over 17.8. Okay, easy to follow. But now I have a question. So R1 has a small error than R2. Does that mean this is a good split? Do you see any problem with that? And time coffee time slide problem.
(32:56) You see anybody sees it? What else should I consider here? One only has one point. R2 has a lot of points. Yes. You said the regions are disproportionate in the numbers. Maybe we should weigh each region based on the number of points. That's the answer. So what we do, we wait region one by the n1 divide by n and region two by n2 divide by n and we just wait uh average them.
(33:35) Does that make sense to everyone? Yeah. So eventually what I'm going to do I'm going to find the minimum of that with respect to the predictor P and for each predictor the threshold. The threshold is the value we do. Okay, that's it. Lecture is over. We're done. That's the basic idea. The rest are details. Let me just summarize. This is the basic idea.
(34:03) We find a criteria that defines purity and we're just doing the split by waiting average over two regions. Very simple. The the splitting we'll do is always binary. Could do more, but no, we're going to stay to binary. Um and we just find where to split which predictor where to split and then at the end of the day we use the data to find that splitting.
(34:28) At the end of the day we have a tree which is my train model which I can use to do prediction. How do we do prediction? Traversing the tree. Okay. I know it's simple, right? Underwhelming. I like it. All right. But um there's other ways. For some reason, classification error is not something we use. There's better ways of doing it.
(34:57) Let's talk about two more ways of doing different criteria. Remember, I still have to have my conditions. I want a criteria that kind of measures the purity of each region and I want it to be simple. Those are my two criteria. Let's find another one. Right? Classification error is one way of doing it. But there's others. Let's look at another one called the genie index.
(35:21) Assume we have predictors clay classes. We can assess the quality of the split using the genie index. Genie index measures I keep forgetting what is gene index measure purity or impurity. Impurity. All right. So the gene index the way we define it now is one minus the sum of the square of this ratio right of every class.
(35:46) Now we're going to spend a little bit 20 seconds to think about that. Before I have one minus the max over all the classes. Here there is no max. I have the sum of the squares. The question is, what is the effect of squaring the proportion of each class? And you can see the symbol is coming. It's coming. Oh, where is my sound? See, I haven't taught for a while and I forgot.
(36:26) I'll do it the traditional way. All right. So can you hear the dramatic music? It's f. Okay. So remember we play these games. Today we have a double double attendance freedom uh waiver for any volunteer. If no but you hold on Jacob. Anybody else? Let's take one person from this region. No, no. All right. Introduce yourself. I'm Hugh.
(37:12) I'm in first year in the M state data science masters. Hi, Hugh. Any fun fact we should know about you? I know you take AC25 too, right? Yeah, I'm in 215. Um, fun fact, uh, I used to be a semi-professional Overwatch player. Professional what? semi-professional Overwatch player, which is a it's a video game.
(37:31) It's what I was doing during CO. You're a video gamer. I was. Good. And you stopped because you study now, right? Oh, yeah. For the most part. Good. All right. So, here here's a question. Which of the following statements best describes the effect of squaring the proportions of each class when calculated? Generally, it's a double one because a little bit tricky, right? So, we need to think about that, right? Uh the first one is squaring the proportion magnifies the influence of the majority classes in a region thereby overstating their significance. So I'm
(38:06) going to go back. Let me put all the options. The squaring process accentuate accentuates the contrast between pure regions and mixed ones enabling the index to better differentiate between quality splits. Number three, the act of squaring them diminishes the index sensitivity to minor fluctuation class distribution make it more stable.
(38:33) And number four, squaring the proportions directly correlates the gene index with the count of predictors P bias in the selection split. I have to make an confession. I wrote the quiz and then I asked Chikin to make them worthy just to confuse you even more. All right. So let's think one by one. You just remember what we have with classification.
(38:55) We have one minus the max over this s over all the case, right? All the class. Now I change it one minus the square. What does the square would do? So let's say I have actually I'm going to let you think first. Um I think yeah the square would probably accentuate the the differences between like larger and smaller uh majorities.
(39:21) And even if I add the minority into the thing, it doesn't matter so much, right? Yeah. Okay. Now, uh the answer sounds correct, but I'm going to ask everybody, it would be a good idea to put your computers down every now and then and pay attention to me. You're not even Hello. Just pay attention every now and then. Close your computer just for a minute. Okay.
(39:50) Now here you have seen another function in this class that does the same thing. It takes the values and finds the maximum without actually putting the max there. I give you the first letter S. I give you another one O. I give you the third one F. Soft max. Soft max. Why is it called soft max? These have exponentials. Why is it called soft max? Because it finds the maximum without having to actually doing the operation of maximum. Right? Here we find the maximum by squaring it.
(40:27) And if you think about one, if you take exponential, you expanding as a tailor, you get the square term as the first term or the second term. Right? So therefore these if you put it to the fourth power, you even more accentuate the maximum.
(40:47) Right? Now why don't we like to have the operation maximum? Because operation maximum is computationally expensive. This is much easier. Computers like to multiply and add instead of doing max. Okay. So your final answer with uh A. I think you read B. You did say exceptionate, right? Yeah. Wait. Yeah. I'll say yes. Yeah, for sure. I thought you said B. I give it to you. It's good enough.
(41:17) You're I I mean, but like a kind of feels like it's also saying it is. Yes, it's a little bit confusing. Chachib make it more confusing, but uh thank you very much. Um good job. Um yeah. All right. So, I think now we understand why the genie index actually works as the maximum, right? is nice is basically is the same one and blah blah blah. Okay, let's move to the next.
(41:51) All right, so this is the genie index. Now we're going to do the same operations left and right. R1 and R2. R1, the gen index is one minus the square of those sides is going to be zero again, right? Yep. Because I have 6 over 6 is one and the other is zero. So that will give me 6 over 6 which is one. One minus one is zero. Boom. Zero. Good. Pure gene index gives me zero.
(42:16) Right? That's good. Now let's look at the other one. Let me not read these numbers. Uh but you can look and I get 47. If you remember for the thing was 30 something. So it's a little bit higher. Keep that in mind because I'm going to come back to however it seems that gen index follows actually the purer it is the smaller the genie index is okay cool now what if is half and half let's think about if it's half and half it will be half square plus half square is a half so gene index will be half that's good so
(42:57) the highest gene index I'm going to get is half this is going to is zero. So somewhere between those. Okay. And the mclassification error if you do the calculation in your head is going to be half again. It's go from zero to a half and back. Right? That's all are the range. Okay. Uh I have it actually compared to 3 classification.
(43:23) So it does go from zero to a half but it's not exactly the same number. It is monotonic which I like it. All is good. Okay. So let's do do the same thing. Of course, I'm going to weight average them based on the number of examples I have in the region and I'm going to do the the minimization over all predictors and every possible threshold. Yeah. Good. Yeah. All right.
(43:54) Uh there's one more that we sometimes call is based on information theory is called the entropy. Many of you have in some way or another been introduced to the idea of entropy. Entropy measures how chaotic the system is or how pure impure it is, right? Kind of measures how many bits do I have to get it very pure. This is the Shannon information.
(44:16) But it has the following formula. CX times the log of two of CIX. Okay. Okay. But this doesn't tell us anything, right? Just a formula. Let's just actually see a little bit how the the intuition what I do here. I have first the the points mixed and I see what the entropy is starts about one and then as I separate them now I have nicely separate two regions that will give me entropy zero because they are nicely separate and pure in each region. Okay.
(44:48) All right. So again the same story the entropy is that it's going to be the sum over the k and we can do the same calculation let's see if I have a pure region the entropy turns out to be zero that's good pure regions give me zero classification error gives me zero genie index it gives me zero entropy now if I look at the other side now my gen my entropy here is 1.38 before I said the maximum I could get is half for one.
(45:21) So now let's we do the same thing and we're going to calibrate in a second just to see in a second. Okay. So so far we see classification error. I think we all understand gene index. Let's just go slowly in the check information theory or entropy is a little bit more confusing but it's another measure. Think about it.
(45:42) Another measure of opurity right? So this is what I get at then. And now let's see. I don't know if you can guys see um it's very hard to see the blue one is when the purity is zero I get zero mclassification or and zero gene index and zero entropy right that makes sense if we have very pure in the middle here is where I have half and half totally half and half the mclassification error is a half the genie index a half and the entry now I calibrate it to be a half here so I divide by the one and I get 0.
(46:25) 5 just to match them right now what I want you to pay attention the other end here is when purity is one means you just inverted flipping everything I go back to pure pure right and therefore is zero now what I want you to see and it's very hard to see on this maybe you can look at it on your PDF is that if you look at the blue line is a straight line like this.
(46:51) The green one is over here and the red one is over here. The green is the genie. The blue is a classification error and the red is the entropy. Now what it means is that if I have a little bit of impurity, which one is going to penalize my model the most? misclassification error entropy or gene index. Let's look at let's look at somewhere 02 I have purity of 02 which one penalize more entropy okay so keep that in mind entropy is the one that is less forgiving for a little bit of impurity gene index is the second less forgiving and mclassification error is the most forgiving so if you make few mistakes it's okay right think about Chris Pablo
(47:47) and Kevin who is more forg give it. I don't want to know the answer to this. Okay. Um Okay. So that's they so each one of them does exactly the same thing in a way. It promotes purity. However, um mclassification error is the most forgiving meaning that if you have a little bit impurity won't penalize it.
(48:09) It's a and then gene index and then the entropy. Three three of these we can choose right which one we want. All right, this is to go back to what I was saying is a greedy algorithm. I don't have one loss that I put um every data and I just trying to find out what is the best possible splits. Why is that? I said it before.
(48:36) Let's think about it because there is infinite number of splits I can do, right? I can split like this and this. Then I can split like this. I can split again like this. I can split like that. I there's infinite possible splits I can make there's infinite number of possible trees I can make right so in order to avoid searching in the infinite space we use this greedy algorithm so at each step we decide what's the best and we keep going all right so the second one we choose the optimal predictor which the split and the recurse in each new
(49:10) node until the stopping condition is met this is the basic we start with an entropy empty decision tree undivided We choose the optimal predictor which to split. We choose one of this index and then we recurse until some stopping condition is met. What's the question here? One thing I didn't explain.
(49:40) Which one is that? I give you a minute to think this. So this is the algorithm. Start with empty decision three. We decide how where to split and what. Let's say we get gen index and then we keep doing that until the stopping condition is met. Which part I didn't explain yet the stopping condition. Okay. So that should be the next one.
(50:09) And then for the case of for classification predict each region to have a class label based on the largest cloud or the majority. Right? So we decide what is the decision on the lift note by looking at the majority. All right. And this is a stopping condition. Let's make a summary at this point. And this is kind of your learning objectives. If you know these things, I'm very happy. I give you an A. Okay? If you don't know these things, you don't get an A.
(50:34) Okay? You get a little bit less. So this is my learning objective. So you have some target when you studying. What I want you to know what are the key advantage of decision tree models over logistic regression let's try what did we learn Jacob decision boundary more complex decision how to do predictions made using a decision tree model yes okay you rock your rolling why is it deserable to have progressive pure region as we move down the tree.
(51:19) Yes, betteration homogeneity label gives better period. Great. Summary continue. How does the gene index is used to assess uh the quality of a split decision? What is the impact of squaring the proportion of classes? Do you want to take that? You know the answer. Yeah. Okay. So, we just invers are paying attention so you miss this chance. Okay.
(51:52) Uh and finally, what is the primary motivation behind using entropy as a splitting criteria? How does it relate to the concept? Entropy quantifies the certainty or randomness. By minimizing entropy, we aim to create splits and maximize information gain. Right? So the intro becomes for information theory and it's good to have that as an option. Okay. All right. So you know your things. Now we have one game.
(52:17) Uh let's see if it's going to work. Uh just we're taking a break in a way. Uh all right. And now I know who is in class. Huh? Don't send the QR code. I'm checking every IP package leaving this room now. All right. I said we're taking a break. It's not that difficult. So don't panic. Okay. All right. So let's look at the questions.
(52:58) How did the CAD build the decision tree? To split attention between two laser pointers to minimize the impurity. It's both choices to decide which branch to nap on or to reduce over full fairing over 50. All right, let's as I said it's just say ah. All right. So, you can't decide. By the way, I'm not grading you guys on this one. Do you need to take a photo? us. No voting.
(53:56) Okay, we have the which is the two ones I choose correctly, but okay, let's move on. Oh, we have I didn't realize this. Good. Great. Nobody got it right. Then you want an A. All right. So, let's move to the next one. I'm going to share. Don't worry. All right. Part two. The photo today is by Jenny. Is Jenny here? Thank you for the photo. Beautiful photo. It is from Switzerland. It looks like Switzerland.
(54:47) It is. Okay. So, this lecture we're going to talk about stopping condition and we're going to tie it up with overfeitting bias variance um trade-offs and the likes. Okay. So far everything should be clear, right? Any questions, confusions? Maybe you have some questions like can I split three? No. Well, you could. Let me actually give you the caveat.
(55:12) What I'm presenting it is kind of the canonical decision tree. When decision trees came about, which is in the believe in the 80s, late 80s, 90s, then there was a plethora of different flavors. But this is what is settled down. This is the simplest, easier to implement. This is what is implemented at the skarn, R and the likes, right? So this is the canonical decision tree.
(55:41) Of course you can make modifications if you want to to make more sophistic. All right. So let's talk about stopping conditions back with the memes. Um now if we don't terminate right let's say we don't put any stopping condition. I didn't tell you what a stopping condition but you can imagine what it is. We stop somewhere right? We put a condition to stop. But what if you don't stop somewhere? What will happen? Who is it? I have the last and see this.
(56:20) Yes. Parts for each box for each. Thank you very much. So, it's exactly what's going to happen. We split. We split and we split. Now, every box has own thing. What's the problem with that? No problem. It doesn't tell you. It doesn't tell. No, I have a trade. I can make decisions. Overfeeding. Yes. Back to that.
(56:52) You forgot about overfeitting for a couple of weeks with all these probabilistic models. Now, we're back to overfeeding. And what's going to be the next overfeeding? And then the next thing I like a lot to talk about cross validation. All right, we're back into the overfeeding cross validation work. I told you it's getting easier. All right, so so the tree will continue to grow until each region contains exactly one training point.
(57:16) How can we prevent this from happening? My favorite emoji. Come on, just stop it somewhere. Right. So let's decide how to stop. First the one we call maximum maximum depth or max depth in skarn. I believe that's correct. Okay. What does it mean? It means let's say maximum depth one. I'm going to do one split and I stop. Yeah.
(57:45) Maximum depth two. I do two split level of splits and I stop. That's it. I do two splits and I stop. That's it. Right. No. Three. That one. Right. Good. Another one it is called uh I'm going to stop if all instances in the region belong to the same class. Duh. Of course, why should I split if I get there? Because even if I want to split, my criteria will not work because it's always pure, right? So the genie index, the mclassification error and the entropy will give you zero. So how do I split it to minimize? It's zero already, right? Okay. Pure li
(58:22) not nodes number three minimum samples leave. So this don't split a region if the number of instance in any of the sub regions will fall below the predefined threshold. Now Chris why is it called minimum or not maximum? I have a table or it just okay so basically you say if I have four I know uh but it's confused you have to admit. So meaning that I say minimum samples lift is equal to four.
(58:53) That means that's the minimum number I can accept before I stop stop splitting right. So in this case I stop because everything has four or more right. So I want I will stop splitting when I any split I do the next level will go below that minimum lift not okay simple cool another common one is called don't split a region if the total number of leaves in the tree will exceed a predefined threshold. Ah that's a little bit trickier.
(59:27) So maximum lift nodes is three. So if I hit three uh lift nodes I stop, right? So one, two, three. I stop there. Yeah, pay attention now because things get a little more complicated. Three live nodes. And the question, do you see any issue with this tricky question? And this is where student said, "Professor, you never told us.
(1:00:01) " But the idea is to see chick um unbalanced in sense that the right side being split again. Is that because the right split or maybe not being correct? But I want one more thought about that. Jacob says he's in balance. Let's think about it. When I split this thing, I split the first level and then I split here. Why didn't I split here first? Because it's large. Okay, that Yeah, that's a misfortune of my example.
(1:00:37) That Yeah, that's good observation. Very good. But why did I start on the left? What if I start on the right? We don't have hierality here. spontaneous breaking symmetry of kyality I'm I'm giving you fancy words to confuse you right so there's no preference to go left first and right next right and therefore that's a problem because if I go left I'm going to get this if I go right I'm going to split ah I'm going to split this so I'm going to have one two three can you see that so the choice if I go left and right matters okay
(1:01:21) let's talk about that uh escalating grows trees in what is called level order and let me focus on these words until a stopping condition such as max step is met. However, if the value of max live node is specified, sklearn will instead grow the tree in the best first fashion. Let me explain that.
(1:01:47) Um oh yes, there's a note here just to avoid any confusion. Sometimes this is called breath first but we decided not to use that term because it gets confusing with other terms right so it's level we're going to use level order or best first okay let's talk level order level order is what we use so we just get that let's this is my root node the gene index is 0.
(1:02:09) 9494 I'm talking about so now I'm splitting on the sex and I get to live nodes right okay And then I split again. And I split there again. And I stop at that level. Okay? It's a level order. So it doesn't matter if I go left and right because I'm going to go until everything has the same level. Okay? That's not a problem.
(1:02:34) We get that this first is going to take the node and it's going to split it. Now, now I'm going to go left and I'm going to split it again. And what I'm going to calculate is the impurity decrease by doing this split. Okay, here I use classification error as my impurity measure. You can use gene index, doesn't matter.
(1:03:00) So what I do, I split and I see how much it improve my impurity or improve my purity. Okay? And then I'm going to go to the right and I'm going to split again and measure again the impur decrease. Okay? And then I'm going to choose which one to go based which one gives me the best. Right? So in this case this was a better choice. So I have three lift nodes. But what I did I checked left and right.
(1:03:27) All right. Any concern with that? This will work. But there is something that maybe concerns you. Yeah. It's computationally very expensive because now we're in the first lip. We have two branches. I have to check when I go down to fourth leaf which is going to be two to the four branches. I have to check each one of them and then decide.
(1:03:51) And if you use max lip nodes in your sklearn and you and it's a big data set, you're going to be waiting for a while because it's going to take time to do all this. Okay. So keep that in mind. All right. So that's one. All right. So I think that's it.
(1:04:11) Another stopping condition is actually to to look how much your impurity or your gain in in R will change and you put a threshold. I'm going to keep splitting until I get my thresh my gain smaller than some. Okay. All right. Now, how to decide what is the appropriate stopping condition or stopping method? Let's say we decide maximum depth.
(1:04:34) Should I do two, three, four, five? How do I decide that? cross validation. Okay, let's talk about that for a sec. Before we talk about cross validation, let's see what what will happen when I increase the maximum depth. On the very left, I have maximum depth of four. It just gets a square where the green points is, but it is it doesn't get the exact shape.
(1:05:10) What does that mean? Huh? Under underfitting, right? So, small depth under fitting. Now, as we increase to the right, notice here I get the I get the circle. But every time there's a green dot there, it makes a little square around. Why there is a green point here? Let's look at this. Why there's a green point there? Why? What's wrong with this? Why do we have a green dot in the middle of the white dots? All right, I'm getting warm up now.
(1:05:43) What did you say? I heard it all. All right. See? Excited. Good job. I should print three. Can I bring three for it? Yeah. All right. So why do I have green dots in the middle of the of the wide area or white dots in the middle of the grid? Because data are inherently noisy, right? And what does overfeitting means? It means we fit to the noise. That's exactly what we see here. Very clear.
(1:06:19) These points here are pretty much noise, right? But I'm overfitting. So I'm creating little areas around that. when I get a new data set and same data set those green points will not be there. So what I'm going to be making a mistake right okay is that clear yeah all right so this way the model becomes more complex the bias decreases we can overfeit or this way the variance decrease can overfeit we've seen this once before and we see that again trade-off between bias variance right all right complex trees are also harder to interpret and more
(1:06:57) computationally expensive to train but let's do that so high bias low variance the tree if I if I take different data set and do it again and again I'm going to be getting exactly almost exactly the same square right on this one if I it has low bias but if I take a slightly different data set it's going to make another green areas around and it's going to jiggle around right so that will have high okay actually I have few of them here's okay let's go back back. This is one data set. You see the decision boundaries which is the green area. Uh
(1:07:35) another data set you see the decision m moving around. It goes crazy, right? So it has high variance. All right. So what do we do? Trade off between bias and variance. And how do we do? No, no, forget that. That was from last year. There's a new questions that the train uh all right stop conditions we have all these stopping conditions and for each one of them we can define what is the threshold what is the stopping condition for each one and how we going to do that cross validation of course okay now we're back overfeeding and cross validation back in the house ready to
(1:08:19) rock and roll all right so summary for today um who again this is my summary so you all um know what to study. These are my key learning objectives. I'll be doing that for all my classes. So at least you have a target what to study, right? And then you're going to ask for practice questions.
(1:08:47) But nevertheless, uh so explain the concept of overfeeding in decisions. How can stopping condition help prevent overfeeding? Anyone? Come on. How can we stop overfeeding? Not yet of less depth. Less depth. We can regularize it or we can reduce the complexity by reducing either the depth or the maximum lift nodes. Any one of those, right? Second, describe two common stoping condition using decision learning and explain how they limit their growth.
(1:09:18) All right. First maximum depth limit is the maximum depth and minimum sample sleep which sets a minimum n. Okay, there's more but we just did them. Differentiate between level order and best fit the decision. When would you prefer one method over the other? Someone said it earlier.
(1:09:44) Yeah, but because of computation computational intensity. All right, then I think I have finally explained the trade-off between bias and variance in decision. How does threedev impact bias and variance? Shallow trees have a high bias. We just saw that. What is the role of cross validation? Just to determine what is the the what is coming. Do you hear it? I hear something.
(1:10:14) All right, let's play one game and we finish for today. I promise you it's going to be easy. I don't promise you it's going to stay easy until the very end of the semester. But are we ready? Who wants to play? Game time single. Can you run down? Can I run up? Can I throw it to you? No. No, I won't be. That's the end of professor injured student in class.
(1:10:51) Okay. Can you speak louder? What's your name? Say yes. I suffer. All right. So B program considered the arrow ship plot below A, B, C and D represents four different B classification. Where is that coming from? Arrange the model name such that they correspond to the sequence of statement below. Actually it's a good opportunity for by the way let's put the secret word.
(1:11:27) Um, actually, let me put them up so you can see. Chris, does this going to work? Can you see it? Can they use synonyms? No. I'm not making your life difficult. All right, Hannah. So, the model is the perfect optimal classifier. Number two, the model is the worst classifier.
(1:12:11) The model The classifi what's going on? Okay, I'll read it for you. The secret code for today is 127.0.0.1. Anybody knows what is that? is is the local horses. How I sniff the package leaving this room. Okay, Hannah, how we doing? B. All right, so B, one is C, which is the model is the perfect, which is obviously that uh two is A, um, which is the worst classifier. D is a random one. Good final answer.
(1:12:56) Hannah, this is the final answer. And I think it's correct. Oh, what happened here? What's happening? I make a mistake. Two should be the model worse classifier. Why? D. Ah, I trick you, Hannah. Everybody pay attention to this. Why Hannah made a mistake? I trick her because if it's below the line, I can switch this. I can switch the predictions. Yeah. Okay.
(1:13:28) Yeah. All right. You got it right. All right. I give it to you, Hannah. All right. So, that's it and I'm done for today. We see you all on Monday. We're going to be talking regression trees and we're going to move to random forest bagging boosting adaboose gradient boosting mixture of experts. All right. Thank you.