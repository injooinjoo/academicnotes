(2) 109 day24 - YouTube
https://www.youtube.com/watch?v=JeessjKF4H4

Transcript:
(00:01) Good morning. Good morning. All right. 10 9 8 5 4 Testing testing. One, two, fo. All right. All right. Welcome everyone. Welcome back from Thanksgiving. I hope you had somehow rest Thanksgiving. I don't doubt it because I'm sure there's a lot of
(01:05) milestones, homeworks, and a bunch of other things. Not from this class, of course, for all the other classes you're taking. Um, I hope though you got a little chance to rest. Uh, we definitely did at least a day. Um, some of you are wondering what is going to happen with AI and your jobs and you're taking this class.
(01:26) You're wondering what useful is this class? So, I'll show you what I did for Thanksgiving. Uh this is my app that I made is Oliver is my wife. Thanksgiving lunch when to come. This is a full deploy app that I share with my guest. Now notice that we have predictive here of when the turkey will be ready, how many more minutes. And I did confidence intervals in two ways.
(01:51) One with bootstrap and one with base. And notice actually the base is slightly tighter. Uh maybe someone can tell me besides maybe Kevin can explain why the base confidence intervals are a little bit tighter because my priors were a little bit tighter right so in that way my confidence interval so this is a full-fledged app that I deploy on GCP or Google and my guests were getting updates per minute when the turkey will be ready.
(02:24) So you can see here this is the now time and it was predicting to be inund minutes and actually happened exactly that time I took it out at that time. So useful skills right predictive models with base and confidence intervals with bootstrap everything you learn in this class plus this app has a lot of how many of you are in AC2 and5 raise your hands I know a few of you so this is fully deployed with pulumi on with kubernetes cluster the whole thing I did it in half a day so I have of course all the the scripts okay all right that's just to warm up so now you know what to
(03:03) do with your data science skills predicting your turkey cooking time. All right, but today we're going to be actually have a lecture. We're going to talk about Adaboost. The first part of the lecture will be how we actually build Adaboost. Adaboost is the boost method for classification. This actually was the first paper out of boosting.
(03:29) Then a little bit of mathematical formulation on adabus not as much as last time but a little tidied it up with that the same ideas and then some final thoughts on boosting. Okay, we ready? Okay. So what is adabus? Well, there's two main ideas in adabus similar with gradient boosting. The first one we iteratively built a complex model t by combining several weak learners.
(03:57) And here for trees again a weak learner is a tree with one note and two leaves. Okay. And we call this the stump. One note two leaves. That's my weak learner how I'm going to do it. Of course you can go beyond that but that's my framework here. It's as simple as that. One note and two leaves.
(04:20) Now idea number to two is and again is the same as gradient boosting. The idea here is that each new step added to the ensample model T will learn from the mistakes of the current tree. We have T. Okay. So this is going to be done by assigning higher weights on the examples that we're making a mistake. Okay. Two ideas and second is that we're learning from the mistakes. Okay.
(04:53) I'm going to show a very simple example and I'm going to go a little bit slowly. So if I if I'm going too slow, let me go let me know to go faster. But I rather go slowly what step by step. So you see there's about six, seven steps we're going to be doing. So let's start with a simple example.
(05:12) I have here uh eight data points. We have class one and class two. Class one is orange. Class two is the triangle blue. Now notice one thing and I'm going to explain a little bit later. The labels I'm using instead of 0 and one we're using minus1 and one. I can do that right there's no problem with that.
(05:32) There is of course a reason I'm doing it which is going to be revealed a little bit later. But for now understand my labels I'm going to use is minus one and one which I hope can you hear me on the back or shall I put it? Yep. So uh and I hope you understand there's no reason not to. I mean there's nothing harm will happen by changing my labels, right? Minus one and one instead of zero and one. Okay. All right.
(05:58) So let's go there. Here's my step one. I fit a stump which I call s0 to split this data. How do I do that? Is a st. So I'm going to find the predictor that and the threshold of the predictor that will give us the most pure regions the weighted purity in both regions. Okay, that that should be clear. Yeah. All right. So this is what I found.
(06:25) X1 is larger than 4.6. And if I go yes to the right I have two uh oranges and zero blue. and in the right is uh two and four. Okay. So on the left I predict orange and on the right I predict blue triangles. Why? Because the majority is blue. Okay. Is that clear? Right. So two regions. Region one, region two.
(06:52) The region two has uh two orange and four blue. So the majority is blue. On the left I have the orange. The majority is orange. Is that so? So that's my first step. So now I have my first time. Step number two, uh we'll assign a stamp a scaling factor lambda which I call lambda zero is the first.
(07:16) The scaling factor indicates how much the stamp contributes to the entire ensemble. I think you remember if you do remember I hope you do from last week uh when we do gradient boosting every next stab every next correction we make we give a weight which I call lambda which I call learning rate but for now lambda I give it a value and I'll explain later while um how I find these values for gradient boosting we have used kind of lambda values learning rate values empirically if it was too small it was going too slow.
(07:51) If it was too large, it was jumping up and down. Is that remember that from last week? Anyone? Or did the turkey destroy all our brain cells? Okay. Or alcohol. Uh, all right. So now I'm going to give this uh for this stamp I'm going to give lambda. 25. We'll explain how we find the lambdas, but for now just to show the algorithm the flow I am going to give it a value 25.
(08:19) All right. So this is my tree and I have a weight for this tree. Step number three, I'm going to construct the ensemble model which I call t0 and I'm going to use this simple formula here. If I is equal to zero which is the first one. So the t0 will be lambda 0 * s0. Basically what I have if after the first one after i is equal to 0.
(08:44) I'm going to add to the previous one the new start interatively. Right? So right now I'm equal to zero first is the first one I did. So I'm going to use this formula. So t0 will be lambda 0 * s0. Okay. So is is this one times 0.25. Yep. Are we cool? All right. So step number four, we adjust the weights assigned to each data point to ensure the next stamp focuses on points that the mclassified up to this point.
(09:23) Okay, so at this point you can see these two here are mclassified. So I want to weight this more than the rest. Okay, so let's do that. this increase the weight of the mclassified and decrease the weights of correctly classified samples. Okay, so how do I rewe them? Here is the formula we're going to use which is over here. Now this formula looks messy.
(09:54) We're going to break it out into small pieces. So this is the new weights, right? The previous weights were 80. Now the new weights will become so I'm going to take the previous weights which I call w of zero right the previous weights I have in the previous iteration I am going to multiply by the exponential of minus lambda time y and this should be lambda 0 I believe yn which is the truth the ground truth between minus1 and not between it's either minus one or stamp.
(10:33) I am going to have the prediction from the current stamp. Okay, this is my prediction I got from the current stamp and this is thing is the normalization of the new weight. I need to normalize my weights. Okay, so let's one more thing I I mentioned that already. Yes, the labels are minus1 and plus one, not zero and one.
(10:58) The choice makes the math cleaner and we'll see uh that soon. Okay. And also, how do we normalize? I just put the formula there so you have it for reference. It just basically makes sure if you sum them all up, you get one. Okay. All right. So, that's how we update the weights. Now, let's think a little bit before I move on.
(11:19) If I get the right prediction, this sigma and the y will be the same sign at least. So, it's going to be e to the minus lambda. If I get it wrong, this is going to be this and this will be different signs. So it's going to be e to the lambda. So that means the previous weight I multiply with e to the lambda if it's mclassified and I'm going to multiply with e to the minus lambda if it's correctly classified.
(11:48) So that means if it's correctly classified e to the minus lambda is a number smaller than one. So the weights will go down. If it's mclassified e to the lambda is bigger than one. So the weights will go up. Is that clear? Okay. So by doing that now what we have it oh went too fast. So you can see the new weight it is 1.5 over8 for the mclassified one now they're bigger and the other ones the weight became 8 / 8.
(12:23) Now you can see these ones weights, the mclassified one, the weight went up and the correctly classified weights they went down. Now this is what we're going to use now for the next stamp. And you can see now I'm putting more weights on the two points that the first stamp or up to that point I mclassify. Okay, so far so good.
(12:46) Are you able to Am I going too slow? Shall I speed it up? Yeah, speed it up. No, someone looks scared. Don't speed it up. Okay, I just want to So, this is my step number four. Let's see where we are. We started with the data. We fit one stamp. We took the stamp, we waited it, and then we add it to the ensemble.
(13:10) Then we look how many uh what we doing correctly and what we're doing incorrectly. We wait the ones we're doing incorrectly higher and we wait the ones we predict correctly lower. Okay, so should be clear. So step number four is create another stamp. This is S1 on the reweed data. So we have X now two bigger than eight. And again when I create a ST I using my tree rule.
(13:43) The tree rule is to increase purity or decrease impurity using gene index or entropy or whatever. Nothing new here. Okay. All right. So now this is my new stamp. Notice it's just a stamp. It's one node with two leaves. And again I have here on the bigger than that which is here I have two orange and one blues.
(14:05) And therefore I'm predicting orange. And on the bottom I have two orange and three blues. I'm predicting blue. Okay. Uh now notice that these ones are correctly classified because I put more weight on those. I don't I care only to classify those two. So I put them in a category such as I'm predicting orange so I don't mclassify those two points that I'm paying attention to. Yep.
(14:34) All right. Step number six with the new ways calculate the total error in the stamp using this formula. Okay, let's look at this formula a little bit. What does this say? I'm going to weight every mistake I make because um and I calculate to here.3. Now, what is this gray column here, Vanos? There's a gray column here.
(15:04) I have no idea. Okay, it's a great column. Simple just means one when the st is wrong and zero when it's right. It's called the indicator function. Okay, it's just simple. It picks if it's correct, if it's actually it takes one if you make a mistake and it picks zero if it's not.
(15:24) So if you look at it, so what I'm adding here is only the mistakes because I'm only picking one when I have a mistake and I'm weighting every single point by the weight I have. Okay. So now I have my weighted error which I calculate using this formula here. So the error is.3. Okay. All right. Next I'm going to of course uh put my lambda here lambda one because it's a new stamp. So lambda one will be 02.
(16:01) I give it a value. I'll explain again later how I get these values but there's a trick to it. It's not so simple. But now I have an lambda for that. And now therefore now I have the new tree which I'm using now this formula. So I have I is equal to 1 now. So t1 will be t 0 which is was the previous one plus lambda of 1 which is 2 times the stamp of one which is this line here. Okay.
(16:28) So that's my new tree and here is the way I do it 25 times that times 20 of that. Okay. Any questions so far? Look upstairs the faces scanning the room. All good. All right. Step up number whatever. Now we repeat this process as we go. It's the same process over and over again. Okay. And then we stop at one point.
(17:07) When do we stop? Well, we get to that when we overfeit, when the validation error goes up, etc., etc., right? Remember boosting is not is more like neural networks mean as you train the training error will be going down the validation at one point is going to come up because we overfeitting because what we do we at one point what we do we fitting into the error to the noise. Okay.
(17:33) All right. Let's summarize what we have done. We start with the uh the data. We start with weights zero to be 1 / n where n is the number of points. So every point gets equal weight. So for i is equal to zero until stopping condition is met. Train a weak learner which I call si using the weights that I have at that point.
(17:57) Calculate the total error of the weak learner. Calculate the importance of each model lia. combine all stamps into new a sample and update the sample weights. So mclassify points receive higher weights and correctly classify points receive lower weights. Okay, that's the the summary. I'm going to do it once more with a little more details.
(18:22) Again, it's the same train. Now that calculate the total error and I'm going to use the formula with the indicator function or the Greek column so you'll never forget it. um then I calculate the importance of the model then I construct the sample model using the formula and update the sample weight so that the mclassified blah blah blah the same thing and finally that's my formula I use and finally uh the final model which is important I haven't shown you yet how do we combine all these trees we said we're adding it up so what I do I of course the final model
(19:01) is the sum over all the stamps because I iterative adding them. But what I do at the end, I take whatever I get out of here and I just get the sign. Now you may see why I have minus one and one. So if it's negative is minus one. If it's positive is + one. Okay, cool. So that's the whole algorithm.
(19:25) It only took me 20 minutes. I have another hour to go, but we'll get there. Okay, now maybe you have some questions. Yes, >> if you're not fitting on the actual errors, >> it's not gradient. This is okay. It has similarities with gradient boosting, but it's not gradient. There's no there's no residual such we'll get to that, right? Any other questions? Anybody has question? said Orlando was 0.
(20:02) 25 and you just said that's what it was. >> Yes. What other questions you have? Good. Give it >> said that we create those thresholds and maximize purity way the first but is the that different stamps have the same type of purity between them. How do we decide whether those which one we start with? So I have my data.
(20:30) I'm going to get a stamp. So I have two predictors or three predictors. I'm going to check every predictor. Let me repeat the question for the video. The question is how do I find where the stamps is? Right? Sorry. So as I said is the same as any tree. So let me describe. So I have my data. I have two three predictors.
(20:48) The first split which is the only one I'm going to do. I'm going to check every predictor and every possible threshold split and I find the one that gives me the most weighted purity, right? The best the least impurity, right? The same way we did with the trees. Okay. But there is a catch there, buddy. So, so far we've been doing it with equally weighted points.
(21:16) Here I'm doing a stamp. So I'm creating a tree with weighted. Anybody knows how to deal with that? If I give you a bunch of points and I said weight them, what are you going to do? Okay. So I says I anticipate your questions but you not all of them are. So there's few questions here. One is calculate importance of each model lambda. I said lambda is 2.
(21:45) 25 25 but I didn't tell you how I calculate so we're missing that and the other one train a week learner using weights w I never tell you how to do a tree with weights actually I did mention it last week but nobody questioned me I said rewe for imbalanced data set I said rewe your points nobody asked me how do you do a tree with weights weighted points right you should question me more often.
(22:15) Okay. All right. So, let's uh just make copies. Yes, of course. How do I create a stamp in the stamps are created using simple decision tree with max steps one panos? That's your answer. It's just simple decision trees with max step one. How do you use normalized ways to make the stamp? Kevin says there are two options.
(22:40) First option, Kevin's option is just create a new data set, same size original with repetitions based on the newly updated sample weights. Okay, so we just copy them as Kevin said. And the second one, you can put actually the weights in the gene index. Remember I calculate the gene index. I took the weighted sum of the gene index. I can put the weights right there.
(23:01) I believe is exactly the same. Okay, so that's easy. We got that. How do we calculate the scaling factor lambda for each star? Next few slides. So I promise I'm going to explain to you how we find lambda for gradient boosting. There is not a way to find lambda. You just play. You try some lambda, the learning rate.
(23:24) If it's too small, it's just going to be going down very, very slowly. If it's too large, it's going to be fluctuating a lot. So we want the right learning rate and anybody who has done any neural networks you know how to tune your learning rate. You just play you try something you see how it goes and you try something else.
(23:44) For gradient boosting that was the message I gave. Try small learning rate see how it goes. Try big learning rate. See how it goes and then adjust it until it looks nicely like an elbow. Right? Okay. But here in Adabus, I have good news. We don't need to play that game. There is a way to calculate analytically what's the best lambda we can have.
(24:14) That's my mean. I made this. All right. Recall in gradient boosting the regression we minimize the MSE. But in the other boost, we minimize a different function which we call exponential loss. So let me show you the loss we're going to be using. Uh it is the sum of the exponential. So minus y times the prediction y.
(24:42) Again I don't know if I have it in the slice and again the y goes from minus one I mean the y is the true labels in minus one and one. The y is my prediction. The yight is my prediction. And let's actually look at it without before I do anything and again it's the same thing I said before if the yhat is equal to the y n so if I'm predicting one or close to one and the true label is one y * yhat will be some close to one number right so the error is e to the minus one if I'm making a mistake if the true label is one and my prediction
(25:28) is close to minus1 I have one * minus1 is minus one I have a negative sign is + one so the loss for the ones I'm making a mistake is e to the lambda e to the lambda is a number bigger than one e to the minus lambda is a it's a number that is close to zero or goes to zero fast I see you all in your computers but you I hope that's super clear right shake your head if you understood what I said because that's an important thing.
(26:01) So this laws make sure that if you get it right the loss is small and if you get it wrong the loss is high. Okay. All right. So exponential loss is differentiable with respect to y and always larger or equal to the 01 error. So minimize is indirectly reduces classification error. That statement is important but we're not worried so much.
(26:26) Meaning that as opposed to other things we have done like when we did binary cross entropy I did mention it the binary cross entroproy and your classification error are not one to one the monotonic sometimes your binary cross entropy will go down and your accuracy instead of going up it can go down in this case we have one to one and that's why we like this all right so now how do we choose that learning rate this lambda So in this sense what do we do? We minimize this loss which was y * yhat and yhat remember is my tree which is t + lambda
(27:09) i sigma xm. So this is the last of the updates I'm going to do right now. You can prove and if we have time at the end of the class sometimes I get challenged to do it. You can prove that you can actually find the lambda that will minimize that and that lambda gets this this form is 12 the logarith of 1 minus epsilon / epsilon where epsilon is the weighted errors and the weights is the one that we showed before.
(27:41) It's a nice little proof but and I think I'm going to have time at the end of the class. I'll leave it at the end of the class. We need a whiteboard and if my brain wakes up and I can do it on the board without notes I think I can do it. Okay. So what I'm saying here is that there's actually a mathematical derivation that in this case in the case of Adabus you can find the lambda the optimal lambda that will give you the arc mean of the loss.
(28:11) Okay which is kind of unique for adabus. It's not often that we can kind of tune a hybrid parameter with having an analytical expression. Okay. Anybody any questions? Yes. Weight of each model. Yeah. Learning is the weight of each one. >> Different for every solvent. So that's so there it is the is the way in this case for every usually in adabus and I show you some slides later you can set the lambda constant for every single stamp right but if you want to fully optimize and you go to sklearn it's going to find the lambda for every stamp
(29:02) you do is going to find the appropriate lambda I also follow you is the church but what has learned as something >> so Chris just to repeat what Chris said is he said SK learned as something haggi doesn't follow this rule but this is absolutely right and that's okay so you can do this that's if you want to build your own adabus but if you use skarn is going to use some constant lambda okay any other questions so Remember boosting is the workhorse of any machine learning with random forest.
(29:48) So it's good to understand. All right. Now we're going to spend a little bit of time to tied up the mathematical formulation similar to what we did last week with the gradient boosting. Same idea. We're going to do gradient uh algorithm in the prediction space, not in the parameter space because there's no parameters.
(30:09) uh is no parametric model as such. Okay. So we're going to do the same thing but I'm not going to get into the big details because we've done it last week. So similar to what we did gradient boosting, we compute the gradient. So we start with the loss which is the exponential loss that we showed before. And now I'm going to take the gradient of that loss with respect to my prediction. Okay.
(30:34) So if I do if I take the gradient of that with respect to yhat what I'm going to end up having is that the y's will come down and you have the exponential there. So this is what we get y minus y1 exponential of that. Now this this is the the gradient. So it's for each one of them right? Yep. Cool. Now what we going to say is that this think about this e to the minus y yhat we're going to call it the weight because now the exponent the gradient is y1 times something which is the weights which is happens again to be the same weights I show you before if you do the
(31:16) expansion it ends up being exactly the same. Okay, so this is my weights, right? So now what I have my my gradient of the exponential loss is basically the direction is basically the right point I end up want to go times some weights. Remember this y1 to yn is the correct solution. So if y had end up there, I have the exact minimum exponential loss.
(31:45) Right? In this case, it's not going to be zero like in the MSE, but it's going to be the absolute minimum of the exponential loss. So, if you think about it, if my y hat become y, it's the the ultimate prediction the so my my my loss will get in it global minimum, right? All right. So, now we're there and we're going to have the same problem.
(32:08) So it's just reweing applied to the target values. And if you do gradient descent, you're going to end up in the actual uh ground truth to the actual wise. Okay. And this is what happened last week when we do gradient boosting. If we do gradient descent with this gradients of the prediction, what we end up is exactly at the right solution.
(32:32) But it was totally useless because we're not mapping the input to the output. So what do we did last week? We said, okay, I'm not going to use the exact gradients and I'm going to use an approximation. Okay, this is going to be exactly the same, right? So if you see the update steps, if we do this, we're going to end up exactly at the y's, right? Because if you see the gradient say, I'm going in the direction of the y's.
(32:57) Eventually, I'm going to end up there. So what we going to do? We're going to approximate the gradient here. If you look at this y * w is the weighted points which I'm fitting a stamp on it. So I'm going to approximate this gradient here with a stamp. So if we basically that's how we fit this stamp is on x and w1 y1 all the way to xn wn yn.
(33:31) Remember the stamps are fitted on the weighted points right? So therefore those stamps are approximation to actual gradient in the prediction space. So which is exactly what we did last week with the gradient boosting. We approximate the residuals with the next tree was fitted on the residuals. Here we approximate the gradients which is w * y with a stamp that is fitting to find the w * y. That's what we did.
(34:00) All right. So that comes nicely. So let's compare the two. In gradient boosting, we minimize the MSE. In data boost, we minimize the exponential loss. And here are the formulas. The MSE, we know the exponential loss is this new thing we introduced today. We compute the gradient for the loss with respect to the predictions.
(34:21) That's what we did last week. And we get minus two the residuals. We compute the gradient with respect to the predictions. we end up with the y's weighted by the w's, right? And to the update step we did last week, we just change the residuals with the residuals hat, which was the fit that we get from our little trees.
(34:46) And the same with here, we are going to approximate the w times the weighted u wise with a new st. So in some ways exactly the same we do with the gradient boosting we're doing basically gradient descent in the prediction space and we approximate the gradient with the stamps as we go and so that's the same idea and this is the thing right this is the approximation of the residual and lambda here plays the same role as the learning rate the only difference in adaboo is that learning rate can be uh estimated analytically to
(35:22) have your optimal step at each at each step right okay so at this point that's all is in few things I want to show some examples any questions so about this is it >> Joe >> we saw approach for that lambda and go through just exponential loss >> h we we solve for no the exponential loss doesn't have the lambda right >> so we do that process >> in here instead of lambda should lambda r. So we do it at each step.
(36:03) Okay. All ready for the final. Yes. So maybe it's the time to do some announcements now everybody's here. So the final is December 11th. Um I put a post. Most of you must have seen it. Three cheat sheets for that. Uh I'll also we're not going to have a coding uh in case you missed that post.
(36:27) Instead of coding, we're just going to give you questions. I posted a bunch of uh examples of these questions on at uh there's a post there. So I have about five sample questions about coding. So there's two parts to the final. An hour and a half is the conceptual similar to the midterm conceptual similar to the quiz. We're going to be covering uh I think the number I gave about 80 to 85% of material after the midterm but we expect you to understand what is the things before the midterm.
(37:07) So you can say look we didn't cover cross validation after the midterm. The questions may contain concepts from the first part of the thing. Is that okay with everybody? But mainly the questions will be motivated driven by the material we cover after the midterm. But just because it's very hard to make questions that you know I don't want anybody say look we didn't talk about overfeitting or after the midterm we may ask questions like that.
(37:34) We may ask questions what is logistic regression was after the midterm. Right? But we may want you to compare to linear regression. you can't say look I don't know I forgot everything about linear regression um because it was before the midterm but overall the questions will be focusing on the material we did after the midterm uh so I said an hour and a half of conceptual questions regular multiple choice questions as we did in the two quizzes and the midterm um a little bit more because it's uh 90 minutes instead of 75 minutes
(38:11) You can bring three chits that for the whole exam. After the an hour and a half, we have 15 minutes of break. And then we have the rest of the time which is going to be an hour and 15 minutes on another multiplechoice questions, but it's not going to be conceptual. It will be about coding. If you're wondering what I mean, that's why I make these five questions.
(38:41) H I highly recommend to go and look at them because there's one kind of question is called parsons that you have to rearrange the lines of code. It's a little bit tricky. So I want you to practice to make sure you know how to move these lines. Uh indentation does matter. So pay attention to that. The rest of the things is questions about um so I think I already said there's four things we want you to understand in coding.
(39:08) We don't want you to remember syntax exactly, but you should be able to read code. You should be able to understand error messages. You should be able to syngmic syntax to put it together. So, we're not asking you to write line by line. But if I give you five lines of code and I said we're doing bootstrapping, you should be able to put the loops together and everything.
(39:30) And the final one is I give you a code that maybe is for one predictor and I want you to extend it to two predictors. It's so more algorithm. So I have five examples. I think they cover pretty much what we want uh on that. So that's for the Jacob online. uh there is a possibility I'm not taking away that we may have some open-ended questions that is easier to do it on the paper.
(40:02) It's not that we want you to have on the paper but especially if there math that you have to do is easier for you to do it on the paper. We haven't decided yet but I want to leave that door open. So most of it will be online like on ET remember you only allowed to go on the ED page that purple ED logo has to be visible for any angle in the room right if you go away from that that's not okay so yes online any other questions about that >> yes are as you said 80% of the new material but also the previous one or only Sorry the second part I'm not sure
(40:46) about I mean it's coding there's no separation um yeah I mean you should understand what Python dictionary is but I don't know if you can separate the two boss it's not possible in my mind at least any other questions about the final okay so now let's talk yes >> turn to ask how like questions >> there will be some more questions or or more different slightly different for the midterm I think we have few more on 209 remove some of 109 we have the slight difference yes the same for both parts >> as for the when it was on paper it was
(41:32) like a common question some 209 question then more common question >> no it was like in the the quiz there was two different quiz one for the one line 909 when you if you register correctly and we have few cases that were not then when you go to ed you only going to see yours because we have you t in the All right any other questions about now uh talking about reviews tomorrow at 6 what did I say 6:30 6:30 outside my office like we did for the midterm this is not going to be recorded unfortunately it's not possible possible
(42:11) to record. Um then on Friday, Kevin, did you decide what time? What time? >> 10:30 Friday, Kevin is doing is going to announce where, but that's going to be recorded another review and Chris will announce some Thursday. >> So you and Kevin and Chris will put something on it. uh if it's going to be recorded or if it's going to not be recorded, where he's going to do it.
(42:45) And then the week after is just going to be a bunch of office hours. So I I won't be here the next week. I'll be online, but I'm going to see my daughter. Sorry. Um and then but Kevin will be here and Chris will be here, but I'll be online. I won't be off. Okay. So that will give you a good review for the final um or December 5th. Yes.
(43:07) get with that again. >> So we can see >> No, no, there's nobody to take it. >> We have Yes. >> Yeah, we'll put it up today. There's few people last week and then it was Thanksgiving and we got distra but we'll put it up today. Right, Chris? Yeah. Um, anything else related to that? Uh I was waiting for all of you to come before I make announcement.
(43:42) Uh just to get an idea how many of you planning to come tomorrow to my review because last time we're very crowded there. Okay, about this. Yeah. So it's fine there. Last time we were a little bit too crowded and remember there's going to be more review sessions by Kevin and Chris and at least Kevin will be recording it so you can see that. Okay.
(44:02) So what we're going to do tomorrow in the review is pretty much everything that we cover a little bit more emphasis on not not real emphasis I'll cover a little bit the hierarchical because I noticed some people will be they still having thing but I think the best place to go and get the hierarchal basian review is on Friday.
(44:23) Uh I think Kevin has the the hierarchian much more master than than me but we'll do it tomorrow too. Okay. Uh let's move on. All right. So what we show here is just to give you an idea this is actually uh this is for uh overfeitting in boosting. So we want to explain that actually what will happen in boosting is very similar to sort of neural networks as you train which is the the the x-axis here is the number of stumps you do right or you can call them iterations.
(45:04) Uh your training loss will be going down and your validation loss will go down and then you start going up again. So that means somewhere here you start overfeitting. Okay. Now remember one thing which model would you use in the wild? This model with two stamps 5 10 15 or 40 15 20 about there. Right about here. And now notice that we're wasting time there.
(45:41) But you know something you keep in mind. We can actually what you need to keep in mind is that if you run your boosting with 40 or 60 stamps, don't use the last one necessarily for your final model because that at that point you may be overfitting so much. So you want to get the model somewhere here. Um now this is a bunch of runs we did.
(46:05) I think Chris did it I believe maybe. Uh this is hyperparameters for boosting. So on the x-axis we have the number of estimators or number of iterations. Okay as we go into the tree. Remember this is very different from random forest and bugging. The number of estimators in random forest that do not lead to overfeeding.
(46:31) Here we do because as we go down and we're learning from mistakes what we end up at one point we learn all the patterns that they're in the data and now we going into feeding the noise right all right so what we have here is um we changed the learning rate and as we kept the max depth of the stamps to one and now let's see what's happening the learning rate here is very large and you can see now that it's just it just start fluctuating the learning rate very slow is kind of going very very slowly.
(47:11) Now you can change the max depth of your stamp. So your stamps are not so stumpy you can actually go down and what you see as you go down you increase the maximum depth you start overfeitting more. So you can see here the learning rate is high the max depth is high your accuracy on the training set went to mix one but your accuracy on the validation is not getting anywhere okay so you can change the max depth of the stamp though I don't recommend it keep it one maybe two and just play with the hyper with the learning rate than anything else but
(47:47) if you want to play with this is that uh so here is hyperparameter You can tune we have n estimators here is 50. So number of iterations is 50. We have different learning the different view of that and this is the test lock loss or validation loss. Now what we see here if the learning rate is very small as I say it's going down very very slowly.
(48:13) And if you look at the blue one let's see what you conclude by looking at the blue one. The learning rate is small very small. Look at the blue one. Tell me what you think is happening or what would you be your next action? >> Yes. >> Yeah. So if I look at this blue one then the loss the validation loss or the test loss is decreasing.
(48:52) But has it reached the minimum? So what shall we do? Keep going. Right? Add more estimators. Okay. Now let's go to the other extreme which is the learning rate is one. So it went down very fast and then you went start going up. So I'm starting to overfeed about eight. It seems this one the learning rate about one seems to be giving me the best results as fast as possible. Okay.
(49:20) And in between the orange one, I like the orange one because it goes down and then it plateaus. This is the kind of curves we like to see. Uh it's a little bit dangerous with the red because the learning rate may be too large and you may miss. But this is the kind of games that I want you to start getting familiar with that.
(49:38) So here we play with different learning rates and the random state we didn't set the random state. So fine. And there is the algorithm which is s or I don't know how to say that which is basically for multiclass classification algorithm. Um all right s yes it combines probabilities predicted by the stamps to do multiclass exponential loss. Okay.
(50:05) So let's talk about the final thoughts of boosting but somewhere I have somewhere um okay stopping condition. We do need to do to decide on the stopping condition. We usually put it at one but you can play the same game as we've done with bagging and random forest and trees. You can actually hyperparameter tune your depth of your stamp.
(50:29) Everything I talk today, I consider my stamp to be one node and two two leaves. But as I said, you can change that, right? You may find it more effective to give your weak learners to be a little bit stronger depending on your data, depending on your situation. You may want to play with that.
(50:49) That's a hybrid parameter. So I'm going to be playing with the same thing. Right? So the hyper the maximum the stopping uh sorry that's one of the hyperparameters I want to do. Now the stopping condition is the same as gradient boosting maximum iterations and you say look I don't want to wait for more than a thousand iterations that's reasonable or what you see if we go back to this so if you look at this you can what you can do you can monitor your validation and you can see if my validation error is not improving stop that's very reasonable you can do what
(51:29) is called early stopping in the sense that if you have certain number of iterations that your validation error is not improving either it stays the same or it goes up you stop okay so that's your kind of stopping conditions we use uh and I said overfeeding other sample measures like bagging the number of estimators would lead to overfitting uh all the hyperparames with the st and the stopping condition mentioned here are hyper parameters that you want to play learning rate.
(52:03) Of course, if you do add a boost and you use the formula I show, you don't have to tune it. But most of the times what we see is people playing with fix the learning rate and then uh adjust it as a hybrid parameter. Okay, a little bit confusing, but let me let me say it again. In gradient boosting, the learning rate is a hybrid parameter, right? This lambda, if it's too large, we said if it's too small, we said it's going to go too slow. That's a hyperparameter.
(52:30) Hyperparameter is something we choose, right? Yep. In Adabus is this exception that may confuse you. There is actually a way to figure out this hybrid parameter without tuning it. It just gives you two. Okay. Now, a little bit more about boosting. There's this is an industry, right? It's not just adaboose or gradient boosting that we describe here.
(52:57) These are kind of the workh horses of machine learning sons neural network right this is the the two methods that you're going to be using every time you have tabular data you can try neural networks but I said it often gradient boosting or boosting in general and random forest are the two methods that you should be using for anything you're going to be doing that it doesn't involve images text time series okay those are the two methods etc.
(53:27) Even with time series we can do with uh with the boosting and everything but because of that um what we describe in class are the canonical algorithm but people have created libraries with a lot of hacks a lot of additions a lot of features the three most ones most common ones one is called XG boost which is something that I think 80% of our projects for the last few years they use extra boost.
(53:57) They didn't use the boosting straight out of skarn. Uh extra boost is I believe from Google. Uh LGBM is a light gradient boosting machines. It is a library uh for training developed by Microsoft to compete with XG boost. Now you need to understand that until neural networks were the big players in the game, these were the big machine learning algorithms.
(54:24) So when people were doing machine learning for anything they were using this library. So there was a market for that and CAD boost uh is a new library actually new not anymore because these slides were made three years ago uh for gradient boosting decision trees offering appropriate handling for of categorical features.
(54:45) Now each one of these adds a little bit twist like we said sklearn for categorical features it doesn't deal with it. uh these ones they may deal with it missing data we talked about surrogate uh predictors few weeks ago uh skarn will not do it for you but these guys will do it that handle missing data thing so the algorithm is very similar to what I described but when you make a package and a library you can add a lot of pictures so xtus is the one that I believe the most do say and you can use it for your projects, not for homework five, right? No, not
(55:28) for homework five, but for your projects. Now, we're talking projects. Now, you're at the cutting edge of machine learning, right? Now, you want to do something that is going to give you good performance. I'm not going to restrict you to say only use sklearn uh boosting. You can use a xg boost, right? So I listed some of their um features.
(55:53) I would say some of their additions and I highly recommend to at least read a little bit. I'm not going to write slides to explain all these things but it is highly optimized for gradient boosting. Now highly optimized it means it runs faster how the code is written. It does have regularization L1 and two regularization to prevent overfeitting.
(56:16) uh you put it straight into your loss. It can be parallelized uses you can use more than one core in your CPU. It can do distributed computing. So now think about this. Why I'm saying this is important. This is not libraries for homework for CS 109A. These are algorithms that they use for large data set.
(56:41) So now you can do a distributed computing using spark or Hadoop uh does the cross validation can uh tune hybrid parameters easily. It does it automatically. You tell them which are the hyperparameters. So it will do the hybrid parameter tuning internally and any any handles missing values. Um so this is everything you need to know about X3.
(57:08) I'm putting these two slides in case you're going to use it for your projects. It's at least reference slides. I'm not going to test you on XG boost on the final of course it makes no sense. Uh so these are basically uh it has this called dmetrix uh which is a data structure that is optimized for these kind of algorithms is using uh it has a classifier and a regressor and you can the hybrid parameters of course is the model complexity the regularization the learning rate and you can change even the loss function you don't have to necessarily use the the exponential
(57:47) loss. Okay. So as I said the I think the the meme tells it very well. sklearn kind of maps very closely to what I have shown here except the optimal lambda for adabus xus using that optimal learning rate for each individual estimator that was writing that from you and it has an additional it calls that the estimator it's doing that and it has an additional global learning this additional five.
(58:23) >> Okay, let me explain this confused. So, uh give me give me five seconds to explain. So, remember we have the the we adding a stamp by multiplying by lambda. So, what sklearn does it does calculate the lambda like the formula I showed but on top of it you can scale everything down or scale everything up. So, I'll write it on the board on it.
(58:52) And because you're not actually I remember last year we dig in and we just All right. Uh tree of the day is spruce. So what the I hear an echo. It's me return. Now I'm out. Uh so remember the t of i is equal to t i minus i -1 plus let's call it mu * lambda i of the stamp right this is the formula this
(59:57) is the formula we have that I show this lambda is how I describe it can you see up there yeah is it big Yeah. So what does karn does? It calculates that but then it puts mu which is like the global learning rate. Okay. So if you put as Chris says mu is equal to one is exactly what I describe in the slides. All right.
(1:00:35) So next I put my learning objectives again for you so you know how to study. Uh explain how adabus works. Describe why adabus is a boosting algorithm. Explain how weight decision stamps are constructed. Understand how the optimal stamp weight is derived from minimized exponential loss. That one don't misunderstand me.
(1:00:58) I don't expect you to derive it. But understand that there is a closed form solution for that. Um recognize notice I'm using the the word recognize. I don't again I don't expect you to prove everything but understand that Adaboos perform functional gradient descent or prediction space gradient descent and identify when adap over fits. All right.
(1:01:24) So that's my learning objective. So you have something to do that. And this is one last game that we're going to have for today. Uh the reason I'm putting is because we never explained this explicit. Can you see the word spruce there? The tree of the day is spruce. Yeah, spruce. You all right? Now I have the final game. Um and it's fun is because I wanted to address one of the things that I kind of talk about is never in my slides, but I wanted to do.
(1:01:55) So these games are not to test you of course is to provoke thinking and to sometimes use it as an opportunity to explain. So the question is are trees parametric or nonparametric? There is two versions. The Bablo versions and the Kevin version. You'll be surprised. Just be just to hold it the suspense. Anybody wants to play the game? We have a new person.
(1:02:23) Did you ever play John? No. >> But can you have somebody else? >> We have a second version. Okay. John, introduce yourself. >> Uh, my name is John. I am a junior in Winthrop House. >> In what? >> Winthrop House. >> Is that a house? >> The best house. >> I'm not Quincy. Sorry. >> Okay. Uh, all right. So, the question is, uh, are decision trees parametric or not parametric? Option one parametric because they estimate parameters, splits and threshold.
(1:02:56) Parametric because they produce finite set of decision trees. Non-parametric because the number of parameter is not fixed in advance and grows with the data. And nonp parameter because they do not assume a specific functional for the relationship. Um well I think it's nonparametric but I feel like I'm between C and D. I feel like they're both.
(1:03:20) They can be both. You can do You can pick two, >> I think. So, um, then I'll probably do C and D. Okay, we all agree with John. Yes. Yeah, there are two correct answer. Okay, now we have the same question inversion. And can you introduce yourself, please? >> Hi, I'm Alen. I'm a junior in Cab House. >> Which house? >> Cabbage.
(1:04:00) >> All right. Ready? It's exactly the same question that what would Kevin said? >> Uh, also CN D. Why it would be different? Yeah, CND the the reason I put it is because in if you go to LLM or you read books there is a definition no parametric depending on the data but for the trees that doesn't play any role right so I wanted to because last time I said statisticians have a different but in the case of trees this is the only reason we don't have all right and I think I'm done I have 10 minutes so this is the latest LLM x2 boost
(1:04:45) Um, all right. This is all I have for today, but I have 10 minutes left. So, I'm going to let everybody go if they want. Actually, we stick around, but I'm going to try to prove that thing because I have time. Um, of why lambda is that it's a nice little proof that every now and then is nice to see.
(1:05:07) So, thank you very much. I see you all on Wednesday. Yesterday is our last lecture. Uh, bring your good clothes. We all going to be wearing white shirt. That's the new thing. Last lecture is white shirt. White shirt or thing. And that will be our last lecture. So conclude this. Richard, stay online. What are you doing on powers on Thursday? >> No Thursday. I'm done.
(1:05:47) >> No, Thursday. >> You didn't come last week. You ditch me. You didn't even told me. I was waiting, crying. Where are my friends? Nobody on Monday. Nobody. No. Thursday. I'm leaving. Leaving. I'm leaving on Wednesday. Yeah. But today I'll be there. Yeah. >> Yeah. Yeah. Yes. >> Also I I didn't really catch what is skarn doing.
(1:06:19) >> Um >> it does calculate the lambdas >> which is the waiting of each model. >> Yes. But then it adds a scaling on top of it. >> Oh to prevent then overfitting. >> Yeah. So you can >> because you're fitting on more and more basically errors. So you need to scale them down on top of the optimal rate >> like regularization >> sort of.
(1:06:40) Yes, actually it's a good way of thinking about. All right. Anybody wants to see the proof? >> Um, today at five. Are you going to have like individual >> if you want? Yes. Nice officer. >> Yeah. >> Let's talk individually. Yes. >> Yeah. Let's talk. >> Okay. Thank you. >> Thank you for the group. But I also wanted to ask um is there a statistical reason why we're using the exponential loss for um our >> the only reason maybe I don't know but the only reason is what I said is it is always the upper bound of the between the accur so you cannot cross it as
(1:07:26) opposed to binary centropy and and accuracy binary centropy and accuracy are not monotonic right it's not upper bound where exponential loss always upper bound to that. So in some ways it goes one to one. So if you have the lowest exponential loss, you guarantee to have the higher saturation which is a nice property to interest.
(1:07:51) Um yes >> I would assume you want binary cross entropy because if you minimize that you minimize well you approximate the likelihood ratio right? >> Yeah but you don't maximize the accuracy. >> You maximize accuracy. >> Yeah. There's a very simple example to see right. So you know because in the accuracy you have to put a threshold.
(1:08:08) So if you you can kind of move everything up. So your binary let me draw this. So this is my threshold right? So let's say I have an example that is one right I can get it with here or here right the binary cross entropy wants to go there. Right? Accuracy doesn't care. But when I go there there's maybe an another example that move from here to here.
(1:08:34) And this goes from here to here. The binary concentrate will reduce because this gain is much more. But the accuracy now you get one hit. Before I got both right. Now I get one right and one wrong. Does that make sense? >> Yeah. And your name again? Michael. >> Michael. Okay. I'm going to do the proof then we do questions. Okay.
(1:08:55) Is anybody wants to see the proof beside Jacob? I'm surprised. Come closer. And I don't have notes, so you're going to have to help me. Right. So the loss is Yeah. Open up. So you can >> Oh. >> So the loss is this. Let's say from one to n e to the minus y. Let's call it n. Okay. So the first thing we're going to do is um split the sum into correct e to the minus actually let's expand this right before we do that.
(1:09:46) So we do e to the minus y and then I have t plus lambda i of s of i of xn right? Yep. So this is going to give me this part right which is e to the minus y n t* e to the minus y n lambda i s i of xn >> lambda iix x i s iixn. This is a stamp right you remember we adding so this is the yhat is the previous t plus this right yeah >> now this is is that clear so I take this I put it here and the rest here >> this is this is the weights uh e to the minus y n lambda i s i xn okay now again now I'm going to split need it and then I'm going to have to turn
(1:10:50) around. So then I'm going to split that sum into the correct and incorrect. Right? So correct. So it's wn and the correct will be e to the minus lambda plus sum of the w n incorrect e to the lambda. Okay. Good. Okay. Uh, now notice maybe I can do it here that the error is sum over the W ends, right? And it's only the correct one, incorrect one, right? Because I have the I.
(1:11:34) So let's put the right. So if it's correct, this is zero. So what I'm going to end up is sum of the incorrect or WN, right? But I also know that this the sum of the W's all of them right is equal to one. So so therefore the sum of the correct is equal to one minus epsilon. You see that step I did a little bit too quickly because these the incorrect plus the correct should be equal to one.
(1:12:10) The incorrect is epsilon. So the correct is uh 1 minus one. This is a correct. Okay. Now this is going to come out e to the minus lambda sum of the correct of w plus e to the lambda of sum of the incorrect of w. But this is correct is 1 minus epsilon. So it's 1 minus epsilon e to the minus lambda plus epsilon e to the lambda.
(1:12:50) Now I solve for this equal to zero. Let's see if I can do it. So is 1 minus epsilon to e to the minus lambda. >> Don't take the derative first. Uh >> we do. Sorry. There's a minus sign. That's all I'm going to get. Right. Then then this goes to the other side. E to the Thank you. The that derivative is important.
(1:13:21) >> Equal lambda. >> E to the lambda. Right. So this goes here. So I have e to the two lamb ah two lambda is equal to 1 minus epsilon / epsilon. And therefore lambda is 12 of log of 1 - epsilon / ep. Ah I got it with no notes. I'm so proud of me. >> This is the perfectly optimal learning rate.
(1:13:56) Any reason why in skarn we don't set this? >> It does. That's what Chris said. So skarn what it does is it says t is going to be plus lambda the optimal. Let's call it >> but they're looking at you said an extra right >> yeah they adding a scaling things just to I think it's an extra regularization right uh I adding an extra thing because I think the problem is I'm not 100% sure why I think it's an extra regularization or what I'm afraid is that this epsilon is too small this whole thing blows up.
(1:14:36) So it gets a little bit un unstable. But I need to read why they're doing that. But in principle, if you put learning rate is equal to one, you you're into that. Did I make a mistake? There was one mistake. Did you find it? There was one little mistake in my notes. I'll correct it. Okay.
(1:14:58) So that's that's how you get the I hope it was clear. Maybe some details you have to go by yourself. Yeah, it's a nice little proof. I like it because this idea of splitting the sum appears in >> equal to this. >> Yeah. Because I went from here I wrote it like that. >> This came out this become the W. This is the sum over everything and then I split it into two parts. Right.
(1:15:19) >> And W is what? >> The weights >> the weights of what? >> You remember every step we rewe the >> the weights of each obser >> observation not the not the >> not the overall >> not the weights of the st is the weight of each observation. Yes. >> Okay. Thank you. >> Yeah. You're welcome. So when we do it this um lambda is it's only an XGA boost that we need that doesn't have