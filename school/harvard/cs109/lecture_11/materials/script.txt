109 day11 - YouTube
https://www.youtube.com/watch?v=CRmioHr-Zvs

Transcript:
(00:05) Can you hear me online? Can you see me online? Great. Good morning everyone. Thank you for those who have braved the weather. We finally had a day that wasn't sunny. You know, it's as if we were in Southern California for a while. Unbelievable. There's going to be a turn for fall weather in the next couple of days. It'll be nice over the weekend.
(00:47) Kevin predicts. That's my Beijian modeling going on. And then uh we'll see how it goes from there. Today we are talking about Beijian modeling and we'll get into that in a bit. Uh but a couple announcements. One homework three we didn't post yet but it'll be posted very soon later today after class today. We're coming together and getting that posted.
(01:14) So expect to see that this afternoon posted for you. Uh it might be a little bit shorter than the first two homeworks and that might be intentional. uh because you also are studying for your midterm at the time as well. So it's a little bit lighter. It's more on interpretations, more on concepts spec uh specifically statistically speaking and trying to understand what those models are doing and of course using them in practice too.
(01:47) Okay, there are a few things on that homework that we haven't directly covered yet in class, though we've hinted at those and if I have a chance today, I'll kind of run through those. One of those is using logarithms for transformations in your variables and how to interpret the resulting models. Another one essentially is what we're going to cover today is using Beijian models and thinking about how to implement those in practice.
(02:18) And I'm drawing a blank on the third one, but it'll come to me eventually. Oh, interaction models, dealing with interactions and interpreting those. You've seen that already, but uh we might go through that again. Okay. Any questions out there announcements wise? You can see the lecture notes on on ad. Great. Great. I want to make sure I got those. I don't have uh Chris over here giving me the thumbs up. All right.
(02:48) So, let's get in today. We're going to start with a little bit of review. And that review is essentially of the quiz. How' the quiz go? Great. You got 100%. No, there's a few little tricky problems, I'm sure. But we're going to do a little game time here. I don't know if the audio comes through. I guess not.
(03:20) Based on the quiz, any volunteers? And if not, I can go through it. All right. name, background, Harvard affiliation, etc. Uh, I'm John. Uh, welcome. I am a junior in Winthrop House. Are you a Browns fan? I am a Browns fan. Congratulations in Ohio. Good luck. Not great this year, but uh it's always a building year.
(03:49) Um, so I think hastily on the exam or on the quiz, I threw down a I saw that MSE formula. Uh but now looking back I I realize the the error I made. Um so I would go with B because we have to train uh that other parameter that we're trying to capture for ridge regular station. Oh so we have we have a debate. We have a debate.
(04:14) This is directly from the quiz. Is it a what is a called MSE? Are we dividing by n? Yes we're dividing by n. or B. What is B? One form of the loss function in since it's squared ridge. Okay, which should we use? Let's hear a round of applause. A or B? How many people think it's A? [Applause] How many people think it's B? Oh, I heard A little bit more than B.
(04:56) Do you want to change what's your answer right now? Well, I think on the quiz I put A and there were more claps for A, so I'm getting a little excited now. And I think it might have been A. Uh, so maybe I'll stick with A. Even a blind squirrel finds nuts sometimes. Yes, A is the right answer. Why? Why? What are we doing? We're trying to assess how well a model is doing out of sample in our validation sets.
(05:32) We don't want to penalize that for a halfaphazard chosen value of lambda in this case. We want a natural loss function or error metric when we're looking out of sample. And that's why we use MSE in our validation sets. John, great job. You got it right. Lucky or not. questions on that. The answer is A. The answer is A. That was the trickiest one, I think. All right. And then the open-ended question we can kind of run through fairly quickly.
(06:03) Oh, I hear some audio. It's not coming through the speakers though, unfortunately. We're fitting a regression model. How many groups? four groups. How many binary predictors do we have? K minus one if there's K groups. So three. The intercept reflects. The prediction for the left out group we call the reference group or the baseline group.
(06:35) And that baseline group is the one left out. That looks like alphabetically chosen AC 209. And so it's the interpretation. And it's the predicted result number of hours spent for those in AC 209. And in fact, it is the sample average if this is coming from real data.
(07:00) So it's the average of that group is what the intercept estimates because that's what minimizes error around that group around the box plot for that group if you will. Minus2 for CS 109A or 109A. What's the minus2 reflect? The difference on average, the drop in the average number of hours spent when you're comparing your baseline group AC 209 to the now relevant group, the CS 1090 or 109. Okay, so two fewer hours.
(07:37) And so we can interpret each of these coefficients. Do we need to say holding for the other variables constant or other predictors in the model constant? I ask it that way. I stage it that way because the answer is no. You got points taken off if you said controlling for other factors in the model. There are no other factors in the model. There is one factor in the model.
(07:58) It is a grouping variable which is parameterized by the other binary predictors as well. There's nothing else we're controlling for. We're only controlling for registration type which is categorical with four groups. Okay, don't blindly use that term when it doesn't apply. 115. Which group is the highest? Obviously, it's the stat 109, my brethren. Which group took the least time? The CS 1090. This is made up data.
(08:27) And so, if we're enrolling somebody as an extension student, they have a zero, they have a one, they have a zero. So you'd predict them to on average spend 14 and a half hours. And we could write out the reg estimated regression model. If instead CS 109 was removed and replaced with AC 209, who's the new baseline group? CS 1090.
(08:50) What should be the new intercept? The 11us 2 9. And everything is in reference to the nine. And so AC 209's estimate would be positive2. and everybody else would be bumped up to because E109 is five and a half hours above the nine hours that 1090 would be as the baseline group dot dot dot. Okay, with me? Great. So that's just through a quick review over from the quiz.
(09:27) Important ideas, those interpretations of those uh categorical variables come over up over and over and over again. And when we get to classification models, logistic regression, and the like coming up after the break, right before the midterm, uh then we'll uh dive into those a little bit more in a different model statement. Don't forget what's on Monday.
(09:53) A holiday. No class. Yay. You got a break. So do we. All right. So let's review where we were last time. We were talking about Beijian inference. It was all based on the idea of Baze rule. What is Baze rule? It's when you flip the conditional sign. All right. In a conditional probability statement. You're given B given A and you're trying to figure out A given B.
(10:19) How does this apply in context of data and models? B given A is our likelihood. It is our model. The probability model that we're inducing on our data. It's the probability distribution of your data given the parameters of that distribution. It's a PDF. It's a PMF. Okay. And then what we're trying to solve for is A given B.
(10:45) What is the now likelihood? the now probability distribution of the parameters which we are now treating as random variables given the data we measured. Okay. And so we start with a prior probability a on those parameters and we're updating its distribution the information given the data we collected and we'll see it again here in a second. Okay.
(11:14) So just giving you some context that prior probability is what is in the formula the probability of a by itself it's a marginal statement it's ignoring the data this is the prior probability and we result in the posterior probability after we take into account the likelihood model that we used for our data connecting the two and so the prior probability the posterior probability in the inferial world is just taking that away from the standard Baze rule formula for events that hopefully you saw in stat 100, stat 104, stat 110 or any stat class you may have taken before coming here.
(11:51) Okay, slow me down if I'm going too fast. We talked about this a little bit last time. These are just copied slides. So this formulation we can talk in terms of theta and x. Theta is the parameters in our model. Whatever model you choose, the distribution you choose and x is the data.
(12:10) This is just the general placeholder for data X. So there's going to be a set of X's and Y's that you really care about. We're just saying in general X for data. Okay, don't get confused on that. Oh, and so we kind of broke that down. We'll often write it in terms of PDFs and likelihoods. And so if we're dealing with continuous random variable and with a continuous prior distribution and posterior distribution on our parameters, then everything's going to be terms of PDFs and little fs.
(12:45) And so mathematically, this is how it breaks down. X is just our data matrix or vector. Sigma is just the set of parameters. And then we have the likelihood. We talked about likelihood already. It's the model we're using. It'll be a regression model. And a regression model has likelihood. We'll get to that in a second.
(13:03) Okay, we'll have the marginal PDFs of our x's. We kind of have to just treat that denominator as a normalizing constant. And it's unimportant actually when we're thinking about the information on the parameters. All right. And so we're kind of just going to cancel that out when we most of the time we do this. We just need the functional form.
(13:27) And then the prior distribution of theta is exactly our belief going into this data collection process of what we think reasonable parameters of theta are. And we'll get into that a little bit more deeper today. And then that posterior distribution is the result. And that's what we're going to use to talk about and interpret what our model is telling us. Okay. Kind of with me? All right. Review from last time.
(13:52) we're going to have to do some in uh integration to figure out what that marginal probability is. But in the as a result, typically we just think about expressing that posterior distribution as being proportional to the likelihood function and the prior distribution, right? And so that's kind of what we're going to rely on all the time.
(14:19) I'm going to ignore this denominator almost always because it doesn't provide any information really that we care about. All right, so here's the simple example. This is kind of where I left off last time. You have three coins in your pocket. You pull all three of them out. Sorry, not all three of them out. You pull one out at random.
(14:40) You know, one is biased to towards heads, one is biased towards tails, and one is a fair coin. And you flip the coin three times and you get one tail and three sorry four times you get one tail and three heads. And your prior probability distribution on your parameters is what? This is contrived. It's a little weird. Sorry people on video. I'm hidden. But hopefully it'll help illustrate what's going on conceptually, intuitively.
(15:11) Where do we expect our posterior distribution to live? What do I mean by that? Yeah, closer to the 90% than to the 10%. 50% is pretty reasonable, too. Okay. How'd you get there? We update our priorities and use the information to see more. The data is giving us information towards that unknown parameter.
(15:48) Okay, that information in the data is a estimated proportion of 3/4s. And so the parameter that is going to favor that estimated parameter of 3/4s is the one where we're going to start to pile up probability. Okay, in the posterior. That's the intuition here. All right, let's define this a little bit. What's our prior for this problem? It's weird. It's contrived.
(16:22) We can put a name distribution to it in a second. We can use a uniform distribution though it's discreet in nature. Okay. So what we're going to do is we're going to say all right our prior for possibilities what's our unknown parameter the true probability P and the probability that P takes on each of those values this is weird notation I'll call it K and K my prior probabilities it could be values 0.5 and 0.
(17:02) 9 and in prior that's 1/3 1/3 Okay, so it's a contrived situation because usually there's no reason in most applications to think a priority that you're going to have a discrete function in your parameter. The only reason we know that here is because there's three coins that I'm picking from.
(17:32) Okay, so this is the discrete uniform distribution if you want to put it in technical terms. Okay, what's our likelihood? What's the likelihood? [Applause] What's the PMF we're going to use? What's our data? It's heads and tails. And we can model that heads and tails result through a binomial.
(18:20) Okay, you could do it as Berni's or you could just do it as one data point based on the binary. Okay, with me and so we're just going to say our data in the end is going to be X which will be the count of heads [Applause] and X is based on a binomial with a P. Well, an N is four. That's fixed. That's known. and a P is the question mark.
(18:50) That's the parameter we're trying to update our information from. Okay, so we're just going to leave it in the general P here. What's the PMF for a binomial? We saw it two lectures ago. If you are a TF for 110 or 104 or something like that, you probably have it memorized. So the probability that X= little K is N choose K P to the K 1 - P to the N minus K. Okay.
(19:27) So that's the probability that X equals K given your value of P with me. Okay. So give me a P. It's going to be one of three things. 0.1 or 0.9 and I can redo this calculation. All right, anybody have a h calculator handy? You all have computers. That's great. I can rely on you as calculators. All right, so there's three choices. We have the world where P is 0.
(19:53) 1, the world where P is.5, the world where P is 0.9. I may have written it too fast. I can evaluate the likelihood the PMF for each of those choices of P. All right. And so the probability that X equals three when P equals 0.1 is just simply what? Plug those numbers in. Right? Plug those numbers in. Four choose three P to the which is 0.
(20:36) 1 3 0.9 to the one with me. Do the same thing for the next one. This is going to be four choose three.5 to the 3.5 to the 1. And this is going to be 4 choose 3.9 to the 3.1 to the 1. All right, you can do this calculation for all three possible choices for P. It's discreet. I can write it on the board.
(21:17) If it was continuous distribution, we're assuming for P. This is a whole lot harder to write out on a board. Okay. And so what do we do here? Just plug those numbers in. Anybody got a calculator? What's four choose three? Four. Great. 1 3.91. There's 10 4th in the denominator. So there's 10 to the 4th in the denominator. There's 9 to the 3r in the numerator. Try to do that in your head. 729 or 00729 * 4.3 something. 03.
(21:53) Did I do that right? Yeah. 93. And then this is going to be similar 4 * 5 4th over 10 4th. And then this is going to be 4 * my bad 0.9 to the 1. This is the one I was thinking of. 93 over 10 4th. I can estimate these. This is going to be a really small value. 036. This is going to be 2562. See if I can do it.
(22:39) 2525 no 25 and this will be 0729 10,000 or something. So this will be like 296 something like that. How close was I? I was probably off by a decimal point. Anybody have a calculator? I did what? 25. 0.25. Is it 036 or 036? Is this 2916? Awesome. Great. Kevin told that sometimes. All right. So, what how do we interpret those three numbers? Which number is biggest? Which number's smallest? Right.
(23:35) This number is unbelievably small. This number is unbelievably big. This number, not unbelievably, this number is a little bit smaller than the largest. Okay? And so we're going to use these. These are the likelihoods of seeing three heads when you flip a coin four times.
(24:01) If you use this coin, if you use that coin, the fair coin, or you use the highly biased coin, which one's most likely? Where should we put our posterior probability weight? in the coin with the highest probability of seeing the data we saw. Okay? And what we do then is our posterior probability the probability that we'll just call it P = 0.1 given X= 3 is proportional to the probability that X = 3 time given that P equals 0.
(24:41) 1 times There should be a times in here times our prior probability. The probability that P equals 0.1. So this is the posterior is proportional to the likelihood times the prior. Our likelihood we just calculated to be 036. Our probability that P equals 0.1 as a prior we said was 1/3. Repeat that process for a posterior of 0.5 just plug it in.
(25:23) This number becomes 0.25. A posterior of 0.9 plug it in. This becomes a posterior or a pri a likelihood of 2916. You calculate those three different probabilities. They don't add up to one. So what do you do? This is a posterior distribution. The probabilities better sum up to one or integrate to one. Normalize. You got to normalize it.
(25:54) So just add up the three probabilities that result and divide each one by that. You can kind of see that since it's a uniform prior distribution, you can see it really just boils down to these three numbers in comparison. All right. And if you do that normalization, that's what's the numbers on the board, re-enormalizing them based on their sum. And intuitively, the numbers match what we think. The probability that P is 0.
(26:21) 9 given these data is roughly 53%.5 roughly 46%. And the chance that it's now the coin with probability 0.1 is not zero, but really small. Okay, we just updated our probability from 1/3 1/3 based on the data we saw and the likelihood of the data that we saw to get our posterior distribution. Okay, it's contrived. It's discreet.
(26:52) We can do things on on paper and pencil or on the board and sum things up. In reality, our parameters are typically continuous, and we're using continuous distributions for those prior and posterior distributions. And I'm not going to be able to solve things in closed form solution on the board with me. Okay? But this is a whole distribution that I get for the possibilities of this unknown parameter P.
(27:22) Okay. Okay, it's a posterior distribution and that distribution in this case is discreet. Which do you believe was chosen? Well, yeah, either one of these is reasonable. It's almost a equal percentage there. How would these probabilities change if instead we collected four coin tosses and we got a K of two instead of a K of three? What would that poster distribution look like? The fair coin is where most of the probability would be. What about the other two? It's symmetric.
(27:58) The other two would have equal probability less than the fair coin. Okay, I don't know if the numbers work out. Go ahead and try it on your home. Practice problem. What if n= 40 and k equals 30? Why did I pick those numbers? The sample proportion is still three quarters. However, the probability now gets shifted way more towards the two models that are close to that 75%. The two choices that are close to that 75%.
(28:34) And so now, as a result, when n equals 40 and k= 30, this is going to have probability with like eight zeros before any nonzero. And these two will shift more towards 535 is going to go up a little bit more. 458's going to go down a little bit. Okay, you with me? Great. Like I said, this parameter space is discreet. That's rarely going to be the case in practice.
(28:58) It's a contrived set. Usually, we're going to put a whole continuous distribution to that parameter. So, this whole idea of taking a basian approach is completely different to the inferences we've done before that you've typically seen in an introstat course, which we call a frequentist approach. It relies on this idea of a prior distribution on a parameter.
(29:18) We're no longer saying there's one true value of the parameter. We just say there's a distributional distribution of believable values for that parameter. This adds the extra uncertainty in the approach. If we have extra priors that can lead to different results.
(29:38) So if you come in with a different prior than me then conditional on the data you might get slightly different answers. Okay? Okay, but as the data and the sample size increases, it's going to start to win out in comparison to your prior, as long as your prior wasn't too strong. And we'll talk about the choices of the priors in a bit. So, we get a whole distribution on our parameter. We're treating it like a random variable.
(30:02) What is it really measuring? It's essentially measuring in the not in the frequentist world but in the Beijian world it's a description of the belief or plausibility in those values of the unknown parameter theta p on the example here we can essentially apply this belief or plausibility to anything that's unknown and uncertain and that can be related to latent things that aren't measured and this idea of the Beijian interpretation of probability is essentially to me equivalent to what a frequentist would call a confidence interval.
(30:36) It's really no different. Okay, so confidence interval that they use in confidence intervals, it's the exact same thing. The posterior probability is just the confidence that a frequentist would use in that statement. All right, so your prior belief is kind of how do you come up with it? It kind of depends on where you're coming from and what information you have going into your modeling before you collect your data. The posterior distribution is basically going to be talking about your belief in the parameter after you've
(31:08) collected data and seen the sample and we update this based on that likelihood. So in practice that's what we're going to do and we're going to see that here in a second. We think of this as the data being fixed once it's measured and we're updating and waiting the values in our unknown parameter P on the board or theta in general based on what speaks to the data what is most in line with the data and the PDF the likelihood is what's giving us that we can start to do inferences based on theta just using a whole posterior distribution a lot of times it's hard to say all right we get this posterior
(31:45) distribution but it's hard to interpret an entire distribution. Just like when you look at a histogram, you want to pull out important pieces of information from that distribution. And so we'll talk about ways to summarize that distribution. Be careful. It's not exactly a sampling distribution. What's a sampling distribution? ific statistic.
(32:22) It's the distribution through repeated sampling of a statistic of what you would see in data if you were to collect it again from the same model. This is different. This is a distribution on the parameter theta. And so it's a different perspective. It's a different use of a random variable, but we can kind of use it in a similar way. It's measuring the uncertainty of a parameter.
(32:46) Whereas the sampling distribution helps us imagine or examine the uncertainty of the estimator. But we can use that posterior to give us really easy ways to calculate frequentist ideas of estimates and interval estimates. And there are things like hypothesis testing, but we're not going to get into that in the Beijian world. It just doesn't really make sense. Okay.
(33:06) Which is better? So when should you use a bay approach? When should you use a frequented approach? How many of you in here have done Beijian modeling before? Why have you chosen to do Beijian modeling before if it wasn't for a class? People just heristically operate that way. People heruristically operate that way.
(33:38) the same naturally. I think in some settings it lends itself very well to the way people naturally think. I have this belief going into my data collection process and then after my data collection process, I want to update my own natural belief. Okay, the big picture idea about Beijian modeling, it does depend on the setting and who you're doing the work for. Uh the frequentist approach is nice and has all of our classical approaches.
(34:07) They were developed first. They're easy to solve numerically. Typically, the Beijing approach are often more computationally intensive. We'll talk about that in a bit. And have really taken off in the last, it says 10 plus years, but you know, 20 or more years. Both times are used, both methods are used. And in some settings, you do both and you compare them.
(34:29) You might have better accuracies with one model than another for future predictions. It might improve your predictions under certain contexts. So if you care about prediction accuracy, it might be a better approach. We'll connect them as well in a bit. A lot of times your results will be similar if you care about the inferences.
(34:49) The credible interval, which we'll talk about in a second, for a Bayian model is going to be very similar to the confidence interval. All right. So why Beijian model? Just to beat a dead horse. It allows for greater flexibility and more complexity. It might improve uh prediction accuracy. It allows you to incorporate expert opinion or prior information, data from an old study, an old survey.
(35:11) Uh it allows for combining various sources of data or studies together and in fact allows you to update your model in real time if data is streaming in. So in the tech world, that's nice examples. Well, I use it in the medical world all the time for meta analyses. So I go through a whole lot of uh literature. I see studies looking at a answering the same question.
(35:35) They all have different estimates for relationships. They all have different uncertainty of those estimates for lack of a better word and then I want to combine them into one grand estimate and I can use these Beijian models to do that and allows for data to be measured at various different levels. What do I mean by this? This is deal and we'll see these hierarchical models when we get back to Beijian modeling later where we might have data measured at different uh levels of hierarchy meaning you might have measures at the state level policy at the state level you might have measures at the county level demographic
(36:13) summaries at the county level and you might have measures at the individual person level and you want to incorporate all of those pieces of data in a proper way into one larger model and so it allows for that as well. We'll see those hierarchical models later in this course. Okay, so just a little bit of motivation.
(36:37) All right, the example we're going to use besides the toy example is the normal normal model. What do I mean by the normal normal model? Usually when you talk about models in the Beijian world, you talk about what the prior model is. It has a distribution. The prior is a pre-specified distribution for the parameter and then com or dash what likelihood function what PDF for the data you expect to see.
(37:05) So the normal normal model says that our prior belief on some parameter follows a normal distribution and then the data when we collect it will follow a normal distribution conditional on that parameter. Okay. And so the normal normal model basically is saying we expect our data to be normally distributed and we're going to take a simple approach here for now because we're going to assume the variance of the likelihood model that data generating model the variance is known.
(37:34) Okay, there's two parameters in that normal and we're just going to put a normal distribution on the mean of that data generating process. Okay, there's a lot of parameters to get your head around here. It can be very confusing very easily. Okay, we're assuming sigma squar is known and fixed. And then this mean prior has its own two parameters which we call hyperparameters.
(38:01) And those hyperparameters are given specific values. We just for now are labeling it as mu0 and sigma 0 squared. Okay, with me kind of how would we write out this model more explicitly? What are the parameters? The unknown parameters in your data generating process essentially are mu and sigma squared. Mu is unknown. Sigma squar is known. So we don't have to put a distribution on it.
(38:28) We can say it's fixed. What are the hyperparameters? Those are what are put on the prior distribution. We can write down the prior. What do I mean by that? What you start out assuming? What you start out assuming? You can write it in several different ways, but mathematically we need to know its PDF. PDF stands for probability density function.
(39:05) So we say the prior for this model is that my mu is distributed normal. mu 0 variance sigma squar 0. What does that mean? Write out the PDF. What's the PDF for this mu? I wouldn't be a good statistician if I didn't know it. I don't expect you to know it. Right? The normal distribution 1 over 2i sigma^ 2 e to the - 12 x - mu^ 2 over sigma^ 2 something like that. Okay, but it's weird. It's not x.
(39:47) What's my random variable? Instead of x, it's now mu. My mean of this distribution isn't isn't just the general mu, it's the mu0. And the variance isn't just sigma, it's the sigma 0. All right? And so we have to be a little bit more careful when we write it down. There's a distinction between mu and mu0.
(40:15) It's confusing, but at least it's somewhat informative as to what those values represent. Okay? What's my likelihood? What are we saying? We're saying our XI's are coming from an independent normal distribution with the general mu and the general sigma squared. The mu is this one. And so it is being treated like a random variable.
(40:51) And since this distribution depends on that mu, I want to be explicit in saying my data as a random variable is a conditional distribution based on another random variable mu. Okay, sigma square we're treating like a constant. You can condition on it too, but if it's a constant, you can ignore it. Okay, sort of with me? Writing out that distributional assumption leads to a PDF.
(41:17) What's that PDF? F ofx subi given mu. Same form. And so that same form 1 over 2 pi. Now it's the general sigma squar e to the - one2 x - mu over sigma that quantity squared. And I think I got it. Okay, note they both have mues involved. All right, and then when I write out the posterior, we have our prior, we have our likelihood.
(41:54) This is for one observation. And what's our assumption about how all the observations are related? They're not. They're independent. And so what happens to the joint PDF of all of my observations together? It's just the product of all the individual measurements. I should put a little I here to know it's the E observation.
(42:24) Okay. And so I can just do the product. So my joint PDF of my X vector given mu is the product of all of these things. Take this whole quantity and plug it in there. The product of that whole function ends up being when you multiply a bunch of e to the things together, it becomes e to the sum of those things, right? E to the 1 * e 2 is equal to e to the 3.
(43:05) Okay? And so we're summing up everything in those exponents. And then what's the posterior? Once we write out the prior and the likelihood, what's the posterior? Do you remember what equation or what symbol we use for that? This is f of mu the prior. This is the theta.
(43:35) This is f ofx given mu the likelihood the theta. And what do we want to return when we combine them together? We want f of theta given our data. The theta now is just a single mu. And B rule, B formula says what is this proportional to? The likelihood times the prior. And so you just take the likelihood X given mu times the prior f of mu.
(44:08) Mathematically, you take this thing and you multiply it by this thing as a product. Simple enough. Okay. And that's what we're now proportional to. Combine those terms. We have two squares. Two things that the unknown function we care about is mu. It shows up twice in these two functions, both in the exponent.
(44:33) And both are in squared terms. And we just need to complete the square and solve to figure out what functional form that distribution looks like. It's all e to something squared. It's going to be based on a normal and solve from there. We're not going to go through the algebra. Okay? Go look online for the algebra today.
(44:53) Okay? What's the normalizing constant? We don't have to worry about it. All we have to do is look for the functional form involving the remaining unknown random variable, which here is just mu. And the functional form of mu is e to mu minus something squared. It's going to be based on a normal distribution. Okay, so that's why the normal normal model is often used because as a result the posterior distribution of mu given x is normal and if you do all the algebra you can solve for it.
(45:26) Okay, we have now an updated mean. We have an updated variance for that posterior distribution that is still normal. And we try to dissect what each of these pieces mean. Okay. What's the posterior distribution look like? It's normal. It's bell-shaped. Great. How spread out is it? Where is it centered? Where's the middle 95%.
(45:55) This these are the questions we're going to ask of that posterior distribution. We're going to figure out what the mean of this normal distribution is. Well, that's easy. We're going to talk about the posterior's mean of that normal distribution.
(46:12) and we're going to talk about the other variables uh pulling out the middle 95% confidence interval credible interval for the Beijian perspective. Okay, let's try to dissect what this formula what this result is telling us. This prior sorry posterior distribution that we see here that should be Xbar. I don't know why there's not a full bar on there. Okay, our data is normally distributed.
(46:38) How do we use our data in the posterior distribution through its mean? Makes sense, right? Where do we think mu is going to be? Centered at where the data says it should be, but it's not exactly there. Okay? Part of it is weighted based on the measurement of the mean. Part of it is based on where we set the prior distribution to be.
(47:03) It's a weighting average of those two variables of those two measurements. The mean in our sample is weighted based on sample size. That's good, right? We want to put more weight to the sample of data. The more data we have and our prior parameter here is based on the variability of our data.
(47:28) And an increase in the variance puts more weight on the data as well in the prior hyperparameter variance. So what does that mean? If I set my prior hyperparameter variance to zero, where's my posterior mean distribution going to be that the prior distribution's mean? should make sense. If I'm saying I'm pretty darn certain that the parameter is right here with no variability, it doesn't matter what data you measure. There's only one place to put the posterior distribution.
(48:03) If I set the po prior distributions hyperparameter variance to be really wide. Now it's basically saying proportionally the prior mean had no bearing whatsoever because I was very uncertain in where the true mean should be where the distribution should be centered with my prior information.
(48:29) Okay, just trying to decompose what those little pieces of information are. and the variance term has a function of n in the denominator which is again a good thing because you're more and more certain that your data is going to win out the distribution gets squeezed.
(48:46) It's sort of like the law of large numbers around that posterior distribution trying to decipher what's happening. Okay, great. Variance of this posterior distribution decreases as n increases assuming you didn't pick something silly uh for various different variance terms. Okay, so that's put in practice how you solve things analytically. We'll see computationally we're going to have to do this instead of closed form solutions in some applications.
(49:11) Okay, we'll get to that in a bit. Before we get there, we want to talk a little bit about our choices of priors. Okay, this is the information we're bringing into our model before we collect our data. All right, and there's a lot of choice or a lot of freedom in how we choose what prior to use. It has bearing on the calculation of the posterior the model results.
(49:36) But how does one choose a prior? I generally say there's three perspectives you can take when defining what your prior distribution will be. One is based on sort of previous studies or a expert's opinion, experts knowledge. One puts alternatively you could put as little information on that parameter that you care about as possible.
(49:59) make it really wide or you choose a posterior distribution that makes things easy to compute and sometimes you can have the best of a few of these worlds. Okay, you don't have to necessarily only pick one out of the three. Okay, previous studies. What do you do? Well, you're interested in predicting the temperature at noon tomorrow. What kind of prior information as an expert on weather, we all are, would you bring into modeling what value you think the temperature might be at noon tomorrow? Ignore the weather forecast.
(50:39) Yeah, let's use some distribution going into it that we think will be centered somewhere near past data suggests it should be. Maybe we just look at the last 10 days and calculate the average and that will be our prior information going into October 9th weather prediction.
(51:01) Okay, a normal distribution centered at maybe today's temperature at noon or pri previous day's temperature at noon. And we might use a prior variance that has to do with day-to-day noon temperatures from the past. You're interested in modeling some probability alternatively that a patient will be cured from a disease based on some new novel treatment.
(51:19) What you care about is putting a prior on P. That probability everybody's either cured or not. It's kind of following this Berni binomial situation. What parameter P? How do you want to model that parameter P? What kind of prior distribution before you collect data and run your study should you put on P? If it was uninformative, what uninformative prior would you put on P? What value of P could it be? What's the probability of success of treatment? What could it be between what values? Zero and one. And if you have no idea
(52:05) going into it where it should be, what do you do to that range of zero and one values? Just pick a random one and put a uniform distribution on it. We're not picking a single number. We're putting a whole distribution to it as a prior. And just say, I don't know, equal weight to all values. That's possible.
(52:26) But if you want to bring some expert information into it, what might you do? Say that again. use a beta distribution. Okay, I won't get to beta distributions later, but what beta distribution should you use based on a placebo? So, use your placebo, use your control experiment as your a priority information.
(52:59) Maybe you pick some distribution like a beta that has the mean the middle of the distribution and somewhat peaked near where standard of cares probability is. It's known to be 80% successful a cure rate for the old uh distribution for the old standard treatment and now maybe we want to create a prior that's centered there.
(53:19) Okay. And maybe use a beta to do it. So distribution whose mean will be the standard of care cure rate. Okay, bringing old information or other information into our modeling process through the prior. Uninformative basically just saying you want to choose a prior that has as little effect on the posterior as possible.
(53:41) If you don't trust your prior beliefs very much, don't put a lot of weight onto it. We saw that in that result of the posterior distribution for the normal normal model already. What do you do? You make your distribution as wide as possible. Okay? Spread out as much as possible or at least in that normal case. And so that uninformative or really minimally informative one is what we want to do.
(53:59) If we're looking at the temperature of noon tomorrow, what might you do? Use a uniform distribution between the record low and the record high temperatures for the day. If you're using a proportion, just put that uniform distribution between values zero and one. Look at the all possible ranges and make it uniform distribution between those.
(54:19) Okay? Doesn't have nice mathematical properties because you might not be able to solve what the posterior distribution will be analytically. That's okay. We have other methods to handle that. Okay. The last thing are use the use of these easily used mathematical results. Those are called conjugate priors. Conjugacy as it's sometimes called.
(54:38) The third approach is basically just the mathematical useful one. And it doesn't only have to be mathematically useful, but it could also have the property of being fairly uninformative or also incorporating information from the past. You can have the best of all three worlds.
(54:56) And so this property is going to be the idea of the use of a conjugacy prior. It doesn't have to be conjugate, but this is a prior distribution that the posterior distribution has the same family as the prior distribution. This is really easy to get confused. It has everything to do with the likelihood. But the prior and the post deer have to match around it.
(55:16) If your data is being generated from a binomial, your distribution of the parameter you care about is on P. And so you put a prior distribution on P, that natural parameter of probability of success. And you're not going to put a binomial on that. It's completely separate from the likelihood, the data generating function.
(55:42) It's based on what reasonable values for that parameter you could have. We've seen this in the likelihood. We had the normal normal model which we put a prior distribution on the normal distribution for the mew on the board. Our data was based on a normal and as a result the posterior was also normal because the functional form in that posterior distribution matched that e to the x^2 idea which is the normal distribution.
(56:14) Why is this conjugate? because the prior normal distribution matches the posterior normal distribution. How do we handle this if both mu and sigma squar are unknown? So we can still use mu being normal. But anybody take a baze class before? Anybody know what conjugacy is in the normal distribution? What's the other unknown parameter? Sigma squar. Okay, let's take a second. Sigma squared. What do we call it in words? the variance.
(56:41) What values can a variance take on? Zero to infinity, some really large number. Okay. And so for a distribution as a prior, we want to pick one that has that support that can take on as a random variable any value between zero and infinity. What distributions take on values between zero and infinity? Not a normal, not a binomial.
(57:05) If you've taken stat 110, what's an example? exponential and the generalization of an exponential is a gamma. Okay. And so it's not technically this variance that we say is gamma distributed. We actually use the inverse gamma here. There's technical reasons for that. It just allows for the conjugacy. Okay.
(57:33) So the precision matrix which is just the inverse of the variance matrix or the precision measure one over the variance measure is what we set to have a gamma distribution. And as a result the resulting joint distribution of mu and 1 over sigma squar in the posterior will still be normal and gamma which is great. We'll get a little bit more into that. So there's a short list. The normal, the two parameters are mu, set it to be normal.
(58:02) One over sigma squar, set it to be gamma. Exponential distribution. For those of you who have taken stat 110 or have heard of the exponential distribution before, what is it? Is it parameter? Joe likes to say it's lambda. Sometimes it's parameterized as one over lambda. Okay, lambda is the rate parameter. It's between zero and infinity as well.
(58:29) And so the rate parameter lambda we also set to be gamma results in a posterior that's also gamma. A binomial distribution. What are the unknown parameters in a binomial distribution? What defines a binomial distribution? We should know this n and p. Which of those are known in a study? Which of those are unknown? N will always be known. You know how many data once you collect okay or going to collect.
(58:56) P on the other hand is unknown and what are the values for P between zero and one. So we want to pick a distribution as a prior that has the bounds between zero and one and P you say let's have it be a beta distribution and as a result we're not going to prove this stuff the posterior distribution will also be beta. Okay, go look this up online.
(59:20) And a pluson Kevin's favorite distribution. I love fish. Unknown parameter is lambda. Again, a rate parameter. And what distribution do you think we're going to put on lambda? Also, gamma. It just matches. There's some exponential family distribution re rationale for why this all works out.
(59:48) But just realize if you're going to pick a prior distribution and put it into code, these are good ones to use. Okay, once you get your whole posterior distribution based on your prior, if you can write it out analytically, if you know the form of your posterior distribution, you can do some calculations pretty easily. Let's go to the normal normal distribution. So if we have as a posterior our normal distribution oops looks like this.
(1:00:15) It's a normal distribution. It's a whole distribution of potential values. It's a bell-shaped curve. And if you take that bell-shaped curve and you want to describe it to your boss, how would you do that? Well, you'd show them the bell-shaped curve. What else would you do? You can use the quantiles. Tell tell your boss where the middle 95% of that distribution is.
(1:00:43) 95% is the general rule of thumb. What else can you do? Talk about where the middle of the distribution is. Talk about the spread in the distribution. Talk about the peak in the distribution. All of these are different summaries of not only data but also theoretical distributions is what is what we're dealing with here.
(1:01:01) And so a normal distribution, the mean of the distribution is easy to figure out. What is it? The mean of a normal distribution is mu. You can just see it right there. Easy to describe. What's the mode of a normal distribution? It's there. It's the mean. So for a data set, once you collect your data and have a prior, you can just say, oh, the middle the mean of my posterior distribution is do the calculation.
(1:01:32) the mode of my distribution do the calculation middle 95% of the distribution which we're now going to call the credible interval and the Beijian padigm how would you do it for a normal distribution I'm asking my students in stat 104 to do it in their midterm today not for a posterior distribution but for a normal distribution in general how do you find the middle 95% The middle inverse normal if you want to be technical.
(1:02:12) Mean plus or minus 1.96 time sigma. Take the square root of that guy the variance. Take your mean plus or minus two or 1.96 more technically that value. And now you got your 95% cred credible interval. It's a normal distribution. Treat it like a normal distribution. Okay. Great. All right.
(1:02:42) So that's just the general idea of use of Beijian modeling, use of Beijian estimation, use of Beijian inference. Let's connect it to what we've learned so far. So in this class, where are we going to apply this in the regression paradigm? Okay, what are our unknown parameters in regression? Let's think about for now just the simple linear regression model. What are the unknown parameters in simple linear regression? How many do we got? Three. What are they? Beta 0, beta 1, and sigma squ.
(1:03:14) All right. And we're going to have to put priors to each of those three terms if we want to take a bayan approach. Okay. with me? What prior should we put to it? Well, what is our functional form of our likelihood model? We'll come back to the prior in a second. Come back to the prior.
(1:04:01) What's the likelihood in regression? How do you write out the model from a probabilistic perspective? Your response variable Y depends on X follows what distribution? A normal distribution. Normal distributions need means and variances. Every observation needs a mean and a variance. What do we say the mean is in simple linear regression. It's linearly related to the predictor.
(1:04:42) It depends on the predictor X in a linear way. And so we just say mu is beta 0 plus beta 1 * x The variance of every observation is the second parameter. What do we make an assumption on in the variance? It's constant. And so every single individual observations variance is just a single number sigma squared. Okay.
(1:05:10) What are the unknown parameters in that expression? Beta 0, beta 1, and sigma squared. And so we need to put distributional assumptions on those. as priors. What distributional assumptions do you want to put on them? What does it feel like? Feels like a normal distribution. In a normal distribution, we have unknown parameters mu and sigma The mu is not just a mu now, but it's a beta 0 and a beta 1 term. It's a linear transformation of two other variables.
(1:05:56) If they're both normal, then and multivariable normal, the resulting will be normal. And so here, beta 0 we're going to assume to be normal. Beta 1 we're going to assume to be normal. It has a prior mean and a prior variance. It has a prior mean and a prior variance. And for now, we're going to just simplify it and say going into it, we have a priority, no correlation between the two. You can generalize this and incorporate a correlation or co-variance.
(1:06:30) And what did we say about the variance for the normal normal model? Rather than modeling the variance directly, we're modeling the inverse variance. And we model that inverse variance based on a gamma distribution. If you don't know what a gamma distribution is, I'm sorry, but we'll get there. What are the parameters on a gamma? It's either n and lambda or a and lambda, depending on who you talk to.
(1:06:55) And we're just going to put little zeros on this. Okay, with all this information, we can write out the PDF for the likelihood function. It's a product of independent observations. We can write out the joint distribution of our three parameters here.
(1:07:17) Note eventually what we're going to do as a result we are treating these three independent but as a result our observations are posterior distribution. The three terms are not independent. Okay. We can write out the prior times the likelihood and write out the posterior in its functional form. As a result, what do we get? We get a normal distribution for the beta 0.
(1:07:36) So we got a normal distribution for the beta 1. We get a inverse gamma distribution for the sigma squared in the posterior. Okay, not going to go through all that algebra. It's important to think about to kind of get a sense of what's going on. So one of the keys here though is that when you get a posterior distribution, I can't tease out two separate distributions for beta 0 and beta 1 and sigma squar itself.
(1:08:05) Beta 0 and beta 1 have a correlation that's induced between them based on the data because your line when you change the slope intuitively you're going to change the intercept. Okay. In the expression for beta 0 beta 1 I'm conditioning on the variance of sigma squared. So it's a conditional distribution.
(1:08:30) How beta 0 and beta 1 how it's distributed depends on sigma squared. And so I need to model sigma squared before I model beta 0 and beta 1 in the posterior distribution. This expression I don't give you the parameters here because man is it long and complex. Okay. But if you want to see it I'll give you the answers eventually. It's also you can find them online.
(1:08:55) This can be generalized so that the prior beta 0 and beta 1 don't have to have independent normals. They could be multivariable normal with a coariance matrix. And number three, we can extend this to multiple regression. There's the extension. What changes? Your beta 0 beta 1 is now a vector of betas. Still multivariable normal.
(1:09:13) And we still have the assumption that there's a single sigma squared. And so we're still using a gamma distribution. This is called the normal gamma joint distribution. It's a multivariable normal distribution. Last time we did apple. Today we do pi. I want to write it pi and not pie. But pi pie apple pie because it's pi season.
(1:09:42) Feels like pi weather coming up. All right. So the last thing I'm going to talk about is the connection with ridge and lasso. Why do we care about beige and linear regression? Because it's intimately connected to ridge and lasso. with a correct choice of your prior.
(1:10:01) It's essentially equivalent to fitting a ridge or lasso model loss function in linear regression. What's this called? Be careful. It's the sums of squares and not the mean square because I didn't divide by n. Okay, n's a constant. Doesn't matter. You're still going to get the same beta estimates. Okay.
(1:10:31) What's the loss function in ridge regression? What do we do to the OS least squares? We penalty penalize that with the squared terms of those betas. And so we take a lambda and sum up with all the beta terms. So I think technically in the notes before and in your quiz it had MSSE with a penalty term. Technically it's SSE with a penalty term.
(1:10:57) So I think that's what's working under the hood. And then what is it for lasso? What do we do instead? It's a different lambda but now we're summing up not the beta squared but the absolute values of the betas. Okay. And then we have a different loss function.
(1:11:17) How can we think about this in terms of prior distributions in order to create the extra penalty term? What are we shrinking our betas towards? A zero. It's as if we put a prior distribution on our beta parameters that are centered at zero. How much weight do we give to the prior distribution depends on lambda and so the variance of the prior distribution is inversely related to lambda.
(1:11:47) Which prior distribution do we know do we need? Well, if it's in terms of squares, don't forget this SSE and the likelihood is in the exponential. If we have beta squared, it's going to be in the exponential and that's going to be lead to a normal distribution. in the denominator in the exponential in the normal likelihood this is in the exponential frame squared and in the prior we want this in the exponential beta in absolute values L1 norm that's going to be an exponential distribution as a prior technically that exponential distribution since it's absolute value what we do instead is shrink towards
(1:12:32) zero and we use what's called the lelass distribution. So a new distribution if you know what an exponential distribution is all it is is it's a mirrored exponential distribution across some value you care about in lasso the value you care about is a zero and so what we do is we use a prior distribution that we're putting weight at zero ridge uses a beta distribution that's based on a normal the sigma squ isn't one. This is an example of sigma squared being one.
(1:13:14) Llas sorry low saying low lasso uses the lelass distribution as its prior. And so you can think about how they all piece together to estimate essentially the posterior distribution has the functional form of the prior times the likelihood. Using lelass as the prior gives you less.
(1:13:37) Using ridge as a prior centered at zero gives you essentially the result of being ridge. Okay, you get a single estimate when you do ridge and lasso. So if you're doing the Beijian approach, you get a whole distribution. So it's a point estimate from that distribution. It's the posterior mean for ridge or posterior mode and for lasso it's the posterior mode. Okay. Anyway, that's all we got today.
(1:14:05) We'll finish up with simulating a posterior next time. Homework 3 is going to be posted in a few hours if it's not already posted. Chris is great at that stuff. And have a great weekend. Don't forget to uh submit pet or homework 2 uh if you haven't already. And if you ask what the word of the day is, you're not paying attention.
(1:14:24) The word of the day is pi. It's not open. It's not open. Yeah, Chris isn't here. He's screwing me over. All right, I'm gonna open up right now.