%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Harvard Academic Notes - 통합 마스터 템플릿
% 모든 강의 노트에 적용되는 통일된 스타일
% 버전: 2.1 - 가독성 개선 (선택적 최적화)
% 최종 수정일: 2025-11-17
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[11pt,a4paper]{article}

%========================================================================================
% 기본 패키지
%========================================================================================

% --- 한국어 지원 ---
\usepackage{kotex}

% --- 페이지 레이아웃 ---
\usepackage[top=20mm, bottom=20mm, left=20mm, right=18mm]{geometry}
\usepackage{setspace}
\onehalfspacing                      % 1.5배 줄간격
\setlength{\parskip}{0.5em}          % 문단 간격
\setlength{\parindent}{0pt}          % 들여쓰기 없음

% --- 표 관련 ---
\usepackage{booktabs}              % 고품질 표
\usepackage{tabularx}              % 자동 너비 조절 표
\usepackage{array}                 % 표 컬럼 확장
\usepackage{longtable}             % 여러 페이지 표
\renewcommand{\arraystretch}{1.1}  % 표 행간 조절

%========================================================================================
% 헤더 및 푸터
%========================================================================================

\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\small\textit{CS109A: 데이터 과학 입문}}
\fancyhead[R]{\small\textit{Lecture 06}}
\fancyfoot[C]{\thepage}
\renewcommand{\headrulewidth}{0.5pt}
\renewcommand{\footrulewidth}{0.3pt}

% 첫 페이지는 헤더 없음
\fancypagestyle{firstpage}{
    \fancyhf{}
    \fancyfoot[C]{\thepage}
    \renewcommand{\headrulewidth}{0pt}
}

%========================================================================================
% 색상 정의 (파스텔 톤 + 다크모드 호환)
%========================================================================================

\usepackage[dvipsnames]{xcolor}

% 밝은 배경용 파스텔 색상
\definecolor{lightblue}{RGB}{220, 235, 255}      % 부드러운 파랑
\definecolor{lightgreen}{RGB}{220, 255, 235}     % 부드러운 초록
\definecolor{lightyellow}{RGB}{255, 250, 220}    % 부드러운 노랑
\definecolor{lightpurple}{RGB}{240, 230, 255}    % 부드러운 보라
\definecolor{lightgray}{gray}{0.95}              % 밝은 회색
\definecolor{lightpink}{RGB}{255, 235, 245}      % 부드러운 핑크
\definecolor{boxgray}{gray}{0.95}
\definecolor{boxblue}{rgb}{0.9, 0.95, 1.0}
\definecolor{boxred}{rgb}{1.0, 0.95, 0.95}

% 진한 색상 (테두리/제목용)
\definecolor{darkblue}{RGB}{50, 80, 150}
\definecolor{darkgreen}{RGB}{40, 120, 70}
\definecolor{darkorange}{RGB}{200, 100, 30}
\definecolor{darkpurple}{RGB}{100, 60, 150}

%========================================================================================
% 박스 환경 (tcolorbox) - 6가지 타입
%========================================================================================

\usepackage[most]{tcolorbox}
\tcbuselibrary{skins, breakable}

% 1. 개요 박스 (강의 시작 부분)
\newtcolorbox{overviewbox}[1][]{
    enhanced,
    colback=lightpurple,
    colframe=darkpurple,
    fonttitle=\bfseries\large,
    title=📚 강의 개요,
    arc=3mm,
    boxrule=1pt,
    left=8pt,
    right=8pt,
    top=8pt,
    bottom=8pt,
    breakable,
    #1
}

% 2. 요약 박스
\newtcolorbox{summarybox}[1][]{
    enhanced,
    colback=lightblue,
    colframe=darkblue,
    fonttitle=\bfseries,
    title=📝 핵심 요약,
    arc=2mm,
    boxrule=0.7pt,
    left=6pt,
    right=6pt,
    top=6pt,
    bottom=6pt,
    breakable,
    #1
}

% 3. 핵심 정보 박스
\newtcolorbox{infobox}[1][]{
    enhanced,
    colback=lightgreen,
    colframe=darkgreen,
    fonttitle=\bfseries,
    title=💡 핵심 정보,
    arc=2mm,
    boxrule=0.7pt,
    left=6pt,
    right=6pt,
    top=6pt,
    bottom=6pt,
    breakable,
    #1
}

% 4. 주의사항 박스
\newtcolorbox{warningbox}[1][]{
    enhanced,
    colback=lightyellow,
    colframe=darkorange,
    fonttitle=\bfseries,
    title=⚠️ 주의사항,
    arc=2mm,
    boxrule=0.7pt,
    left=6pt,
    right=6pt,
    top=6pt,
    bottom=6pt,
    breakable,
    #1
}

% 5. 예제 박스
\newtcolorbox{examplebox}[1][]{
    enhanced,
    colback=lightgray,
    colframe=black!60,
    fonttitle=\bfseries,
    title=📖 예제: #1,
    arc=2mm,
    boxrule=0.7pt,
    left=6pt,
    right=6pt,
    top=6pt,
    bottom=6pt,
    breakable,
}

% 6. 정의 박스
\newtcolorbox{definitionbox}[1][]{
    enhanced,
    colback=lightpink,
    colframe=purple!70!black,
    fonttitle=\bfseries,
    title=📌 정의: #1,
    arc=2mm,
    boxrule=0.7pt,
    left=6pt,
    right=6pt,
    top=6pt,
    bottom=6pt,
    breakable,
}

% 7. 중요 박스 (importantbox - warningbox와 유사)
\newtcolorbox{importantbox}[1][]{
    enhanced,
    colback=boxred,
    colframe=red!70!black,
    fonttitle=\bfseries,
    title=⚠️ 매우 중요: #1,
    arc=2mm,
    boxrule=0.7pt,
    left=6pt,
    right=6pt,
    top=6pt,
    bottom=6pt,
    breakable,
}

% 8. cautionbox (warningbox와 동일)
\let\cautionbox\warningbox
\let\endcautionbox\endwarningbox

%========================================================================================
% 코드 블록 설정 (밝은 배경)
%========================================================================================

\usepackage{listings}

\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.95}

\lstset{
    basicstyle=\ttfamily\small,
    backgroundcolor=\color{lightgray},
    keywordstyle=\color{darkblue}\bfseries,
    commentstyle=\color{darkgreen}\itshape,
    stringstyle=\color{purple!80!black},
    numberstyle=\tiny\color{black!60},
    numbers=left,
    numbersep=8pt,
    breaklines=true,
    breakatwhitespace=false,
    frame=single,
    frameround=tttt,
    rulecolor=\color{black!30},
    captionpos=b,
    showstringspaces=false,
    tabsize=2,
    xleftmargin=15pt,
    xrightmargin=5pt,
    escapeinside={\%*}{*)}
}

% Python 코드 스타일
\lstdefinestyle{pythonstyle}{
    language=Python,
    morekeywords={self, True, False, None},
}

% SQL 코드 스타일
\lstdefinestyle{sqlstyle}{
    language=SQL,
    morekeywords={SELECT, FROM, WHERE, JOIN, GROUP, BY, ORDER, HAVING},
}

%========================================================================================
% 목차 스타일링
%========================================================================================

\usepackage{tocloft}
\renewcommand{\cftsecleader}{\cftdotfill{\cftdotsep}}
\setlength{\cftbeforesecskip}{0.4em}
\renewcommand{\cftsecfont}{\bfseries}
\renewcommand{\cftsubsecfont}{\normalfont}

%========================================================================================
% 표 및 그림
%========================================================================================

\usepackage{graphicx}              % 이미지
\usepackage{adjustbox}             % 표/박스 크기 조절

% 표 캡션 스타일
\usepackage{caption}
\captionsetup[table]{
    labelfont=bf,
    textfont=it,
    skip=5pt
}
\captionsetup[figure]{
    labelfont=bf,
    textfont=it,
    skip=5pt
}

%========================================================================================
% 수학
%========================================================================================

\usepackage{amsmath, amssymb, amsthm}

% 정리 환경
\theoremstyle{definition}
\newtheorem{theorem}{정리}[section]
\newtheorem{lemma}[theorem]{보조정리}
\newtheorem{proposition}[theorem]{명제}
\newtheorem{corollary}[theorem]{따름정리}
\newtheorem{definition}{정의}[section]
\newtheorem{example}{예제}[section]

%========================================================================================
% 하이퍼링크
%========================================================================================

\usepackage[
    colorlinks=true,
    linkcolor=blue!80!black,
    urlcolor=blue!80!black,
    citecolor=green!60!black,
    bookmarks=true,
    bookmarksnumbered=true,
    pdfborder={0 0 0}
]{hyperref}

% PDF 메타데이터는 각 문서에서 설정
\hypersetup{
    pdftitle={CS109A: 데이터 과학 입문 - Lecture 06},
    pdfauthor={강의 노트},
    pdfsubject={Academic Notes}
}

%========================================================================================
% 기타 유용한 패키지
%========================================================================================

\usepackage{enumitem}              % 리스트 커스터마이징
\setlist{nosep, leftmargin=*, itemsep=0.3em}

\usepackage{microtype}             % 타이포그래피 개선
\usepackage{footnote}              % 각주 개선
\usepackage{url}                   % URL 줄바꿈
\urlstyle{same}

%========================================================================================
% 사용자 정의 명령어
%========================================================================================

% 강조 텍스트
\newcommand{\important}[1]{\textbf{\textcolor{red!70!black}{#1}}}
\newcommand{\keyword}[1]{\textbf{#1}}
\newcommand{\term}[1]{\textit{#1}}
\newcommand{\code}[1]{\texttt{#1}}

% 용어 설명 (인라인)
\newcommand{\defterm}[2]{\textbf{#1}\footnote{#2}}

% 섹션 시작 전 페이지 분리
\newcommand{\newsection}[1]{\newpage\section{#1}}

%========================================================================================
% 문서 제목 스타일
%========================================================================================

\usepackage{titling}
\pretitle{\begin{center}\LARGE\bfseries}
\posttitle{\par\end{center}\vskip 0.5em}
\preauthor{\begin{center}\large}
\postauthor{\end{center}}
\predate{\begin{center}\large}
\postdate{\par\end{center}}

%========================================================================================
% 섹션 제목 간격
%========================================================================================

\usepackage{titlesec}
\titlespacing*{\section}{0pt}{1.5em}{0.8em}
\titlespacing*{\subsection}{0pt}{1.2em}{0.6em}
\titlespacing*{\subsubsection}{0pt}{1em}{0.5em}

%========================================================================================
% 메타 정보 박스 명령어
%========================================================================================

\newcommand{\metainfo}[4]{
\begin{tcolorbox}[
    colback=lightpurple,
    colframe=darkpurple,
    boxrule=1pt,
    arc=2mm,
    left=10pt,
    right=10pt,
    top=8pt,
    bottom=8pt
]
\begin{tabular}{@{}rl@{}}
▣ \textbf{강의명:} & #1 \\[0.3em]
▣ \textbf{주차:} & #2 \\[0.3em]
▣ \textbf{교수명:} & #3 \\[0.3em]
▣ \textbf{목적:} & \begin{minipage}[t]{0.75\textwidth}#4\end{minipage}
\end{tabular}
\end{tcolorbox}
}

%========================================================================================
% 끝
%========================================================================================


\begin{document}

\maketitle
\thispagestyle{firstpage}

\metainfo{CS109A: 데이터 과학 입문}{Lecture 06}{Pavlos Protopapas, Kevin Rader, Chris Gumb}{Lecture 06의 핵심 개념 학습}


\tableofcontents

\newpage

\section{개요}

이 문서는 머신러닝 모델을 만들고 평가하는 핵심 과정인 '모델 선택'에 대해 다룹니다.

모델의 성능은 학습 데이터가 아닌, **본 적 없는 새로운 데이터**로 평가해야 합니다.
이 과정에서 모델이 학습 데이터의 노이즈까지 암기하는 **'과적합'**이 가장 큰 문제입니다.
우리는 선형 회귀를 확장한 **'상호작용 항'**과 **'다항 회귀'**를 통해 더 복잡한 모델을 만들 수 있지만, 이는 과적합의 위험을 높입니다.
'모델 선택'은 이 복잡성과 일반화 성능 사이의 균형점을 찾는 과정입니다.
**'교차 검증(Cross-Validation)'**은 단일 검증 세트의 함정을 피하고 모델의 일반화 성능을 신뢰성 있게 추정하는 표준적인 방법입니다.

\newpage

\section{핵심 용어 정리}

모델 선택과 평가 과정을 이해하기 위해 필수적인 용어들을 정리했습니다.

\begin{table}[h!]
\caption{모델 선택 및 평가 핵심 용어}
\label{tab:terms}
\begin{adjustbox}{width=\textwidth, center}
\begin{tabular}{@{}llll@{}}
\toprule
용어 & 쉬운 설명 & 원어 & 비고 (예시) \\
\midrule
\textbf{과적합} & 모델이 학습 데이터를 '암기'해버려서, \\ & 새로운 데이터에 대한 예측 성능이 떨어지는 현상. & Overfitting & 시험 족보만 외우고 응용 문제를 못 푸는 학생. \\
\textbf{일반화 오차} & 모델이 '처음 보는' 데이터에서 발생하는 오차. \\ & 이 오차를 최소화하는 것이 최종 목표. & Generalization Error & 실전 모의고사 성적. \\
\textbf{모델 선택} & 여러 모델 후보(예: 다항식 차수) 중에서 \\ & 일반화 오차가 가장 낮을 것으로 기대되는 모델을 고르는 과정. & Model Selection & 1차, 2차, 3차 함수 중 2차 함수를 선택. \\
\textbf{하이퍼파라미터} & 모델이 학습하기 전에 '사람'이 미리 정해야 하는 값. & Hyperparameter & 다항 회귀의 '차수(M)', KNN의 'K값'. \\
\textbf{검증 세트} & 하이퍼파라미터 튜닝(모델 선택)을 위해 사용하는 데이터. & Validation Set & 여러 모델을 테스트해보는 연습 문제지. \\
\textbf{테스트 세트} & 모델 선택이 끝난 후, '단 한 번' 최종 성능을 보고하기 위해 \\ & 사용하는 데이터. 절대 모델 선택에 사용하면 안 됨. & Test Set & 최종 학기말 고사. \\
\textbf{상호작용 항} & 한 예측 변수의 효과가 다른 예측 변수의 수준에 따라 \\ & 달라지는 효과(시너지 효과). & Interaction Term & TV 광고 효과($X_1$)가 라디오 광고($X_2$)와 함께할 때 \\ & & & 더 커지는 현상 ($X_1 X_2$). \\
\textbf{다항 회귀} & $X, X^2, X^3$ 등 예측 변수의 거듭제곱을 \\ & 새로운 예측 변수처럼 사용해 비선형 관계를 학습하는 기법. & Polynomial Regression & $Y = \beta_0 + \beta_1 X + \beta_2 X^2$ \\
\textbf{잔차} & 모델의 '예측값'과 '실제값'의 차이. \\ & 모델이 잘 맞는지 진단하는 핵심 도구. & Residual & $e_i = y_i - \hat{y}_i$ \\
\textbf{동분산성} & 예측 변수 $X$의 값에 관계없이 잔차의 분산이 일정한 것. \\ & (선형 회귀의 중요 가정) & Homoscedasticity & 잔차 그래프가 깔때기 모양이 아님. \\
\textbf{이분산성} & $X$가 커질수록 잔차의 변동 폭도 커지거나 작아지는 현상. \\ & (동분산성 가정이 깨진 상태) & Heteroscedasticity & 잔차 그래프가 깔때기(fanning) 모양. \\
\textbf{K-겹 교차 검증} & 학습 데이터를 K개의 '조각'으로 나눈 뒤, \\ & K-1개로 학습하고 1개로 검증하는 과정을 K번 반복. & K-Fold Cross-Validation & 데이터를 5조각(Fold)으로 나눔. \\
\bottomrule
\end{tabular}
\end{adjustbox}
\end{table}

\newpage

\section{모델 평가와 과적합의 문제}

\subsection{학습 오차(Training Error)의 한계}

모델을 평가할 때 MSE(평균 제곱 오차)나 $R^2$(결정 계수) 같은 지표를 사용합니다. 하지만 모델을 학습시킨 \textbf{학습 데이터(Training Data)}로 계산된 오차(학습 오차)는 모델의 실제 성능을 보장하지 않습니다.

\begin{warningbox}[title=학습 오차는 믿을 수 없다]
네 개의 서로 다른 데이터셋이 동일한 MSE=1을 가질 수 있습니다. 하지만 그래프를 보면 어떤 모델은 비선형 관계를 놓치고, 어떤 모델은 수직선을 잘못 학습하고, 어떤 모델은 특이점에 과도하게 영향을 받습니다.

단순히 MSE가 낮다고 해서 좋은 모델이라고 말할 수 없습니다.
\end{warningbox}

\subsection{일반화 오차(Generalization Error)의 중요성}

우리의 진짜 목표는 모델이 \textbf{본 적 없는 새로운 데이터(Unseen Data)}에서도 잘 작동하도록 하는 것입니다.
이때 '새로운 데이터'에서 발생하는 오차를 \textbf{일반화 오차(Generalization Error)}라고 부릅니다.
모델 선택의 목표는 이 일반화 오차를 최소화하는 모델을 찾는 것입니다.

\subsection{과적합(Overfitting)이란 무엇인가?}

\textbf{과적합(Overfitting)}은 모델이 학습 데이터의 패턴(경향성)뿐만 아니라, 데이터에 포함된 사소한 노이즈(Noise)나 특이점(Outlier)까지 모두 '암기'해버리는 현상을 말합니다.

\begin{examplebox}[title=과적합 비유: 암기만 잘하는 학생]
과적합된 모델은 마치 시험 범위의 모든 예제와 답을 통째로 암기한 학생과 같습니다.
\begin{itemize}
    \item \textbf{학습 데이터 (시험 족보)}: 100점을 받습니다. (낮은 학습 오차)
    \item \textbf{새로운 데이터 (응용 문제)}: 암기한 내용과 조금이라도 다르면 전혀 풀지 못합니다. (높은 일반화 오차)
\end{itemize}
모델은 데이터의 '개념(Trend)'을 배워야지, 데이터 자체를 '암기(Noise)'하면 안 됩니다.
\end{examplebox}

과적합은 모델이 필요 이상으로 복잡할 때 발생합니다.
\begin{itemize}
    \item 예측 변수(Feature)가 너무 많을 때
    \item 다항 회귀의 차수(Degree)가 너무 높을 때
    \item 상호작용 항이 너무 많을 때
\end{itemize}

\subsection{모델 해석(Interpretation)의 함정}

모델의 성능 지표(MSE)가 좋아 보여도, 반드시 모델의 계수(Coefficient)를 해석하여 상식에 맞는지 확인해야 합니다.

\begin{examplebox}[title=모델 해석의 중요성: TV 광고 예산]
TV 광고 예산(X)과 매출(Y)의 관계를 모델링한 두 가지 경우입니다.

\begin{itemize}
    \item \textbf{사례 1: $Y = -0.05 X + 6.2$}
        \item \textbf{문제}: 기울기가 음수(-0.05)입니다. 이는 TV 광고 예산을 늘릴수록 매출이 줄어든다는 뜻입니다. (상식에 맞지 않습니다. 데이터에 오류가 있거나, 모델이 잘못되었을 수 있습니다.)
    \item \textbf{사례 2: $Y = 0.02 X - 0.5$}
        \item \textbf{문제}: 절편이 음수(-0.5)입니다. 이는 광고 예산이 0일 때(X=0) 매출이 음수가 된다는 뜻입니다. (마찬가지로 상식에 맞지 않습니다.)
\end{itemize}
단순히 숫자에만 의존하지 말고, 모델이 현실을 잘 설명하는지 항상 비판적으로 검토해야 합니다.
\end{examplebox}

\newpage

\section{선형 회귀의 확장: 비선형성 다루기}

단순 선형 회귀는 강력하지만 현실의 복잡한 데이터를 설명하기엔 한계가 있습니다. 더 복잡한 모델을 만들기 전에, 선형 회귀의 기본 가정부터 확인해야 합니다.

\subsection{선형 회귀의 4가지 핵심 가정}

우리가 사용하는 MSE(평균 제곱 오차) 손실 함수는 다음 4가지 가정을 암묵적으로 전제합니다.
\begin{enumerate}
    \item \textbf{선형성(Linearity)}: 예측 변수와 반응 변수 간에 직선적인 관계가 있다.
    \item \textbf{독립성(Independence)}: 각 데이터의 오차(잔차)는 서로 독립적이다. (MSE는 단순히 오차 제곱을 '더하기' 때문에 이 가정이 필요합니다.)
    \item \textbf{등분산성(Homoscedasticity)}: 모든 데이터 포인트에서 오차의 분산이 동일하다. (MSE는 모든 오차에 '가중치'를 두지 않기 때문에 이 가정이 필요합니다.)
    \item \textbf{잔차의 정규성(Normality of Residuals)}: 잔차가 정규분포를 따른다. (오차를 '제곱'하는 방식은 정규분포 가정과 통계적으로 연결됩니다.)
\end{enumerate}
이 외에도 '예측 변수 X는 오차가 없다(Fixed X)', '예측 변수 간 상관관계가 높지 않다(No Multicollinearity)' 등의 가정이 있습니다.

\subsection{진단 도구: 잔차 분석(Residual Analysis)}

위의 가정이 맞는지 확인하는 가장 좋은 방법은 \textbf{잔차 분석}입니다. 잔차($e = Y - \hat{Y}$)를 X축에, 예측 변수($X$)나 예측값($\hat{Y}$)을 Y축에 그려봅니다.

\begin{itemize}
    \item \textbf{좋은 모델 (가정 만족)}: 잔차가 0을 기준으로 특별한 패턴 없이 무작위로 흩어져 있습니다. (White Noise처럼 보입니다.) 잔차의 히스토그램은 종 모양(정규분포)을 띕니다.
    \item \textbf{나쁜 모델 (선형성 위반)}: 잔차가 U자형, S자형 등 뚜렷한 패턴을 보입니다. 이는 모델이 데이터의 비선형적 경향을 놓치고 있다는 신호입니다.
    \item \textbf{나쁜 모델 (등분산성 위반)}: $X$가 커질수록 잔차의 변동 폭이 커지거나(깔때기 모양, Fanning) 작아집니다. 이는 이분산성(Heteroscedasticity)을 의미합니다.
\end{itemize}

\begin{summarybox}[title=잔차 분석의 핵심]
"잔차 플롯에서 어떤 패턴이든 보인다면, 심지어 용이나 성(Dragons flying over castles)이 상상되더라도, 모델의 기본 가정이 위반되었을 가능성이 높습니다."
\end{summarybox}

\subsection{확장 1: 상호작용 항 (Interaction Effect)}

현실에서는 한 변수의 효과가 다른 변수에 따라 달라지는 \textbf{시너지 효과(Synergy Effect)}가 흔합니다. 이를 모델링하는 것이 \textbf{상호작용 항}입니다.

\begin{examplebox}[title=예시: 소득과 학생 여부가 대출 잔액에 미치는 영향]
\textbf{모델 A: 상호작용 항 없음}
$balance = \beta_0 + \beta_1 \times income + \beta_2 \times student$
\begin{itemize}
    \item 비학생(student=0): $balance = \beta_0 + \beta_1 \times income$
    \item 학생(student=1): $balance = (\beta_0 + \beta_2) + \beta_1 \times income$
\end{itemize}
\textbf{해석}: 학생과 비학생은 기본 잔액(절편)만 다를 뿐, 소득(income)이 1단위 증가할 때 잔액이 $\beta_1$만큼 증가하는 \textbf{기울기는 동일}합니다. (두 개의 평행선)

\textbf{모델 B: 상호작용 항 추가}
$balance = \beta_0 + \beta_1 \times income + \beta_2 \times student + \textbf{$\beta_3 \times (income \times student)$}$
\begin{itemize}
    \item 비학생(student=0): $balance = \beta_0 + \beta_1 \times income$
    \item 학생(student=1): $balance = (\beta_0 + \beta_2) + \textbf{$(\beta_1 + \beta_3)$} \times income$
\end{itemize}
\textbf{해석}: 학생과 비학생은 절편도 다르고($\beta_0$ vs $\beta_0+\beta_2$), 소득이 증가할 때의 \textbf{기울기도 다릅니다}($\beta_1$ vs $\beta_1+\beta_3$).
만약 $\beta_3 > 0$이라면, 학생은 소득이 증가할 때 비학생보다 대출 잔액이 더 가파르게 증가(더 많은 소비)한다는 의미입니다.
\end{examplebox}

\subsection{확장 2: 다항 회귀 (Polynomial Regression)}

데이터가 명백한 곡선 형태일 때, \textbf{다항 회귀}를 사용합니다.
$Y = \beta_0 + \beta_1 X + \beta_2 X^2 + \dots + \beta_M X^M$

\begin{summarybox}[title=다항 회귀의 "속임수": 왜 이것도 선형 회귀인가?]
다항 회귀는 $X$와 $Y$의 관계는 비선형이지만, 통계적으로는 \textbf{다중 선형 회귀의 특수한 경우}입니다.

\textbf{속임수(Trick)}: $X^2$를 $\tilde{X}_2$, $X^3$를 $\tilde{X}_3$라는 완전히 새로운 예측 변수로 취급합니다.
$Y = \beta_0 + \beta_1 X_1 + \beta_2 \tilde{X}_2 + \dots + \beta_M \tilde{X}_M$

이렇게 변환하고 나면, 이 모델은 각 계수($\beta_0, \beta_1, \beta_2, \dots$)에 대해 선형입니다.
따라서 다중 선형 회귀를 푸는 것과 동일한 방식($\hat{\beta} = (\tilde{X}^T \tilde{X})^{-1} \tilde{X}^T y$)으로 $\beta$ 값들을 찾을 수 있습니다.

\texttt{sklearn}에서는 \texttt{PolynomialFeatures}로 $X, X^2, X^3...$ 항들을 만든 후, \texttt{LinearRegression}을 \texttt{fit}시키면 됩니다.
\end{summarybox}

\subsection{다항 회귀의 함정: 스케일링과 항의 개수}

\begin{warningbox}[title=다항 회귀 사용 시 주의사항]
\begin{enumerate}
    \item \textbf{특성 스케일링(Feature Scaling) 필수}:
    $X$의 범위가 100만 되어도 $X^{10}$은 천문학적인 숫자가 됩니다. 이렇게 값의 범위 차이가 극심하면 컴퓨터가 $\beta$ 값을 계산할 때 수치적으로 불안정해집니다.
    다항 회귀 사용 전, \texttt{StandardScaler} 등을 사용해 $X$의 범위를 (평균=0, 표준편차=1)로 표준화하는 것이 좋습니다.

    \item \textbf{\texttt{PolynomialFeatures}의 작동 방식}:
    \texttt{sklearn}의 \texttt{PolynomialFeatures}는 기본적으로 '1' (절편 항), '상호작용 항' ($X_1 X_2$) 등을 모두 포함하여 생성합니다.
    \begin{itemize}
        \item 이 도구가 '1'을 이미 만들었으므로, \texttt{LinearRegression}을 학습시킬 때 \texttt{fit\_intercept=False} 옵션을 주어야 절편이 중복 계산되지 않습니다.
        \item 예측 변수가 여러 개일 때 불필요한 상호작용 항이 너무 많이 생겨 과적합을 유발할 수 있습니다.
    \end{itemize}
\end{enumerate}
\end{warningbox}

다항 회귀의 차수 $M$을 몇으로 할지 정하는 것 자체가 \textbf{하이퍼파라미터 튜닝}이며, 모델 선택의 핵심 문제입니다.
\begin{itemize}
    \item \textbf{M이 너무 낮으면 (예: 1차)}: 데이터의 곡선 트렌드를 못 잡아냄 (과소적합, Underfitting)
    \item \textbf{M이 너무 높으면 (예: 50차)}: 데이터의 모든 노이즈를 통과하는 구불구불한 선이 됨 (과적합, Overfitting)
\end{itemize}

\newpage

\section{최적의 모델 찾기: 모델 선택 (Model Selection)}

모델 선택은 과소적합과 과적합 사이의 '최적점(Sweet Spot)'을 찾는 과정입니다.

\subsection{데이터 3-분할: 학습, 검증, 테스트}

이를 위해 데이터를 3가지 용도로 나눕니다.
\begin{tcolorbox}[title=데이터의 3가지 역할]
    \begin{itemize}
        \item \textbf{학습 세트 (Training Set)}: 모델을 학습(훈련)시키는 데 사용. (모델의 $\beta$ 계수들을 찾는 데 사용)
        \item \textbf{검증 세트 (Validation Set)}: 학습된 모델들 중 최적의 하이퍼파라미터(예: 다항식 차수 $M$)를 \textbf{선택}하는 데 사용.
        \item \textbf{테스트 세트 (Test Set)}: 모델 선택까지 모두 끝난 후, 우리가 선택한 최종 모델의 일반화 성능을 \textbf{보고}하기 위해 '단 한 번' 사용.
    \end{itemize}
\end{tcolorbox}

\begin{warningbox}[title=테스트 세트의 신성불가침 원칙]
"테스트 세트를 사용해 모델을 선택하거나 튜닝하는 행위는 학계의 가장 큰 금기 중 하나입니다." (마치 모의고사 문제로 기말고사를 내는 것과 같습니다.)
테스트 세트는 모델 개발 과정에서 완전히 격리되어야 하며, 최종 성능 보고 시에만 사용해야 합니다.
\end{warningbox}

\subsection{모델 선택 방법론}

예측 변수가 $J$개 있을 때, 어떤 변수를 모델에 포함시킬지 고르는 방법입니다.

\begin{itemize}
    \item \textbf{전체 탐색 (Exhaustive Search)}: $J$개의 변수로 만들 수 있는 모든 조합($2^J$개)의 모델을 다 만들어보고, 검증 세트 성능이 가장 좋은 것을 고릅니다. 변수가 10개만 돼도 1024개, 20개면 100만 개가 넘어 현실적으로 불가능합니다.
    \item \textbf{탐욕적 알고리즘 (Greedy Algorithms)}: 매 순간 '지금 당장' 가장 좋아 보이는 선택을 하는 방식입니다.
        \begin{itemize}
            \item \textbf{전진 선택법 (Forward Selection)}:
                1. 아무 변수도 없는 모델($M_0$)에서 시작.
                2. $J$개의 변수 중 1개를 추가했을 때 검증 오차가 가장 많이 줄어드는 변수를 추가 ($M_1$).
                3. $M_1$에 $J-1$개의 남은 변수 중 1개를 추가했을 때 검증 오차가 가장 많이 줄어드는 변수를 추가 ($M_2$).
                4. ... 변수를 $J$개 다 쓸 때까지 반복.
                5. 만들어진 $M_0, M_1, \dots, M_J$ 중에서 검증 오차가 가장 낮았던 모델을 최종 선택.
            \item (이 외에 후진 제거법, 단계적 선택법 등이 있습니다.)
            \item \textbf{장점}: $2^J$에 비해 $O(J^2)$ 수준으로 계산이 훨씬 빠릅니다.
            \item \textbf{단점}: 최적의 조합을 놓칠 수 있습니다. (예: $X_1$만 있을 때보다 $X_2$만 있을 때가 더 나빠도, $X_1+X_2$ 조합이 $X_1+X_3$ 조합보다 훨씬 좋을 수 있습니다.)
        \end{itemize}
\end{itemize}

\subsection{하이퍼파라미터 튜닝과 검증 세트}

다항 회귀의 차수 $M$을 찾는 것과 같은 하이퍼파라미터 튜닝이 모델 선택의 핵심입니다.
$M=1, 2, 3, \dots, 10$까지의 모델을 모두 \textbf{학습 세트}로 학습시킨 뒤, 각 모델의 성능을 \textbf{검증 세트}로 평가합니다.

\textbf{모델 복잡도(Degree)에 따른 오차 그래프}
\begin{itemize}
    \item \textbf{학습 오차 (Training MSE)}: 모델이 복잡해질수록(차수가 높아질수록) 학습 데이터를 더 잘 '암기'할 수 있으므로 \textbf{계속 감소}합니다.
    \item \textbf{검증 오차 (Validation MSE)}:
        \begin{itemize}
            \item \textbf{과소적합 영역 (Underfitting)}: 차수가 낮으면 트렌드를 못 잡아 오차가 높습니다.
            \item \textbf{최적점 (Best Model)}: 트렌드는 잘 잡고 노이즈는 무시하는 지점에서 오차가 가장 낮아집니다.
            \item \textbf{과적합 영역 (Overfitting)}: 차수가 너무 높으면 노이즈까지 암기하기 시작해, '새로운' 검증 데이터에서는 오차가 다시 \textbf{증가}합니다.
        \end{itemize}
\end{itemize}
우리는 이 검증 오차 그래프(U자형 커브)에서 \textbf{오차가 최소가 되는 지점(Minimum)}의 차수 $M$을 최적의 하이퍼파라미터로 선택합니다.

\newpage

\section{신뢰할 수 있는 평가: 교차 검증 (Cross-Validation)}

\subsection{단일 검증 세트의 문제점 (CV의 동기)}

만약 데이터를 학습/검증 세트로 딱 한 번만 나눈다면, \textbf{검증 세트가 우연히} 특정 모델에 유리하게 뽑힐 수 있습니다.

\begin{examplebox}[title=단일 검증 세트의 함정]
데이터의 실제 트렌드는 3차 함수(노란색 선)에 가깝다고 가정해봅시다.
하지만 우리가 \textbf{우연히} 뽑은 검증 데이터(분홍색 점)가 1차 함수(녹색 선) 근처에 몰려있을 수 있습니다.

이 경우, 우리는 1차, 2차, 3차 모델을 검증 세트로 테스트한 후, "검증 오차가 가장 낮은 1차 모델이 최고다!"라고 잘못된 선택을 하게 됩니다.

이는 우리가 \textbf{학습 데이터에 과적합}되는 것을 피하려다, \textbf{검증 데이터에 과적합}되는 결과를 낳습니다.
\end{examplebox}

\subsection{K-겹 교차 검증 (K-Fold Cross-Validation) 절차}

이 문제를 해결하기 위해, 데이터를 '여러 번' 다르게 쪼개서 검증하고 그 성능을 '평균'내는 것이 \textbf{교차 검증}입니다. (K-Fold CV가 표준입니다.)

\textbf{전제}: 테스트 세트는 미리 분리해두고 절대 사용하지 않습니다. \textbf{남은 학습+검증 데이터}를 가지고 다음을 수행합니다.

\begin{enumerate}
    \item 전체 학습 데이터를 K개의 균등한 '조각(Fold)'으로 나눕니다. (보통 K=5 또는 K=10 사용)
    \item K번의 반복(Iteration)을 수행합니다.
    \item \textbf{1번째 반복}:
        \begin{itemize}
            \item 1번 조각(Fold 1)을 \textbf{검증 세트}로 사용합니다.
            \item 나머지 K-1개 조각(Fold 2, 3, 4, 5)을 \textbf{학습 세트}로 사용해 모델을 학습합니다.
            \item 학습된 모델로 Fold 1을 예측하여 검증 오차($MSE_1$)를 계산합니다.
        \end{itemize}
    \item \textbf{2번째 반복}:
        \begin{itemize}
            \item 2번 조각(Fold 2)을 \textbf{검증 세트}로 사용합니다.
            \item 나머지 K-1개 조각(Fold 1, 3, 4, 5)을 \textbf{학습 세트}로 사용해 모델을 학습합니다.
            \item 학습된 모델로 Fold 2를 예측하여 검증 오차($MSE_2$)를 계산합니다.
        \end{itemize}
    \item \textbf{... K번째 반복}까지 동일하게 수행합니다.
    \item \textbf{최종 CV 점수}: K개의 검증 오차($MSE_1, \dots, MSE_K$)를 \textbf{평균}냅니다.
    $CV(Model) = \frac{1}{K} \sum_{i=1}^{K} MSE_i^{val}$
\end{enumerate}

모델 선택(예: 다항식 차수 $M$ 찾기)을 할 때, $M=1, M=2, M=3$ 등 각 후보에 대해 이 K-Fold CV 과정을 모두 수행하고, \textbf{CV 점수가 가장 낮은 $M$}을 최종 모델로 선택합니다.

\subsection{LOOCV (Leave-One-Out Cross-Validation)}

K-Fold CV의 극단적인 형태로, $K=N$ (데이터 포인트 개수)인 경우입니다.
\begin{itemize}
    \item 총 N번의 반복을 수행합니다.
    \item 매 반복마다 데이터 1개만 검증 세트로 쓰고, 나머지 N-1개로 학습합니다.
    \item 장점: 편향(Bias)이 매우 낮습니다.
    \item 단점: $N$번이나 모델을 학습시켜야 하므로 계산 비용이 매우 비쌉니다.
\end{itemize}

\subsection{구현: \texttt{sklearn}과 \texttt{neg\_mean\_squared\_error}}

\texttt{sklearn.model\_selection.cross\_validate} 함수를 사용해 교차 검증을 쉽게 수행할 수 있습니다.

\begin{warningbox}[title=Scoring: 왜 'Negative' MSE를 쓰는가?]
\texttt{sklearn}의 교차 검증 및 튜닝 도구는 점수(Score)를 \textbf{최대화(Maximize)}하도록 설계되어 있습니다. (예: 정확도(Accuracy)는 높을수록 좋음)

하지만 MSE는 \textbf{최소화(Minimize)}해야 하는 '오차(Error)' 지표입니다.
따라서 MSE를 최소화하는 것은 \textbf{-MSE를 최대화}하는 것과 같습니다.

\texttt{cross\_validate}의 \texttt{scoring} 매개변수에 'mse'가 아닌 \textbf{'neg\_mean\_squared\_error'}를 전달해야 올바르게 작동합니다.
\end{warningbox}

\begin{lstlisting}[language=Python, caption={sklearn을 사용한 교차 검증 (의사 코드)}, label={lst:cv}]
from sklearn.model_selection import cross_validate
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline

# 예: 3차 다항 회귀 모델 파이프라인 생성
model = make_pipeline(
    PolynomialFeatures(degree=3, include_bias=False),
    LinearRegression(fit_intercept=True) 
    # PolynomialFeatures가 1을 만들지 않게(include_bias=False)하고
    # LinearRegression이 절편을 찾게(fit_intercept=True) 할 수 있음
    # (또는 반대로 설정)
)

# 데이터 X, y와 5-겹(cv=5) 교차 검증 수행
# 점수 지표로 'neg_mean_squared_error' 사용
cv_results = cross_validate(
    model, 
    X, 
    y, 
    cv=5, 
    scoring="neg_mean_squared_error",
    return_train_score=True # 학습 스코어도 반환
)

# cv_results['test_score'] 에 5개의 (음수) MSE 값이 들어있음
# 이 값들의 평균을 내고 부호를 바꾸면 최종 CV 점수(MSE)가 됨
final_cv_mse = -cv_results['test_score'].mean()
\end{lstlisting}

\newpage

\section{빠르게 훑어보기 (1페이지 요약)}

\begin{tcolorbox}[title=모델링 핵심 요약 카드]
    
    \begin{tcolorbox}[colback=white, title=\textbf{1. 목표: 일반화 (Generalization)}]
    모델의 진짜 성능은 '처음 보는' 데이터(Unseen Data)에서 나옵니다.
    이때의 오차(일반화 오차)를 최소화하는 것이 목표입니다. 학습 데이터 오차(Training Error)는 중요하지 않습니다.
    \end{tcolorbox}

    \begin{tcolorbox}[colback=white, title=\textbf{2. 적: 과적합 (Overfitting)}]
    모델이 너무 복잡해져서(예: 너무 높은 차수, 너무 많은 변수) 학습 데이터의 '노이즈'까지 암기하는 현상입니다.
    \textbf{증상}: 학습 오차는 매우 낮지만, 검증 오차(일반화 오차)는 매우 높습니다.
    \end{tcolorbox}
    
    \begin{tcolorbox}[colback=white, title=\textbf{3. 확장: 비선형 모델링}]
    \begin{itemize}
        \item \textbf{상호작용 항 ($X_1 X_2$)}: 한 변수의 효과가 다른 변수에 따라 달라지는 '시너지' 효과를 모델링합니다.
        \item \textbf{다항 회귀 ($X, X^2, X^3$)}: 데이터의 곡선 트렌드를 잡습니다. (주의: 스케일링 필수!)
    \end{itemize}
    \end{tcolorbox}

    \begin{tcolorbox}[colback=white, title=\textbf{4. 전략: 모델 선택 (Model Selection)}]
    과소적합(너무 단순)과 과적합(너무 복잡) 사이의 균형점을 찾는 과정입니다.
    \begin{itemize}
        \item \textbf{데이터 3-분할}: \textbf{학습}(훈련), \textbf{검증}(모델 선택/튜닝), \textbf{테스트}(최종 보고).
        \item \textbf{방법}: 하이퍼파라미터(예: 차수 $M$)를 바꿔가며 \textbf{검증 세트} 오차(Validation MSE)가 U자 곡선을 그릴 때, 가장 낮은 지점을 선택합니다.
    \end{itemize}
    \end{tcolorbox}

    \begin{tcolorbox}[colback=white, title=\textbf{5. 무기: K-겹 교차 검증 (K-Fold CV)}]
    단일 검증 세트는 '우연'에 의해 잘못된 모델을 선택할 수 있습니다. (검증 세트에 과적합)
    \textbf{해결}: 데이터를 K조각으로 나눠, K번의 (학습/검증)을 반복하고 그 오차를 \textbf{평균}냅니다.
    이 CV 점수를 기준으로 하이퍼파라미터를 선택하는 것이 가장 신뢰할 수 있습니다.
    \end{tcolorbox}
\end{tcolorbox}

\newpage

\section{초심자 FAQ}

\textbf{Q: 다항 회귀가 왜 '선형' 회귀인가요? 너무 헷갈립니다.}

A: $Y$와 $X$의 관계(그래프)는 곡선(비선형)이 맞습니다. 하지만 모델을 수식으로 볼 때, $Y = \beta_0 + \beta_1 X + \beta_2 X^2$에서 우리가 찾아야 할 값은 $\beta_0, \beta_1, \beta_2$입니다. 이 \textbf{계수(Coefficient) $\beta$에 대해서는 덧셈으로만 연결}되어 있으므로 '계수에 대해 선형(Linear in parameters)'이라고 부릅니다. $X^2$을 $\tilde{X}$라는 새로운 변수로 보면 $Y = \beta_0 + \beta_1 X + \beta_2 \tilde{X}$가 되어 다중 '선형' 회귀와 형태가 똑같아집니다.

\textbf{Q: K-겹 교차 검증에서 K는 몇으로 정해야 하나요?}

A: 정답은 없지만, 관례적으로 \textbf{K=5 또는 K=10}을 가장 많이 사용합니다.
K가 너무 작으면 (예: K=2) 검증 데이터의 변동성이 커서 불안정하고, K가 너무 크면(예: K=N, 즉 LOOCV) 계산 시간이 매우 오래 걸립니다. 5 또는 10이 계산 비용과 추정치의 안정성 사이의 적절한 타협점으로 알려져 있습니다.

\textbf{Q: 검증 세트와 테스트 세트가 뭐가 다른 건가요? 둘 다 '평가'하는 것 아닌가요?}

A: 역할이 완전히 다릅니다.
\begin{itemize}
    \item \textbf{검증 세트 (Validation Set)}: '모델을 고르기 위한' 평가 세트입니다. 마치 여러 벌의 옷(모델 후보)을 입어보고(테스트) 가장 잘 어울리는 옷(최적 모델)을 \textbf{'선택'}하는 과정입니다.
    \item \textbf{테스트 세트 (Test Set)}: '선택이 끝난 후' 최종적으로 한 번만 평가하는 세트입니다. 가장 잘 고른 옷을 입고 나가서 사람들(새로운 데이터)에게 \textbf{'평가 보고'}를 받는 과정입니다.
\end{itemize}
검증 세트로는 여러 모델을 반복적으로 테스트하지만, 테스트 세트로는 최종 선택된 단 하나의 모델만 테스트해야 합니다.

\textbf{Q: 특성 스케일링(StandardScaler)은 언제나 필요한가요?}

A: 항상 필수는 아니지만, 사용하는 것이 훨씬 안전합니다.
단순 선형 회귀($Y=\beta_0+\beta_1 X$)에서는 스케일링이 결과에 영향을 주지 않습니다.
하지만 \textbf{다항 회귀}($X^2, X^3...$), \textbf{정규화 회귀}(Ridge, Lasso), \textbf{KNN}, \textbf{SVM}, \textbf{신경망} 등 대부분의 고급 머신러닝 모델은 특성 간의 스케일 차이에 매우 민감합니다. 따라서 모델링 전 스케일링을 적용하는 것을 습관화하는 것이 좋습니다.

\end{document}
