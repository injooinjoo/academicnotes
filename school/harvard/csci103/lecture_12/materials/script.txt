(4) 103 day 12 - YouTube
https://www.youtube.com/watch?v=FaaJQozVdGw

Transcript:
(00:01) Okay, awesome. So, uh, we're 5 minutes past 6:30 p.m. here on the East Coast. So, I'll get started. Um, we'll see if other people join as we go along. So, today we are going to discuss uh governance. Um, so data and AI governance and a few other topics that I'll be talking about related to governance.
(00:27) And uh, it's going to be a lot of theory and some terms that I'll throw at you. Um, in case you've not heard some of these terms before, that's totally fine. Um, depending on who you talk to, governance is either super interesting or super boring. Uh, so your perspective may differ depending on where you sit in an organization. And, uh, I personally like thinking about governance.
(00:50) Um, so you know, data bricks has a tool called Unity catalog which you guys have, uh, you know, seen a little bit. Um so I I do um like work with that product team a little bit. So I uh this is a space that I'm interested in. But uh the first half of this today's lecture will be a lot of theory. So please bear with me. Uh I'll try to like not make it too boring.
(01:10) Uh and then the second half we'll try to link what whatever we learned in the theory part to actual product features in data bricks. Right? And then that's just to give you a frame of reference of you know here are some theoretical concepts and this is how an organization may implement it using a tool of their choice.
(01:28) Uh that doesn't have to be data bricks that could be any other enterprise governance catalog or tool. Uh but you know wherever you go there will be some tool uh some you know SAS product or or or a platform as a service product that is doing something similar. uh so you know giving you both sides of the spectrum will at least help uh help you see something similar when you when you encounter it at some other organization right so let's get started um so this is the agenda for today I've uploaded the the slides uh and it's it's it's actually the slide deck is much longer than stuff that Eric and Anita
(02:02) have done um but uh we won't touch on every slide I just wanted to have have have that there for reference um but the structure is going to be like we'll talk a little bit about information governance and data and AI governance just to set the foundation and then um then we'll connect all of that to various features and data bricks that do u you know try to achieve the same things not not always um not always identical but working towards the same goal and that will give you an idea and then we'll spend some time in the data bricks workspace just seeing some of these features
(02:36) okay so just to set some expectation here there uh depending on who you talk to again their concept of governance or their frame of reference for governance uh could be very different depending on where they sit in the org and what their background is. Um so the larger sort of umbrella term here is information governance and that's an all-encompassing term that contains these constructs of data governance and AI governance in them.
(03:08) uh in most organization when when when let's say you're a data engineer and somebody says you are not supposed to have access to this data set that's data governance right uh but what's the reason that you're not supposed to have access to that particular data set that is probably some overriding information governance principle uh which you may or may not be privy to and you don't know or you don't care but the organization cares about it so that's where like a lot of the larger umbrella picture of information governance comes in it influences is decisions made to achieve data governance or AI governance.
(03:41) So let's first talk about information governance, right? So information is basically any data or knowledge or AI asset or however you want to categorize it uh that is created, collected, stored, processed, shared, right? It's it's anything uh that is uh that is transmitted in some way that is considered information. So it's a very very broad term.
(04:06) Uh and it's not just you know things on the cloud. Uh it's physical u copies. um like if you uh you know most organizations at least when look I work from home a lot these days but back when I was sitting in a cubicle for uh for uh for you know years and years uh it was a big no no to essentially like let's say print something and not go pick it up right because you don't know what you printed like or the organization doesn't know what a certain person printed but there may be something sensitive in there that somebody else is not supposed to have access to. So the the rules that govern th those kind of things within the
(04:42) organization that that's part of the big umbrella picture of information governance, right? Um it's also things like um you know or lock your laptop before you you leave the your desk, right? You're just you're these are like sort of physical uh physical security controls that an organization is trying to do.
(05:05) So, but it all comes part of that information governance umbrella because what the organization is trying to do is protect whatever is sensitive or considered sensitive or what they consider uh you know PII or what they consider um their IP you know they want to protect all of those things right um today in like you know in in most organizations what when you hear governance you're thinking about uh data and AI governance which is you know what are the data sets we're ingesting and who has access to them and you know what models are we producing and things of that nature, right? Um so but it's all
(05:35) governed by this larger information governance umbrella. Um so how how do we break it down like what is what is information governance really right? So as it states here it's a framework of a few different things. So there are policies, procedures, standards and controls and we'll touch on each of these as as we go along.
(05:55) And what is the purpose of these things? They want to manage uh the assets effectively. They want to ensure that data is secure and accurate and accessible. Uh and almost most importantly they want to be compliant with legal and regulatory requirements because there may not be a large cost to you know you printing out some sensitive information within the organization.
(06:17) Uh but the problem is like if that's ever if if some action like that is ever caught in an audit and you are under some regulatory guideline um like you know HIPPA or PCI compliance or something like this or like GDPR rules whatever like there are all these rules in the organization uh that you're supposed to be adherent to right and so when an audit comes uh what's going to get caught that's the biggest concern from an organizational perspective and most of the controls that that happen in information governance are coming from
(06:48) the perspective of we should not make a mistake that costs us a lot of money, right? Uh and all of the policies and procedures and standards are all sort of tying back to that larger umbrella. Um and so whatever organization is uh whatever uh however the org is structured uh there's somebody in your organization that may be like the chief data officer or the chief governance officer or there's some title like this who who cares about making sure the organization is safe and secure and that's what they're tasked with and they
(07:21) are the ones implementing um sort of the policies internally that align to standards externally right um so what what are the goals of information governance, right? So, everybody's sort of heard the term that like data is the new oil. Um, I actually think it's it's more valuable than oil, right? Because it's not it's it's it's not a uh uh a a resource that runs out.
(07:46) You're constantly producing data. Uh your customers are producing data or uh you're buying data or selling data. And so, um there there it's it's almost like renewable or limitless from that perspective. and you want to generate the maximum amount of value from that particular data.
(08:04) Right? So that's the left part of this quadrant which is like you want to maximize information value. Um you also at the same time want to mitigate risk which is like the bottom um section here. So while you want to maximize value, you also want to minimize risk.
(08:25) So you have these two goals and they're both equally important because you may not be able to maximize value if you had you know introduced risk. somewhere, right? Um, so one might drag the other one down. Um, so that's the way to think about it. Uh, and all of these other uh things that you see on the slide here, which is that you want to enhance, uh, information security. You want to make sure your organization is compliant with uh, you know, the latest and greatest.
(08:48) Uh, like for a long time, we were all, you know, having uh, like, you know, changing passwords maybe every 15 days or 30 days or whatever your organization might mandate. Uh then we moved or at least a lots of organizations have moved to essentially like hardware based keys, right? Maybe you have a UB key or an RSA token or something like this that you plug in to your machine and you know you you touch it cuz that's your your second level of authentication. Um so and though and the organization wants to keep up with whatever standards are uh you know sort
(09:20) of adopted in the industry to be the most secure. Uh and then you want to optimize information life cycle management because you are constantly uh likely ingesting a lot of data from your own sort of apps or sources. Maybe you're buying data. Uh but then you have to think about like uh is it always valuable to store this data forever? Uh do you have like sort of aging out policies? Do you have an archival strategy uh at some point this data you know is there a time to live for this particular data set? you're starting to
(09:54) think about that like what is the life cycle of any piece of information that I need to govern in my organization uh and then you want to promote transparency and accountability right so uh we'll talk a little bit about this later but there are various like ways in which an organization may take this uh some of it is like very centralized and some of it is like uh you know decentralized federated sort of models uh and whatever works best for the organization they're going to align with that uh but they're always or trying to establish these clear roles
(10:25) as to who is supposed to do what. Uh there are different types of data stewards uh and there are different types of governance officers and they have slightly different lens on what is important in an organization and so they they try to like delineate those roles.
(10:43) Uh which is why you some sometimes find you know like a chief data officer then there's chief data asset officer and there's all these like slight distinctions between titles. Um but uh like I mentioned before implementing these audit trails and reporting mechanisms is like super super important uh because that's the you have to have audit of everything that's happening but you also need an easy way to report on this because when an auditor comes asking uh you don't want to have to go and spend you know cycles to try to figure out their answer. you should be
(11:12) anticipating the question and have the answer ready to go, right? And a lot of time is spent on establishing the frameworks that make you successful from that perspective. Um so let's talk a little bit about um what the definition and uh or or how to think about this from a larger perspective.
(11:30) Uh you'll see on the left here there's uh a a title called definition which is the top part of the slide which I'll click through and then there's an operations right and I just want to talk about the entire life cycle. So imagine this is your organization. You have some executive leadership. You have some corporate governance office.
(11:47) That's a chief governance officer or something like this. Then you have a legal and compliance department. And then you have each business unit, right? You have several business units for example. So the legal and compliance officer uh or office is supporting the corporate um governance office who is essentially supporting executive leadership uh in terms of making sure that they're doing the right thing for the organization.
(12:10) Um and then as we click through into this um there are corporate standards and policies that are typically defined by some type of executive leadership position. Now that may be the CEO, CEO, CFO uh not the CFO typically but maybe the co or the C chief governance officer and they're defining these corporate standards and policies.
(12:32) Um and then the business unit uh leadership is essentially defining their own business unit standards and policies but they have to be compliant with the larger organization policies right so there's a sort of um element of a little bit of decentralized leadership but they're still compliant with the larger goal right and that defining that larger goal is very important uh and then you have these IT standards and policies which are also compliant uh with all of these policies uh because um you know It's it's sometimes I see the arrow go the
(13:03) other way around like a business unit wants to do something but it is the one that's saying you cannot uh so you know it's not hard and fast that this is the only way to draw this diagram uh but this is typically it wants to support business objectives right and they don't want to get in the way of business objectives so that's the way to think about this um and then we come into the actual uh thing that we may be dealing with on a day-to-day basis which is like the data office or the governance specialty office or whatever you want to define it. They are defining standards for actual data assets, right? Which is
(13:38) your tables, your files, your models, whatever you're generating within the organization. You have thousands of PDFs lying around. Uh who has access to these PDFs? How are they being governed? You know, these questions are being asked and somebody has to answer these questions.
(13:54) Um but why are we doing all of these things? It's because of these external guidelines. Right? Now obviously organizations typically want to do the right thing uh to just be safe and secure and there's no like unnecessary like sprawl and messiness but uh there is like sort of this like the sword of damic lease hanging uh you know on top of their necks which is all of these rules right there are laws and jurisdictions uh there are industry regulations there's compliance certifications so depending on where your organization falls you are
(14:25) answerable to an authority higher than you and they're going to come asking you those questions. So your whole goal in defining these standards and policies over here is to make sure that you can answer the questions here and uh that you are always compliant.
(14:44) Uh and so that's essentially a huge like motivator to do the right thing, right? Uh and then also there are external other recommendations, right? So they may be uh sort of uh cultural and ethical things that are happening slightly different in geographical parts of the world. Uh in many cases sometimes the EU is ahead of the US. Uh when it comes to certain you know regulations um and like for example like GDPR you know started started in the EU. Uh then like CCPA is a similar thing in California.
(15:13) But there are different types of rules where they establish um what is the right of an individual right to their data. So if if an individual says my data should be erased then if there's a law governing how soon a corporation should act on that that's coming from these uh sort of uh you know laws and jurisdictions and you know cultural and ethical sort of mix that is happening geographically right but uh notice we haven't gotten to the operation aspect right so what happens in the operation aspect is basically you can establish all of these things but you have to have a way to implement these things. How are you implementing
(15:53) this? So that's the operational aspect of this whole discussion. And so they you have now IT and business units that's the people uh essentially one step below the leadership here who are implementing uh whatever rules need to be implemented in an organization and they are implementing it through platforms and data on and on data and AI assets they own and so this is where like the operational aspect comes into play and this is actually what the data bricks platform uh will do right so we're linking back to an actual tool tool here. Uh you don't have to think of
(16:28) it as data bricks specifically but any other platform. So just if I flip back the original slide was information governance overview and then when we flip we say information governance with data bricks and says okay what is data bricks responsible for? We are not defining corporate standards and policies. We are not defining laws and jurisdictions.
(16:52) We are helping uh IT organizations and business units implement whatever is required for them to be compliant right through features that we may have. Now we may not have all the features and you may have to build your own. Uh but that's the goal. The goal is that as a platform we hope to have enough uh governance features in there that help you meet some or all of your uh requirements. Right.
(17:18) Um any questions at this point or I'll keep going. Moan, I just I had a question about like today there was um some news that Door Dash had some sort of um data breach and where I think credit card information was lost. So I was wondering is that also a driver in this um in this diagram like like consumer trust where does that fit in? Yeah.
(17:54) Uh yeah it's not it is definitely yeah could be added here um but um they are so like for for data breaches specifically there are like let's say laws right like I I get sometimes like a flyer in my email or not in the actual mailbox that says uh whatever like you know Experian had some data loss like in your example it was Door Dash uh but your data may be compromised and then you know like uh do you do you want to join this whatever class action lawsuit or you may be entitled to some free protection for credit monitoring for 3 months or whatever. And they're not doing that out of the goodness of their heart. They're doing that because they were mandated by one of these things
(18:30) here uh that you know you you breached consumer trust and you're you had an agreement that uh you would you know secure your data a certain way and you breach that right so there's a repercussion to the organization uh but I think it's more monetary it's uh more more than monetary it's a reputational risk right um I remember a few years ago there was a capital one uh data breach like it may have been five or 10 years ago I don't remember exactly and they it took a long time for them to like live that live that down and build up their reputation as uh you know as having
(19:05) enough security standards. Uh so even though uh there is a there's definitely a loss of reputational uh you know there's a reputational risk and a lack of trust uh that that happens. Uh but it's yeah it's not specifically called out but I would say that uh it's definitely another carrot. Right.
(19:31) So regardless of whether these laws were there when there is an incident like that uh you are losing some reputational risk which is you know much harder to make make back up. Makes sense. Thank you. Um so okay so data governance or governance in general is a holistic approach right? So like we said there are if you go back a few slides uh unfortunately I have to page through but there's these policies procedures standards and controls and we're going to essentially dive into that now uh and there are some policies right so those policies could be defined like I said it could be like by a government or by some
(20:03) independent body uh that you have to adhere to um and those policies are essentially uh recommending certain standards that you need to adhere to uh and then you you have these procedures uh that you have to do to implement those policies and then you have controls to enforce those policies, right? Um and we'll break it down a little bit. So this is the like the definition.
(20:26) How do you actually do the operational aspect? So procedures are typically implemented as processes. So how the the way to think about that is let's say I'm onboarding a new user to a platform. what is the process to onboard that user to the platform and what should he have access to once he's onboarded.
(20:51) So, if I'm onboarding a new employee and he ends up with a new laptop, uh it's somewhere written down that these are the things that need to be pre-installed on the laptop, right? Uh maybe there's a sort of u like antivirus thing installed. Maybe there's some other agent installed that monitors my actions on the laptop. those were uh those were those those processes were defined by the organization uh as an implementation of some procedure they wanted to do right so that's the way to think about that and it's executed by people obviously right because there's your IT department or whoever else in the case of like uh the big data world or the cloud it expands to your you know
(21:25) your admin admins from a cloud perspective uh right uh whether it's like data bricks admin or like a bigquery admin or an AWS admin there are these roles roles that people play uh that that control what what access people have. Uh and so that's your people.
(21:44) Uh and then the people are obviously uh using uh the standards meaning the people are adhering to the standards established. Uh and then how do you actually do it? You you know hopefully you're automating it but even if you're not automating it, you have some technology uh that could be data bricks, it could be something else.
(22:03) uh if you're talking about like enterprise data governance catalogs it's like things like you know Elation and Calibbra if you're talking about security it's companies like Immuta and Profera or it's just natural you know you know other cloud vendor sort of tools that are available and you have acquired to do uh you know to implement this right you're not writing everything from scratch is the point here you uh because that that's you know there's a lot of risk in doing everything from scratch when there are established ways to do So you most likely will go and procure some software or some tool that allows you to implement these processes,
(22:36) right? And so in the in this is a simple example, it's saying that uh from the technology perspective here, you're using data bricks, but it could be anything else that you use to implement that. Uh and these controls are obviously implemented in that particular tool.
(22:52) So if I'm a user and I have access and I'm supposed to have access to some particular data set uh in in in this particular example it would be that that data set is governed by unity catalog uh and there is like a schema owner or a meta store owner or a catalog owner who's defining who has access to what uh and then as we go more into the fine grain things it'll be like oh he's only supposed to have access to part of this table right so you get finer and finer in terms of how you want to implement these controls But the basic principle is that it's a least privilege uh thing.
(23:24) Uh I should not be onboarding and just having access to everything all data assets that organization has. There has to be some set of policies and processes that define what is the narrowest scope of um access this person needs in order to be able to function uh in order to be able to fulfill his job function and then expand out from there if needed.
(23:48) Right? It's always it's u much easier to like start a little bit secure and expand out as needed rather than sort of leaving the door open. Right. So the horse has bolted the barn. Um and then yeah so how are they implemented in whatever tool you you are procuring for that using the standards right so it's basically like it's sort of an end to end loop if you want to think about it.
(24:13) Um and um again uh just like just a visual to think about all of these things fitting in together right but let's take a concrete example so GDPR is basically you know the rule uh you know it started in the EU it said uh you know it started off as sort of the right to be forgotten uh if I submit a request that says uh you know my data should be removed from your system in 45 days well not in 45 days removed from your system the GDPR rule says that you should act on this in in such a period of time. Right? So let's take that as an
(24:43) example. So the policy is that uh there is a data protection policy, a privacy policy and a retention policy. Right? So that's essentially what GDPR is. It is telling you the policy and then the procedure is actually implemented uh or or GDPR is basically recommending a procedure for you to do this which is that uh how should you go and do this right? It's not telling you exactly how you should implement it. It's telling you what we expect you to do, right? To adhere to the policy.
(25:15) So in this case, it's like, hey, step-by-step instructions for handling requests from individuals who want access to their personal data, right? So it's like give me all of the data I have access to cuz you can do this for example in you can go to your Google account and say give me all of my data. Uh and you can say delete my data.
(25:32) Now you cannot do that quite the same way in let's say in Michigan as in France because the rules are different right. So Google is uh adhering to whatever rule the larger mandate is saying right. Uh and then uh there are these standards. So what are the standards in in terms of how you align uh because those standards are saying that hey you may need to encrypt this data a certain way.
(25:58) you may need to minimize the storage of data uh like not essentially proliferate it within your organization more than it needs to and who has access to what right so when we do our internal like security training like every few months or so uh some of those things are basically like uh how do you essentially control access to uh only what people need to right so those are the the standards um and like arbback is a is a principle sort of a term that you may hear a It's role based access control.
(26:27) So based on whatever role you're playing, what should you have access to, right? And it can be implemented in multiple ways. Uh and then there is controls, right? So the controls are basically the measures or mechanisms that you put in place to enforce these policies. Uh so it's like who this is like the who has access to what basically what's the technical control, right? Uh do you have to do multiffactor authentication to like you know log into something? Uh what is the administrative control, right? Who has you who is allowed to access something? uh and then the physical controls which is like you know typically not something
(26:56) that we have to think about in our roles uh but you know IT admins are thinking about physical controls all the time right so anyway this is an example of like policies procedures standards and controls uh and it changes depending on what you're talking about right so this was just showing an example of GDPR so that that is essentially foundational of information governance now we're going to dive into the data and AI governance which is a subset of it.
(27:26) So what what what is the difference between data governance and AI governance, right? And AI governance has been around for a while in various sort of names and shapes and um you know terms but has really started becoming formalized a lot more as uh more and more you know uh more and more sort of initially started with essentially models that a customer would take their own data uh maybe they would you know do some model training on top of that data and produce a data asset right but it's expanded now out so much because we have these large scale uh you know LLMs that are trained on all
(28:04) types of data uh some of it public data that probably they should not have access had access to train on uh but also data that they may have acquired uh in some in some other way that is not completely disclosed.
(28:21) So anyway the model itself could have been trained on all kinds of data assets they had access to. uh from an organization's perspective the question here is am I uh using any data that I am not legally supposed to access right so when you have security conversations at customers a lot of them are asking hey oh I see you you support you know open AAI's chatgptt model or you support the gemini model um what is my in what is your indemnity right and what that means is really like if I was to use the service that you're providing And let's say they're asking data bricks. This is oh data bricks you're making the Gemini models available. Let's say I use the
(28:57) Gemini model and create a data product and then make profit out of it. Is somebody going to come ask me uh and tell me that I did the wrong thing? Like what is like what what what's my protection that I'm doing the right thing? Right? So the whole AI governance umbrella has expanded because now you're using uh essentially a model in this case a large scale a large LLM to uh to profit from eventually right uh most likely uh it may not be only for that you may be training your own internal tools on on this fine-tuning a model or whatever but the the scope is much
(29:34) larger than it used to be right because you have now access to models that are trained on essentially uh everything that exists out in the Right. Um so again data governance is um is governing essentially how you store the data, how you collect, store and secure this data, right? And AI governance is basically doing a similar thing but it's about the uh the the development, deployment and oversight of AI systems, right? Um so this is more this is more traditional. The data governance is more traditional. It's what organizations have done for
(30:04) like decades. uh AI governance is slightly newer and and crosses the barrier a little bit into like ethics and like am I doing the right thing right over here it was more about protecting uh what was legitimately yours and here you are a little bit concerned about oh am I doing the right thing in terms of you know this particular model that I'm using or am I using the model the wrong way uh is there inherent bias in this model should I account for it you're starting to think about all of these things rather than just securing your data, right? So that's the the difference between those
(30:40) two things. Uh but organizations today have to think about both, right? Every organization wants to be a data and AI organization. So your governance principles have to accommodate for both. Uh and I've seen like uh I think recently I think it was this week one of our large financial services customer, they introduced a brand new like sort of uh chief uh chief data AI governance officer or something like this, right? So if they they're trying to like make it more and more formal uh so that they don't make any missteps um going forward right so it's it's part of the maturity
(31:13) uh journey of that organization um again just to summarize so you have information governance which is like the all-encompassing um structure and you have data governance and AI governance and I'm not going to read all of this but uh you can just sort of see the scope is very broad here right for information governance like we talked about data governance is narrower because you're talking about data life cycle, quality, protection, security, and then when you go to AI, you're thinking about models, algorithms, risks, bias, things of that nature,
(31:41) right? Um, and all of these things have to be considered in a large organization today. Um, if you want to dive a little bit deeper, these are the kinds of things that you'll see in a typical organization.
(32:00) You say, hey, how's my m how how can I find the metadata of all of the data that I have? How do I do data discovery? How do I do master data management? how do I classify data? Right? All of these things are being debated from an organizational perspective. Um, and on the AI governance side, it's about again like I said, model life cycle, right? So, you have all of these models.
(32:19) What's the life cycle? What are they using? Uh, how am I how am I monitoring uh the model for uh to prevent it from doing anything wrong, right? So if I have let's say a data product uh that is that is powered by a model and that model is giving uh harmful or incorrect answers how am I monitoring the quality of that right uh because it's it's much more dynamic than just saying oh I certified my data it's this is clean like you know certified gold level data and I have you know a bunch of SQL queries running on this that's that's less risky than essentially having a model query that and answering something
(32:58) that is incorrect. Right? So how am I monitoring that? Uh so the scope is a little bit bigger and there is a capability section we'll touch on later if we have time. Um but the important takeaway from this slide is you cannot have AI governance without data governance.
(33:21) Like I think it would be impossible for an organization to be a great AI governed organization. let's say without having a good data governance strategy, right? Because all of the things that you're doing uh from the perspective of AI is founded upon the fact that you secured your data in the first place. Uh so again, it's one of these maturity curves where uh you know, maybe it's a new organization and they think they can be AI govern AI governance is the first thing they should do, but that would be a mistake, right? they should start from sort of the fundamental building blocks uh
(33:51) before they get to AI governance. uh and uh I'm not going to touch on this in in too much detail but there are things these are the kinds of things that a that a vendor like data bricks or anybody else is going to think about say oh should we build a build a feature for data classification should we build a feature for lineage right and maybe we do and maybe another vendor has but some of these things are directly tied to features that some vendor may tell you they have and some of these are more uh
(34:20) sort of opaque in that you may have to implement it on your phone or maybe it's just a process on top of a feature, right? Um so that's where like you know there are these topics uh and topics don't always align one-on-one to actual feature lists that any vendor is giving you.
(34:38) Uh and that's where like uh you know your governance officer and your procurement officer are looking at these things and figuring out what is the best tool for the job uh when they are actually going and making a a purchasing decision. Um again another way to look at it. So there's uh okay so sorry this is a slightly uh slight of tangent here.
(34:57) We've talked about data governance so far, but there's also the concept of data management that we've been talking about for way longer, right? Ever since, you know, data warehouses existed 30 years ago or even probably before that I was too young to know. Uh there's always been the concept of data management, right? It is the operational aspects of handling data.
(35:16) Uh and it involves all of these things that is that is said here which is slightly different from data governance because you are establishing the policies, procedures and standards for managing. So this is the operational aspect of uh essentially like what is the life cycle of data if you want to think about it that way.
(35:35) But then here you are asking the questions about the who what and how of of that uh you know life cycle like who's supposed to have access who's not supposed to have access how should they have access. So that's the data governance pillar and this is the data management pillar which is more uh more established. Uh but it's it's of common topics of interest to all of the the play the players who are interested in these things right.
(35:54) uh there is uh somebody in your organization who's worried about data quality. Uh it may be part of the governance thing. It may be part of something else but there's somebody who cares about it and there's somebody who cares about compliance, right? And that's your uh the legal side also cares about compliance.
(36:15) So all of these like sort of um functions uh map somehow to you know governance and management and there's overlap between uh these topics depending on you know the personas involved right and in a similar fashion there's one for AI governance and AI management this is newer so AI management again if you think about it just like data management it's the operational process how should we do this right how should we model uh how should we do the life cycle of a model how should we monitor uh those models. So this is like comes into like the whole like sort of MLOps life cycle.
(36:45) Uh but on the left side AI governance is again uh the little bit of the gray area like should we do this like uh is it ethical or should I think about some repercussions here right so it goes far beyond the scope of just operationalizing some process uh and again there are all of these sort of committees or however you want to think about it there's roles and committees that are thinking about this in your organization and driving processes and procedures within your organization. to achieve uh these things in in in the
(37:18) right way. Um uh this is a very heavy slide so I'm not going to read all of it. Uh but this is all of the things that uh you uh you have to think about as like if you were a chief data governance officer these are the kinds of things they're thinking about right uh they want a unified data ecosystem they want standardized data practices they want collaboration because you want to break down silos uh sorry and then you want to increase data data literacy which means if I have a piece of data in my organization let's say there's a table and uh there's no
(37:52) common definitions to uh there's no there's no way for a user without uh significant training to understand what this means. That means there's a very high data literacy bar. Meaning like it's very difficult to get to the point where the common user in your organization can just understand what a particular data element is talking about.
(38:16) Right? So it comes from metadata descriptions uh businessfriendly names which is typically called like semantic layer. So all of these things uh increase the data literacy of an organization. Uh and then ownership and accountability is like sort of a given like uh there should be a clear owner for every data asset data and AI asset in your organization, right? So I I spoke about the maturity, right? Like uh you cannot do AI governance without doing data governance.
(38:41) So we're going to we're going to dive into that uh a little bit. So um these are structured frameworks. There's actually like standards uh that that talk about this uh that help organizations assess, benchmark and systematically improve. So how does an organization measure itself in the governance journey and how do they know where they are, right? Um and these are some of the reasons why they do that. They want to know where can we improve.
(39:09) They want to know how do we stand against somebody else, right? So that's the benchmarking aspect. Um how should we unify teams, right? because there may be different teams that are trying to achieve the same things in very different ways and that means your organization is not at the highest maturity curve right it's an indication that you you have ways to go in that maturity curve uh so these are all uh essentially the reasons if you want to think about it uh of why an organization needs to go on this sort of maturity uh journey and we'll talk about the maturity models now right
(39:45) Uh okay so there are five uh essentially maturity curve uh so or maturity stages if you want to think about it that way and the first one is initial/aware right um actually I'll click through here so it's easier to understand so we have these five stages so initial and aware means like imagine you're just starting a new company you're starting a startup you have like five people what kind of standards have you established between the five of you uh likely nothing, right? If if you're in a startup and
(40:18) you're doing you're just doing whatever it takes uh on a daily basis. You're not thinking about any particular standard. You're just going you're just trying to ship something out. That's it, right? You want to get your first customer. That's it. Uh so it's individual efforts and uncoordinated. You don't really you're not really mature from the perspective of how you're thinking about all of your assets.
(40:39) Um then at some point of time you get into this sort of managed reactive phase where oh you understand that hey we're doing some repetitive things. We have lots of data elements that are doing the same thing. Maybe we should sort of standardize this somehow and you're reaching that level of of maturity.
(40:59) Um and you start establishing some some set of rules right it's not very organized but you're starting you just you went from the point of like not knowing anything to like oh I should think about this. So that's where you are here. Um and then when you get to here, I would say 50 60% of organizations are probably never passed this, right? They just like uh they they they have defined a framework. They have taken some time to define this framework.
(41:24) And depending on how long your organization has existed, let's say you're a company that existed for 10 years, you were doing a lot of stuff here. it's going to take you a lot more time to get to this enterprisewide data governance framework. The problem is that now you have lots of teams, you have lots of stakeholders, and you have to get everybody's buy in to get into this data governance framework.
(41:49) Uh because the data governance officer can sometimes carry a big stick, but it's not big enough to get everybody to draw the line. So it's it takes a long time. So it's it's easier if you get started earlier in the in the life cycle of your organization and difficult more difficult if you start later. Um and then once you once you get to that point if you got get to that point now you want to measure right uh which is like very similar to uh like anything else you would do in life like if you're doing something you want to know is this uh like worth doing right what is my ROI it could be as simple as you shipping a product if the product manager doesn't
(42:21) know how to measure the success of what they shipped then how do you know it's successful right same thing so it's quantitative measuring of data governance and it's basically saying uh here's my framework, here's what I expect everybody to do and here's all the standards I expect to be done and here are some processes I establish. How do I know it's working right? You have to be able to measure it.
(42:43) So that's the quantitative measuring of data governance and based on that you have these outcomes, impacts and risks and then you mitigate those risks and you sort of improve the measuring and you improve the governance framework. And then the last one is like you know uh ideal state very very few people are here uh which is like you have everything sort of happening automatically because you establish the processes and the automation to take care of this.
(43:10) um the actual industry trend is uh trending towards AIdriven automation for uh establishing uh governance controls right because you can uh you can have uh like for example I'll give you a simple example uh if you try if I try to share a file let's say I have a file in Google drive and I try to share it with the world as public uh my organization will tell me hey you shared this out too openly consider reducing the permissions.
(43:41) How are they doing that? They're doing that because they have some tool that is checking everything in Google Drive, for example, that is getting shed out and saying, "Oh, you you've opened this out too much. We're going to either turn it off. We're going to give you like a day to turn it off or we're going to do it for you.
(43:59) " Right? They're So, how did they get there? They got there through some automation, uh, through some tool that they implemented, uh, and it's, you know, embedded in the arc, right? Um, and I'm not saying that it'll be part of everything that you do in the org. It's again uh a maturity level, but they have to start somewhere. But for any little control that you do, are you automatically able to block some harmful uh sort of thing that's supposed to happen, right? That would be a completely optimized phase. And the same steps happen for AI.
(44:30) It's all the exact same things except the questions are slightly different, right? So here if you could take a basic example of AI, I don't know I I started using chat GPT yesterday for the first time. Am I thinking about anything? No, not really. Right? I'm just aware, right? So it's the same thing from an organization perspective.
(44:49) If they haven't thought about it before releasing it to uh their sort of users, uh they're not they're not really doing anything. There's no governance really. And then then you start experimenting, right? You say, oh, who's supposed to have access to what tool? Maybe the engineers are supposed to have access to tools that help you code.
(45:07) Uh but maybe the other people don't have access to it because their questions are more sort of agentic. Right? I'm just asking questions and answers to get some information from I don't know my internal confluence or driver or whatever. So the the tools that you use for different roles get different and that's how you experiment through this uh sort of uh governance strategy and then eventually you have a standardized process and then you again have a way to measure it and then you have this continuous self-improvement. Now again I don't think I don't really know all of the organizations in the
(45:35) world but I would really really doubt a lot of them are at this sort of stage five of AI governance. Uh if at best case people are somewhere between three and four right. Um, so that's how I would think about it. Uh, which means there's a lot of scope here in this field.
(45:55) If this is a field that's of interest to you, uh, and you know, you want to dive deeper, I'm sure there's a lot of opportunities in this space. Uh, just like from an industry perspective. Um, one sort of um, you know, mistake an organization may make is that they can jump. Oh, I'm aware of everything. I did something here. I can jump straight to you know another step.
(46:19) It's it's highly unlikely to be the case. It is very much uh you know almost like watching a child grow up right. They have to go through some maturity levels before they get to uh you know uh like something some deeper level of understanding. It's the same sort of thing.
(46:41) uh it it would be you could possibly skip steps but you probably make make you'll have to iterate to make sure you didn't miss something in the previous step. Right? So that maturity curve is like uh it's it's best to think of it as sort of a waterfall model where you finish uh you know maturing in one thing and then move on to the next thing.
(46:59) And that may take longer uh but it actually probably will stick versus you having to you know iterate on it and sort of inconvenience your users on the way. Right. Um the the next few slides are very heavy in content. So I'm not going to touch on everything but you can see you can at least read the headings. So what are what are the capabilities an organization is looking for when they look when they talk about data governance right? So let's say an organization comes to data bricks and says hey tell me your data governance capabilities these are the kind of things they're looking for right and they are looking for it from the
(47:34) perspective of roles and functions um like uh rather functionality and roles right so data cataloging so if you take the top left here it's metadata management and data discovery the question may be like oh do I have a way to search and discover all the metadata in my organization and data may say yes, we may say no. Some other organizations may say yes, they may say no.
(47:58) But they may have completely different ways on how to implement it, right? Which is where uh like from a procurement perspective, you're thinking what is the best thing that works in my organization. Uh similarly, there's master data management, policy and compliance management, there's all of these things that an organization is looking for and there is not one tool uh that will satisfy everything, right? It's impossible.
(48:21) There's nothing like that that exists in the market. So it's always finding uh the best tool for each job function but also not going into like tools sprawl, right? You don't want like 13 tools to do these things. You want to try and do it to through two or three tools that integrate with each other. So then you're sort of it's like oh you give me this, the other vendor give me this.
(48:46) Can I integrate this to make my organization successful? And you know that's where like essentially like partners come into play like partner integrations things like that. So these are the kind of conversations that happen on a sort of on a daily basis uh with our customers who ask for all of these features. Uh some of these things are built-in features in data bricks.
(49:02) We'll touch on some of these some of these are not. So you have to do it yourself right like for example if you take the right side of here governance workflow is very organization specific. uh depending on your organization, your role, the way your organization structured, it's very different when the way another one would do. So it has very little to do with actual tool or vendor or or or technology.
(49:26) It's process, right? Uh and that's similar to some of these things here. And uh that's not the only thing. There's also data lineage, measurement, uh integration and all of this. This is where I was talking about the integration crossplatform governance. So there's all of these large uh sets of requirements that all customers have when it comes to data governance and uh some of them may not even be thinking of one of these matrices, right? Uh like for example, I could easily think of an organization that is uh you know uh not not very mature in master data
(50:00) management uh because that itself is a huge space by itself. Uh but they are really good in policy and compliance management, right? And so when they are going and doing some procurement they are thinking very much from the from the perspective what tool is best for this and not really thinking about what tool is best for this that may come later as they mature and then they are like oh man I wish we had you know one thing to do both right but that was not the factor in their purchasing decision whenever they did it. uh which is why which is why you see like organizations
(50:30) have lots and lots and lots of tools um and then struggle to essentially like um sort of govern all of it equally. Uh in a similar fashion there are AI governance capabilities that um that come under all of these things and you'll see they're very similar. So this model management and life cycle if you go back here this is metadata management and data discovery right.
(50:52) So the titles are actually quite similar uh but but slightly different um because of just the nature of the beast. Uh so you need to monitor you want to uh govern essentially or you want to figure out how your AI governance ties to your data governance which is uh what I talked about earlier which is this particular uh uh you know slab here.
(51:17) And then security privacy obviously very very important. Uh audit is very important. collaboration again is more opaque. Uh and then you have even more now you're talking about a fairness and ethical AI. You're talking about transparency like why did I decide why did the model decide to do something you need to be able to explain that uh in case it made a wrong decision you need to be able to explain why so that you can go and correct uh whatever was used.
(51:41) Maybe it was uh biased data, maybe it was something else, maybe you missed something in the tuning exercise. But you need to have all of those things. Uh and then obviously you want to be compliant. So if somebody comes asking you want to be able to give them away, give I mean be easy to prove to them that uh that you did right the right thing.
(52:06) Uh and this is sort of new, right? Uh AI education and training is still very new. uh you'll see like lots of uh posts on like Twitter or LinkedIn of people uh basically uh trying to sell these programs uh because it is very new and um it is still evolving and it's evolving very fast and these programs will change over time.
(52:30) Um AI skills assessment is a very interesting one because I have seen uh both in my own organization and my customers that um organizations are actually biasing towards hiring folks with AI skills of some type right it may be that you're really good at bip coding maybe you're something else but they are actually looking for these skills now uh because it just it's it's almost becoming uh expected that you know how to do some of these things uh even if you're a job function is just a data engineer or a data analyst, right? So, it's something to be uh keep an eye on uh just as you like continue uh learning u not just you
(53:06) me as well. So, it's it's one of these things that we need to keep a close eye on. Uh this one uh this one is more generic, right? You you can like I said, you can move really fast. You can try to implement a lot of things really fast. Uh but there's also a trade-off you have to make, right? So if you look at this, there are some things that are really high risk uh such as sensitive personal information, financial data, things like that. If those things are compromised, then it's likely the organization has to
(53:36) pay a heavy price. So those are high risk and you have to be very very diligent about how you implement the controls and governance on that. And on the sort of the opposite end of the spectrum, you may have lower risk data and applications, right? Uh it doesn't have any PII uh maybe it's all anonymized uh maybe it's all tokenized maybe you did all the right things.
(53:58) So once it lands somewhere in that form and fashion uh there's very little risk uh from the perspective of you know uh you being in any trouble if it got into the wrong hands and uh so that's low risk. Uh so in the example of uh you know like what Eric mentioned or what some other customers have done um there may be a breach and you know you've seen these things in the news that there was a breach and there was a a file with a bunch of SSNs and it was protected with a password and the password was you know 1 2 3 4 5 literally large organizations have done this and got in in trouble. So that's like terrible, right? Because
(54:35) they paid no attention at all to how to secure the most valuable uh by valuable I mean the thing that's going to get them in trouble the most. They didn't they didn't do enough due diligence in trying to secure that, right? Um and the factors uh determining are like I said before industry specific regulatory requirements.
(54:55) What is the impact right impact on individuals and organization? Organizational impact like I said reputational risk is a huge thing. uh the scale, right? If something got into the wrong hands, is are a 100 people affected or like a million people affected, right? Um not everybody has a million customers, but the largest organizations have hundreds of millions of customers.
(55:20) So, they're thinking about this very very um you know, very very deeply, right? Um and that translates whatever we talked about there in terms of high-risisk loss translates to this curve which is that if you have high-risk applications you need really really strict governance and that might require that uh uh people have to jump through a lot of hoops to get access to some piece of data right that they think is required for their job function and you established good processes for them to get it but they still have to go through that process right whereas the very opposite end of the spectrum is
(55:50) that hey we have uh you know we're doing this like machine learning experiment like data science experiment or we're doing it on nonsensitive data we're doing it on synthesized data it's less risk right I I could put this on like um it's still in my internal S3 bucket or whatever in my company but I'm not really worried who has access to this um in within my company uh because there's nothing sensitive here we we are doing some some data science experiment to get to some point. So you have this like spectrum of like strict governance and responsiveness and they uh you know
(56:26) depending on where you land it's like a balance between between these two sort of uh ends of the axis. Um here are some general considerations. Uh like I said you cannot buy data and governance. By that I mean you're not going to be able to buy one tool and say you you're good. I I've taken care of everything. Right.
(56:52) It is something you have to implement across the people, process and technology we talked about before. Um and it depends on all teams. So you have to u get you governance has to be second nature for any team that's implementing anything in and then that sort of usually comes down from the from the literacy aspect like you're teaching everybody how important this is.
(57:12) But it also comes in from like a top- down approach where each business unit or each uh sort of uh need for for the for the area understands the importance of it and you know they are you know mandating it. There's training they're they are figuring out who's certified blah blah blah. So they're doing all of these things to essentially push the organization in the right way in terms of education and literacy.
(57:35) Uh but whatever you choose to implement, you always have to start simple, right? Like don't go and try to be the most optimized thing on that uh the five-step process. Uh because you'll likely fail. You have to start with something and you have to let it percolate, improve, it trade, then move to the next thing.
(57:54) Uh and that's usually like how it expands out. And that that that uh that journey may be different for different areas of the business, right? uh like the way like let's say people ops thinks about it uh which is like hey this is like my sensitive people information there's like wage information whatever this should be secured a certain way the way they think about that journey is very different than uh the example we talked about before where I have this sort of like forward deployed engineers building like cool applications they are just like you know not reigned in by the same
(58:24) thing uh they we just have to secure the fact that they have access to the right type of data right So uh that matrix is very different uh depending on who you talk to within your organization uh which is what this uh choosing the level is speaking to. um what are the roles and tasks uh so there are all of these roles right so uh again I won't read everything out but um you have data governance and AI governance and you have all of these uh definitions which is like hey you develop and approve data governance policies okay that's one example uh but then in the operations you have to
(58:59) implement and enforce data governance policies so one is defining these things um and one is implementing it like we talked about before uh and that expands to both data and AI governance Um and uh so these are the tasks rather and these are the roles right so who is defining it.
(59:22) So you may have a co you may have a data governance council committee whatever you have some structure in your organization that coming up with all of these things and then you assign certain roles to go implement it right so a co is basically defining what needs to be happening and then a data steward is may not be implementing it but he's writing it down he or she is codifying it in some form or fashion for then a team to go implement it right so that's like the the normal way you should think about this and the same type of roles here. Um now if this space is interesting to you
(59:53) at all these are the kind of roles that you'll find in like LinkedIn or other job postings. Um and uh you know since AI is all the rage you'll see AI thrown in now in a lot of the roles that were typical. So it says data steward now now you go look for it it's like you know data and AI steward or AI steward right? you'll find these variations in roles that didn't exist till a few years ago. Um, okay.
(1:00:24) So, this is uh this van diagram is basically telling you that there are lots of operational uh or a lot of ops that happen in your in your uh organization and they can be sliced and diced various ways and there are sub ops here as well. Um because this is only telling you how we are thinking about governance.
(1:00:49) So there's governance ops, data ops, MLOps and they all sort of overlap in in some aspects that you see here. But the other way to look at ops is um people ops, sales ops, finops those is a BU specific slices right of your organization. uh but how do they align to this thing right they are all going through the same set of because they all have data they all want to do AI or ML and they all have to solve some governance challenges uh so they may have a slightly uh you know different lens on this but all of the things are the same right maybe some things are more important for people ops and some things are more important for sales ops but if everybody aligns to the
(1:01:27) fact that there is a common uh organizational structure for data ops MLOps and gov ops then it makes it easier to sort of align to that right so I see I see lots of organizations building these things in silos without thinking about the overall standardization um and I think there's there is a high sort of uh you know value ROI in terms of spending the time to getting it right at a higher level it just is much diff much more difficult to do because it requires buying from different parts of the organization so but the ones that do it really L are you know using some type of forcing function to make sure
(1:02:04) everybody aligns to this by proving the value to them of aligning to it right and it's easier to do these days because you can you know somebody who's like really good at stitching things together could you know whip up a quick quick prototype uh and you know show it to people ops and say hey guys like you know you could you could you could do this uh and here's a here's a framework for you to do this versus them having to go figure it out.
(1:02:30) Um, so that's the way it usually works. You have to sort of prove it out so that the values are obvious to some part of your business. Um, awesome. So, okay, where is 737? I'll try to run a little bit. So, um, I wanted to jump into something called well architected framework, which you may have heard about.
(1:02:49) Every cloud vendor has a well architected framework. AWS has a wellarched framework. Azure has a well architected framework. Cloud architect I mean GCP has a what they call a cloud architecture framework. But it's basically built on these pillars, right? Cost optimization, performance, reliability, security, and operational excellence.
(1:03:06) And if you did any of cloud certifications like a fundamental cloud thing is like they talk about these pillars so that you understand what this means. Um the reason I'm bringing it in here is because um uh you may have seen sort of this lakehouse architecture where like everything you know all of these assets in data bricks and unity catalog is governing everything.
(1:03:26) But the reason I'm bringing this up is we have our own well architected lakehouse uh paradigm which extends this. So you see there are five pillars here on top uh going from operational excellence to cost optimization and here's the data bricks lens of it and we added these two data governance pillar and introp and usability pillar and uh because this is what we see happening across uh our customers.
(1:03:54) So uh everybody was aligning really well to the cloud sort of pillars. Um and I think AWS if I remember right has started adding governance as a pillar as well. Uh but we did it before them. So but the reason we did it was because because we were on all three clouds. We would get questions from our customers asking us you know some questions that are common across all three uh but weren't answered in each one.
(1:04:24) So then we basically saw an opportunity to essentially expand this and came up with this data governance pillar and introp and usability pillar and we actually have an assessment program that you can go run at your customers that tells you your sort of maturity level in the space right I'm not I don't have that uh to show here I just wanted to set uh some context here before I jump into uh unity catalog itself uh so data governance is essentially governing everything all of your assets uh that are sitting in the lakehouse um And intropusability is basically not all of your data is
(1:04:54) governed in data bricks. It's sitting you know you you have an RDBMS somewhere. Uh you have some SAS sources like you know Salesforce or something. You have all of these sources lying around. You have SFTP files. I don't know. Uh so how do you come up with like an interlocity governance story right? So that's what these two pillars are talking about.
(1:05:16) Um and again it's just a theory but if you wanted if you anybody is more interested in this we do have like a well architected sort of framework and paper I'm happy to send that across uh and our documents um our public documents talk about this lakehouse architecture well architected framework so you can take a read as well uh I'll pause here the next part is all sort of data bricks features and how they help achieve governance so if anybody has any questions before I jump to that Uh I'll take a short pause.
(1:05:49) Awesome. Let's keep going. So from a data bricks perspective, uh Unity catalog is the foundation of what we call the data intelligence platform. But if you look at the slide uh here, it's like fundamental, right? You have all of your data here and it's not just Delta Lake, iceberg, and park.
(1:06:06) It could be PDFs, CSV, whatever. Whatever you're storing on cloud storage, it's all governed by Unity catalog, right? So that's a fundamental, you have to go through the governance layer to get to your data. And if you go through like a good governance layer, then all of these things that you build on top uh are easier to secure because they are secured by this governance layer, right? Uh and that's the principle behind sort of what we call the data in platform. And this is the problem we're trying to solve, right? So it's all of these things. You have these
(1:06:38) multiple data sources. You have these diverse assets and you have multiple data formats. Right? And this is a very data bricks specific lens on it. Uh but you can expand it to whatever you want it to be because the governance officer in your organization is trying to solve this problem for sure. Uh because they have fragmented governance.
(1:06:55) They have too many things lying in too many places. Uh there is lack of collaboration. Uh there's not even internal data sharing between organizations. So people are essentially duplicating uh data sets and projects sometimes in two different parts of the organization uh because they're not willing to collaborate or not allowed to collaborate.
(1:07:18) Uh and then the lack of built-in intelligence which is if my organization has a source of truth for something anybody in my organization should be able to find that it should not be gated behind anything. It should be completely open. It's still secure. I am not able to do anything with it but I should have access to the fact that this information exists.
(1:07:36) Uh and there may be a process in which I go get access to it. Right? So that's the essentially the built-in intelligence part that we're talking about. Um and Unity catalog is is our solution to solve this. So uh we basically saying hey we're going to give you all of these features access control auditing discovery data sharing lineage quality monitoring cost controls.
(1:08:01) And you'll notice a lot of these terms did come in uh when we talked about the theory of like what organizations are looking for in governance. Uh and we are trying to solve that with Unity catalog. Are we solving everything? No, not yet. Uh but it gives you a lens on how data bricks does it. So it gives you a frame of reference on how some other vendor may do it that uh you may use in the future, right? Um so if you are if you have used data bricks before unity catalog existed we always had this concept of a metas store and that metas store was essentially where you store metadata of all of your
(1:08:32) objects uh but it was only tabular uh data right meaning it was tables I if I had tables I could register those tables with my metas store if I had a random PDF file sitting in an S3 path there was no way I could register that with the metas store right uh so that's the old metas store before unity catalog and with unity catalog the UC metas store can you can register all types of assets that's the first advantage but also it's now common across multiple database workspaces right so here it was siloed and here it is you have a common
(1:09:03) metadata layer so and why does this help because it gives an organization essentially one common place to register all of their assets and then one set of common controls that they need to establish and then processes to build on top of that control so it just makes it easier here to do all of the controls and processes because you don't have to do it you know 30 times right uh so that's essentially the way to think about this um and there are some fundamental concepts in unity catalog which uh you know it's just here for information
(1:09:34) purposes there's there's a concept of a credential if you're coming from AWS that's an IM role if you're coming from Azure that's a managed identity uh if you're on GCP it's a service account and then external locations are basically the object storage parts of any any any of those clouds.
(1:09:53) So S3 or uh ADLS or uh G or GCS and then on top of that you are storing table tabular data or you're storing unstructured data right which is all your PDFs files some of you have done exercises uh on essentially taking files from from volumes for example but you can also connect uh foreign connections what we call foreign connections which is other RDBMS sources other SAS platforms uh and things of this nature and you registered UC and you can use the same governance principle.
(1:10:23) So I could say select on this table but I could also say select on a table from a connection and they're the exact same construct. So it makes it easier to sort of unify the governance story. Uh and that's what is shown here in this slide. Uh you can see uh at the bottom here we have a select that says select star from main.pall.red. So this is a catalog. Main is a catalog.
(1:10:42) Paul is a database and wine is a table. But at the same time I can also do select star from snowflake because I registered snowflake or bigquery or red shift or whatever you want whatever is your favorite one as a foreign catalog in data bricks through a foreign connection what we call it and read from a schema and table in that right and I can give the same set of grants like I can select on this and select on this and I'm governing it the exact same way right uh which is why this diagram is basically saying that hey you have unity catalog it's a central meta store uh you have
(1:11:14) catalog, schemas and all of these things under it, but you also have foreign cataloges, foreign schemas, and you can govern them with the exact same set of graphs. Uh, so it essentially unifies your governance story under one platform. Um, so any questions about that since it's datab specific? Okay, awesome. I'll keep going.
(1:11:44) Uh, how do you do it? you basically do you know if you're coming from a database world you're familiar with grant statements uh so even though the the data is itself is secured by an IM role or a you know managed entity or whatever depending on your cloud uh the a user doesn't get direct access to anything till you actually give them some type of grant right so you unity catalog is basically uh your second layer of security on top of your cloud primitives.
(1:12:12) your cloud primitives or your you know IM roles for example and UC is adding a layer on top of it that says oh even though the cloud primitive the IM role has let's say get and put and list on something I can give moan only select so I cannot do an insert because nobody gave me an insert even though the IM ro had put and put object so that's the two levels of u uh you know uh controls and the advantage with that is now you don't need as many IM roles for like siloed parts of your uh lake. You can have an IM role that
(1:12:48) has broad access but you can govern it with a second set of controls. And we're not the only ones doing this. Other cloud vendors uh and like you know other cloud data warehouses do the same kind of construct. Uh it's just that the difference in UC is because data bricks started off as uh you know a data science machine learning company.
(1:13:07) So we started with like models and files and all this as first class citizens that you could govern under UC. Whereas for some of the other tools on the market they're coming at it the other way right it's like they're building those functionalities whereas for us we always had these.
(1:13:24) So it was easy to sort of uh build UC on top of it. Um and then you can do like role level security and column level masking which I'll talk about in a little bit. So this is the uh this is this is version one if you want to think about it of rowle security and column level masking because you had to do it at a table level.
(1:13:42) Uh but then we had we introduced a feature called attribute based access control in which you can do it at a schema and catalog level and we'll we'll take a look at that. Um um so this is a higher level view of how UC actually works. So, Unity catalog is a service, a data bricks service that sits in a databicks control plane uh and has this uh access control which is where you store all of the grants uh and those grants control what this user can access.
(1:14:07) So, a user is coming through some type of compute cluster SQL warehouse or since you're using the free edition is basically serverless. So you're not really controlling compute but you are using some compute to access something and what's happening at that point is the user's credentials are being checked not credential but the user's access is being checked here to say does moan have select on object X because my query here said select star from X. So the access control is saying does moana have select honestly if not I'll get an error back
(1:14:36) saying hey you don't have select go request this access if it does what happens is you see is essentially at this point delegating to the IM role or the cloud primitive to say hey go get this piece of data for me I know where it exists I know where it exists because I registered it in UCS this path this table whatever right uh and so it goes and does the get for me and brings back the result so I I personally I'm not my identity is not the one that's going all the way to the cloud storage bucket at this point after the access control it's
(1:15:08) this particular credential right which is the cloud credential that's taking over and UC is just brokering this connection um in um uh in in AWS for example this is called like sort of the equivalent of assuming a role a role can assume a role so if you think about it unity catalog was a role it's assuming an IM role or a managed identity to do something and that role has access to do something but it's gated by the fact that this user first of all needs basic principle primitive to do a select if not it's never even going to go past this particular lock symbol right so
(1:15:44) that's essentially simplified version of how this whole thing works um and this is how you store data uh you can store data at a meta store catalog or schema level well not really metas store metas store like the house but uh our recommendation is to store uh like register your cloud paths as containers uh at a catalog and schema level so that you get natural sort of data isolation right schema a data lives in this path schema B lives in this part schema C lives in this part so they're naturally isolated and each of them could be governed by a different IM role which you register as a storage scratch so
(1:16:22) that's how you sort of like uh achieve all of the uh sort of strict data isolation requirements but in a much simpler fashion than you would have to do it yourself if you were trying to do this. Um and then uh like I said you you have these uh permissions here and in this case the permission says this user does not have select.
(1:16:48) So he is not able to select from these table and data uh that's sitting here. Uh even though this data may actually be under the same external location. So this external location is an S3 path and this data may be sitting under that S3 part but because I don't have select I can't but I could still read and write from other subp parts of that extra location.
(1:17:07) That's the volume, right? Other S3 part uh and those grants are separate. So I have essentially access on paths, access on files, and access on tables. And they can be separated, but they're all like simple grant statements that I would do. Uh we'll skip this. It's basically just talking about data isolation. Um and now we'll go to attribute based access controls.
(1:17:31) So the concept of attribute-based access controls came in because um you know it was not enough to just govern tables. That was the first thing but it was also not enough to govern at at a per table basis right so you wanted to have some some organizational way to apply a set of rules. So uh that rule here is let's say uh a data element was categorized as PII.
(1:17:58) So I want to have a general rule that says anytime something is categorized as PII uh Mohan should only see the masked version of this data versus somebody else may be able to see the unmasked version of this data. So I can have this distinction in rules um where somebody's able to see masked, somebody's able to see unmasked, somebody's able to see uh you know 1 2 3 4 star mask like meaning like part mask, substring mask. I can do all kinds of like funky rules in terms of who's supposed to see what and how.
(1:18:27) Uh but it's all driven by the fact that I knew there was a data element there that I needed to do something with. So in this case it is PII right so the challenge with doing this is that I have to now apply a mask on like various various places which is like very confusing.
(1:18:45) So what ABACK did is really moved it up a level and said hey let's give you one way to define rules and apply consistently and we will give you uh essentially because you know this is the this is the new age of AI we're going to give you uh AI based classification rules and governance rules that you can use to uh you know restrict who has access to what so you may not even have to write the rule uh we will generate the rule for you and you just have to apply the rule right that's the sort of the uh ideal state uh and you give these clear roles and responsibilities right because in in database you have this concept of manto catalog and schema like
(1:19:28) we looked and each of this could have separate administrators and they could govern their slices of the world however they see fit uh but an overall data governance officer could still set up a rule for masking everything that had a specific tag for example.
(1:19:48) So you are you are centralizing your uh your governance strategy but still being able to democratize to some extent with you know sub leaders of your various subject areas right it's always a balance between this no organization goes fully one way or the other uh they're always sort of trying to do this delicate dance so what is aback you first uh you know you tag columns and tables right uh and I'll I I'll talk talk to you about tag but tagging we are calling it through a feature called govern tags.
(1:20:20) So you tag it and then you create a policy to define a data access rule based on a tag and then when and you're saying that you know the analyst group should be treated this way and so when that analyst group comes and selects something that you know it was automatically masked for them because you created this policy and because you created a tag that control uh controlled where the policy is implemented right so that's that's like the simplified journey um How does it work? You first create a govern tag. So you you you you create a set of tag. You
(1:20:54) create a tag and you say these are the allowed values and so that's your tag and then you give permissions on who can use these tags. And then once you do that you can do other stuff like aback one is applying but also discovery right you can discover your data assets that are created based on some tags.
(1:21:12) You can um slice and dice who's supposed to see what. And I I'll talk about this in a little bit. All based on these tags. And the other thing that was added at the same time is basically this feature called data classification that automatically detects PII for you like these examples shown here like email address, location, name, whatever. And it is doing this by running essentially a model behind the scenes.
(1:21:37) You don't control when it runs. as data lands this model will just uh run on incremental data behind the scenes and and essentially apply the tag automatically for you. What is the advantage? Let's say this data was automatically classified as email address and I and this is this is a system govern tag and I had a rule that said when whenever there's email address analyst group should see it as masked then I can set that up as a catalog level really and it applies to everything in that catalog right anytime a new email address field
(1:22:11) is added which is automatically classified you don't have to worry about it that particular rule applies automatically And so that makes it like much more easier to govern. Like is it 100% going to cover all of your governance rules? No, of course not, right? But it gives you a much much easier way to get started. Um and gives you like all of these nice reports which which we'll look at in a little bit.
(1:22:34) And so once you have that, you create what is called an Aback policy. So uh today it extends to column masking and row filtering, which is like mask some data or filter out rows from a data set. uh but in the future it'll also expand to you know uh like highlevel select and deny rules right so based on a policy you could say um you know somebody has access to hundreds of these tables in one schema but they're denied access to one of these tables uh and that could all be written in in like one rule so that's something that we're working on it should come out sometime next year but
(1:23:10) right now uh it's basically applied to cataloges and schemas and downwards but primarily for column masking profit, right? And how do you put it all together? You mask all of the columns containing the PII and the data classification automatically finds the PII.
(1:23:29) So you didn't have to go individually and do it and applied that govern tag. And then your Aback policy that you created just once consistently applies it. So you have essentially uh you know the persons owning the tag the govern tags you can think of them as uh governance uh stewards or whatever you want to think about it and then the aback policy are the people who are uh you know thinking about how should I ensure that the right people have access to the right data and only see what they have. So it's the it's the operationalizing of it if you want to think about it and the people
(1:24:04) coming up with the rules in the middle are you know like the steward right so the governance tags is are coming up with how you want to tag your objects and the policy people are implementing those rules for you at a higher level um so that's what that does um I'll I'll skip these uh because it's the same thing um but these are the core use cases for classification automatically detect it uh log everything uh to a system table. We we audit everything and then use it for essentially AVAC policies and we're
(1:24:38) actually um working on something that says you know and this is common to most organizations not all classified data is of the same sensitivity level right so you may have different types of classifications and you may have tiers of classifications so you may say this is tier zero classification tier one classification rule tier two and you may have different treatments of these uh and you can do this today uh with with classification and govern tags but we are trying to make it even more automated in the future like basically allow customers to define uh
(1:25:07) classification tiers. Um, so that's all great, but what about all of the data that's actually landing in my organization, right? All of the things that are happening through data ingestion, right? Uh, that's where we added another feature called data quality monitoring. And again, this is from a governance perspective.
(1:25:31) You want to know that the data that your organization is operating on is clean and you spend a lot of cycles trying to clean this data, but what if you didn't have to, right? That that's the premise behind this. So this is again something that you just set up once and then we run uh essentially automated rules behind the scenes.
(1:25:50) Uh and in future we'll give you a way to customize those rules, right? Uh and that's the way most most organizations or most other tools in the in the in the world are also doing the same way. So you don't have to do it per table. You don't have to write your rules hundreds of times.
(1:26:07) you essentially set it once uh at the schema level and then it applies to everything in that particular schema, right? Uh and the two things that come as part of this are basically anomaly detection which tells you uh you know uh do I do I detect anomalies in your data like do I see patterns that changed over time? Uh and then uh data profiling is basically giving you statistics on you know like min max counts things whatever things like that that giving you again because these are all exposed as a dashboard and you can build alerts on top of it uh you can get you know immediately alerted when something changes right uh and it's a simple setup as shown you it's just a
(1:26:46) click button I'll I'll show you in the UI as well um and this is like AI powered like I said it's basically running models behind the scenes And it's giving you these sort of uh slices of data. Freshness, completeness, segmentation. Uh freshness is like how how how you know how fresh is this data. Uh completeness is basically like um it's right now it's doing like a trend line analysis. So let's say you had 100 rows today, uh 100 rows tomorrow, 1,000 rows tomorrow, 2,000 rows tomorrow.
(1:27:15) That's all fine. But suddenly one day you had 2,000 rows and one day you went to zero. we would flag that and say hey I think your you know your data is not complete uh and then you would be able to customize those rules um in future right now it's just like a a static rule uh the other thing organizations want to do is I want to know where all of my data came from and where is it going right uh this particular data element that showed up in a BI report where did it come from and so if you had lineage you would be able to track it all the
(1:27:46) way back down to the source right u initi Actually when we launched lineage the first step in the lineage was essentially whenever you ran any job in data bricks uh that brought data in because it went through our compute layer we could tell you exactly what the source was and what the target was but everything beyond that was a black box right we don't know like what it is but now we actually uh launched a feature which is this one custom lineage that actually act allows you to come in and plug in your source So you could come in and say hey the I want to link this
(1:28:23) table here or this set of tables here to let's say my my Salesforce connection here. So then we would be able to link it back and say okay it's coming from here from this table in Salesforce and this particular data element in Salesforce right. Um and this this feature only launched I mean it was in preview for a while but it launched publicly a few months ago.
(1:28:48) So it's going to get better but it's a way to essentially what we are calling bring your own lineage and you can do this both at the source level and at the target level. So you could essentially link it to I don't know PowerBI or something and say you know it's going to this particular table in PowerBI because once we publish to PowerBI our visibility is gone.
(1:29:06) We don't know what you're doing there but then you can like essentially stitch that back. Uh so that's what it does and how it really works is like this way. any code that's submitted in data bricks um there's essentially a lineage service uh that runs and um you know uh parses out the dependencies between you know columns and tables.
(1:29:27) So you can say like um you know maybe you split one column into four columns right maybe you did a substring uh maybe you split name into like three names uh you would see all of that in lineage so it's pretty cool and this integrates with external tools um you know that are shown here as well because there's an API and there's system tables through which they can ingest it onto their own site.
(1:29:50) Um, one last thing before I move to the UI is we also have LOS federation which is a way for you to bring all of your uh RDBMS sources or SAS sources and register them in uh data bricks as connections and that allows you to like I said before govern everything from one place. Um um from from from a consumer perspective everything is in one place and you have a same set of grants.
(1:30:15) Um the the interesting thing about federation is that for most of the sources we do like really good push down. So we're not we're not pulling data out and then computing everything in spark. We're actually pushing the query down. So if there are performance uh you know uh if the if like let's say for example like SQL server has really great push down on a particular type of query and when you write that query that push down is happening on the SQL server side and the results are coming back to data bricks we're not pulling like a terabyte of data through the through the
(1:30:48) wire and then trying to push down here right so it's actually pretty efficient uh but it's really not meant for like large scale ingestion uh we have a different product called layflow connect for that which is like CDC based. Uh so the the common theme among all of these things is if you are not on Unity catalog all of the features that I just talked about are not applicable to you.
(1:31:11) Right? So that's why I'm saying like from a data bricks perspective the governance layer is like is like absolutely fundamental to do anything about it. Uh and so so UC is our governance layer. Uh different organizations have different ways to do this. Uh, Snowflake has two different cataloges, Polaris and Horizon. Um, you know, fabric is what Microsoft is doing because they're trying to like stitch everything under the fabric ecosystem.
(1:31:38) So, everybody has some type of governance layer that they're trying to come up with to govern access to everything under it. Um, and the real winner in this story is going to be whoever can govern the other person's assets most effectively, right? So uh it shouldn't be that data bricks governs data bricks assets and does a terrible job of connecting to snowflake or fabric and vice versa for any of them.
(1:32:09) So whoever gets the the most cohesive story will probably have the most uh sort of assets under management uh if you want to think about that and then they become like uh a good player right and that that's u um the market is there for the taking basically so we don't know who's going to win. Um, one last thing is that we also have delta sharing uh, which is a really cool technology that not just allows you to share data sets but also notebooks and AI models and other things in data bricks even volumes.
(1:32:35) Uh, and that's because uh, delta sharing is a service that we uh, I mean it's open source technology but we have our managed data sharing service and it talks it's tightly integrated with unity catalog. So anything in Unity catalog that is governable delta sharing theoretically should be able to share out with the same sort of you know governance rules.
(1:32:56) Um now it doesn't cover everything in UC yet because essentially it's like you know delta sharing has to catch up with UC uh in terms of the features but it's really cool way for you to say hey I created a notebook and I want to share it across the cloud or to somebody else sitting somewhere else and uh how do I do it right? I don't have to download it, email it, or I don't have to upload it to GitHub, whatever.
(1:33:20) Whatever way you're choosing to share, you can just share it just like you were sharing a table or a model, and they all fit into the same structure. And the really, really cool thing is all of these foreign sources that are shown here like Synapse, Azure, SQL, everything that you're bringing in through Lakehouse Federation for example, you are now able to share.
(1:33:38) So you can query a table from Snowflake uh because you're registering it as a snow as a as a connection in in data bricks and then you can share that Snowflake table to somebody sitting uh in a different cloud on data bricks right so on Azure I created a connection from Snowflake let's say I'm in the same region and then I share it to like you know AWS some other or GCP or whatever that didn't have an easy connection to that Snowflake so it it actually expands out the type of things you can share and it's uh pretty cool. So that's what uh what is shown here that all of these
(1:34:12) things are valid things to be able to share and through the protocol your recipient could be anywhere. Uh now in most cases in data bricks customers are are al also on data bricks but you can actually consume it from you know Tableau or PowerBI pandas whatever you want. Um the performance will vary of course but it's really an open protocol.
(1:34:32) You don't have to be a datab bricks consumer to a customer rather to consume, right? Uh and snowflake has their own snowflake data sharing technology. Um red shift has theirs. Everybody has their own sharing technology.
(1:34:50) It just comes down to who has more convenience and who has more, you know, uh bells and whistles that they can give, right? But it's a very common pattern that you should understand from a governance perspective. All of this data that I'm governing is likely going to be needed somewhere else. So how should I share it and how can I govern that share? So it's uh something to think about.
(1:35:10) Anyway uh so this is all all of the shares about and the last one is like interoperability like I said everybody wants not just delta they want iceberg uh these are the two large uh leading data formats and they want to share all of this across the wire uh you know to other clouds other platforms whatever and now you can share uh iceberg tables as well from data bricks. Um, so yeah, the ecosystem is getting more and more stronger.
(1:35:31) Cool. I have 20 minutes, so I'm going to jump to uh jump to the UI now. Just bring this here and walk you through some of the things that we showed. So let me start. So this is not a free edition workspace. This is uh our internal workspace. So it has like you know lots of objects and lots of cataloges and stuff like that.
(1:35:58) uh which is probably what like an enterprise catalog would look like in in your organization. Now I have gone to my catalog. So this is my catalog and I I basically searched for it from here. Uh and I went to that catalog and the first thing I want to touch is aback right. So Aback is this under this policy tab here. So let me zoom in a little bit. So this policies is basically Aback policies.
(1:36:21) And actually if I go back to the overview tab uh it's not zoomed in. It's here. You can see the policies that that are applied on this catalog because I chose to apply them. Now what are the policies? There's one that says hide EU customers. So I have some rule that says hide EU customers from somebody and then I have some rule that says mask SSL.
(1:36:47) Right? So this is like a row filter because it's it's removing you know some some condition where uh it evaluates to EU is true and this is a column level mask and I can have multiple of these right I can have multiple and they're all evaluated sort of um um the the if you have multiple row filters and multiple column masks on you know common set of tables they are all evaluated.
(1:37:08) So it has to pass through essentially like a seieve of all of these things and you'll only see the result of all of those things after evaluation. Right? How do I create a policy? I basically click on the policies tab here uh and I can say new policy. Before that if I go into a schema, I can also create a schema a policy at the schema level.
(1:37:30) Right? So if you notice these sche these policies here, two of these are inherited from the catalog because I created them at the catalog. So they are propagated down and then one of them is specifically created for this schema cuz I don't want it to apply to any other schema. And I think this is a dummy schema. Let me see.
(1:37:47) No, it's not a dummy schema. It basically has a mask and says, "Hey, mask these things." So I created a thing, but I'll I'll I'll cover it in a little more detail. So remember, you can create policies in two places, one at the catalog and one at the schema. And so it it propagates down from that perspective.
(1:38:06) And actually the the long-term road map here in data bricks is to actually take it above the catalog level. So imagine you had a account level policy and you could apply to all cataloges in all regions at the same right. So that's the sort of the holy grail we're trying to work towards. We're not there yet. Uh but hopefully we'll get there.
(1:38:26) Now what does this uh do if I do create a new policy? I have to give it a name. I have to say apply to somebody which means who are the users that should be uh governed by this policy. That's what it means. But it also has a break glass approach which is accept. So which means even though this table may have a policy, I want to allow one person or one group to be able to see everything anyway, right? So I can do an accept clause for a specific group.
(1:38:53) And this is really great uh like when you're testing something or maybe you want to give access to temporary access to an auditor or something like this where you want somebody to be able to see everything uh but in general you want to secure right so it gives you that sort of break glass approach and then you can set the scope which is which which catalog which schema etc.
(1:39:17) So in this case it's this catalog all schemas but I could also choose a specific schema and I could say apply to all tables that have specific tags and this is where the the tagging comes in. Uh if I create a tag I can apply to a bunch of tables and that I could apply it manually or I could apply it automatically through like data classification right uh and I'll I'll show you how to do that.
(1:39:35) uh and you can give like custom conditions which is like a combination of things like this hashtag tag value or hashtag value whatever it's a bunch of things you can do and then you can choose do I want to mask it and if so I have to give it some uh uh you know what are the tags I want to mask on and then or I could say hide in which case I would create a function like this and luckily because we have the assistant now you can actually get you know pretty pretty easily started right so let's go back and look at one of the conditions One of the policies I created this was the mask SSN. So the
(1:40:08) mask SSN applies to all account users. That means everybody in this account and I don't have any except which means even for myself even though I have act full access to this catalog I am also beholden to this particular condition because I'm part of all account users.
(1:40:27) uh and I've said hey mask the column if it has a specific tag and the tag I'm looking for is you know a tag I created MGMPI which is not a custom class I mean which is not a automatic classification tag it's something I created and then I gave it a function right so all Aback is governed by functions um that you define and then apply and you're applying it through to through tags on objects if you want to think about it that way right but at the base uh level you have to define a function So what I've said in this function is hey this mask SSN function uh takes an SSN and it returns
(1:41:00) a string uh of this right now this SSN really is like anything that applies it's not doesn't have to be the field name doesn't have to be SSN it's just anything that has the tag SSN uh and you can test the function by giving it uh some some string so let's say 1 2 3 4 5 6 7 8 9 this looks like an SSN let's see if it works and comes back as mask, right? Because it's an SSN. What if I give it 1 2 3 4 and run the test. Uh this also masked.
(1:41:34) I'm not sure why. Uh but uh I think because it had the tag uh but I I can't fully explain that now, but you can understand how it works. Uh it's basically this is how you would test your function before you would deploy. And there's other ways to test the function.
(1:41:52) And so once you deploy this what happens is anywhere that that tag is found uh it will automatically apply. So let's go look at a a table which I think is here and see if there's any tags applied. Um no. So there's no tags applied because there's no SSN or anything like that. But I could add tags from here. I could add a mask directly from here. I could add a a row filter directly to the table from here.
(1:42:20) So there's multiple places from which I can interact and all of these avenues are open for you when you do it through the API as well. We have an API SDK all of these things. You don't have to do it through the UI. Uh but you can you can add the tag from here. You can mask from here.
(1:42:38) Uh you can do all of these things, right? Um but what are these tags really? Right? When we say tags, we are talking about something called govern tags which you see here. And those are specific key value pairs basically. So let's see if I could find mine. Yeah. So I have something like this PI and I have two types of values SSN and address.
(1:43:01) So I could apply one of those to this. So let's just apply this to this. U now obviously current page title is not an SSN but I applied this tag. Right? So if I was to look at if I was to go query this data, what do you think should happen? Right? So let's try to query this data and see if the tag applied. So it was on click stream. Yeah, I think this is the right one.
(1:43:34) So you see the current page title was masked, right? It's not really an SSN, right? But it's just to show you for demonstration purposes because I applied that tag and that tag was then uh there was a policy saying when you see this tag do something all of that happened automatically right so that's how that's like really the power and you you you don't have to do it multiple times right because you can set up this rule uh at the top level and you can apply the tag automatically SSN actually get classified automatically this is obviously like a dummy example um and then you can create your own set of tags
(1:44:12) and apply your own set of rules. So it it it makes it quite easy to govern your real estate. Now if I delete this tag, let me delete this tag and then query this table again. What do you think will happen? Because I remove the tag now I see the data. Right? So that's the that's sort of how Aback works.
(1:44:45) It's it's masking data based on tags, based on policies, based on rules that you're setting and it's hierarchical. Uh and it's quite powerful once you figure out um you know how to uh implement it effectively. U it's uh most customers are new to it. So it is something that is still you know uh I would say like best practices are still being worked out I would say. Uh but you you get the you get the idea.
(1:45:09) Now one really cool thing um that we launched recently is let me see if I can find it is this particular page which is a data governance page. Now uh hopefully this will get better and better over time but already covers quite a significant portion of data bricks real estate. You can view all of your tags, you can discover data assets. Uh you can see the results of all of the data classification that happened.
(1:45:33) you can see the results of data quality monitoring which was like the freshness and completeness I was telling you uh and then the administration will forget about but it it's telling you some some statistics about your overall real estate uh you know like the overview of this tab it's interesting that this is showing me an error I think uh my warehouse is overloaded but uh let's try to run it again but anyway it'll tell you what are your active tables how many tables have been used so let's say your organization created thousands of tables but you saw
(1:46:05) that only 20% of them are being used and we are saying being used because we can track lineage and who's quering and stuff like that. Uh so maybe your organization is wasting a lot of time on storage, right? Um anyway, these this is the governance tab. It shows you t popular table tags, popular column tags, all of these things.
(1:46:26) Um it's spinning here because my warehouse is overloaded. Um okay, here popular table tags. Some stuff came, right? So these are popular table tags. I can go look at I can go look at protected tables with tags. So all of this stuff uh tables without comment because I could go bug a team and say hey why aren't you adding comments and descriptions to your tables things like that.
(1:46:51) So it's giving you uh a really good way and like um uh who who has select who has modify on a table who has select but not modify. So it's various ways to slice and dice uh and you can choose the principle. Right now obviously all of this is spinning because I'm on a shared workspace. Uh but it's pretty powerful.
(1:47:10) Now if you look at data classification which is if you click the see results you will end up with something like this and I am actually I only set this up yesterday for my small catalog. So there's nothing much here but you can get a sense I can choose a catalog and I can say all the tables that was scanned automatically to look for elements and it actually told me that all of this stuff is there in my data. I may not have known this at all.
(1:47:27) Right? Uh if I go review uh let's say I go review email address uh it's telling me that there are a bunch of tables that I have that have email address and you can see obviously these are dummy email addresses but I have email addresses in a lot of these places and maybe I want to auto attack right uh u and like it it gets automatically secure so that's the kind of thing that most governance teams are looking for a way to make it really Easy. Uh, this is the data quality monitoring tab, which again is telling
(1:48:01) me my data is healthy and three tables were monitored because I only set it upon one schema that had three tables and it's telling me it's it's healthy. If I go select something else, this is not going to change much because I may not have monitored. Oh, now I have two monitored and one table unhealthy.
(1:48:18) So, let's go look at the issue. So it says this particular table, this event log table has some health related issue that it thinks that it there is and I think it's because I didn't run it recently. Yeah. So the commit freshness is stale.
(1:48:39) Uh it's telling me it's unhealthy based on uh the fact that this thing is stale. Um but it's not really true because this is a dummy example. I haven't run it. But you you get the idea, right? If I'm running a pipeline every day, I get these signals. uh I can configure it to say you know do data profiling which is giving me all of the statistics which I've not done for this but I could I could do that here.
(1:48:58) So I could say what type of profiling do I want to do? Do I want to do time series profiling? Do I want to do snapshot profiling? And it'll give me a bunch of um again bunch of tables where it publishes to. Right? So all of this the the advantage with all of these things is all of the results are published to sets of tables that you choose and so it becomes really easy to query an alert on top of it.
(1:49:22) It's not just sitting in a file somewhere that uh that is difficult to get to. Uh let's see if there's anything else I wanted to touch on. Uh I think that was it. Oh yeah, govern tag. So this is the page where you see all of the govern tags. So if I go look at the tag that I created which is MJM this one I can actually give permissions on who can use it.
(1:49:47) So if I say uh let's say I I'll pick Anenda she should be in this workspace and I say Anand can assign this means Anand can use this tag that I created MJMPI on some object that she chooses uh is sees fit to be right. So this is a manual tag. By that I mean that this is a tag that I created and defined a rule for uh which is slightly different from system tags which if you go back to govern tags here and look for email you'll see this little spanner uh symbol that says it's a system tag.
(1:50:22) So this is automatic. So when I set up classification for a schema, it will automatically classify uh elements as um that particular thing and then I could choose that choose to say auto apply a rule basically. So if I have a rule that says anytime email address should be masked and an email address is detected, it will automatically apply that rule.
(1:50:51) But I can choose to automatically apply that rule or manually apply that rule depending on my perspective. Um so it gives you like a really good way to uh sort of um you know like tag and classify all of these objects. Um and before we go one more thing I wanted to show you is if you actually go to I think connections. Yes. So these are the connections that I was talking about.
(1:51:16) So if you see uh you know several people in our in our internal workspace have actually created connections to SQL server you know Salesforce uh glue AWS glue which is you know AWS is metas store Oracle uh s Amazon red shifts postgret SQL so you can create any of these connections to any of these sources you can see there's a lots of sources we support and these these kind of sources keep expanding all day long um and the advantage antage to doing this is because it's registered as a connection any object that I bring in through this connection I can govern just like any delta table that exists in data bricks right from a governance
(1:51:54) perspective it's exactly the same and so it allows you to unify that governance layer um and uh yeah that's that's all I had for for today's session I know I spoke a lot unfortunately sorry uh but if there are any questions uh I'm happy to take Uh I have a question regarding the case study and I'm not sure if I can ask right now. Uh I mean you could uh I may need Eric to comment on that but yeah go for it.
(1:52:29) Okay. So for case 2 study um the background is that we need to um choose a vendor for particular I guess type of uh um functionality or data product and then for the organization presumably we're working for right but um I think the then we go through essentially vendor selection analyze the different um types of options but the part one um when it comes to an introduction I assume that means we first to introduce the organization we're working for what what what's the problem what's a basically challenge and why we need to look for this kind of uh solutions am I
(1:53:19) understanding that correctly because um otherwise when it comes to deciding which option we should choose then it really depends on what kind of organ organization, what kind of problem, what kind of you know characteristics and you have it's like I I don't think we can choose a vendor or solution without really knowing what this organization is.
(1:53:44) Are we hypothetically needs to essentially just create a hypothetical organization that um we're actually choosing these vendors for? Um yeah, Eric, I don't know if you have a lens on that. Yeah. Yeah. I yeah I think um yeah I think for the part one um as you said you know introduce the organization the challenges and maybe you know if you know the the challenges of the specific organization then you can state those or maybe they're gen general challenges for the industry and then and then um and then select the
(1:54:35) solution and and vendors based on that. Okay. Um I guess among all of our members, we can decide on uh one organization. That organization can be a real one like the company company that I'm working for. I can definitely use that as a case. But um does it require to be a actual company or can be a hypothetical example? It it should be an actual company.
(1:55:08) Okay, sounds good. Thank you for clarifying that. Yeah, I'll confirm that with On and Dub, but I'm I'm pretty sure that's that was her intent as well. Thank you. Okay. Okay. So, uh, unless there are questions, uh, we're at time, so we can wrap, but if there are questions, I'm happy to take it. Awesome. So, thanks everyone for sticking around.
(1:55:47) Um, and, uh, yeah, if you have any other questions, maybe you can join the Thursday 6:00 to 7:00 p.m. Eastern. Thanks, Mohan. Nice work. All right. Yep. Thank you. Good night everyone. Thank you. Bye.