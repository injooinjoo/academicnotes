\documentclass[a4paper,12pt]{article}
\usepackage{kotex}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{adjustbox}  % í‘œ/ë°•ìŠ¤ í¬ê¸° ì¡°ì ˆ
\usepackage{xcolor}
\usepackage[most]{tcolorbox}
\tcbuselibrary{breakable}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{fancyhdr}

% í˜ì´ì§€ ì„¤ì •
\geometry{left=25mm, right=25mm, top=30mm, bottom=30mm}
\pagestyle{fancy}
\fancyhead[L]{MIT 6.86x Unit 1}
\fancyhead[R]{Introduction to ML}

% ìƒ‰ìƒ ì •ì˜
\definecolor{mainblue}{RGB}{0, 51, 102}
\definecolor{subblue}{RGB}{230, 240, 255}
\definecolor{warningred}{RGB}{204, 0, 0}
\definecolor{conceptgreen}{RGB}{0, 102, 51}
\definecolor{storypurple}{RGB}{102, 0, 102}

% ë°•ìŠ¤ ìŠ¤íƒ€ì¼ ì •ì˜
\newtcolorbox{summarybox}[1]{
  colback=subblue, colframe=mainblue, 
  title=\textbf{#1}, fonttitle=\bfseries,
  boxrule=0.5mm, arc=2mm
}

\newtcolorbox{warningbox}[1]{
  colback=white, colframe=warningred, 
  title=\textbf{âš ï¸ #1}, fonttitle=\bfseries,
  boxrule=0.5mm, arc=0mm,
  coltitle=white
}

\newtcolorbox{conceptbox}[1]{
  colback=white, colframe=conceptgreen, 
  title=\textbf{ğŸ’¡ #1}, fonttitle=\bfseries,
  boxrule=0.5mm, arc=2mm,
  coltitle=white
}

\newtcolorbox{storybox}[1]{
  colback=white, colframe=storypurple, 
  title=\textbf{ğŸ¬ #1}, fonttitle=\bfseries,
  boxrule=0.5mm, arc=2mm,
  coltitle=white
}

\title{\textbf{MIT 6.86x: ì˜ˆì¸¡ì˜ ë¯¸í•™}}
\author{Unit 1: Introduction to Machine Learning}
\date{}

\begin{document}

\maketitle

% 1. ì „ì²´ ëª©ì°¨ (TOC)
\tableofcontents
\vspace{1cm}
\hrule
\vspace{1cm}

\section*{Course Structure \& Current Focus}
\begin{itemize}
    \item \textbf{\textcolor{mainblue}{Unit 1: Introduction to ML (í˜„ì¬ ë‹¨ì›: ìš´ë™ì¥ ì„¸íŒ…)}}
    \begin{itemize}
        \item 1.1 Formalizing the Problem (í•¨ìˆ˜ ê·¼ì‚¬ ë¬¸ì œ)
        \item 1.2 Hypothesis Space ($\mathcal{H}$)
        \item 1.3 Learning Paradigms (ì§€ë„ vs ë¹„ì§€ë„)
        \item 1.4 Generalization ($E_{in}$ vs $E_{out}$)
    \end{itemize}
    \item Unit 2: Linear Classifiers (Perceptron)
    \item Unit 3: Neural Networks
\end{itemize}

\newpage

% 2. í˜„ì¬ ë‹¨ì› ì œëª©
\section{Unit 1. í•™ìŠµì˜ ê¸°ì´ˆ (Fundamentals of Learning)}

% 3. ì´ì „ ë‹¨ì›ê³¼ì˜ ì—°ê²°
\begin{quote}
\textit{ìš°ë¦¬ëŠ” 18.6501(í†µê³„í•™)ì—ì„œ "ë°ì´í„°ê°€ ì–´ë–¤ ë¶„í¬ì—ì„œ ë‚˜ì™”ëŠ”ê°€(Inference)?"ë¥¼ ê³ ë¯¼í–ˆìŠµë‹ˆë‹¤. 6.86x(ë¨¸ì‹ ëŸ¬ë‹)ì—ì„œëŠ” ì§ˆë¬¸ì„ ë°”ê¿‰ë‹ˆë‹¤. \textbf{"ê·¸ë˜ì„œ, ë‚´ì¼ ì£¼ê°€ê°€ ì˜¤ë¥¼ê¹Œ ë‚´ë¦´ê¹Œ(Prediction)?"} ë¶„í¬ì˜ ëª¨ì–‘ë³´ë‹¤ëŠ”, ì •ë‹µì„ ë§íˆëŠ” ì„±ëŠ¥ì— ëª©ìˆ¨ì„ ê±°ëŠ” ìƒˆë¡œìš´ ì—¬ì •ì´ ì‹œì‘ë©ë‹ˆë‹¤.}
\end{quote}

% 4. ê°œìš”
\subsection*{ğŸ“Œ ê°œìš” (Overview)}
ì´ ë‹¨ì›ì€ ì½”ë“œë¥¼ ì§œê¸° ì „, ë¨¸ì‹ ëŸ¬ë‹ ë¬¸ì œë¥¼ ìˆ˜í•™ì ìœ¼ë¡œ ì •ì˜í•˜ëŠ” ë‹¨ê³„ì…ë‹ˆë‹¤. ë¨¸ì‹ ëŸ¬ë‹ì„ **"ë¯¸ì§€ì˜ ëª©í‘œ í•¨ìˆ˜ $f^*$ë¥¼ ì°¾ê¸° ìœ„í•´ ê°€ì„¤ ê³µê°„ $\mathcal{H}$ë¥¼ íƒìƒ‰í•˜ëŠ” ê³¼ì •"\textbf{ìœ¼ë¡œ ì •ì˜í•˜ê³ , í•™ìŠµì˜ ê¶ê·¹ì  ëª©í‘œì¸ }ì¼ë°˜í™”(Generalization)**ì˜ ê°œë…ì„ í™•ë¦½í•©ë‹ˆë‹¤.

% 5. ìš©ì–´ ì •ë¦¬ í‘œ
\subsection*{ğŸ“ í•µì‹¬ ìš©ì–´ ì‚¬ì „}
\begin{table}[h]
\centering
\begin{tabularx}{\textwidth}{|p{0.28\textwidth}|X|}
\hline
\textbf{ìš©ì–´ (Term)} & \textbf{ì§ê´€ì  ì˜ë¯¸ (Meaning)} \\
\hline
\textbf{Target Function ($f^*$)} & ì‹ (God)ë§Œì´ ì•„ëŠ” ì§„ì§œ ì •ë‹µ ê·œì¹™. ìš°ë¦¬ëŠ” ì´ê±¸ ëª¨ë¥¸ë‹¤. \\
\hline
\textbf{Hypothesis ($h$)} & ìš°ë¦¬ê°€ $f^*$ë¼ê³  ì¶”ì¸¡í•œ ëª¨ë¸ (ê°€ì„¤). \\
\hline
\textbf{Hypothesis Space ($\mathcal{H}$)} & $h$ë¥¼ ì°¾ì„ ìˆ˜ìƒ‰ ë²”ìœ„ (ì˜ˆ: ì§ì„ ë“¤, ì‹ ê²½ë§ë“¤). \\
\hline
\textbf{Inductive Bias} & ë°ì´í„°ë¥¼ ë³´ê¸°ë„ ì „ì— ì •í•´ë‘” í¸ê²¬ (ì˜ˆ: "ë‹µì€ ì§ì„ ì¼ ê±°ì•¼"). \\
\hline
\textbf{Generalization} & ì•ˆ ë°°ìš´ ë¬¸ì œ(Test Data)ë„ ì˜ ë§íˆëŠ” ëŠ¥ë ¥. \\
\hline
\end{tabularx}
\end{table}

\vspace{0.5cm}\hrule\vspace{0.5cm}

% 6. í•µì‹¬ ê°œë… ìƒì„¸ ì„¤ëª…
\subsection{1. í•™ìŠµ ë¬¸ì œì˜ ì •ì˜ (Formalizing the Problem)}


\begin{conceptbox}{ê°œë… 1: í•¨ìˆ˜ ê·¼ì‚¬ (Function Approximation)}
\textbf{í•œ ì¤„ ìš”ì•½:} ë¨¸ì‹ ëŸ¬ë‹ì€ ì…ë ¥($x$)ê³¼ ì¶œë ¥($y$) ì‚¬ì´ì˜ ìˆ¨ê²¨ì§„ ê´€ê³„ì‹($f^*$)ì„ ë°ì´í„°($S_n$)ë¥¼ í†µí•´ ì—­ì¶”ì í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.
\end{conceptbox}

\subsubsection*{1) ì§ê´€ì  ë¹„ìœ : ì¥ì¸ì˜ ë ˆì‹œí”¼ ë³µì›}
ìœ ëª… ë§›ì§‘ì˜ ë¹„ë²• ì†ŒìŠ¤($f^*$)ê°€ ìˆìŠµë‹ˆë‹¤. ì‚¬ì¥ë‹˜ì€ ë ˆì‹œí”¼ë¥¼ ì ˆëŒ€ ì•ˆ ì•Œë ¤ì¤ë‹ˆë‹¤.
\begin{itemize}
    \item \textbf{Data ($S_n$):} ìš°ë¦¬ê°€ ë§›ë³¼ ìˆ˜ ìˆëŠ” ê±´ ê²°ê³¼ë¬¼(ìŒì‹) ë¿ì…ë‹ˆë‹¤.
    \item \textbf{Goal:} ë§›ì„ ë³´ê³  ì¬ë£Œì™€ ë¹„ìœ¨ì„ ì—­ì¶”ì í•´ì„œ, ì‚¬ì¥ë‹˜ì˜ ë§›ê³¼ ê±°ì˜ ë˜‘ê°™ì€ ë§›ì„ ë‚´ëŠ” ë‚˜ë§Œì˜ ë ˆì‹œí”¼($h$)ë¥¼ ë§Œë“œëŠ” ê²ƒì…ë‹ˆë‹¤.
\end{itemize}

\subsubsection*{2) ìˆ˜í•™ì  êµ¬ì„± ìš”ì†Œ}
\begin{itemize}
    \item \textbf{Input ($\mathcal{X}$):} ì¬ë£Œ (ë²¡í„° $x \in \mathbb{R}^d$)
    \item \textbf{Output ($\mathcal{Y}$):} ë§› (ê°’ $y$)
    \item **Unknown Target ($f^*$):** $f^*: \mathcal{X} \to \mathcal{Y}$. (ì´ìƒì ì¸ ì •ë‹µ ê·œì¹™)
    \item \textbf{Data ($S_n$):} $\{(x^{(i)}, y^{(i)})\}_{i=1}^n$. ($f^*$ì— ë…¸ì´ì¦ˆê°€ ì„ì¸ ê´€ì¸¡ì¹˜)
    \item \textbf{Final Hypothesis ($h$):} ìš°ë¦¬ê°€ ì°¾ì€ ìµœì ì˜ í•¨ìˆ˜. $h \approx f^*$ì´ê¸°ë¥¼ í¬ë§í•¨.
\end{itemize}

\vspace{0.5cm}\hrule\vspace{0.5cm}

\subsection{2. ê°€ì„¤ ê³µê°„ (Hypothesis Space, $\mathcal{H}$)}

\begin{conceptbox}{ê°œë… 2: ìˆ˜ìƒ‰ ë²”ìœ„ ì„¤ì •}
\textbf{í•œ ì¤„ ìš”ì•½:} "ì„¸ìƒì˜ ëª¨ë“  í•¨ìˆ˜" ì¤‘ì—ì„œ ì •ë‹µì„ ì°¾ì„ ìˆ˜ëŠ” ì—†ìŠµë‹ˆë‹¤. "ì§ì„  ì¤‘ì—ì„œ ì°¾ì" í˜¹ì€ "ê³¡ì„  ì¤‘ì—ì„œ ì°¾ì"ì²˜ëŸ¼ íƒìƒ‰ ë²”ìœ„ë¥¼ ì œí•œí•´ì•¼ í•©ë‹ˆë‹¤.
\end{conceptbox}

\subsubsection*{1) ê·€ë‚©ì  í¸í–¥ (Inductive Bias)}
ê°€ì„¤ ê³µê°„ $\mathcal{H}$ë¥¼ ì •í•˜ëŠ” ìˆœê°„, ìš°ë¦¬ëŠ” ë°ì´í„°ì— ëŒ€í•œ \textbf{í¸ê²¬(Bias)}ì„ ê°–ê²Œ ë©ë‹ˆë‹¤.
\begin{itemize}
    \item ì„ í˜• íšŒê·€ë¥¼ ì“´ë‹¤ë©´? $\rightarrow$ "ì„¸ìƒì€ ì„ í˜•ì ì¼ ê±°ì•¼"ë¼ëŠ” í¸ê²¬.
    \item í¸ê²¬ì´ ë‚˜ìœê°€ìš”? \textbf{ì•„ë‹ˆìš”, í•„ìˆ˜ì…ë‹ˆë‹¤.} í¸ê²¬(ì œì•½ ì¡°ê±´)ì´ ì—†ìœ¼ë©´, ë°ì´í„° ì ë“¤ì„ ì‡ëŠ” ë°©ë²•ì´ ë¬´í•œíˆ ë§ì•„ì„œ í•™ìŠµ ìì²´ê°€ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.
\end{itemize}

\subsubsection*{2) Trade-off}
\begin{itemize}
    \item $\mathcal{H}$ê°€ ë„ˆë¬´ ì‘ìŒ (ì˜ˆ: ìƒìˆ˜ í•¨ìˆ˜): ì •ë‹µì„ í‘œí˜„ ëª» í•¨ (Underfitting).
    \item $\mathcal{H}$ê°€ ë„ˆë¬´ í¼ (ì˜ˆ: 100ì°¨ ë‹¤í•­ì‹): ë…¸ì´ì¦ˆê¹Œì§€ ë‹¤ ì™¸ì›Œë²„ë¦¼ (Overfitting).
\end{itemize}

\vspace{0.5cm}\hrule\vspace{0.5cm}

\subsection{3. ì§€ë„ í•™ìŠµ vs ë¹„ì§€ë„ í•™ìŠµ}

\begin{conceptbox}{ê°œë… 3: ì •ë‹µì§€ì˜ ìœ ë¬´}
\textbf{í•œ ì¤„ ìš”ì•½:} ë¬¸ì œì§‘ ë’¤ì— í•´ì„¤ì§€ê°€ ìˆìœ¼ë©´ ì§€ë„ í•™ìŠµ, í•´ì„¤ì§€ ì—†ì´ ë¬¸ì œë“¤ì˜ ìœ í˜•ì„ ìŠ¤ìŠ¤ë¡œ ì •ë¦¬í•´ì•¼ í•˜ë©´ ë¹„ì§€ë„ í•™ìŠµì…ë‹ˆë‹¤.
\end{conceptbox}

\subsubsection*{1) ì§€ë„ í•™ìŠµ (Supervised)}
\begin{itemize}
    \item ë°ì´í„°: $(x, y)$ ìŒ.
    \item ëª©í‘œ: $h(x) \approx y$ ì¸ $h$ë¥¼ ì°¾ìŒ. (íšŒê·€, ë¶„ë¥˜)
\end{itemize}

\subsubsection*{2) ë¹„ì§€ë„ í•™ìŠµ (Unsupervised)}
\begin{itemize}
    \item ë°ì´í„°: $x$ë§Œ ìˆìŒ.
    \item ëª©í‘œ: ë°ì´í„°ì˜ êµ¬ì¡°, íŒ¨í„´, êµ°ì§‘ì„ ì°¾ìŒ. (í´ëŸ¬ìŠ¤í„°ë§, ì°¨ì› ì¶•ì†Œ)
    \item ì˜ˆì‹œ: ë„¥ìŠ¨ ìœ ì €ë“¤ì˜ í–‰ë™ ë¡œê·¸($x$)ë§Œ ë³´ê³  "ì´ë“¤ì€ í•˜ë“œì½”ì–´ ìœ ì €êµ°ì´ë‹¤"ë¼ê³  ê·¸ë£¹í•‘í•˜ê¸°.
\end{itemize}

\vspace{0.5cm}\hrule\vspace{0.5cm}

\subsection{4. ì¼ë°˜í™” (Generalization)}


\begin{conceptbox}{ê°œë… 4: ë¨¸ì‹ ëŸ¬ë‹ì˜ ì¡´ì¬ ì´ìœ }
\textbf{í•œ ì¤„ ìš”ì•½:} ì—°ìŠµë¬¸ì œ(Training Data)ë¥¼ 100ì  ë§ëŠ” ê±´ ì˜ë¯¸ ì—†ìŠµë‹ˆë‹¤. ì‹¤ì „ ìˆ˜ëŠ¥(Unseen Data)ì„ ì˜ ë³´ëŠ” ê²ƒì´ ì§„ì§œ ëª©í‘œì…ë‹ˆë‹¤.
\end{conceptbox}

\subsubsection*{1) ë‘ ê°€ì§€ ìœ„í—˜ (Risk)}
\begin{itemize}
    \item \textbf{ê²½í—˜ì  ìœ„í—˜ ($E_{in}$, Empirical Risk):}
    ì§€ê¸ˆ ê°€ì§„ í•™ìŠµ ë°ì´í„°($S_n$)ì—ì„œì˜ ì˜¤ì°¨. (ëª¨ì˜ê³ ì‚¬ ì„±ì )
    \item \textbf{ì‹¤ì œ ìœ„í—˜ ($E_{out}$, True Risk):}
    ì „ì²´ ë°ì´í„° ë¶„í¬($\mathcal{D}$)ì—ì„œì˜ ê¸°ëŒ€ ì˜¤ì°¨. (ìˆ˜ëŠ¥ ì„±ì )
\end{itemize}

\subsubsection*{2) ê·¼ë³¸ì ì¸ ê¸´ì¥ ê´€ê³„ (Fundamental Tension)}
ìš°ë¦¬ëŠ” ì•Œê³ ë¦¬ì¦˜ì„ í†µí•´ $E_{in}$ì„ ì¤„ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ $E_{in}$ì„ 0ìœ¼ë¡œ ë§Œë“ ë‹¤ê³  $E_{out}$ì´ 0ì´ ë ê¹Œìš”?
\begin{itemize}
    \item \textbf{Overfitting:} $E_{in} \approx 0$ì´ì§€ë§Œ $E_{out}$ì€ ë§¤ìš° í° ìƒíƒœ. (ë‹µì„ ë‹¬ë‹¬ ì™¸ì›Œì„œ ì‘ìš©ì„ ëª»í•¨)
    \item \textbf{Goal:} $E_{in}$ë„ ì‘ê²Œ í•˜ë©´ì„œ, ë™ì‹œì— \textbf{$E_{out} \approx E_{in}$}ì´ ë˜ë„ë¡ ë³´ì¥í•˜ëŠ” ê²ƒ. ì´ê²ƒì´ 6.86x ê³¼ì •ì˜ í•µì‹¬ ì§ˆë¬¸ì…ë‹ˆë‹¤.
\end{itemize}

\vspace{0.5cm}\hrule\vspace{0.5cm}

\section{ì‹¤ì „ ì‹œë‚˜ë¦¬ì˜¤: ë„¥ìŠ¨ ê²Œì„ ì´íƒˆì ì˜ˆì¸¡}

\begin{storybox}{Scenario: ì™„ë²½í•œ ì˜ˆì¸¡ ëª¨ë¸ì˜ í•¨ì •}
ë‹¹ì‹ ì€ ìœ ì € ì´íƒˆ ì˜ˆì¸¡ ëª¨ë¸ì„ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤.
ê³¼ê±° 1ë…„ ì¹˜ ë°ì´í„°($S_n$)ë¡œ í•™ìŠµì‹œì¼°ë”ë‹ˆ, ì •í™•ë„ 99.9\%($E_{in} \approx 0$)ê°€ ë‚˜ì™”ìŠµë‹ˆë‹¤.
"ì™„ë²½í•´!"ë¼ê³  ì™¸ì¹˜ë©° ì‹¤ ì„œë²„ì— ë°°í¬í–ˆìŠµë‹ˆë‹¤.
\end{storybox}

\begin{enumerate}
    \item \textbf{ê²°ê³¼:} ë‹¤ìŒ ë‹¬, ëª¨ë¸ì€ ì´íƒˆìë¥¼ í•˜ë‚˜ë„ ëª» ë§ì·„ìŠµë‹ˆë‹¤. ($E_{out}$ í­ë§)
    \item \textbf{ì›ì¸ ë¶„ì„:} ëª¨ë¸ì„ ëœ¯ì–´ë³´ë‹ˆ ì´ëŸ° ê·œì¹™ì´ ìˆì—ˆìŠµë‹ˆë‹¤.
    \textit{"ì•„ì´ë””ê°€ 'User1234'ì´ê³  3ì›” 5ì¼ì— ì ‘ì†í•œ ì‚¬ëŒì€ ì´íƒˆí•œë‹¤."}
    \item \textbf{í•´ì„:} ê°€ì„¤ ê³µê°„ $\mathcal{H}$ë¥¼ ë„ˆë¬´ ë³µì¡í•˜ê²Œ ì¡ì•„ì„œ, ìœ ì €ì˜ í–‰ë™ íŒ¨í„´($f^*$)ì„ ë°°ìš´ ê²Œ ì•„ë‹ˆë¼ íŠ¹ì • ìœ ì €ì˜ IDì™€ ë‚ ì§œ(ë…¸ì´ì¦ˆ)ë¥¼ ì™¸ì›Œë²„ë¦° ê²ƒì…ë‹ˆë‹¤.
    \item \textbf{í•´ê²°:} ëª¨ë¸ì„ ë‹¨ìˆœí™”(Regularization)í•˜ê±°ë‚˜ ë°ì´í„°ë¥¼ ë” ëª¨ì•„ì„œ \textbf{ì¼ë°˜í™” ì„±ëŠ¥($E_{out}$)}ì„ ì±™ê²¨ì•¼ í•©ë‹ˆë‹¤.
\end{enumerate}

\vspace{0.5cm}\hrule\vspace{0.5cm}

\section{ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ (FAQ)}

\begin{description}
    \item[Q1. $f^*$ì™€ $h$ì˜ ì°¨ì´ê°€ ì •í™•íˆ ë­”ê°€ìš”?]
    \textbf{A.} $f^*$ëŠ” 'ì§„ë¦¬(Truth)'ì´ê³  $h$ëŠ” 'ì¶”ì¸¡(Guess)'ì…ë‹ˆë‹¤.
    ì˜ˆë¥¼ ë“¤ì–´, ë¬¼ë¦¬ ë²•ì¹™($F=ma$)ì€ $f^*$ì…ë‹ˆë‹¤. ìš°ë¦¬ê°€ ì‹¤í—˜ ë°ì´í„°ë¥¼ í†µí•´ $F = 0.98 m a + 0.02$ë¼ëŠ” ì‹ì„ ì–»ì—ˆë‹¤ë©´ ì´ê²ƒì´ $h$ì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì˜ì›íˆ $f^*$ë¥¼ ì™„ë²½í•˜ê²Œ ì•Œ ìˆ˜ëŠ” ì—†ê³ , $h$ë¥¼ $f^*$ì— ê°€ê¹ê²Œ ë§Œë“¤ ë¿ì…ë‹ˆë‹¤.
    
    \item[Q2. Inductive Biasê°€ ì™œ í•„ìš”í•œê°€ìš”?]
    \textbf{A.} í¸ê²¬ ì—†ì´ëŠ” í•™ìŠµë„ ì—†ìŠµë‹ˆë‹¤(No Free Lunch Theorem). "ëª¨ë“  ê²ƒì´ ê°€ëŠ¥í•˜ë‹¤"ëŠ” ë§ì€ "ì•„ë¬´ê²ƒë„ ì•Œ ìˆ˜ ì—†ë‹¤"ëŠ” ë§ê³¼ ê°™ìŠµë‹ˆë‹¤. "ë‹µì€ ì—°ì†ì ì¼ ê±°ì•¼", "ë‹µì€ ê°„ë‹¨í•  ê±°ì•¼" ê°™ì€ ê°€ì •ì´ ìˆì–´ì•¼ë§Œ ìœ í•œí•œ ë°ì´í„°ë¡œë¶€í„° ë¬´í•œí•œ ë¯¸ë˜ë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
\end{description}

% 10. ë‹¤ìŒ ë‹¨ì› ì—°ê²°
\vspace{1cm}
\begin{quote}
\textbf{Next Step:} "ì¼ë°˜í™”"ê°€ ì¤‘ìš”í•˜ë‹¤ëŠ” ê²ƒì€ ì•Œì•˜ìŠµë‹ˆë‹¤. ê·¸ë ‡ë‹¤ë©´ ê°€ì¥ ë‹¨ìˆœí•˜ë©´ì„œë„ ê°•ë ¥í•œ ê°€ì„¤ ê³µê°„ì¸ \textbf{'ì„ í˜• ëª¨ë¸(Linear Model)'}ë¶€í„° ì‹œì‘í•´ë³¼ê¹Œìš”? ë‹¤ìŒ \textbf{Unit 2}ì—ì„œëŠ” ì§ì„  í•˜ë‚˜ë¡œ ë°ì´í„°ë¥¼ ë¶„ë¥˜í•˜ëŠ” \textbf{í¼ì…‰íŠ¸ë¡ (Perceptron)} ì•Œê³ ë¦¬ì¦˜ì„ ë°°ì›ë‹ˆë‹¤.
\end{quote}

% 11. ë‹¨ì› ìš”ì•½ ë°•ìŠ¤
\begin{summarybox}{Unit 1 í•µì‹¬ ìš”ì•½}
\begin{itemize}
    \item \textbf{ëª©í‘œ:} ë°ì´í„°($S_n$)ë¥¼ ì´ìš©í•´ ë¯¸ì§€ì˜ í•¨ìˆ˜ $f^*$ì— ê·¼ì‚¬í•˜ëŠ” $h$ë¥¼ ì°¾ëŠ”ë‹¤.
    \item \textbf{ê°€ì„¤ ê³µê°„($\mathcal{H}$):} íƒìƒ‰ ë²”ìœ„ë¥¼ ì œí•œí•˜ëŠ” ê²ƒ. í•„ì—°ì ìœ¼ë¡œ í¸ê²¬(Bias)ì„ ë™ë°˜í•œë‹¤.
    \item \textbf{ì¼ë°˜í™”:} í•™ìŠµ ë°ì´í„° ì˜¤ì°¨($E_{in}$)ê°€ ì•„ë‹ˆë¼, ë³´ì§€ ëª»í•œ ë°ì´í„°ì˜ ì˜¤ì°¨($E_{out}$)ë¥¼ ì¤„ì´ëŠ” ê²ƒì´ ì§„ì§œ ëª©í‘œë‹¤.
    \item \textbf{Overfitting:} $E_{in}$ì€ ë‚®ì§€ë§Œ $E_{out}$ì´ ë†’ì€ ìƒíƒœ. (ì•”ê¸°ì™•)
\end{itemize}
\end{summarybox}

\end{document}