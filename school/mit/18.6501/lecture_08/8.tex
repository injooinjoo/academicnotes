\documentclass[a4paper,12pt]{article}
\usepackage{kotex}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{adjustbox}  % í‘œ/ë°•ìŠ¤ í¬ê¸° ì¡°ì ˆ
\usepackage{xcolor}
\usepackage[most]{tcolorbox}
\tcbuselibrary{breakable}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{fancyhdr}
\usepackage{bm} % ë³¼ë“œì²´ ë²¡í„° í‘œì‹œìš©

% í˜ì´ì§€ ì„¤ì •
\geometry{left=25mm, right=25mm, top=30mm, bottom=30mm}
\pagestyle{fancy}
\fancyhead[L]{MIT 18.6501 Unit 3}
\fancyhead[R]{Linear Regression}

% ìƒ‰ìƒ ì •ì˜
\definecolor{mainblue}{RGB}{0, 51, 102}
\definecolor{subblue}{RGB}{230, 240, 255}
\definecolor{warningred}{RGB}{204, 0, 0}
\definecolor{conceptgreen}{RGB}{0, 102, 51}
\definecolor{storypurple}{RGB}{102, 0, 102}

% ë°•ìŠ¤ ìŠ¤íƒ€ì¼ ì •ì˜
\newtcolorbox{summarybox}[1]{
  colback=subblue, colframe=mainblue, 
  title=\textbf{#1}, fonttitle=\bfseries,
  boxrule=0.5mm, arc=2mm
}

\newtcolorbox{warningbox}[1]{
  colback=white, colframe=warningred, 
  title=\textbf{âš ï¸ #1}, fonttitle=\bfseries,
  boxrule=0.5mm, arc=0mm,
  coltitle=white
}

\newtcolorbox{conceptbox}[1]{
  colback=white, colframe=conceptgreen, 
  title=\textbf{ğŸ’¡ #1}, fonttitle=\bfseries,
  boxrule=0.5mm, arc=2mm,
  coltitle=white
}

\newtcolorbox{storybox}[1]{
  colback=white, colframe=storypurple, 
  title=\textbf{ğŸ¬ #1}, fonttitle=\bfseries,
  boxrule=0.5mm, arc=2mm,
  coltitle=white
}

\title{\textbf{MIT 18.6501: ì„¤ëª…ì—ì„œ ì˜ˆì¸¡ìœ¼ë¡œ}}
\author{Unit 3: Linear Regression (ì„ í˜• íšŒê·€)}
\date{}

\begin{document}

\maketitle

% 1. ì „ì²´ ëª©ì°¨ (TOC)
\tableofcontents
\vspace{1cm}
\hrule
\vspace{1cm}

\section*{Course Structure \& Current Focus}
\begin{itemize}
    \item Unit 1, 2: Estimation (í˜„ì¬ ìƒíƒœ íŒŒì•…)
    \item \textbf{\textcolor{mainblue}{Unit 3: Linear Regression (í˜„ì¬ ë‹¨ì›: ë¯¸ë˜ ì˜ˆì¸¡ê³¼ ê´€ê³„ ê·œëª…)}}
    \begin{itemize}
        \item 3.1 The Setup: Matrix Formulation
        \item 3.2 Least Squares Estimation (LSE)
        \item 3.3 Geometric Interpretation (Projection)
        \item 3.4 Gauss-Markov Theorem (BLUE)
        \item 3.5 Inference (t-test, F-test)
    \end{itemize}
    \item Unit 4: Hypothesis Testing (ì‹¬í™”)
\end{itemize}

\newpage

% 2. í˜„ì¬ ë‹¨ì› ì œëª©
\section{Unit 3. ì„ í˜• íšŒê·€ (Linear Regression)}

% 3. ì´ì „ ë‹¨ì›ê³¼ì˜ ì—°ê²°
\begin{quote}
\textit{ì§€ê¸ˆê¹Œì§€ ìš°ë¦¬ëŠ” í•˜ë‚˜ì˜ ë³€ìˆ˜(ì˜ˆ: ë™ì „ ì•ë©´ í™•ë¥  $p$, í‰ê·  í‚¤ $\mu$)ë¥¼ ì¶”ì •í•˜ëŠ” ë° ì§‘ì¤‘í–ˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ í˜„ì‹¤ ì„¸ê³„ëŠ” ì—¬ëŸ¬ ë³€ìˆ˜ê°€ ì–½í˜€ ìˆìŠµë‹ˆë‹¤. í‚¤ëŠ” ìœ ì „, ì˜ì–‘, ìš´ë™ëŸ‰ì— ì˜í–¥ì„ ë°›ì£ . ì´ì œ ìš°ë¦¬ëŠ” \textbf{"ë³€ìˆ˜ $X$ê°€ ë³€í•  ë•Œ ê²°ê³¼ $Y$ëŠ” ì–´ë–»ê²Œ ë³€í•˜ëŠ”ê°€?"}ë¥¼ ìˆ˜í•™ì ìœ¼ë¡œ ëª¨ë¸ë§í•˜ê³ , ì´ë¥¼ í†µí•´ ë³´ì´ì§€ ì•ŠëŠ” ë¯¸ë˜ë¥¼ \textbf{ì˜ˆì¸¡(Prediction)}í•˜ëŠ” ë‹¨ê³„ë¡œ ë‚˜ì•„ê°‘ë‹ˆë‹¤.}
\end{quote}

% 4. ê°œìš”
\subsection*{ğŸ“Œ ê°œìš” (Overview)}
ì„ í˜• íšŒê·€ëŠ” ì…ë ¥($X$)ê³¼ ì¶œë ¥($Y$)ì˜ ê´€ê³„ë¥¼ ì„ í˜• ë°©ì •ì‹($Y=X\beta$)ìœ¼ë¡œ ì„¤ëª…í•˜ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤. ì´ ë‹¨ì›ì—ì„œëŠ” \textbf{ìµœì†ŒììŠ¹ë²•(LSE)}ì´ ê¸°í•˜í•™ì ìœ¼ë¡œëŠ” \textbf{ì§êµ íˆ¬ì˜(Orthogonal Projection)}ì„ì„ ì´í•´í•˜ê³ , ë°ì´í„°ê°€ ì •ê·œë¶„í¬ë¥¼ ë”°ë¥´ì§€ ì•Šì•„ë„ LSEê°€ ìµœì ì˜ ì¶”ì •ëŸ‰(\textbf{BLUE})ì´ ë¨ì„ ì¦ëª…í•˜ëŠ” \textbf{ê°€ìš°ìŠ¤-ë§ˆë¥´ì½”í”„ ì •ë¦¬}ë¥¼ ë°°ì›ë‹ˆë‹¤.

% 5. ìš©ì–´ ì •ë¦¬ í‘œ
\subsection*{ğŸ“ í•µì‹¬ ìš©ì–´ ì‚¬ì „}
\begin{table}[h]
\centering
\begin{tabularx}{\textwidth}{|p{0.28\textwidth}|X|}
\hline
\textbf{ìš©ì–´ (Term)} & \textbf{ì§ê´€ì  ì˜ë¯¸ (Meaning)} \\
\hline
\textbf{Design Matrix ($\mathbf{X}$)} & ìš”ë¦¬ ì¬ë£Œë“¤ì˜ ëª©ë¡í‘œ ($n \times p$ í–‰ë ¬). \\
\hline
\textbf{Coefficient Vector ($\beta$)} & ê° ì¬ë£Œê°€ ë§›ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ë ¥ (ìš°ë¦¬ê°€ êµ¬í•´ì•¼ í•  ë ˆì‹œí”¼). \\
\hline
\textbf{Residual ($e$ or $\hat{\epsilon}$)} & ì‹¤ì œ ë§›($Y$)ê³¼ ë ˆì‹œí”¼ëŒ€ë¡œ ë§Œë“  ë§›($\hat{Y}$)ì˜ ì°¨ì´. \\
\hline
\textbf{Projection Matrix ($P$)} & $Y$ë¥¼ $X$ì˜ ê³µê°„ ìœ„ë¡œ ìˆ˜ì§ìœ¼ë¡œ ë‚´ë¦¬ê½‚ëŠ” ê·¸ë¦¼ì ìƒì„±ê¸°. \\
\hline
\textbf{BLUE} & Best Linear Unbiased Estimator. (ê°€ì¥ ë¯¿ì„ë§Œí•œ ì„ í˜• ì¶”ì •ëŸ‰). \\
\hline
\end{tabularx}
\end{table}

\vspace{0.5cm}\hrule\vspace{0.5cm}

% 6. í•µì‹¬ ê°œë… ìƒì„¸ ì„¤ëª…
\subsection{1. ì„ í˜• íšŒê·€ ëª¨ë¸ì˜ êµ¬ì¡° (The Setup)}

\begin{conceptbox}{ê°œë… 1: í–‰ë ¬ë¡œ ì„¸ìƒì„ í‘œí˜„í•˜ë‹¤}
\textbf{í•œ ì¤„ ìš”ì•½:} ë³µì¡í•œ ì—°ë¦½ë°©ì •ì‹ ë¬¸ì œë¥¼ $\mathbf{Y} = \mathbf{X}\beta + \epsilon$ì´ë¼ëŠ” ìš°ì•„í•œ í–‰ë ¬ì‹ í•˜ë‚˜ë¡œ ì••ì¶•í•©ë‹ˆë‹¤.
\end{conceptbox}

\subsubsection*{1) ì§ê´€ì  ë¹„ìœ : ì•„íŒŒíŠ¸ ê°€ê²© ë§ì¶”ê¸°}
\begin{itemize}
    \item $\mathbf{Y}$ (ê²°ê³¼): ì•„íŒŒíŠ¸ ê°€ê²©ë“¤ (10ì–µ, 15ì–µ, ...)
    \item $\mathbf{X}$ (ì¬ë£Œ): [í‰ìˆ˜, ì—­ê¹Œì§€ ê±°ë¦¬, í•™êµ° ì ìˆ˜]
    \item $\beta$ (ì˜í–¥ë ¥): [í‰ë‹¹ ê°€ê²©, 1kmë‹¹ ê°ê°€ì•¡, í•™êµ° í”„ë¦¬ë¯¸ì—„]
    \item $\epsilon$ (ì¡ìŒ): ì˜†ì§‘ì´ ì‹œì„¸ë³´ë‹¤ ì‹¸ê²Œ ë‚´ë†“ì€ ê¸‰ë§¤ë¬¼ ê°™ì€ ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥í•œ ìš”ì¸.
\end{itemize}

\subsubsection*{2) ìˆ˜í•™ì  ì •ì˜}
$$ \mathbf{Y} = \mathbf{X}\beta + \epsilon $$
ì—¬ê¸°ì„œ $\mathbf{X}$ëŠ” $n \times p$ í–‰ë ¬ì…ë‹ˆë‹¤ ($n$: ë°ì´í„° ê°œìˆ˜, $p$: ë³€ìˆ˜ ê°œìˆ˜).
\textbf{ì£¼ìš” ê°€ì •:}
\begin{enumerate}
    \item $\mathbb{E}[\epsilon] = 0$ (ì¡ìŒì˜ í‰ê· ì€ 0ì´ë‹¤.)
    \item $\text{Var}(\epsilon) = \sigma^2 I_n$ (ëª¨ë“  ë°ì´í„°ì˜ ì¡ìŒ ìˆ˜ì¤€ì€ ì¼ì •í•˜ê³  ë…ë¦½ì ì´ë‹¤.)
\end{enumerate}

\vspace{0.5cm}\hrule\vspace{0.5cm}

\subsection{2. ìµœì†ŒììŠ¹ë²• (Least Squares Estimation, LSE)}


\begin{conceptbox}{ê°œë… 2: ì˜¤ì°¨ì˜ ì œê³±ì„ ìµœì†Œí™”í•˜ë¼}
\textbf{í•œ ì¤„ ìš”ì•½:} ëª¨ë“  ë°ì´í„° ì ë“¤ê³¼ ì§ì„  ì‚¬ì´ì˜ ê±°ë¦¬(ì”ì°¨) ì œê³±í•©ì„ ìµœì†Œë¡œ ë§Œë“œëŠ” $\beta$ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
\end{conceptbox}

\subsubsection*{1) ìµœì í™” ë¬¸ì œ}
ìš°ë¦¬ì˜ ëª©í‘œëŠ” ì”ì°¨ ë²¡í„°ì˜ ê¸¸ì´($\| Y - \mathbf{X}\beta \|^2$)ë¥¼ ìµœì†Œí™”í•˜ëŠ” $\hat{\beta}$ë¥¼ ì°¾ëŠ” ê²ƒì…ë‹ˆë‹¤.
$$ \hat{\beta} = \text{argmin}_{\beta} \| \mathbf{Y} - \mathbf{X}\beta \|^2 $$

\subsubsection*{2) í•´ êµ¬í•˜ê¸° (Normal Equations)}
ìœ„ ì‹ì„ $\beta$ë¡œ ë¯¸ë¶„í•˜ì—¬ 0ì´ ë˜ëŠ” ì§€ì ì„ ì°¾ìœ¼ë©´ ë‹¤ìŒê³¼ ê°™ì€ \textbf{ì •ê·œ ë°©ì •ì‹(Normal Equations)}ì´ ë‚˜ì˜µë‹ˆë‹¤.
$$ \mathbf{X}^T \mathbf{X} \beta = \mathbf{X}^T \mathbf{Y} $$
ë§Œì•½ $(\mathbf{X}^T \mathbf{X})$ì˜ ì—­í–‰ë ¬ì´ ì¡´ì¬í•œë‹¤ë©´, ìš°ë¦¬ëŠ” \textbf{ë‹¨ í•œ ë²ˆì˜ í–‰ë ¬ ì—°ì‚°}ìœ¼ë¡œ ì •ë‹µì„ ì–»ìŠµë‹ˆë‹¤.
$$ \hat{\beta} = (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \mathbf{Y} $$

\vspace{0.5cm}\hrule\vspace{0.5cm}

\subsection{3. ê¸°í•˜í•™ì  í•´ì„: ì§êµ íˆ¬ì˜ (Projection)}


\begin{conceptbox}{ê°œë… 3: ê·¸ë¦¼ì ë†€ì´}
\textbf{í•œ ì¤„ ìš”ì•½:} ìš°ë¦¬ì˜ ì˜ˆì¸¡ê°’ $\hat{Y}$ëŠ” ì‹¤ì œ ë°ì´í„° $Y$ë¥¼ $\mathbf{X}$ê°€ ë§Œë“œëŠ” í‰ë©´(ê³µê°„) ìœ„ë¡œ \textbf{ìˆ˜ì§ìœ¼ë¡œ ë‚´ë¦¬ê½‚ì€ ê·¸ë¦¼ì}ì…ë‹ˆë‹¤.
\end{conceptbox}

\subsubsection*{1) ê³µê°„ì˜ ì´í•´}
\begin{itemize}
    \item ë°ì´í„° $\mathbf{Y}$ëŠ” $n$ì°¨ì› ê³µê°„ì— ë–  ìˆëŠ” í•˜ë‚˜ì˜ ì ì…ë‹ˆë‹¤.
    \item ìš°ë¦¬ê°€ ê°€ì§„ ì¬ë£Œ $\mathbf{X}$ë“¤ë¡œ ë§Œë“¤ ìˆ˜ ìˆëŠ” ëª¨ë“  ì˜ˆì¸¡ê°’ë“¤ì˜ ì§‘í•©ì„ \textbf{ì—´ ê³µê°„(Column Space, $\mathcal{C}(\mathbf{X})$)}ì´ë¼ê³  í•©ë‹ˆë‹¤. ì´ëŠ” $n$ì°¨ì› ê³µê°„ ì†ì˜ ì‘ì€ í‰ë©´ì…ë‹ˆë‹¤.
\end{itemize}

\subsubsection*{2) ì§êµì„± (Orthogonality)}
ì  $Y$ì—ì„œ í‰ë©´ $\mathcal{C}(\mathbf{X})$ê¹Œì§€ ê±°ë¦¬ê°€ ê°€ì¥ ì§§ìœ¼ë ¤ë©´? ë‹¹ì—°íˆ \textbf{ìˆ˜ì§(Orthogonal)}ìœ¼ë¡œ ë‚´ë ¤ì•¼ í•©ë‹ˆë‹¤.
ì¦‰, ì”ì°¨ ë²¡í„° $e = Y - \hat{Y}$ëŠ” í‰ë©´ $\mathcal{C}(\mathbf{X})$ì™€ ì§êµí•©ë‹ˆë‹¤.
$$ \mathbf{X}^T e = 0 \implies \mathbf{X}^T (Y - \mathbf{X}\hat{\beta}) = 0 $$
ì´ ì‹ì„ í’€ë©´ ì•ì„œ ë³¸ ì •ê·œ ë°©ì •ì‹ $\mathbf{X}^T \mathbf{X} \beta = \mathbf{X}^T \mathbf{Y}$ê°€ ë°”ë¡œ ìœ ë„ë©ë‹ˆë‹¤!

\subsubsection*{3) íˆ¬ì˜ í–‰ë ¬ (Hat Matrix)}
ì˜ˆì¸¡ê°’ $\hat{Y}$ëŠ” $Y$ì— \textbf{íˆ¬ì˜ í–‰ë ¬ $P$}ë¥¼ ê³±í•œ ê²ƒì…ë‹ˆë‹¤.
$$ \hat{Y} = P Y, \quad \text{where } P = \mathbf{X}(\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T $$
($P$ë¥¼ Hat Matrixë¼ê³  ë¶€ë¥´ëŠ” ì´ìœ ëŠ” $Y$ ë¨¸ë¦¬ ìœ„ì— ëª¨ì $\hat{Y}$ë¥¼ ì”Œì›Œì£¼ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.)

\vspace{0.5cm}\hrule\vspace{0.5cm}

\subsection{4. ê°€ìš°ìŠ¤-ë§ˆë¥´ì½”í”„ ì •ë¦¬ (Gauss-Markov Theorem)}

\begin{conceptbox}{ê°œë… 4: ì™œ í•˜í•„ LSEì¸ê°€?}
\textbf{í•œ ì¤„ ìš”ì•½:} ë°ì´í„°ê°€ ì •ê·œë¶„í¬ê°€ ì•„ë‹ˆë”ë¼ë„, ì˜¤ì°¨ì˜ í‰ê· ì´ 0ì´ê³  ë¶„ì‚°ì´ ì¼ì •í•˜ë‹¤ë©´ LSEê°€ \textbf{"ê°€ì¥ ë¶„ì‚°ì´ ì‘ì€(ì •ë°€í•œ) ì„ í˜• ì¶”ì •ëŸ‰"}ì„ì´ ìˆ˜í•™ì ìœ¼ë¡œ ë³´ì¥ë©ë‹ˆë‹¤.
\end{conceptbox}

\subsubsection*{BLUE (Best Linear Unbiased Estimator)}
LSE ì¶”ì •ëŸ‰ $\hat{\beta}$ëŠ” ë‹¤ìŒ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì±”í”¼ì–¸ì…ë‹ˆë‹¤.
\begin{itemize}
    \item \textbf{Linear:} ë°ì´í„° $Y$ì˜ ì„ í˜• ê²°í•©ìœ¼ë¡œ ê³„ì‚°ë¨.
    \item \textbf{Unbiased:} í‰ê· ì ìœ¼ë¡œ ì°¸ê°’ $\beta$ë¥¼ ë§ì¶¤ ($\mathbb{E}[\hat{\beta}] = \beta$).
    \item \textbf{Best:} ìœ„ì˜ ë‘ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì• ë“¤ ì¤‘ì—ì„œ \textbf{ë¶„ì‚°ì´ ê°€ì¥ ì‘ìŒ(Minimum Variance)}.
\end{itemize}
ì¦‰, ë‹¤ë¥¸ ë°©ë²•ì„ ì“°ë©´ ì˜ì ì´ í”ë“¤ë¦¬ê±°ë‚˜(Biased), íƒ„ì°©êµ°ì´ ë„“ì–´ì§‘ë‹ˆë‹¤(High Variance).

\vspace{0.5cm}\hrule\vspace{0.5cm}

\subsection{5. ì¶”ë¡  (Inference): ê°€ì„¤ ê²€ì •}

ì´ì œ $\epsilon \sim \mathcal{N}(0, \sigma^2 I)$ë¼ëŠ” \textbf{ì •ê·œë¶„í¬ ê°€ì •}ì„ ì¶”ê°€í•©ë‹ˆë‹¤. ê·¸ë˜ì•¼ ì‹ ë¢° êµ¬ê°„ê³¼ p-valueë¥¼ êµ¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

\subsubsection*{1) ì¶”ì •ëŸ‰ì˜ ë¶„í¬}
$\hat{\beta}$ëŠ” ì •ê·œë¶„í¬ ë”°ë¥´ëŠ” $Y$ì˜ ì„ í˜• ë³€í™˜ì´ë¯€ë¡œ, ì—­ì‹œ ì •ê·œë¶„í¬ë¥¼ ë”°ë¦…ë‹ˆë‹¤.
$$ \hat{\beta} \sim \mathcal{N}\left(\beta, \sigma^2 (\mathbf{X}^T \mathbf{X})^{-1}\right) $$

\subsubsection*{2) t-test (ë³€ìˆ˜ì˜ ìœ ì˜ì„± ê²€ì •)}
"í•™êµ°($\beta_3$)ì´ ì§‘ê°’ì— ì§„ì§œ ì˜í–¥ì´ ìˆë‚˜?" ($H_0: \beta_3 = 0$)
$$ T = \frac{\hat{\beta}_j - 0}{\text{SE}(\hat{\beta}_j)} \sim t_{n-p} $$
ì—¬ê¸°ì„œ $\text{SE}(\hat{\beta}_j)$ëŠ” $\hat{\sigma} \sqrt{(\mathbf{X}^T \mathbf{X})^{-1}_{jj}}$ ì…ë‹ˆë‹¤.

\begin{warningbox}{ì½”í¬ë€ì˜ ì •ë¦¬ (Cochran's Theorem)}
ìš°ë¦¬ê°€ t-ë¶„í¬ë¥¼ ì“¸ ìˆ˜ ìˆëŠ” ì´ìœ ëŠ” \textbf{"ì¶”ì •ëœ ê³„ìˆ˜($\hat{\beta}$)ì™€ ì”ì°¨($\hat{\epsilon}$)ê°€ ì„œë¡œ ë…ë¦½"}ì´ë¼ëŠ” ìˆ˜í•™ì  ì„±ì§ˆ ë•ë¶„ì…ë‹ˆë‹¤. ì´ëŠ” ê¸°í•˜í•™ì ìœ¼ë¡œ íˆ¬ì˜ëœ ê·¸ë¦¼ì($\hat{Y}$)ì™€ ìˆ˜ì§ì„ ($e$)ì´ ì§êµí•˜ê¸° ë•Œë¬¸ì— ì„±ë¦½í•©ë‹ˆë‹¤.
\end{warningbox}

\vspace{0.5cm}\hrule\vspace{0.5cm}

\section{ì‹¤ì „ ì‹œë‚˜ë¦¬ì˜¤: ë„·í”Œë¦­ìŠ¤ ì‹œì²­ ì‹œê°„ ì˜ˆì¸¡}

\begin{storybox}{Scenario: ìƒˆë¡œìš´ ë“œë¼ë§ˆì˜ ì„±ê³µ ì˜ˆì¸¡}
ë‹¹ì‹ ì€ ë„·í”Œë¦­ìŠ¤ì˜ ë°ì´í„° ê³¼í•™ìì…ë‹ˆë‹¤. ì‹ ê·œ ë“œë¼ë§ˆì˜ 'ì²« ë‹¬ ì‹œì²­ ì‹œê°„($Y$)'ì„ ì˜ˆì¸¡í•˜ë ¤ í•©ë‹ˆë‹¤.
\end{storybox}

\begin{enumerate}
    \item \textbf{ë³€ìˆ˜ ì„¤ì • ($\mathbf{X}$):}
    \begin{itemize}
        \item $X_1$: ì œì‘ë¹„ (ì–µ ì›)
        \item $X_2$: ì£¼ì—° ë°°ìš°ì˜ ì¸ìŠ¤íƒ€ íŒ”ë¡œì›Œ ìˆ˜ (ë§Œ ëª…)
        \item $X_3$: ì—í”¼ì†Œë“œ ìˆ˜
    \end{itemize}
    
    \item \textbf{ëª¨ë¸ë§:} $Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \beta_3 X_3 + \epsilon$
    
    \item \textbf{LSE ê²°ê³¼:} $\hat{\beta} = [100, 2.5, 0.1, 50]^T$
    \begin{itemize}
        \item í•´ì„: ì œì‘ë¹„ 1ì–µ ëŠ˜ë©´ ì‹œì²­ ì‹œê°„ 2.5ë§Œ ì‹œê°„ ì¦ê°€.
        \item í•´ì„: íŒ”ë¡œì›Œ 1ë§Œ ëª…ë‹¹ ì‹œì²­ ì‹œê°„ 0.1ë§Œ ì‹œê°„ ì¦ê°€. (ìƒê°ë³´ë‹¤ ì ìŒ)
    \end{itemize}
    
    \item \textbf{t-test:} $X_2$(íŒ”ë¡œì›Œ ìˆ˜)ì˜ p-valueê°€ 0.35ê°€ ë‚˜ì˜´.
    \begin{itemize}
        \item ê²°ë¡ : "ì£¼ì—° ë°°ìš°ì˜ íŒ”ë¡œì›Œ ìˆ˜ëŠ” ì‹œì²­ ì‹œê°„ì— í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ì˜í–¥ì´ ì—†ìŠµë‹ˆë‹¤." $\rightarrow$ ë§ˆì¼€íŒ… íŒ€ì— "ì¸í”Œë£¨ì–¸ì„œ ì„­ì™¸ë³´ë‹¤ ì œì‘ë¹„ ì¦ì•¡ì´ ë‚«ìŠµë‹ˆë‹¤"ë¼ê³  ì œì•ˆ.
    \end{itemize}
\end{enumerate}

\vspace{0.5cm}\hrule\vspace{0.5cm}

\section{ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ (FAQ)}

\begin{description}
    \item[Q1. $(\mathbf{X}^T \mathbf{X})$ì˜ ì—­í–‰ë ¬ì´ ì—†ìœ¼ë©´ ì–´ë–¡í•˜ì£ ?]
    \textbf{A.} ì´ë¥¼ \textbf{ë‹¤ì¤‘ê³µì„ ì„±(Multicollinearity)} ë¬¸ì œë¼ê³  í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ 'í‚¤(cm)'ì™€ 'í‚¤(m)'ë¥¼ ë™ì‹œì— ë³€ìˆ˜ë¡œ ë„£ìœ¼ë©´, ë‘ ë³€ìˆ˜ê°€ ì™„ë²½í•˜ê²Œ ê²¹ì³ì„œ ìˆ˜í•™ì ìœ¼ë¡œ í•´ë¥¼ êµ¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì´ë•ŒëŠ” ë³€ìˆ˜ë¥¼ í•˜ë‚˜ ì œê±°í•˜ê±°ë‚˜, \textbf{Ridge Regression} ê°™ì€ ê¸°ë²•ì„ ì¨ì•¼ í•©ë‹ˆë‹¤.
    
    \item[Q2. ì™œ ì”ì°¨ ì œê³±ì˜ í•©ì„ ì“°ë‚˜ìš”? ì ˆëŒ“ê°’ì˜ í•©ì„ ì“°ë©´ ì•ˆ ë˜ë‚˜ìš”?]
    \textbf{A.} ì¨ë„ ë©ë‹ˆë‹¤(LAD íšŒê·€). í•˜ì§€ë§Œ ì ˆëŒ“ê°’ì€ ë¯¸ë¶„ì´ ë¶ˆê°€ëŠ¥í•œ ì (ë¾°ì¡±í•œ ì )ì´ ìˆì–´ì„œ ìˆ˜í•™ì ìœ¼ë¡œ ë‹¤ë£¨ê¸° ì–´ë µìŠµë‹ˆë‹¤. ë°˜ë©´ ì œê³±($L^2$)ì€ ë¯¸ë¶„ì´ ê¹”ë”í•˜ê³ , ê¸°í•˜í•™ì ìœ¼ë¡œ 'ì§êµ íˆ¬ì˜'ì´ë¼ëŠ” ì™„ë²½í•œ í•´ì„ì´ ê°€ëŠ¥í•˜ê¸° ë•Œë¬¸ì— í†µê³„í•™ì˜ í‘œì¤€ì´ ë˜ì—ˆìŠµë‹ˆë‹¤.
\end{description}

% 10. ë‹¤ìŒ ë‹¨ì› ì—°ê²°
\vspace{1cm}
\begin{quote}
\textbf{Next Step:} ìš°ë¦¬ëŠ” ì—°ì†í˜• ìˆ«ì($Y$)ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ì„ í˜• íšŒê·€ë¥¼ ë°°ì› ìŠµë‹ˆë‹¤. ê·¸ëŸ°ë° ë§Œì•½ ê²°ê³¼ê°€ ìˆ«ìê°€ ì•„ë‹ˆë¼ \textbf{"í•©ê²©/ë¶ˆí•©ê²©", "ì•”/ì •ìƒ"} ê°™ì€ ë²”ì£¼ë¼ë©´ ì–´ë–¡í• ê¹Œìš”? ì„ í˜• íšŒê·€ë¡œëŠ” 0ê³¼ 1 ì‚¬ì´ì˜ í™•ë¥ ì„ í‘œí˜„í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤. ë‹¤ìŒ ì‹œê°„ì—ëŠ” ì´ë¥¼ í•´ê²°í•˜ëŠ” \textbf{ë¡œì§€ìŠ¤í‹± íšŒê·€(Logistic Regression)}ì™€ ì¼ë°˜í™” ì„ í˜• ëª¨í˜•(GLM)ì„ ë°°ì›ë‹ˆë‹¤.
\end{quote}

% 11. ë‹¨ì› ìš”ì•½ ë°•ìŠ¤
\begin{summarybox}{Unit 3 í•µì‹¬ ìš”ì•½}
\begin{itemize}
    \item \textbf{ëª¨ë¸:} $Y = \mathbf{X}\beta + \epsilon$. í˜„ì‹¤ì„ ì„ í˜• ê²°í•©ìœ¼ë¡œ ê·¼ì‚¬í•œë‹¤.
    \item \textbf{LSE:} ì”ì°¨ ì œê³±í•©ì„ ìµœì†Œí™”í•˜ëŠ” ë°©ë²•. $\hat{\beta} = (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T Y$.
    \item \textbf{ê¸°í•˜í•™:} ì˜ˆì¸¡ê°’ $\hat{Y}$ëŠ” ë°ì´í„° $Y$ë¥¼ ì—´ ê³µê°„ $\mathcal{C}(\mathbf{X})$ì— \textbf{ìˆ˜ì§ íˆ¬ì˜(Orthogonal Projection)}í•œ ê²ƒì´ë‹¤.
    \item \textbf{Gauss-Markov:} ì •ê·œì„± ê°€ì •ì´ ì—†ì–´ë„ LSEëŠ” ë¶„ì‚°ì´ ê°€ì¥ ì‘ì€ ìµœì ì˜ ì¶”ì •ëŸ‰(BLUE)ì´ë‹¤.
\end{itemize}
\end{summarybox}

\end{document}